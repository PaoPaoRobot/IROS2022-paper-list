# IROS2022-paper-list


This list is edited by [PaopaoRobot, 泡泡机器人](https://github.com/PaoPaoRobot) , the Chinese academic nonprofit organization. Welcome to follow our github and our WeChat Public Platform Account ( [paopaorobot_slam](https://mp.weixin.qq.com/s?__biz=MzI5MTM1MTQwMw==&mid=100000102&idx=1&sn=0a8a831a4f2c18443dbf436ef5d5ff8c&chksm=6c10bf625b6736748c9612879e166e510f1fe301b72ed5c5d7ecdd0f40726c5d757e975f37af&mpshare=1&scene=1&srcid=0530KxSLjUE9I38yLgfO2nVm&pass_ticket=0aB5tcjeTfmcl9u0eSVzN4Ag4tkpM2RjRFH8DG9vylE%3D#rd) ). Of course, you could contact with [@Yvon Shong](https://github.com/yvonshong).


# Award Session I
# SpeedFolding: Learning Efficient Bimanual Folding of Garments
(Finalist for IROS Best Paper Award and ABB Best Student Paper Award)
(Finalist for IROS Best RoboCup Paper Award Sponsored by RoboCup Federation)
## Keywords:
- Bimanual Manipulation
- Deep Learning in Grasping and Manipulation
- Dual Arm Manipulation
## Abstract:
Folding garments reliably and efficiently is a long standing challenge in robotic manipulation due to the complex dynamics and high dimensional configuration space of garments. An intuitive approach is to initially manipulate the garment to a canonical smooth configuration before folding. In this work, we develop SpeedFolding, a reliable and efficient bimanual system, which given user-defined instructions as folding lines, manipulates an initially crumpled garment to (1) a smoothed and (2) a folded configuration. Our primary contribution is a novel neural network architecture that is able to predict pairs of gripper poses to parameterize a diverse set of bimanual action primitives. After learning from 4300 human-annotated and self-supervised actions, the robot is able to fold garments from a random initial configuration in under 120s on average with a success rate of 93%. Real-world experiments show that the system is able to generalize to unseen garments of different color, shape, and stiffness. While prior work achieved 3-6 Folds Per Hour (FPH), SpeedFolding achieves 30-40 FPH.
# FAR Planner: Fast, Attemptable Route Planner Using Dynamic Visibility Update
(Finalist for IROS Best Paper Award and ABB Best Student Paper Award)
## Keywords:
- Reactive and Sensor-Based Planning
- Motion and Path Planning
## Abstract:
We present our work on a visibility graph-based planning framework. The planner constructs a polygonal representation of the environment by extracting edge points around obstacles to form enclosed polygons. With that, the method dynamically updates a global visibility graph using a two-layered data structure, expanding the visibility edges along with the navigation and removing edges that become occluded by dynamic obstacles. The planner is capable of dealing with navigation tasks in both known and unknown environments. In the latter case, the method is attemptable in discovering a way to the goal by picking up the environment layout on the fly and fast re-planning to account for the newly observed environment. We evaluate the method in both simulated and real-world settings. The method shows the capability to navigate through unknown environments and reduces the travel time by up to 12-47% from search-based methods: A*, D* Lite, and more than 24-35% than sampling-based methods: RRT*, BIT*, and SPARS.
# Learning-Based Localizability Estimation for Robust LiDAR Localization
(Finalist for IROS Best Paper Award and ABB Best Student Paper Award)
## Keywords:
- Field Robots
- Localization
- Failure Detection and Recovery
## Abstract:
LiDAR-based localization and mapping is one of the core components in many modern robotic systems due to the direct integration of range and geometry, allowing for precise motion estimation and generation of high quality maps in real-time. Yet, as a consequence of insufficient environmental constraints present in the scene, this dependence on geometry can result in localization failure, happening in self-symmetric surroundings such as tunnels. This work addresses precisely this issue by proposing a neural network-based estimation approach for detecting (non-)localizability during robot operation. Special attention is given to the localizability of scan-to-scan registration, as it is a crucial component in many LiDAR odometry estimation pipelines. In contrast to previous, mostly traditional detection approaches, the proposed method enables early detection of failure by estimating the localizability on raw sensor measurements without evaluating the underlying registration optimization. Moreover, previous approaches remain limited in their ability to generalize across environments and sensor types, as heuristic-tuning of degeneracy detection thresholds is required. The proposed approach avoids this problem by learning from a collection of different environments, allowing the network to function over various scenarios. Furthermore, the network is trained exclusively on simulated data, avoiding arduous data collection in challenging and degenerate, often hard-to-access, environments. The presented method is tested during field experiments conducted across challenging environments and on two different sensor types without any modifications. The observed detection performance is on par with state-of-the-art methods after environment-specific threshold tuning.
# Adversarial Motion Priors Make Good Substitutes for Complex Reward Functions
(Finalist for IROS Best Paper Award and ABB Best Student Paper Award)
## Keywords:
- Legged Robots
- Reinforcement Learning
- Art and Entertainment Robotics
## Abstract:
Training a high-dimensional simulated agent with an under-specified reward function often leads the agent to learn physically infeasible strategies that are ineffective when deployed in the real world. To mitigate these unnatural behaviors, reinforcement learning practitioners often utilize complex reward functions that encourage physically plausible behaviors. However, a tedious labor-intensive tuning process is often required to create hand-designed rewards which might not easily generalize across platforms and tasks. We propose substituting complex reward functions with ``style rewards" learned from a dataset of motion capture demonstrations. A learned style reward can be combined with an arbitrary task reward to train policies that perform tasks using naturalistic strategies. These natural strategies can also facilitate transfer to the real world. We build upon Adversarial Motion Priors -# an approach from the computer graphics domain that encodes a style reward from a dataset of reference motions -# to demonstrate that an adversarial approach to training policies can produce behaviors that transfer to a real quadrupedal robot without requiring complex reward functions. We also demonstrate that an effective style reward can be learned from a few seconds of motion capture data gathered from a German Shepherd and leads to energy-efficient locomotion strategies with natural gait transitions.
# RCareWorld: A Human-Centric Simulation World for Caregiving Robots
(Finalist for IROS Best Paper Award and ABB Best Student Paper Award)
(Finalist for IROS Best RoboCup Paper Award Sponsored by RoboCup Federation)
## Keywords:
- Simulation and Animation
- Human-Centered Robotics
- Robot Companions
## Abstract:
In this paper, we present RCareWorld, a human-centric simulation world for physical and social robot caregiving with support for realistic human modeling, home environments with multiple levels of accessibility, and robots used for assistance. This simulation is designed using inputs from stakeholders such as expert occupational therapists, care-recipients, and caregivers. It provides a variety of benchmark ADL tasks in realistic settings. It interfaces with various physics engines to model rigid, articulated and deformable objects. It provides the capability to plan, control, and learn both human and robot control policies by interfacing it with state-of-the-art external planning and learning libraries. We performed experiments on a subset of these ADL tasks using reinforcement learning methods. We performed a representative real-world physical robotic caregiving experiment by transferring policies learned in RCareWorld directly to a real robot. Additionally, we performed a real-world social caregiving experiment using behaviors modeled in RCareWorld. Robotic caregiving, though potentially impactful towards enhancing the quality-of-life of care-recipients and caregivers, is a field with many barriers of entry due to it's interdisciplinary facets. RCareWorld takes the first step towards building a realistic simulation environment for robotic caregiving research to democratize this field that would enable robotics researchers around the world to contribute to this exciting field. Demo videos and supplementary materials can be found here: https://emprise.cs.cornell.edu/rcareworld/
# Design and Modeling of a Spring-Like Continuum Joint with Variable Pitch for Endoluminal Surgery
(Finalist for IROS Best Paper Award and ABB Best Student Paper Award)
## Keywords:
- Medical Robots and Systems
## Abstract:
In endoluminal surgery, the miniature instruments shall be of high accuracy and flexibility for the minimal invasive diagnosis and surgical intervention. To this end, continuum robots with flexible joints have been proposed as the mechanism of endoscopic instruments. The compliance and deformability of the continuum joints enable access into the curved lumen. However, the manufacturing tolerances are not normally considered in the design procedure, and led to inaccuracy in the robotic control.
To improve the control accuracy and flexibility of endoluminal surgical robot, we propose a novel design of a metal printed continuum joint in this paper, which incorporates a variable pitch design into the spring-like structure. The design can reduce the position errors accumulated on the distal tip of the joint, especially at large bending angles. The specification of variable pitch is investigated and determined with a friction model. In addition, to eliminate the distortion of the joint induced during the metal printing process, an extensive experiment was conducted to access the effect of the variables in the design (pitch, thickness, width and number of coils), with the aim of determining optimal parameters for reducing discrepancy caused by manufacturing variations. The final results indicated that the bending error of a single joint can be reduced from 18.10% to 4.63%, and a multi-segment prototype was developed to verify its effectiveness for potential surgical applications.
# Learning 1
# CALVIN: A Benchmark for Language-Conditioned Policy Learning for Long-Horizon Robot Manipulation Tasks
## Keywords:
- Data Sets for Robot Learning
- Machine Learning for Robot Control
- Imitation Learning
## Abstract:
General-purpose robots coexisting with humans in their environment must learn to relate human language to their perceptions and actions to be useful in a range of daily tasks. Moreover, they need to acquire a diverse repertoire of general-purpose skills that allow composing long-horizon tasks by following unconstrained language instructions. In this paper, we present CALVIN (Composing Actions from Language and Vision), an open-source simulated benchmark to learn long-horizon language-conditioned tasks. Our aim is to make it possible to develop agents that can solve many robotic manipulation tasks over a long horizon, from onboard sensors, and specified only via human language. CALVIN tasks are more complex in terms of sequence length, action space, and language than existing vision-and-language task datasets and supports flexible specification of sensor suites. We evaluate the agents in zero-shot to novel language instructions and to novel environments and objects. We show that a baseline model based on multi-context imitation learning performs poorly on CALVIN, suggesting that there is significant room for developing innovative agents that learn to relate human language to their world models with this benchmark.
# Bio-Inspired Reflex System for Learning Visual Information for Resilient Robotic Manipulation
## Keywords:
- Bioinspired Robot Learning
- Visual Learning
- Biologically-Inspired Robots
## Abstract:
Humans have an incredible sense of self-preservation that is both instilled, and also learned through experience. One system which contributes to this is the pain and reflex system which both minimizes damage through involuntary reflex actions and also serves as a means of `negative reinforcement' to allow learning of poor actions or decision. Equipping robots with a reflex system and parallel learning architecture could help to prolong their useful life and allow for continued learning of safe actions. Focusing on a specific mock-up scenario of cubes on a `stove' like setup, we investigate the hardware and learning approaches for a robotic manipulator to learn the presence of `hot' objects and its contextual relationship to the environment. By creating a reflex arc using analog electronics that bypasses the `brain' of the system we show an increase in the speed of release by at least two-fold. In parallel we have a learning procedure which combines visual information of the scene with this `pain signal' to learn and predict when an object may be hot, utilizing an object detection neural network. Finally, we are able to extract the learned contextual information of the environment by introducing a method inspired by `thought experiments' to generate heatmaps that indicate the probability of the environment being hot
# RECALL: Rehearsal-Free Continual Learning for Object Classification
## Keywords:
- Continual Learning
- Data Sets for Robotic Vision
- Incremental Learning
## Abstract:
Convolutional neural networks show remarkable results in classification but struggle with learning new things on the fly. We present a novel rehearsal-free approach, where a deep neural network is continually learning new unseen object categories without saving any data of prior sequences. Our approach is called RECALL, as the network recalls categories by calculating logits for old categories before training new ones. These are then used during training to avoid changing the old categories. For each new sequence, a new head is added to accommodate the new categories. To mitigate forgetting, we present a regularization strategy where we replace the classification with a regression. Moreover, for the known categories, we propose a Mahalanobis loss that includes the variances to account for the changing densities between known and unknown categories. Finally, we present a novel dataset for continual learning (HOWS-CL-25), especially suited for object recognition on a mobile robot, including 150,795 synthetic images of 25 household object categories. Our approach RECALL outperforms the current state of the art on CORe50 and iCIFAR-100 and reaches the best performance on HOWS-CL-25.
# PoseIt: A Visual-Tactile Dataset of Holding Poses for Grasp Stability Analysis
## Keywords:
- Data Sets for Robot Learning
- Deep Learning in Grasping and Manipulation
## Abstract:
When humans grasp objects in the real world, we often move our arms to hold the object in a different pose where we can use it. In contrast, typical lab settings only study the stability of the grasp immediately after lifting, without any subsequent re-positioning of the arm. However, the grasp stability could vary widely based on the object’s holding pose, as the gravitational torque and gripper contact forces could change completely. To facilitate the study of how holding poses affect grasp stability, we present PoseIt, a novel multi-modal dataset that contains visual and tactile data collected from a full cycle of grasping an object, re-positioning the arm to one of the sampled poses, and shaking the object. Using data from PoseIt, we can formulate and tackle the task of predicting whether a grasped object is stable in a particular held pose. We train an LSTM classifier that achieves 85% accuracy on the proposed task. Our experimental results show that multi-modal models trained on PoseIt achieve higher accuracy than using solely vision or tactile data and that our classifiers can also generalize to unseen objects and poses. The PoseIt dataset is publicly released here: https://github.com/CMURoboTouch/PoseIt.
# LaneSNNs: Spiking Neural Networks for Lane Detection on the Loihi Neuromorphic Processor
## Keywords:
- Bioinspired Robot Learning
- Embedded Systems for Robotic and Automation
- Autonomous Vehicle Navigation
## Abstract:
Autonomous Driving (AD) related features represent important elements for the next generation of mobile robots and autonomous vehicles focused on increasingly intelligent, autonomous, and interconnected systems. The applications involving the use of these features must provide, by definition, real-time decisions, and this property is key to avoid catastrophic accidents. Moreover, all the decision processes must require low power consumption, to increase the lifetime and autonomy of battery-driven systems. These challenges can be addressed through efficient implementations of Spiking Neural Networks (SNNs) on Neuromorphic Chips and the use of event-based cameras instead of traditional frame-based cameras.
In this paper, we present a new SNN-based approach, called LaneSNN, for detecting the lanes marked on the streets using the event-based camera input. We develop four novel SNN models characterized by low complexity and fast response, and train them using an offline supervised learning rule. Afterward, we implement and map the learned SNNs models onto the Intel Loihi Neuromorphic Research Chip. For the loss function, we develop a novel method based on the linear composition of Weighted binary Cross Entropy (WCE) and Mean Squared Error (MSE) measures. Our experimental results show a maximum Intersection over Union (IoU) measure of about 0.62 and very low power consumption of about 1 W. The best IoU is achieved with an SNN implementation that occupies only 36 neurocores on the Loihi processor while providing a low latency of less than 8 ms to recognize an image, thereby enabling real-time performance. The IoU measures provided by our networks are comparable with the state-of-the-art, but at a much low power consumption of 1 W.
# Striving for Less: Minimally-Supervised Pseudo-Label Generation for Monocular Road Segmentation
## Keywords:
- Deep Learning for Visual Perception
- Computer Vision for Transportation
- AI-Based Methods
## Abstract:
Identifying traversable space is one of the most important problems in autonomous robot navigation and is primarily tackled using learning-based methods. To alleviate the prohibitively high annotation-cost associated with labeling large and diverse datasets, research has recently shifted from tradi-tional supervised methods to focus on unsupervised and semi-supervised approaches. This work focuses on monocular road segmentation and proposes a practical, generic, and minimally-supervised approach based on task-specific feature extraction and pseudo-labeling. Building on recent advances in monocular depth estimation models, we process approximate dense depth maps to estimate pixel-wise road-plane distance maps. These maps are then used in both unsupervised and semi-supervised road segmentation scenarios. In the unsupervised case, we propose a pseudo-labeling pipeline that reaches state-of-the-art Intersection-over-Union (IoU), while reducing complexity and computations compared to existing approaches. We also investigate a semi-supervised extension to our method and find that even minimal labeling efforts can greatly improve results. Our semi-supervised experiments using as little as 1% & 10% of ground truth data, yield models scoring 0.9063 & 0.9332 on the IoU metric respectively. These results correspond to a comparative performance of 95.9% & 98.7% of a fully-supervised model’s IoU score, which motivates a pragmatic approach to labeling.
# Learning Sequential Descriptors for Sequence-Based Visual Place Recognition
## Keywords:
- Deep Learning for Visual Perception
- Localization
- Visual Learning
## Abstract:
In robotics, visual place recognition (VPR) is a continuous process that receives as input a video stream to produce a hypothesis of the robot's current position within a map of known places. This work proposes a taxonomy of the architectures used to learn sequential descriptors for VPR, highlighting different mechanisms to fuse the information from the individual images. This categorization is supported by a complete benchmark of experimental results that provides evidence of the strengths and weaknesses of these different architectural choices. The analysis is not limited to existing sequential descriptors, but we extend it further to investigate the viability of Transformers instead of CNN backbones. We further propose a new ad-hoc sequence-level aggregator called SeqVLAD, which outperforms prior state of the art on different datasets. The code is available at https://github.com/vandal-vpr/vg-transformers
# DCPCR: Deep Compressed Point Cloud Registration in Large-Scale Outdoor Environments
## Keywords:
- Deep Learning Methods
- Localization
- SLAM
## Abstract:
Reliable and accurate registration of point clouds is a challenging problem in robotics as well as in the domain of autonomous driving. In this paper, we address the task of aligning point clouds with low overlap, containing moving objects, and without prior information about the initial guess. We enhance classical ICP-based registration with neural feature-based matching to reliably find point correspondences. Our novel 3D convolutional and attention-based network is trained in an end-to-end fashion to learn features, which are well suited for matching and to rate the quality of the point correspondences. By utilizing a compression encoder, we can directly operate on a compressed map representation, making our approach well suited for operation under memory constraints. We evaluate our approach on point clouds obtained at completely different points in time, showing that our approach is able to reliably register point clouds even under those challenging conditions. The implementation of our approach and the preprocessed data can be accessed at https://github.com/PRBonn/DCPCR.
# Deep Koopman Operator with Control for Nonlinear Systems
## Keywords:
- Deep Learning Methods
- Model Learning for Control
- Machine Learning for Robot Control
## Abstract:
Recently Koopman operator has become a promising data-driven tool to facilitate real-time control for unknown nonlinear systems. It maps nonlinear systems into equivalent linear systems in embedding space, ready for real-time linear control methods. However, designing an appropriate Koopman embedding function remains a challenging task. Furthermore, most Koopman-based algorithms only consider nonlinear systems with linear control input, resulting in lousy prediction and control performance when the system is fully nonlinear with the control input. In this work, we propose an end-to-end deep learning framework to learn the Koopman embedding function and Koopman Operator together to alleviate such difficulties. We first parameterize the embedding function and Koopman Operator with the neural network and train them end-to-end with the K-steps loss function. We then design an auxiliary control network to encode the nonlinear state-dependent control term to model the nonlinearity in control input. For linear control, this encoded term is considered the new control variable instead, ensuring the linearity of the embedding space. Then we deploy Linear Quadratic Regulator (LQR) on the linear embedding space to derive the optimal control policy and decode the actual control input from the control net. Experimental results demonstrate that our approach outperforms other existing methods, reducing the prediction error by order-of-magnitude and achieving superior control performance in several nonlinear dynamic systems like damping pendulum, CartPole, and 7 Dof robotic manipulator.
# Service Robotics
# An Autonomous Descending-Stair Cleaning Robot with RGB-D Based Detection, Approaching, and Area Coverage Process
## Keywords:
- Domestic Robotics
- Service Robotics
- Robotics and Automation in Construction
## Abstract:
Cleaning robots are one of the market dominators in the commercialized robot space. So far, numerous robots have been introduced that can perform cleaning tasks in various settings, including floor, pavement, pool, lawn, windows, etc. However, none of the existing commercial cleaning robots targets the staircase, commonly found in multi-story buildings. Even though few works in the literature introduced robotic solutions for staircase cleaning, they primarily focused on cleaning the ascending staircase often, with a loose connection to access the descending staircase. In this paper, we propose a novel autonomous reconfigurable robotic platform called sTetro-D that can autonomously detect the descending staircase, approach the step, and perform area coverage in an unknown environment. The developed autonomy framework consists of two modes which are search mode and clean mode. In search mode, we implemented an RGB-D camera-based fusion technique wherein we combined the image bounding box from DCNN (Deep Convolution Neural Network) with the depth information to find the 3D first step pose that assists the robot in approaching it precisely. After the successful stair approach, the cleaning mode enables the staircase area coverage process. We described all these aspects and concluded with an experimental analysis of the proposed robotic system in a real-world scenario. The results demonstrate that the robot has a significant performance in detecting the descending staircase, staircase approach, and area coverage.
# Non-Parametric Modeling of Spatio-Temporal Human Activity Based on Mobile Robot Observations
## Keywords:
- Service Robotics
- Modeling and Simulating Humans
- Probabilistic Inference
## Abstract:
This work presents a non-parametric spatio-temporal model for mapping human activity by mobile autonomous robots in a long-term context. Based on Variational Gaussian Process Regression, the model incorporates prior information of spatial and temporal-periodic dependencies to create a continuous representation of human occurrences. The inhomogeneous data distribution resulting from movements of the robot is included in the model via a heteroscedastic likelihood function and can be accounted for as predictive uncertainty. Using a sparse formulation, data sets over multiple weeks and several hundred square meters can be used for model building. The experimental evaluation, based on multi# week data sets, demonstrates that the proposed approach outperforms the state of the art both in terms of predictive quality and subsequent path planning.
# Service Robots in a Bakery Shop: A Field Study
## Keywords:
- Service Robotics
- Social HRI
## Abstract:
In this paper, we report on a field study in which we employed two service robots in a bakery store as a sales promotion. Previous studies have explored public applications of service robots public such as shopping malls. However, more evidence is needed that service robots can contribute to sales in real stores. Moreover, the behaviors of customers and service robots in the context of sales promotions have not been examined well. Hence, the types of robot behavior that can be considered effective and the customers’ responses to these robots remain unclear. To address these issues, we installed two tele-operated service robots in a bakery store for nearly 2 weeks, one at the entrance as a greeter and the other one inside the store to recommend products. The results show a dramatic increase in sales during the days when the robots were applied. Furthermore, we annotated the video recordings of both the robots’ and customers' behavior. We found that although the robot placed at the entrance successfully attracted the interest of the passersby, no apparent increase in the number of customers visiting the store was observed. However, we confirmed that the recommendations of the robot operating inside the store did have a positive impact. We discuss our findings in detail and provide both theoretical and practical recommendations for future research and applications.
# Shared Autonomy for Safety between a Self-Reconfigurable Robot and a Teleoperator Using Multi-Layer Fuzzy Logic
## Keywords:
- Service Robotics
- Safety in HRI
- Robot Safety
## Abstract:
Autonomous vehicles are designed to elevate the efficiency of assigned tasks and ensure the safety of the environment in which they operate. This paper presents a research study focused on shared autonomy using a multi-layer fuzzy logic framework to build a relationship between an autonomous self-reconfigurable robot and a human user by switching control to the teleoperator to assist the robot when it faces challenging scenarios while keeping a good performance and maintaining a safe environment. A novel multi-layer fuzzy logic decision process with shared autonomy for a safety framework is proposed. It evaluates safety based on the robot's multi-sensor inputs, the teleoperator's attention level, and the configuration state of the self-reconfigurable robot and switches the operation mode, robot speed gain, and configuration state for performance and safety without compromises. The experimental outcome successfully demonstrates the self-reconfigurable robot’s capability to navigate safely using shared autonomy in real-world pavement scenarios using the proposed algorithm during autonomous navigation.
# Pedestrian-Robot Interactions on Autonomous Crowd Navigation: Reactive Control Methods and Evaluation Metrics
## Keywords:
- Service Robotics
- Reactive and Sensor-Based Planning
- Autonomous Vehicle Navigation
## Abstract:
Autonomous navigation in highly populated areas remains a challenging task for robots because of the difficulty in guaranteeing safe interactions with pedestrians in unstructured situations. In this work, we present a crowd navigation control framework that delivers continuous obstacle avoidance and post-contact control evaluated on an autonomous personal mobility vehicle. We propose evaluation metrics for accounting efficiency, controller response and crowd interactions in natural crowds. We report the results of over 110 trials in different crowd types: sparse, flows, and mixed traffic, with low# (< 0.15 ppsm), mid# (< 0.65 ppsm), and high# (< 1 ppsm) pedestrian densities. We present comparative results between two low-level obstacle avoidance methods and a baseline of shared control. Results show a 10% drop in relative time to goal on the highest density tests, and no other efficiency metric decrease. Moreover, autonomous navigation showed to be comparable to shared-control navigation with a lower relative jerk and significantly higher fluency in commands indicating high compatibility with the crowd. We conclude that the reactive controller fulfils a necessary task of fast and continuous adaptation to crowd navigation, and it should be coupled with high-level planners for environmental and situational awareness.
# Design of a Reconfigurable Robot with Size-Adaptive Path Planner
## Keywords:
- Service Robotics
- Product Design, Development and Prototyping
- Motion and Path Planning
## Abstract:
Area coverage is demanded from the robots utilized in application domains such as floor cleaning. Even though many advanced coverage algorithms have been developed, the area coverage performance is limited due to the inaccessibility of narrow spaces caused by physical constraints. Reconfigurable robots have been introduced to overcome this limitation where reconfigurability could help in assessing narrow spaces. Nevertheless, the state-of-the-art reconfigurable robots are not capable of changing the morphology size and shape as a single entity. Therefore, this paper proposes a novel design of a reconfigurable robot with a size-adaptive coverage strategy. The reconfiguration mechanism is designed in such a way that the robot can independently expand or shrink its size along the principal planar axes, where the behavior allows the change of size and shape. The coverage strategy is based on boustrophedon motion and the A* algorithm modified for accessing narrow areas using the size adaptability. The design of the robot is detailed in the paper, including electro-mechanical aspects, design considerations, and the coverage path planning method. Experiments have been conducted using a prototype of the proposed design to analyze and evaluate the characteristics and the performance of the robot. The results show that the proposed robot design can improve the productivity of a floor cleaning robot in terms of area coverage and coverage time.
# Testing Service Robots in the Field: An Experience Report
## Keywords:
- Engineering for Robotic Systems
- Performance Evaluation and Benchmarking
## Abstract:
Service robots are mobile autonomous robots, often operating in uncertain and difficult environments. While being increasingly popular, engineering service robots is challenging. Especially, evolving them from prototype to deployable product requires effective validation and verification, assuring the robot's correct and safe operation in the target environment. While testing is the most common validation and verification technique used in practice, surprisingly little is known about the actual testing practices and technologies used in the service robotics domain. We present an experience report on field testing of an industrial-strength service robot, as it transitions from lab experiments to an operational environment. We report challenges and solutions, and reflect on their effectiveness. Our long-term goal is to establish empirically-validated testing techniques for service robots. This experience report constitutes a necessary, but self-contained first step, exploring field testing practices in detail. Our data sources are detailed test artifacts and developer interviews. We model the field testing process and describe test-case design practices. We discuss experiences from performing these field tests over a 10-month test campaign.
# Approximate Task Tree Retrieval in a Knowledge Network for Robotic Cooking
## Keywords:
- Service Robotics
- Task Planning
- Planning under Uncertainty
## Abstract:
Flexible task planning continues to pose a difficult challenge for robots, where a robot is unable to creatively adapt their task plans to new or unseen problems, which is mainly due to the limited knowledge it may have about its actions and world. Because of this, robots typically cannot exploit knowledge or concepts in a way that mimics human creativity. Motivated by our ability as humans to adapt, we explore how task plans from a knowledge graph, known as the Functional Object-Oriented Network (FOON), can be generated for novel problems requiring concepts that are not readily available in the robot's knowledge base. Knowledge from 140 cooking recipes are structured in a FOON knowledge graph, which is used for acquiring task plan sequences known as task trees. Task trees can be modified to replicate recipes in a FOON knowledge graph format, which can be useful for expanding FOON with new recipes containing unknown object and state combinations, by relying upon semantic similarity. We demonstrate the power of task tree generation to create task trees with never-before-seen ingredient and state combinations as seen in recipes from the Recipe1M+ dataset, with which we evaluate the quality of the trees based on how accurately they depict newly added ingredients. Our experimental results show that our framework is able to provide task sequences with 76% accuracy.
# Robotic Depowdering for Additive Manufacturing Via Pose Tracking
## Keywords:
- Service Robotics
- Industrial Robots
- Computer Vision for Manufacturing
## Abstract:
With the rapid development of powder-based additive manufacturing, depowdering, a process of removing unfused powder that covers 3D-printed parts, has become a major bottleneck to further improve its productiveness. Traditional manual depowdering is extremely time-consuming and costly, and some prior automated systems either require pre-depowdering or lack adaptability to different 3D-printed parts. To solve these problems, we introduce a robotic system that automatically removes unfused powder from the surface of 3D-printed parts. The key component is a visual perception system, which consists of a pose-tracking module that tracks the 6D pose of powder-occluded parts in real-time, and a progress estimation module that estimates the depowdering completion percentage. The tracking module can be run efficiently on a laptop CPU at up to 60 FPS. Experiments show that our system can remove unfused powder from the surface of various 3D-printed parts without causing any damage. To the best of our knowledge, this is one of the first vision-based depowdering systems that adapt to parts with various shapes without the need for pre-depowdering.
# Manipulation Systems 1
# A Hierarchical Framework for Long Horizon Planning of Object-Contact Trajectories
## Keywords:
- Manipulation Planning
- Dexterous Manipulation
- Optimization and Optimal Control
## Abstract:
Given an object, an environment, and a goal pose, how should a robot make contact to move it? Solving this problem requires reasoning about rigid-body dynamics, object and environment geometries, and hybrid contact mechanics. This paper proposes a hierarchical framework that solves this problem in 2D worlds, with polygonal objects and point fingers. To achieve this, we decouple the problem in three stages: 1) a high-level textit{graph search} over regions of free-space, 2) a medium-level randomized textit{motion planner} for the object motion, and 3) a low-level textit{contact-trajectory optimization} for the robot and environment contacts. In contrast to the state of the art, this approach does not rely on handcrafted primitives and can still be solved efficiently. This algorithm does not require seeding and can be applied to complex object shapes and environments. We validate this framework with extensive simulated experiments showcasing long-horizon and contact-rich interactions. We demonstrate how our algorithm can reliably solve complex planar manipulation problems in the order of seconds.
# Constraint-Based Task Specification and Trajectory Optimization for Sequential Manipulation
## Keywords:
- Manipulation Planning
- Motion and Path Planning
## Abstract:
To economically deploy robotic manipulators the programming and execution of robot motions must be swift. To this end, we propose a novel, constraint-based method to intuitively specify sequential manipulation tasks and to compute time-optimal robot motions for such a task specification.	 Our approach follows the ideas of constraint-based task specification by aiming for a minimal and object-centric task description that is largely independent of the underlying robot kinematics. We transform this task description into a non-linear optimization problem. By solving this problem we obtain a (locally) time-optimal robot motion, not just for a single motion, but for an entire manipulation sequence. We demonstrate the capabilities of our approach in a series of experiments involving five distinct robot models, including a highly redundant mobile manipulator.
# Quasistatic Contact-Rich Manipulation Via Linear Complementarity Quadratic Programming
## Keywords:
- Manipulation Planning
- Motion and Path Planning
- Dexterous Manipulation
## Abstract:
Contact-rich manipulation is challenging due to dynamically-changing physical constraints by the contact mode changes undergone during manipulation. This paper proposes a versatile local planning and control framework for contact-rich manipulation that determines the continuous control action under variable contact modes online. We model the physical characteristics of contact-rich manipulation by quasistatic dynamics and complementarity constraints. We then propose a linear complementarity quadratic program (LCQP) to efficiently determine the control action that implicitly includes the decisions on the contact modes under these constraints. In the LCQP, we relax the complementarity constraints to alleviate ill-conditioned problems that are typically caused by measure noises or model miss-matches. We conduct dynamical simulations on a 3D physical simulator and demonstrate that the proposed method can achieve various contact-rich manipulation tasks by determining the control action including the contact modes in real-time.
# Efficient Spatial Representation and Routing of Deformable One-Dimensional Objects for Manipulation
## Keywords:
- Manipulation Planning
- Task Planning
## Abstract:
With the field of rigid-body robotics having matured in the last fifty years, routing, planning, and manipulation of deformable objects have recently emerged as a more untouched research area in many fields ranging from surgical robotics to industrial assembly and construction. Routing approaches for deformable objects which rely on learned implicit spatial representations (e.g., Learning-from-Demonstration methods) make them vulnerable to changes in the environment and the specific setup. On the other hand, algorithms that entirely separate the spatial representation of the deformable object from the routing and manipulation, often using a representation approach independent of planning, result in slow planning in high dimensional space.
This paper proposes a novel approach to routing deformable one-dimensional objects (e.g., wires, cables, ropes, sutures, threads). This approach utilizes a compact representation for the object, allowing efficient and fast online routing. The spatial representation is based on the geometrical decomposition of the space into convex subspaces, resulting in a discrete coding of the deformable object configuration as a sequence. With such a configuration, the routing problem can be solved using a fast dynamic programming sequence matching method that calculates the next routing move. The proposed method couples the routing and efficient configuration for improved planning time. Our simulation and real experiments show the method correctly computing the next manipulation action in sub-millisecond time and accomplishing various routing and manipulation tasks.
# Learning and Generalizing Cooperative Manipulation Skills Using Parametric Dynamic Movement Primitives (I)
## Keywords:
- Learning from Demonstration
- Manipulation Planning
- Imitation Learning
## Abstract:
This paper presents an approach that generates the overall trajectory of mobile manipulators for a complex mission consisting of several sub-tasks. Parametric dynamic movement primitives (PDMPs) can quickly generalize the online motion of robot manipulation by learning multiple demonstrations in offline. However, regarding complex missions consisting of multiple sub-tasks, a large number of demonstrations are required for full generalization, which is impractical. In this paper, we propose a framework that reduces the number of demonstrations for a complex mission. In the proposed method, complex demonstrations are segmented into multiple unit motions representing sub-tasks, and one PDMP is formed per each segment, resulting in multiple PDMPs. The phase decision process determines which sub-task and associated PDMPs to be executed online, allowing multiple PDMPs to be autonomously configured within an integrated framework. In order to generalize the execution time and regional goal in each phase, the Gaussian process regression (GPR) is applied. Simulation results from two different scenarios confirm that the proposed framework not only effectively reduces the number of demonstrations but also improves generalization performance. The actual experiments also demonstrate that the mobile manipulators effectively perform complex missions through the proposed framework.
# A Solution to Slosh-Free Robot Trajectory Optimization
## Keywords:
- Manipulation Planning
- Optimization and Optimal Control
- Nonholonomic Motion Planning
## Abstract:
This paper is about fast slosh-free fluid transportation. Existing approaches are either computationally heavy or only suitable for specific robots and container shapes. We model the end effector as a point mass suspended by a spherical pendulum and study the requirements for slosh-free motion and the validity of the point mass model. In this approach, slosh-free trajectories are generated by controlling the pendulum’s pivot and simulating the motion of the point mass. We cast the trajectory optimization problem as a quadratic program—this strategy can be used to obtain valid control inputs. Through simulations and experiments on a 7 DoF Franka Emika Panda robot we validate the effectiveness of the proposed approach.
# Uncertainty-Aware Manipulation Planning Using Gravity and Environment Geometry
## Keywords:
- Manipulation Planning
- Planning under Uncertainty
- Assembly
## Abstract:
Factory automation robot systems often depend on specially-made jigs that precisely position each part, which increases the system's cost and limits flexibility. We propose a method to determine the 3D pose of an object with high precision and confidence, using only parallel robotic grippers and no parts-specific jigs. Our method automatically generates a sequence of actions that ensures that the real-world position of the physical object matches the system's assumed pose to sub-mm precision. Furthermore, we propose the use of ``extrinsic" actions, which use gravity, the environment and the gripper geometry to significantly reduce or even eliminate the uncertainty about an object's pose. We show in simulated and real-robot experiments that our method outperforms our previous work, at success rates over 95%. The source code will be made public at github.com/omron-sinicx.
# Goal-Driven Robotic Pushing Using Tactile and Proprioceptive Feedback (I)
## Keywords:
- Force and Tactile Sensing
- Dexterous Manipulation
## Abstract:
In robots, nonprehensile manipulation operations such as pushing are a useful way of moving large, heavy, or unwieldy objects, moving multiple objects at once, or reducing uncertainty in the location or pose of objects. In this study, we propose a reactive and adaptive method for robotic pushing that uses rich feedback from a high-resolution optical tactile sensor to control push movements instead of relying on analytical or data-driven models of push interactions. Specifically, we use goal-driven tactile exploration to actively search for stable pushing configurations that cause the object to maintain its pose relative to the pusher while incrementally moving the pusher and object toward the target. We evaluate our method by pushing objects across planar and curved surfaces. For planar surfaces, we show that the method is accurate and robust to variations in initial contact position/angle, object shape, and start position; for curved surfaces, the performance is degraded slightly. An immediate consequence of our work is that it shows that explicit models of push interactions might be sufficient but are not necessary for this type of task. It also raises the interesting question of which aspects of the system should be modeled to achieve the best performance and generalization across a wide range of scenarios. Finally, it highlights the importance of testing on nonplanar surfaces and in other more complex environments when developing new methods for robotic pushing.
# Learning to Fold Real Garments with One Arm: A Case Study in Cloud-Based Robotics Research
## Keywords:
- Deep Learning in Grasping and Manipulation
- Performance Evaluation and Benchmarking
- Imitation Learning
## Abstract:
Autonomous fabric manipulation is a longstanding challenge in robotics, but evaluating progress is difficult due to the cost and diversity of robot hardware. Using Reach, a cloud robotics platform that enables low-latency remote execution of control policies on physical robots, we present the first systematic benchmarking of fabric manipulation algorithms on physical hardware. We develop 4 novel learning-based algorithms that model expert actions, keypoints, reward functions, and dynamic motions, and we compare these against 4 learning-free and inverse dynamics algorithms on the task of folding a crumpled T-shirt with a single robot arm. The entire lifecycle of data collection, model training, and policy evaluation was performed remotely without physical access to the robot workcell. Results suggest a new algorithm combining imitation learning with analytic methods achieves human-level performance on the flattening task and 93% of human-level performance on the folding task. See https://sites.google.com/berkeley.edu/cloudfolding for all data, code, models, and supplemental material.
# Computer Vision for Transportation
# Multi-Sensor Data Annotation Using Sequence-Based Active Learning
## Keywords:
- Computer Vision for Automation
- Computer Vision for Transportation
- Intelligent Transportation Systems
## Abstract:
Neural Networks are the state-of-the-art technology for environmental perception in applications such as autonomous driving. However, they require a large amount of training data in order to perform well, making the selection and annotation of sensor data a time-consuming and expensive task. Active learning is a promising approach to reduce the required amount of training data by selecting samples for annotation that are expected to improve the neural network the most. In this work, we propose a sequence-based active learning approach that selects sequences of consecutive frames instead of individual images. This allows to evaluate tracking algorithms and to reduce the annotation effort by interpolating labels between frames. Our approach is compared to a random sampling strategy as baseline. Over 15 iterations, both approaches select 1000 additional images for training in each iteration. The performance of the neural network trained on the data selected by our sequence-based active learning approach is compared to the performance of the network trained on the data select by the baseline approach. The results show that sequence-based active learning can reduce the required amount of training data by up to 25% while reaching a similar performance. Furthermore, sequence-based active learning can improve the neural network’s overall performance by 2% compared to a random sampling strategy. In this work, the proposed method was evaluated with a new dataset consisting of 15 scenes in railway environments. The dataset has 45,888 frames in total, 14,513 frames contain persons on railway stations or close to tracks.
# 3D Single-Object Tracking with Spatial-Temporal Data Association
## Keywords:
- Computer Vision for Transportation
- RGB-D Perception
- Autonomous Vehicle Navigation
## Abstract:
This paper proposes a novel 3D single-object tracker to more stably, accurately, and faster track objects, even if they are temporarily missed. Our idea is to utilize spatial-temporal data association to achieve object tracking robustly, and it consists of two main parts. We firstly employ a temporal motion model cross frames to estimate the object's temporal information and update the region of interest(ROI). The advanced detector only focuses on ROI rather than the whole scene to generate the spatial position. Second, we introduce a new pairwise evaluation system to exploit spatial-temporal data association in point clouds. The proposed evaluation system considers detection confidence, orientation offset, and objects distance to more stably achieve object matching. Then, we update the predicted state based on the pairwise spatial-temporal data. Finally, we utilize the previous trajectory to enhance the accuracy of static tracking in the refinement scheme. Experiments on the KITTI and nuScenes tracking datasets demonstrate that our method outperforms other state-of-the-art methods by a large margin (a 10% improvement and 280 FPS on a single NVIDIA 1080Ti GPU). Compared with multi-object tracking, our tracker also has superiority.
# Instance-Aware Multi-Object Self-Supervision for Monocular Depth Prediction
## Keywords:
- Deep Learning for Visual Perception
- Computer Vision for Automation
- RGB-D Perception
## Abstract:
This paper proposes a self-supervised monocular image-to-depth prediction framework that is trained with an end-to-end photometric loss that handles not only 6-DOF camera motion but also 6-DOF moving object instances. Self-supervision is performed by warping the images across a video sequence using depth and scene motion including object instances. One novelty of the proposed method is the use of the multi-head attention of the transformer network that matches moving objects across time and models their interaction and dynamics. This enables accurate and robust pose estimation for each object instance. Most image-to-depth predication frameworks make the assumption of rigid scenes, which largely degrades their performance with respect to dynamic objects. Only a few SOTA papers have accounted for dynamic objects. The proposed method is shown to outperform these methods on standard benchmarks and the impact of the dynamic motion on these benchmarks is exposed. Furthermore, the proposed image-to-depth prediction framework is also shown to be competitive with SOTA video-to-depth prediction frameworks.
# TransDARC: Transformer-Based Driver Activity Recognition with Latent Space Feature Calibration
## Keywords:
- Computer Vision for Transportation
- Recognition
- Gesture, Posture and Facial Expressions
## Abstract:
Traditional video-based human activity recognition has experienced remarkable progress linked to the rise of deep learning, but this effect was slower as it comes to the downstream task of driver behavior understanding. Understanding the situation inside the vehicle cabin is essential for Advanced Driving Assistant System (ADAS) as it enables identifying distraction, predicting driver’s intent and leads to more convenient human-vehicle interaction. At the same time, driver observation systems face substantial obstacles as they need to capture different granularities of driver states while the complexity of such secondary activities grows with the rising automation and increased driver freedom. Furthermore, a model is rarely deployed under conditions identical to the ones in the training set, as sensor placements and types vary from vehicle to vehicle, constituting a substantial obstacle forreal-life deployment of data-driven models. In this work, we present a novel vision based framework for recognizing secondary driver behaviours based on visual transformers and an additional augmented feature distribution calibration module. This module operates in the latent feature-space enriching and diversifying the training set at feature-level in order to improve (1) generalization to novel data appearances, (e.g. ,sensor changes) and (2) recognition of driver behaviours un-der represented in the training set. Our framework consistently leads to better recognition rates, surpassing previous state of-the-art results of the public Drive&Act benchmark on all granularity levels. Our code will be made publicly available at https://github.com/KPeng9510/TransDARC.
# Attention-Based Deep Driving Model for Autonomous Vehicles with Surround-View Cameras
## Keywords:
- Computer Vision for Transportation
- Autonomous Vehicle Navigation
- Intelligent Transportation Systems
## Abstract:
Experienced human drivers always make safe driving decisions with selectively observing the front, rear and side-view mirrors. Several end-to-end methods have been proposed to learn driving models with multi-view visual information. However, these benchmarking methods lack semantic understanding of multi-view image contents, where human drivers usually reasoning these information for decision making with different visual region of interests. In this paper, we propose an attention-based deep learning method to learn a driving model with input of surround-view visual information and the route planner, in which a multi-view attention module is designed for obtaining region of interests from human drivers. We evaluate our model on the Drive360 dataset with comparison of benchmarking deep driving models. Results demonstrate that our model achieves a competitive accuracy in both steering angle and speed prediction than benchmarking methods. Code is available at https://github.com/jet-uestc/MVA-Net.
# Towards Safety-Aware Pedestrian Detection in Autonomous Systems
## Keywords:
- Computer Vision for Transportation
- Motion and Path Planning
- Deep Learning for Visual Perception
## Abstract:
In this paper, we present a framework to assess the quality of a pedestrian detector in an autonomous driving scenario. To do this, we exploit performance metrics from the domain of computer vision on one side and so-called threat metrics from the motion planning domain on the other side. Based on a reachability analysis that accounts for the uncertainty in future motions of other traffic participants, we can determine the worst-case threat from the planning domain and relate it to the corresponding detection from the visual input. Our evaluation results for a RetinaNet on the Argoverse 1.1 [1] dataset show that already a rather simple threat metric such as time-to-collision (TTC) allows to select potentially dangerous interactions between the ego vehicle and a pedestrian when purely vision-based detections fail, even if they are passed to a subsequent object tracker. In addition, our results show that two different DNNs (Deep Neural Networks) with comparable performance differ significantly in the number of critical scenarios that we can identify with our method.
# Self-Supervised Moving Vehicle Detection from Audio-Visual Cues
## Keywords:
- Computer Vision for Transportation
- Deep Learning for Visual Perception
- Representation Learning
## Abstract:
Robust detection of moving vehicles is a critical task for any autonomously operating outdoor robot or self-driving vehicle. Most modern approaches for solving this task rely on training image-based detectors using large-scale vehicle detection datasets such as nuScenes or the Waymo Open Dataset. Providing manual annotations is an expensive and laborious exercise that does not scale well in practice. To tackle this problem, we propose a self-supervised approach that leverages audio-visual cues to detect moving vehicles in videos. Our approach employs contrastive learning for localizing vehicles in images from corresponding pairs of images and recorded audio. In extensive experiments carried out with a real-world dataset, we demonstrate that our approach provides accurate detections of moving vehicles and does not require manual annotations. We furthermore show that our model can be used as a teacher to supervise an audio-only detection model. This student model is invariant to illumination changes and thus effectively bridges the domain gap inherent to models leveraging exclusively vision as the predominant modality.
# Multi-Source Domain Alignment for Robust Segmentation in Unknown Targets
## Keywords:
- Computer Vision for Transportation
- Deep Learning for Visual Perception
- Semantic Scene Understanding
## Abstract:
Semantic segmentation provides scene understanding capability by performing pixel-wise classification of objects within an image. However, the sensitivity of such algorithms towards domain changes requires fine-tuning using an annotated dataset for each novel domain, which is expensive to construct and inefficient. We highlight that irrespective of the training dataset, structural properties of scenes remain the same hence domain sensitivity arises from training methodology. Thus, in this paper, we propose a domain alignment approach wherein multiple synthetic source domains are used to train an underlying segmentation network such that it performs consistently in unknown real target domains. Towards this end, we propose a pixel-wise supervised contrastive learning framework that enforces constraints in latent space resulting in features belonging to the same class being clustered closely and away from different classes. This approach allows for better capturing of global and local semantics while providing domain invariant properties. Our approach can be easily incorporated into prior semantic segmentation approaches without the significant computational overhead. We empirically demonstrate the efficacy of the proposed approach on GTAV to Cityscapes, GTAV+Synthia to Cityscapes, and GTAV+Synthia+Synscapes to Cityscapes scenarios and report state-of-the-art (SoTA) performance without requiring access to images from the target domain.
# Depth360: Self-Supervised Learning for Monocular Depth Estimation Using Learnable Camera Distortion Model
## Keywords:
- Deep Learning for Visual Perception
- Omnidirectional Vision
- Computer Vision for Transportation
## Abstract:
Self-supervised monocular depth estimation has been widely investigated to estimate depth images and relative poses from RGB images. This framework is promising because the depth and pose networks can be trained from just time-sequence images without the need for the ground truth depth and poses. 
In this work, we estimate the depth around a robot (360 degree view) using time-sequence spherical camera images, from a camera whose parameters are unknown. We propose a learnable axisymmetric camera model which accepts distorted spherical camera images with two fisheye camera images as well as pinhole camera images. In addition, we trained our models with a photo-realistic simulator to generate ground truth depth images to provide supervision. Moreover, we introduced loss functions to provide floor constraints to reduce artifacts that can result from reflective floor surfaces. We demonstrate the efficacy of our method using the spherical camera images from the GO Stanford dataset and pinhole camera images from the KITTI dataset to compare our method’s performance with that of baseline method in learning the camera parameters.
# Aerial Systems 1
# Real-Time Hybrid Mapping of Populated Indoor Scenes Using a Low-Cost Monocular UAV
## Keywords:
- Aerial Systems: Applications
- SLAM
- Human Detection and Tracking
## Abstract:
Unmanned aerial vehicles (UAVs) have been used for many applications in recent years, from urban search and rescue, to agricultural surveying, to autonomous underground mine exploration. However, deploying UAVs in tight, indoor spaces, especially close to humans, remains a challenge. One solution, when limited payload is required, is to use micro-UAVs, which pose less risk to humans and typically cost less to replace after a crash. However, micro-UAVs can only carry a limited sensor suite, e.g. a monocular camera instead of a stereo pair or LiDAR, complicating tasks like dense mapping and markerless multi-person 3D human pose estimation, which are needed to operate in tight environments around people. Monocular approaches to such tasks exist, and dense monocular mapping approaches have been successfully deployed for UAV applications. However, despite many recent works on both marker-based and markerless multi-UAV single-person motion capture, markerless single-camera multi-person 3D human pose estimation remains a much earlier-stage technology, and we are not aware of existing attempts to deploy it in an aerial context. In this paper, we present what is thus, to our knowledge, the first system to perform simultaneous mapping and multi-person 3D human pose estimation from a monocular camera mounted on a single UAV. In particular, we show how to loosely couple state-of-the-art monocular depth estimation and monocular 3D human pose estimation approaches to reconstruct a hybrid map of a populated indoor scene in real time. We validate our component-level design choices via extensive experiments on the large-scale ScanNet and GTA-IM datasets. To evaluate our system-level performance, we also construct a new Oxford Hybrid Mapping dataset of populated indoor scenes.
# GaSLAM: An Algorithm for Simultaneous Gas Source Localization and Gas Distribution Mapping in 3D
## Keywords:
- Aerial Systems: Applications
- Environment Monitoring and Management
- Probabilistic Inference
## Abstract:
Chemical gas dispersion poses considerable threat to humans, animals and the environment. The research areas of gas source localization and gas distribution mapping aim to localize the source of gas leaks and map the gas plume respectively, in order to help the coordination of swift rescue missions. Although very similar, these two areas are often treated separately in literature. In some cases, inferences on the gas distribution are made a posteriori from the source location, or vice-versa. In this paper, we introduce GaSLAM, a methodology that couples the estimation of the gas map and the source location using two state of the art algorithms with a novel navigation strategy based on informative quantities. The synergistic approach allows our algorithm to achieve a good estimation of both objectives and push the navigation strategies towards informative areas of the experimental volume. We validate the algorithm in simulation and with physical experiments in varying environmental conditions. We show that the algorithm improves on the source location estimate compared to a similar approach found in literature, and is able to deliver good quality maps of the gas distribution.
# An Aerial Parallel Manipulator with Shared Compliance
## Keywords:
- Aerial Systems: Mechanics and Control
- Aerial Systems: Applications
- Dynamics
## Abstract:
Accessing and interacting with difficult to reach surfaces at various orientations is of interest within a variety of industrial contexts. Thus far, the predominant robotic solution to such a problem has been to leverage the maneuverability of a fully actuated, omnidirectional aerial manipulator. Such an approach, however, requires a specialised system with a high relative degree of complexity, thus reducing platform endurance and real-world applicability. The work here presents a new aerial system composed of a parallel manipulator and conventional, underactuated multirotor flying base to demonstrate interaction with vertical and non-vertical surfaces. Our solution enables compliance to external disturbance on both subsystems, the manipulator and flying base, independently with a goal of improved overall system performance when interacting with surfaces. To achieve this behaviour, an admittance control strategy is implemented on various layers of the flying base's dynamics together with torque limits imposed on the manipulator actuators. Experimental evaluations show that the proposed system is compliant to external perturbations while allowing for differing interaction behaviours as compliance parameters of each subsystem are altered. Such capabilities enable an adjustable form of dexterity in completing sensor installation, inspection and aerial physical interaction tasks. A video of our system interacting with various surfaces can be found here: https://youtu.be/38neGb8-lXg.
# RAPTOR: Rapid Aerial Pickup and Transport of Objects by Robots
## Keywords:
- Aerial Systems: Applications
- Soft Robot Applications
- Grippers and Other End-Effectors
## Abstract:
Rapid aerial grasping through robots can lead to many applications that utilize fast and dynamic picking and placing of objects. Rigid grippers traditionally used in aerial manipulators require high precision and specific object geometries for successful grasping. We propose RAPTOR, a quadcopter platform combined with a custom Fin Ray® gripper to enable more flexible grasping of objects with different geometries, leveraging the properties of soft materials to increase the contact surface between the gripper and the objects. To reduce the communication latency, we present a new lightweight middleware solution based on Fast DDS (Data Distribution Service) as an alternative to ROS (Robot Operating System). We show that RAPTOR achieves an average of 83% grasping efficacy in a real-world setting for four different object geometries while moving at an average velocity of 1 m/s during grasping. In a high-velocity setting, RAPTOR supports up to four times the payload compared to previous works. Our results highlight the potential of aerial drones in automated warehouses and other manipulation applications where speed, swiftness, and robustness are essential while operating in hard-to-reach places.
# Side-Pull Maneuver: A Novel Control Strategy for Dragging a Cable-Tethered Load of Unknown Weight Using a UAV
## Keywords:
- Aerial Systems: Applications
- Intelligent Transportation Systems
- Control Architectures and Programming
## Abstract:
This work presents an approach for dealing with suspended-cable load transportation using unmanned aerial vehicles (UAVs), specifically when the cargo overcomes the lifting capacity. Herein, this approach is referred to as the Side-Pull Maneuver (SPM). This maneuver is an alternative and viable strategy for cases where there is no impediment or restriction to dragging the load along a surface, such as with pastures or marine environments. The proposal is based on a joint observation of the thrust and altitude of the UAV. To make this possible, the high-level rigid-body dynamics model is described and represented as an underactuated system. Its altitude-rate control input is then analyzed during flight. A flight state supervisor decides whether the cargo should be carried by lifting or by side-pulling, or whether it should be labeled as non-transportable. Comparative real experiments validate the proposal according to which maneuver (lifting or dragging) is performed for transport.
# On-Board Physical Battery Replacement System and Procedure for Drones During Flight
## Keywords:
- Aerial Systems: Applications
- Product Design, Development and Prototyping
- Mechanism Design
## Abstract:
One of the major disadvantages of drones is their limited flight time. This paper introduces a new concept and mechanism for an onboard system that physically replaces batteries during flight, analogous to “aerial refueling”. This capability allows drones to remain in mid-air indefinitely while pursuing their mission without forcing them to change flight paths for logistical needs. The concept is composed of an additional UAV array that delivers new batteries from various ground points. We first describe the Flying Hot-Swap Battery (FHSB) system’s conceptual design. This unique design uses a FIFO logical process and the force of gravity to replace the energy source. The main innovation involves combining the ability to receive a battery from an external source, connect mechanically, hot-swap between the batteries, and dispose of the discharged battery. We report on the design of a dedicated battery cartridge for reception and connection in any spatial variation or orientation. Each component has a duplicate that works independently to increase system redundancy. Finally, we present the multiple experiments conducted to test the FHSB. The prototype successfully hovered and connected the battery in various reception orientations and hot-swapped the battery, thus maintaining the drone’s continuous power supply. This proof of concept of a complete battery replacement process during flight took an average replacement time of 15.2 seconds, which is only a 0.81% energy loss, thus enabling the drone to continue flying indefinitely without needing to modify its flight path (see attached video).
# Frequency-Based Wind Gust Estimation for Quadrotors Using a Nonlinear Disturbance Observer
## Keywords:
- Aerial Systems: Mechanics and Control
- Automation Technologies for Smart Cities
- Environment Monitoring and Management
## Abstract:
In city-wide weather prediction, wind gust information can be obtained using unmanned aerial vehicles (UAVs). Although wind sensors are available, an algorithm-based active estimation can be helpful not only as a weightless substitute but also as feedback for robust control. This paper aims to estimate the wind gusts affecting the quadrotors (a type of UAV) as the input disturbances by using a frequency-based nonlinear disturbance observer (NDOB). To obtain highly accurate estimations, frequency is considered as the main design parameter, thereby focusing the estimation on the frequency range of the wind gusts. The NDOB is developed using the Takagi-Sugeno (T-S) fuzzy framework. In this approach, the twelfth-order nonlinear model is approximated into a sixth-order T-S fuzzy model to reduce computational cost. A two-step verification method is presented, which includes MATLAB/Simulink simulations and the experiments performed using a 2.5 kg quadrotor.
# Vision-Based Relative Detection and Tracking for Teams of Micro Aerial Vehicles
## Keywords:
- Aerial Systems: Applications
## Abstract:
In this paper, we address the vision-based detection and tracking problems of multiple aerial vehicles using a single camera and Inertial Measurement Unit (IMU) as well as the corresponding perception consensus problem (i.e., uniqueness and identical IDs across all observing agents). We design several vision-based decentralized Bayesian multi-tracking filtering strategies to resolve the association between the incoming unsorted measurements obtained by a visual detector algorithm and the tracked agents. We compare their accuracy in different operating conditions as well as their scalability according to the number of agents in the team. This analysis provides useful insights about the most appropriate design choice for the given task. We further show that the proposed perception and inference pipeline which includes a Deep Neural Network (DNN) as visual target detector is lightweight and capable of concurrently running control and planning with Size, Weight, and Power (SWaP) constrained robots on-board. Experimental results show the effective tracking of multiple drones in various challenging scenarios such as heavy occlusions.
# Efficient Concurrent Design of the Morphology of Unmanned Aerial Systems and Their Collective-Search Behavior
## Keywords:
- Optimization and Optimal Control
- Swarm Robotics
- Methods and Tools for Robot System Design
## Abstract:
The collective operation of robots (such as unmanned aerial vehicles or UAVs) operating as a team or swarm is affected by their individual capabilities, which in turn is dependent on their physical design, aka morphology. However, with the exception of a few (albeit ad hoc) evolutionary robotics methods, there has been very little work on understanding the interplay of morphology and collective behavior, especially given the lack of computational frameworks to concurrently search for the robot morphology and the hyper-parameters of their behavior model that jointly optimize the collective (team) performance. To address this gap, this paper proposes a new co-design framework. Here the exploding computational cost of an otherwise nested morphology/behavior co-design is effectively alleviated through the novel concept of ``talent" metrics; while also allowing significantly better solutions compared to the typically sub-optimal sequential morphologytobehavior design approach. This framework comprises four major steps: talent metrics selection, talent Pareto exploration (a multi-objective morphology optimization process), behavior optimization, and morphology finalization. This co-design concept is demonstrated by applying it to design UAVs that operate as a team to localize signal sources (e.g., in victim search and hazard localization), where the collective behavior is driven by a recently reported batch Bayesian search algorithm called Bayes-Swarm. Our case studies show that the outcome of co-design provides significantly higher success rates in signal source localization compared to a baseline design, across a variety of signal environments and teams with 6 to 15 UAVs. Moreover, this co-design process provides two orders of magnitude reduction in computing time compared to a projected nested design approach.
# Medical Robots and Systems 1
# Automatic Laser Steering for Middle Ear Surgery
## Keywords:
- Medical Robots and Systems
- Computer Vision for Medical Robotics
## Abstract:
This paper deals with the control of a laser spot in the context of minimally invasive surgery of the middle ear, e.g., cholesteatoma removal. More precisely, our work is concerned with the exhaustive burring of residual infected cells after primary mechanical resection of the pathological tissues since the latter cannot guarantee the treatment of all the infected tissues, the remaining infected cells cause regeneration of the diseases in 20%-25% of cases, which require a second surgery 12-18 months later. To tackle such a complex surgery, we have developed a robotic platform that consists of the combination of a macro-scale system (7 degrees of freedoms (DoFs) robotic arm) and a micro-scale flexible system (2 DoFs) which operates inside the middle ear cavity. To be able to treat the residual cholesteatoma regions, we proposed a method to generate optimal laser automatically scanning trajectories inside the areas and between them. The trajectories are tacked using an image-based control scheme. The proposed method and materials were validated experimentally using the lab-made robotic platform. The obtained results in terms of accuracy and behaviour meet the laser surgery requirements perfectly.
# Virtual Reality Simulator for Fetoscopic Spina Bifida Repair Surgery
## Keywords:
- Medical Robots and Systems
- Virtual Reality and Interfaces
- Haptics and Haptic Interfaces
## Abstract:
Spina Bifida (SB) is a birth defect developed during the early stage of pregnancy in which there is an incomplete closing of the spine around the spinal cord. The growing interest in fetoscopic Spina Bifida repair, which is performed in fetuses who are still in the pregnant uterus, prompts the need for appropriate training. The learning curve for such procedures is steep and requires excellent procedural skills. 
Computer-based virtual reality (VR) simulation systems offer a safe, cost-effective, and configurable training environment free from ethical and patient safety issues. However, to the best of our knowledge, there are currently no commercial or experimental VR training simulation systems available for fetoscopic SB-repair procedures. In this paper, we propose a novel VR simulator for core manual skills training for SB-repair. 
An initial simulation realism validation study was carried out by obtaining subjective feedback (face and content validity) from 14 clinicians. The overall simulation realism was on average marked 4.07 on a 5-point Likert scale (1 # ‘very unrealistic’, 5 # ‘very realistic’). Its usefulness as a training tool for SB-repair as well as in learning fundamental laparoscopic skills was marked 4.63 and 4.80, respectively. 
These results indicate that VR simulation of fetoscopic procedures may contribute to surgical training without putting fetuses and their mothers at risk. It could also facilitate wider adaptation of fetoscopic procedures in place of much more invasive open fetal surgeries.
# A Pneumatic MR-Conditional Guidewire Delivery Mechanism with Decoupled Rotary Linear Actuation for Endovascular Intervention
## Keywords:
- Medical Robots and Systems
## Abstract:
Percutaneous coronary intervention (PCI) involves the delivery of a flexible submillimeter guidewire and existing x-ray based approaches impose significant ironing radiation. The use of magnetic resonance imaging (MRI) for intraoperative guidance has the advantages of not only being safe but also having high positioning accuracy and excellent tissue contrast. This paper develops a pneumatically driven MR-conditional delivery mechanism for the ease of manipulation of the guidewire in vivo. It incorporates newly developed rotary pneumatic step motors and a pneumatic slip ring for actuation and decoupling of translational and rotational motions. An effective clamping mechanism for the locking and releasing of the guidewire is also incorporated. The proposed pneumatic slip ring mechanism decouples six gas lines, where four are used to supply a pneumatic step motor for translational motion, and two for the clamping mechanism. High friction sil sleeve is used to hold the guidewire firmly and the rotary pneumatic motor has excellent sealing and stability, providing an output torque of 15.75 Nm/MPa. Experiments show that the average error of translational motion is 0.37 mm. Real-time MRI-guided endovascular intervention is performed in a vascular phantom with pulsatile flows to validate its potential clinical use. The imaging artifact test under MRI shows no noticeable distortion and the loss of Signal-to-Noise Ratio (SNR) is less than 2%.
# Design and Evaluation of the Infant Cardiac Robotic Surgical System (iCROSS)
## Keywords:
- Medical Robots and Systems
- Dual Arm Manipulation
- Mechanism Design
## Abstract:
In this study, the infant Cardiac Robotic Surgical System (iCROSS) is developed to assist a surgeon in performing the patent ductus arteriosus (PDA) closure and other infant cardiac surgeries. The iCROSS is a dual-arm robot allowing two surgical instruments to collaborate in a narrow space while keeping a sufficiently large workspace. Compared with the existing surgical robotic systems, the iCROSS meets the specific requirements of infant cardiac surgeries. Its feasibility has been validated through several teleoperated tasks performed in the experiment. In particular, the iCROSS is able to perform surgical ligation successfully within one minute.
# A Robotic System for Solo Surgery in Flexible Ureterorenoscopy
## Keywords:
- Medical Robots and Systems
- Physical Human-Robot Interaction
- Performance Evaluation and Benchmarking
## Abstract:
Urolithiasis is a common disease with increasing prevalence across all ages. A common treatment option for smaller kidney stones is flexible ureterorenoscopy (fURS), where a flexible ureteroscope (FU) is used for stone removal and to inspect the renal collecting system. The handling of the flexible ureteroscope and end effectors (EEs), however, is challenging and requires two surgeons. In this paper, we introduce a modular robotic system for endoscope manipulation, which enables solo surgery (SSU) and is adaptable to various hand-held FUs. Both the developed hardware components and the proposed workflow and its representation in software are described. We then present and discuss the results of an initial user study. Finally, we describe subsequent developmental steps towards more extensive testing by clinical staff.
# Light in the Larynx: A Miniaturized Robotic Optical Fiber for In-Office Laser Surgery of the Vocal Folds
## Keywords:
- Medical Robots and Systems
- Surgical Robotics: Steerable Catheters/Needles
## Abstract:
This letter reports the design, construction, and experimental validation of a novel hand-held robot for in-office laser surgery of the vocal folds. In-office endoscopic laser surgery is an emerging trend in Laryngology: It promises to deliver the same patient outcomes of traditional surgical treatment (i.e., in the operating room), at a fraction of the cost. Unfortunately, office procedures can be challenging to perform; the optical fibers used for laser delivery can only emit light forward in a line-of-sight fashion, which severely limits anatomical access. The robot we present in this letter aims to overcome these challenges. The end effector of the robot is a steerable laser fiber, created through the combination of a thin optical fiber (0.225 mm) with a tendon-actuated Nickel-Titanium notched sheath that provides bending. This device can be seamlessly used with most commercially available endoscopes, as it is sufficiently small (1.1 mm) to pass through a working channel. To control the fiber, we propose a compact actuation unit that can be mounted on top of the endoscope handle, so that, during a procedure, the operating physician can operate both the endoscope and the steerable fiber with a single hand. We report simulation and phantom experiments demonstrating that the proposed device substantially enhances surgical access compared to current clinical fibers.
# A 5-DOFs Robot for Posterior Segment Eye Microsurgery
## Keywords:
- Medical Robots and Systems
- Surgical Robotics: Steerable Catheters/Needles
- Parallel Robots
## Abstract:
In retinal surgery clinicians access the internal volume of the eyeball through small scale trocar ports, typically 0.65 mm in diameter, to treat vitreoretinal disorders like idiopathic epiretinal membrane and age-related macular holes. The treatment of these conditions involves the removal of thin layers of diseased tissue, namely the epiretinal membrane and the internal limiting membrane. These membranes have an average thickness of only 60 μm and 2 μm respectively making extremely challenging even for expert clinicians to peel without damaging the surrounding tissue. In this work we present a novel Ophthalmic microsurgery Robot (OmSR) designed to operate a standard surgical forceps used in these procedures with micrometric precision, overcoming the limitations of current robotic systems associated with the offsetting of the remote centre of motion of the end effector when accessing the sclera. The design of the proposed system is presented, and its performance evaluated. The results show that the end effector can be controlled with an accuracy of less than 30 μm and the surgical forceps opening and closing positional error is less than 4.3 μm. Trajectory-following experiments and membrane peeling experiments are also presented, showing promising results in both scenarios.
# Mechanism Design 1
# DRPD, Compact Dual Reduction Ratio Planetary Drive for Actuators of Articulated Robots
## Keywords:
- Mechanism Design
- Actuation and Joint Mechanisms
## Abstract:
This paper presents a reduction mechanism for robot actuators that can switch between two types of reduction ratio. By fixing the carrier or ring gear of the proposed actuator which is based on the 3K compound planetary drive, the actuator can shift its reduction ratio. For compact design with reduced weight of the actuator, unique pawl brake mechanism interacting with cams and micro servos for switching mechanism is designed. The resulting prototype module has a reduction ratio of 6.91 and 44.93 for ‘low-reduction’ and ‘high-reduction’ ratios, respectively. Reduction ratios can be easily adjusted by modifying the pitch diameters of gears. Experimental results demonstrate that the proposed actuator could extend its operation region via two reduction modes that are interchangeable with gear shifting.
# Single-Rod Brachiation Robot
## Keywords:
- Mechanism Design
- Biologically-Inspired Robots
- Motion Control
## Abstract:
In this paper, we propose a new brachiation robot, a single-rod brachiation robot. Brachiation is a method of locomotion that makes clever use of gravity and has been tried to apply to robots. Conventional brachiation robots are multiple-pendulum-like robots that mimic a gibbon. Although the multiple-pendulum-like robot can easily change the length of one brachiation step by joints, it has complex structures and generates aperiodic motions such as chaos. In contrast, the single-rod brachiation robot has the advantages of simple structure and the ability to suppress complex multiple-pendulum trajectories. The single-rod brachiation robot has a disadvantage because it is difficult to adjust the distance to the next bar. However, we can solve it by aerial brachiation, which includes an aerial phase before grasping the next bar. Using the actual robot, we showed that the swinging amplitude could be increased by appropriately moving its center of gravity like a trapeze motion. In addition, using this, we achieved continuous brachiation across three bars and brachiation including the aerial phase with a flight distance of 140 mm.
# A Compact, Lightweight and Singularity-Free Wrist Joint Mechanism for Humanoid Robots
## Keywords:
- Mechanism Design
- Humanoid Robot Systems
- Kinematics
## Abstract:
Building humanoid robots with properties similar to those of humans in	terms of strength and agility is a great and unsolved challenge. This work introduces a compact and lightweight wrist joint	mechanism that is singularity-free and has large range of motion. The mechanism has two degrees of freedom (DoF) and has been designed to be integrated into a human scale humanoid robot arm. It is based on a parallelmechanism with rolling contact joint behaviour and remote actuation	that facilitates a compact design	with low mass and inertia. The mechanism’s kinematics together with a solution of the inverse kinematics problem for the specific design, and the manipulability	analysis are presented. The	first prototype of the proposed mechanism	shows the possible integration of actuation, sensing and electronics in small	and narrow space. Experimental evaluations shows that the design feature unique performance regarding	weight, speed, payload and accuracy.
# Wirelessly Magnetically Actuated Robotic Implant for Tissue Regeneration
## Keywords:
- Mechanism Design
- Medical Robots and Systems
## Abstract:
Abstract—In biomedical engineering, robotic implants provide new methods to restore and improve bodily function, and regenerate tissue. A significant challenge with the design of these devices is to safely actuate them for weeks or months, while they are residing in a patient’s body. Magnetic, and other force-at distance actuation methods, allow mechanisms to be controlled remotely and without contact or line of sight to the device. In this paper, we present a novel magnetic field driven wireless motor. The motor drives a robotic implant for the treatment of long gap esophageal atresia and short bowel syndrome. The motor is equipped with two oppositely oriented permanent magnets which experience forces in opposite directions when a magnetic field is applied tangential to the magnets’ directions. The implant can produce a force of 2 N. It is demonstrated with an ex vivo porcine esophagus.
# Multiple Curvatures in a Tendon-Driven Continuum Robot Using a Novel Magnetic Locking Mechanism
## Keywords:
- Mechanism Design
- Soft Robot Materials and Design
- Medical Robots and Systems
## Abstract:
Tendon-driven continuum robots show promise for use in surgical applications as they can assume complex configurations to navigate along tortuous paths. However, to achieve these complex robot shapes, multiple segments are required as each robot segment can bend only with a single constant curvature. To actuate these additional robot segments, multiple tendons must typically be added on-board the robot, complicating their integration, robot control, and actuation. This work presents a method of achieving two curvatures in a single tendon-driven continuum robot segment through use of a novel magnetic locking mechanism. Thus, the need for additional robot segments and actuating tendons is eliminated. The resulting two curvatures in a single segment are demonstrated in two and three dimensions. Furthermore, the maximum magnetic field required to actuate the locking mechanism for different robot bending angles is experimentally measured to be 6.1 mT. Additionally, the locking mechanism resists unintentional unlocking unless the robot assumes a 0° bending angle and a magnetic field of 18.1 mT is applied, conditions which are not typically reached during routine use of the system. Finally, addressable actuation of two locking mechanisms is achieved, demonstrating the capability of producing multiple curvatures in a single robot segment.
# Toroidal Origami Monotrack: Mechanism to Realize Smooth Driving and Bending for Closed-Skin-Drive Robots
## Keywords:
- Mechanism Design
- Soft Robot Materials and Design
- Search and Rescue Robots
## Abstract:
We propose a novel toroidal origami monotrack capable of smooth-skin driving and bending for closed-skin-drive robots. Monotracks are a promising solution for achieving high mobility in unstructured environments. Toroidal-drive mechanisms enable whole skin drive; however, conventional methods experience unexpected wrinkling and buckles that lead to a large resistance. In this study, we propose an origami bellows structure with multiple rollers that can maintain the skin tension and deal with the cause of large friction between the skin and the body. The origami structure design method is presented, and the bending angle range and required drive force were derived through a theoretical analysis. The validity of the effectiveness of the concept was verified through prototype testing.
# A Modified Rocker-Bogie Mechanism with Fewer Actuators and High Mobility
## Keywords:
- Mechanism Design
- Actuation and Joint Mechanisms
- Climbing Robots
## Abstract:
In this study, a modified rocker-bogie mechanism that improve mobility using only two actuators and a damper is proposed. Previous mechanisms use large number of motors or complex controls to overcome obstacles such as rough terrain or stairs. To compensate this, the damper-driven rocker-bogie (DDRB) is devised. The effectiveness of the damper was verified using quasi-static analysis, and the optimal parameters of prototype was determined using multibody dynamics. Finally, the performance of climbing stairs was successfully demonstrated through experiments with the prototype. The mobility performance is expected to be improved through additional active systems, and will be applied not only to stairs but also to various rough terrains in the future.
# Planar Multi-Closed-Loop Hyper-Redundant Manipulator Using Extendable Tape Springs: Design, Modeling, and Experiments
## Keywords:
- Mechanism Design
- Redundant Robots
- Manipulation Planning
## Abstract:
This paper describes the development of a planar multi-closed-loop hyper-redundant manipulator. The proposed manipulator consists of two extendable tape springs and several inner tube rods. As the tape springs can be wound, the manipulator achieves a large workspace with a small footprint. The inner tube rods are arranged between the two tape springs, providing the manipulator with a triangular-lattice structure in which the inner tube rods and tape springs are subjected to purely axial loads. By controlling the two fixed drive components and eight mobile drive components in the manipulator, various redundant configurations can be produced. The kinematic model of this manipulator is established, and a configuration planning approach based on optimal stiffness is proposed. Simulations are conducted for three different cases, and a prototype is fabricated and tested to validate the proposed design and method.
# Autonomous State-Based Flipper Control for Articulated Tracked Robots in Urban Environments
## Keywords:
- Machine Learning for Robot Control
- Deep Learning Methods
- Imitation Learning
## Abstract:
We demonstrate a hybrid approach to autonomous flipper control, focusing on a fusion of hard-coded and learned knowledge. The result is a sample-efficient and modifiable control structure that can be used in conjunction with a mapping/navigation stack. The backbone of the control policy is formulated as a state machine whose states define various flipper action templates and local control behaviors. It is also used as an interface that facilitates the gathering of demonstrations to train the transitions of the state machine. We propose a soft-differentiable state machine neural network that mitigates the shortcomings of its naively implemented counterpart and improves over a multi-layer perceptron baseline in the task of state-transition classification. We show that by training on several minutes of user-gathered demonstrations in simulation, our approach is capable of a zero-shot domain transfer to a wide range of obstacles on a similar real robotic platform. Our results show a considerable increase in performance over a previous competing approach in several essential criteria. A subset of this work was successfully used in the Defense Advanced Research Projects Agency (DARPA) Subterranean Challenge to alleviate the operator of manual flipper control. We autonomously traversed stairs and other obstacles, improving map coverage.
# Object Detection, Segmentation and Categorization 1
# Ensemble Based Anomaly Detection for Legged Robots to Explore Unknown Environments
## Keywords:
- Object Detection, Segmentation and Categorization
- AI-Enabled Robotics
- Space Robotics and Automation
## Abstract:
Exploring unknown environments, such as caves or planetary surfaces, requires a quick understanding of the surroundings. Beforehand, only aerial footage from satellites or images from previous missions might be available. The proposed ensemble based anomaly detection framework utilizes previously gained knowledge and incorporates it with insights gained during the mission. The modular system consists of different networks which are combined to determine anomalies in the current surroundings. By utilizing data from other missions, simulations or aerial photos, a precise anomaly detection can be achieved at the start of a mission. The system can further be improved by training new networks during the mission, which can be incorporated into the ensemble at runtime. This allows for synchronous execution of mission and training of models on a base station. The proposed system is tested and evaluated on an ANYmal C walking robot in different scenarios, however the approach is applicable for different kinds of mobile robots. The results show a clear improvement of ensembles compared to individual networks, while keeping a small memory footprint and low inference time on the mobile system.
# FocusTR: Focusing on Valuable Feature by Multiple Transformers for Fusing Feature Pyramid on Object Detection
## Keywords:
- Object Detection, Segmentation and Categorization
- Computer Vision for Transportation
- Sensor Fusion
## Abstract:
The feature pyramid, which is a vital component of the convolutional neural networks, plays a significant role in several perception tasks, including object detection for autonomous driving. However, how to better fuse multi-level and multi-sensor feature pyramids is still a significant challenge, especially for object detection. This paper presents a FocusTR (Focusing on the valuable features by multiple Transformers), which is a simple yet effective architecture, to fuse feature pyramid for the single-stream 2D detector and two-stream 3D detector. Specifically, FocusTR encompasses several novel self-attention mechanisms, including the spatial-wise boxAlign attention (SB) for low-level spatial locations, context-wise affinity attention (CA) for high-level context information, and level-wise attention for the multi-level feature. To alleviate self-attention's computational complexity and slow training convergence, FocusTR introduces a low and high-level fusion (LHF) to reduce the computational parameters, and the Pre-LN to accelerate the training convergence. Comparative experiments on public benchmarks and datasets show that FocusTR achieves a higher detection accuracy than the baseline methods, especially for the small object detection. Our method shows a 2.1 higher detection accuracy on APs index of the small object on MS-COCO 2017 with ResNeXt-101 backbone, a 2.18 higher 3D detection accuracy (moderate difficulty category) for small object-pedestrian on KITTI, and a 6.85 higher RC index (Town05 Long) on CARLA urban driving simulator.
# DeepShapeKit: Accurate 4D Shape Reconstruction of Swimming Fish
## Keywords:
- Object Detection, Segmentation and Categorization
- Deep Learning Methods
## Abstract:
In this paper, we present methods for capturing 4D body shapes of swimming fish with affordable small training datasets and textureless 2D videos. Automated capture of spatiotemporal animal movements and postures is revolutionizing the study of collective animal behavior. 4D (including 3D space + time) shape data from animals like schooling fish contains a rich array of social and non-social information that can be used to shed light on the fundamental mechanisms underlying collective behavior. However, unlike the large datasets used for 4D shape reconstructions of the human body, there are no large amounts of labeled training datasets for reconstructing fish bodies in 4D, due to the difficulty of underwater data collection. We created a template mesh model using 3D scan data from a real fish, then extracted silhouettes (segmentation masks) and key-points of the fish body using Mask R-CNN and DeepLabCut, respectively. Next, using the Adam optimizer, we optimized the 3D template mesh model for each frame by minimizing the difference between the projected 3D model and the detected silhouettes as well as the key-points. Finally, using an LSTM-based smoother, we generated accurate 4D shapes of schooling fish based on the 3D shapes over each frame. Our results show that the method is effective for 4D shape reconstructions of swimming fish, with greater fidelity than other state-of-the-art algorithms.
# E2Pose: Fully Convolutional Networks for End-To-End Multi-Person Pose Estimation
## Keywords:
- Object Detection, Segmentation and Categorization
- Gesture, Posture and Facial Expressions
- AI-Based Methods
## Abstract:
Highly accurate multi-person pose estimation at a high framerate is a fundamental problem in autonomous driving. Solving the problem could aid in preventing pedestrian--car accidents. The present study tackles this problem by proposing a new model composed of a feature pyramid and an original head to a general backbone. The original head is built using lightweight CNNs and directly estimates multi-person pose coordinates. This configuration avoids the complex post-processing and two-stage estimation adopted by other models and allows for a lightweight model. Our model can be trained end-to-end and performed in real-time on a resource-limited platform (low-cost edge device) during inference. Experimental results using the COCO and CrowdPose datasets showed that our model can achieve a higher framerate (approx. 20 frames/sec with NVIDIA Jetson AGX Xavier) than other state-of-the-art models while maintaining sufficient accuracy for practical use.
# Fast Detection of Moving Traffic Participants in LiDAR Point Clouds by Using Particles Augmented with Free Space Information
## Keywords:
- Object Detection, Segmentation and Categorization
- Intelligent Transportation Systems
## Abstract:
To navigate safely, it is essential for a robot to detect all kinds of moving objects that could possibly interfere with the own trajectory. For common object classes, like cars, regular pedestrians, and trucks, there are large scale datasets as well as corresponding machine learning techniques, which provide remarkable results in commonly available detection benchmarks. A big challenge that remains, are less frequent classes, which are not part of a dataset in a sufficient number and variation. Dynamic occupancy grids are a promising approach for detection of moving objects in point clouds since they impose only a few assumptions about the objects' appearance and shape. Typically, they use particle filters to detect motion of occupancy in the grid. Existing approaches, however, often generate false positives at long obstacles because particles move along them. Therefore we propose a highly efficient approach, which performs the classification in a more structured and conservative way by making extensive use of available free space information. As a result, much less false positives are generated while the number of false negatives remains low. Our approach can be used to complement CNN-based object detections in order to detect both, frequent and uncommon object classes reliably. By using polar data structures that match the polar measurement principle, we are able to process even large point clouds of modern LiDARs with 128 lasers efficiently.
# RPG: Learning Recursive Point Cloud Generation
## Keywords:
- Object Detection, Segmentation and Categorization
- Representation Learning
- Deep Learning for Visual Perception
## Abstract:
In this paper we propose a novel point cloud generator that is able to reconstruct and generate 3D point clouds composed of semantic parts. Given a latent represen# tation of the target 3D model, the generation starts from a single point and gets expanded recursively to produce the high# resolution point cloud via a sequence of point expansion stages. During the recursive procedure of generation, we not only obtain the coarse-to-fine point clouds for the target 3D model from every expansion stage, but also unsupervisedly discover the semantic segmentation of the target model according to the hierarchical/parent-child relation between the points across expansion stages. Moreover, the expansion modules and other elements used in our recursive generator are mostly sharing weights thus making the overall framework light and efficient. Extensive experiments are conducted to show that our point cloud generator has comparable or even superior performance on both generation and reconstruction tasks in comparison to various baselines, and provides the consistent co-segmentation among instances of the same object class.
# Fully Convolutional Transformer with Local–Global Attention
## Keywords:
- Object Detection, Segmentation and Categorization
- RGB-D Perception
- Deep Learning for Visual Perception
## Abstract:
In an attempt to imitate the success of transformers in the field of natural language processing into computer vision tasks, vision transformers (ViTs) have recently gained attention. Performance breakthroughs have been achieved in coarse-grained tasks like classification. However, dense prediction tasks, such as detection, segmentation, and depth estimation, require additional modifications and have been tackled only in an ad-hoc manner, by replacing the convolutional neural network encoder backbone of an existing architecture with a ViT. This study proposes a fully convolutional transformer that can perform both coarse and dense prediction tasks. The proposed architecture is, to the best of our knowledge, the first architecture composed of attention layers, even in the decoder part of the network. This is because our newly proposed local--global attention (LGA) can flexibly perform both downsampling and upsampling of spatial features, which are key operations required for dense prediction. Against existing ViTs on classification tasks, our architecture shows a reasonable trade-off between performance and efficiency. In the depth estimation task, our architecture achieves performance comparable to that of state-of-the-art transformer-based methods.
# DeepFusion: A Robust and Modular 3D Object Detector for Lidars, Cameras and Radars
## Keywords:
- Autonomous Vehicle Navigation
- Object Detection, Segmentation and Categorization
- Intelligent Transportation Systems
## Abstract:
We propose DeepFusion, a modular multi-modal architecture to fuse lidars, cameras and radars in different combinations for 3D object detection. Specialized feature extractors take advantage of each modality and can be exchanged easily, making the approach simple and flexible. Extracted features are transformed into bird's-eye-view as a common representation for fusion. Spatial and semantic alignment is performed prior to fusing modalities in the feature space. Finally, a detection head exploits rich multi-modal features for improved 3D detection performance. Experimental results for lidar-camera, lidar-camera-radar and camera-radar fusion show the flexibility and effectiveness of our fusion approach. In the process, we study the largely unexplored task of faraway car detection up to 225 meters, showing the benefits of our lidar-camera fusion. Furthermore, we investigate the required density of lidar points for 3D object detection and illustrate implications at the example of robustness against adverse weather conditions. Moreover, ablation studies on our camera-radar fusion highlight the importance of accurate depth estimation.
# CVFNet: Real-Time 3D Object Detection by Learning Cross View Features
## Keywords:
- Object Detection, Segmentation and Categorization
- Deep Learning Methods
- Intelligent Transportation Systems
## Abstract:
In recent years 3D object detection from LiDAR point clouds has made great progress thanks to the development of deep learning technologies. Although voxel or point based methods are popular in 3D object detection, they usually involve time-consuming operations such as 3D convolutions on voxels or ball query among points, making the resulting network inappropriate for time critical applications. On the other hand, 2D view-based methods feature high computing efficiency while usually obtaining inferior performance than the voxel or point based methods. In this work, we present a real-time view-based single stage 3D object detector, namely CVFNet to fulfill this task. To strengthen the cross-view feature learning under the condition of demanding efficiency, our framework extracts the features of different views and fuses them in an efficient progressive way. We first propose a novel Point-Range feature fusion module that deeply integrates point and range view features in multiple stages. Then, a special Slice Pillar is designed to well maintain the 3D geometry when transforming the obtained deep point-view features into bird's eye view. To better balance the ratio of samples, a sparse pillar detection head is presented to focus the detection on the nonempty grids. We conduct experiments on the popular KITTI and NuScenes benchmark, and state-of-the-art performances are achieved in terms of both accuracy and speed.
# Haptics
# Reduced Interface Models for Haptic Interfacing with Virtual Environments
## Keywords:
- Haptics and Haptic Interfaces
- Dynamics
- Physical Human-Robot Interaction
## Abstract:
Haptic interfacing typically requires high communication frequencies in order to render realistic interactions between a user and a virtual environment. In this work, we introduce reduced interface modelling (RIM) as a method to bridge the discrepancy in frequency requirements between haptic devices and virtual environment simulators. The method offers a model-based approach to approximate the environment behaviour between integration time steps, without relying on time history extrapolations of the environment state with no physical basis. Using a vehicle dynamics simulation interfacing with a haptic steering wheel, we show that the proposed method results in a drastic reduction in the computation time required for numerical integration and updates to the virtual environment compared to the common zero-order-hold method. T-tests on numerical ratings by participants in a multi-user study also confirm that the RIM yields better uncoupled stability and haptic rendering smoothness compared to a common time-history-based multi-rate sampling method.
# A Soft Robotic Haptic Feedback Glove for Colonoscopy Procedures
## Keywords:
- Haptics and Haptic Interfaces
- Force and Tactile Sensing
- Wearable Robotics
## Abstract:
This paper presents a proof-of-concept soft robotic glove that provides haptic feedback to the surgeon’s hand during interventional endoscopy procedures, specifically colonoscopy. The glove is connected to a force sensing soft robotic sleeve that is mounted onto a colonoscope. The glove consists of pneumatic actuators that inflate in proportion to the incident forces on the soft robotic sleeve. Thus, the glove is capable of alerting the surgeon of potentially dangerous forces exerted on the colon wall by the colonoscope during the navigation. The proposed glove is adaptable to a variety of hand sizes. It features modular actuators that facilitate convenient and rapid assembly and attachment before the procedure and removal afterward. The glove is calibrated to respond to incident forces on the soft robotic sleeve ranging from 0-3 N. The glove’s actuators are able to reach an internal pressure of 53 kPa and exert forces up to 20 N, thereby relaying and amplifying the force exerted by the colonoscope on the colon to the surgeon’s hand.
# A Large-Area Wearable Soft Haptic Device Using Stacked Pneumatic Pouch Actuation
## Keywords:
- Haptics and Haptic Interfaces
- Soft Sensors and Actuators
## Abstract:
While haptics research has traditionally focused on the fingertips and hands, other locations on the body provide large areas of skin that could be utilized to relay large-area haptic sensations. Researchers have thus developed wearable devices that use distributed vibrotactile actuators and distributed pneumatic force displays, but these methods have limitations. In prior work, we presented a novel actuation technique involving stacking pneumatic pouches and evaluated the actuator output. In this work, we developed a wearable haptic device using this actuation technique and evaluated how the actuator output is perceived. We conducted a user study with 20 participants to evaluate users’ perception thresholds, ability to localize, and ability to detect differences in contact area and compare their perception using the stacked pneumatic pouch actuation to traditional single-layer pouch actuation. We also used our device with stacked pneumatic actuation in a demonstration of a haptic hug that replicates the dynamics, pressure profile, and mapping to the human back, showcasing how this actuation technique can be used to create novel haptic stimuli.
# EMG-Based Feedback Modulation for Increased Transparency in Teleoperation
## Keywords:
- Haptics and Haptic Interfaces
- Telerobotics and Teleoperation
## Abstract:
In interacting with stiff environments through teleoperated systems, time delays cause a mismatch between haptic feedback and the expected feedback by the operator. This mismatch causes artefacts in the feedback, which decrease transparency, but so does filtering these artefacts. Through modelling of operator stiffness and the expected feedback force with EMG, the artifacts can be selectively filtered without loss of transparency. We developed several feedback modulation techniques to bring the feedback force closer to the expected force: 1) the average between the modelled operator force and the feedback force, 2) a low pass filter and 3) a scaling modulation. To control for overdamping, a transparency check is included. We show that the averaging approach yields significantly better contacts than unmodulated feedback. None of the modulation algorithms differ significantly from the unmodulated feedback in transparency.
# Cutaneous Feedback Interface for Teleoperated In-Hand Manipulation
## Keywords:
- Haptics and Haptic Interfaces
- Telerobotics and Teleoperation
- In-Hand Manipulation
## Abstract:
In-hand pivoting is one of the important manipulation skills that leverage robot grippers’ extrinsic dexterity to perform repositioning tasks to compensate for environmental uncertainties and imprecise motion execution. Although many researchers have been trying to solve pivoting problems using mathematical modeling or learning-based approaches, the problems remain as open challenges. On the other hand, humans perform in-hand manipulation with remarkable precision and speed. Hence, the solution could be provided by making full use of this intrinsic human skill through dexterous teleoperation. For dexterous teleoperation to be successful, interfaces that enhance and complement haptic feedback are of great necessity. In this paper, we propose a cutaneous feedback interface that complements the somatosensory information humans rely on when performing dexterous skills. The interface is designed based on five-bar link mechanisms and provides two contact points in the index finger and thumb for cutaneous feedback. By integrating the interface with a commercially available haptic device, the system can display information such as grasping force, shear force, friction, and grasped object’s pose. Passive pivoting tasks inside a numerical simulator Isaac Sim is conducted to evaluate the effect of the proposed cutaneous feedback interface.
# Sensorimotor Control Sharing with Vibrotactile Feedback for Body Integration through Avatar Robot
## Keywords:
- Haptics and Haptic Interfaces
- Telerobotics and Teleoperation
- Human Performance Augmentation
## Abstract:
An avatar robot can be operated by multiple users, augmenting the operation of a single user. In this study, we assembled a collaborative operation system for a 7-DoF robotic arm with a gripper controlled by two users. The users share the role of controlling the robot with one user controlling the arm and the other controlling the gripper. The actions of the two users must be seamlessly coordinated to ensure smooth and precise operations. Therefore, this study aimed to investigate vibrotactile feedback to promote recognition of the actions of a partner. A pick-and-place task was considered as a basic operation. First, an intensity adjustment was developed for vibrotactile feedback to ensure linear sensitivity and its usefulness was verified. An estimation test for the reaching motion showed that the target position was estimated accurately based on velocity feedback, indicating that the participants imaged the arm motion. Subsequently, collaboration tests with and without vibrotactile velocity feedback revealed a potential effect of vibrotactile feedback in terms of reducing the time required for completing the target task. Our experimental results indicate that vibrotactile feedback for partner's motion can be applied to achieve smooth collaborative operations using an avatar robot.
# Perception of Mechanical Properties Via Wrist Haptics: Effects of Feedback Congruence
## Keywords:
- Haptics and Haptic Interfaces
- Virtual Reality and Interfaces
- Wearable Robotics
## Abstract:
Despite non-co-location, haptic stimulation at the wrist can potentially provide feedback regarding interactions at the fingertips without encumbering the user's hand. Here we investigate how two types of skin deformation at the wrist (normal and shear) relate to the perception of the mechanical properties of virtual objects. We hypothesized that a congruent mapping (i.e. when the most relevant interaction forces during a virtual interaction spatially match the haptic feedback at the wrist) would result in better perception than other mappings. We performed an experiment where haptic devices at the wrist rendered either normal or shear feedback during manipulation of virtual objects with varying stiffness, mass, or friction properties. Perception of mechanical properties was more accurate with congruent skin stimulation than noncongruent. In addition, discrimination performance and subjective reports were positively influenced by congruence. This study demonstrates that users can perceive mechanical properties via haptic feedback provided at the wrist with a consistent mapping between haptic feedback and interaction forces at the fingertips, regardless of congruence.
# Haptic Feedback Relocation from the Fingertips to the Wrist for Two-Finger Manipulation in Virtual Reality
## Keywords:
- Haptics and Haptic Interfaces
- Wearable Robotics
- Virtual Reality and Interfaces
## Abstract:
Relocation of haptic feedback from the fingertips to the wrist has been considered as a way to enable haptic interaction with mixed reality virtual environments while leaving the fingers free for other tasks. We present a pair of wrist-worn tactile haptic devices and a virtual environment to study how various mappings between fingers and tactors affect task performance. The haptic feedback rendered to the wrist reflects the interaction forces occurring between a virtual object and virtual avatars controlled by the index finger and thumb. We performed a user study comparing four different finger-to tactor haptic feedback mappings and one no-feedback condition as a control. We evaluated users’ ability to perform a simple pick-and-place task via the metrics of task completion time, path length of the fingers and virtual cube, and magnitudes of normal and shear forces at the fingertips. We found that multiple mappings were effective, and there was a greater impact when visual cues were limited. We discuss the limitations of our approach and describe next steps toward multi-degree-of-freedom haptic rendering for wrist-worn devices to improve task performance in virtual environments.
# Feeling the Pressure: The Influence of Vibrotactile Patterns on Feedback Perception
## Keywords:
- Haptics and Haptic Interfaces
- Prosthetics and Exoskeletons
- Telerobotics and Teleoperation
## Abstract:
Tactile feedback is necessary for closing the sensorimotor loop in prosthetic and tele-operable control, which would allow for more precise manipulation and increased acceptance of use of such devices. Pressure stimuli are commonly presented to users in haptic devices through a sensory substitution to vibration. The precise nature of this substitution affects pressure sensitivity, as well as the comfort and intuitiveness of the device for the user. This study determines the effects of different vibrational encodings for pressure on user-preference and performance in a 4-alternative absolute identification task. 4 different encoding patterns for pressure were examined: short pulse and long pulse amplitude modulation along with sine and square wave frequency modulation. Of the methods examined, frequency modulation methods led to the best discrimination of stimuli (p < 0.001). There was a notable difference in user preference between the two frequency modulated systems, with sinusoidal stimulation being highest ranked across all the preference metrics and square-wave being ranked lowest in two of the three. This difference trended towards, but did not achieve statistical significance (TLX rankings, p = 0.098). This suggests that prostheses or teleoperated devices utilising vibrotactile feedback may benefit from implementing a discrete frequency-based sinusoidal pattern to indicate changes in grip force
# Human Factors and Human-In-The-Loop
# SPARCS: Structuring Physically Assistive Robotics for Caregiving with Stakeholders-In-The-Loop
## Keywords:
- Human Factors and Human-in-the-Loop
- Physical Human-Robot Interaction
- Human-Centered Robotics
## Abstract:
Existing work in physical robot caregiving is limited in its ability to provide long-term assistance. This is due to (i) lack of well-defined problems, (ii) diversity of tasks, and (iii) limited access to stakeholders from the caregiving community. We propose Structuring Physically Assistive Robotics for Caregiving with Stakeholders-in-the-loop (SPARCS) to address these challenges. SPARCS is a framework for physical robot caregiving comprising (i) Building Blocks that define physical robot caregiving scenarios, (ii) Structured Workflows # hierarchical workflows that enable us to answer the Whats and Hows of physical robot caregiving, and (iii) SPARCS-box, a web-based platform to facilitate dialogue between all stakeholders. We collect clinical data for six care recipients with varying disabilities and demonstrate the use of SPARCS in designing well-defined caregiving scenarios and identifying their care requirements. All the data and workflows from this study are available on SPARCS-box. We demonstrate the utility of SPARCS in building a robot-assisted feeding system for one of the care recipients. We also perform experiments to show the adaptability of this system to different caregiving scenarios. Finally, we identify open challenges in physical robot caregiving by consulting care recipients and caregivers. Supplementary material can be found at emprise.cs.cornell.edu/sparcs/.
# To Ask for Help or Not to Ask: A Predictive Approach to Human-In-The-Loop Motion Planning for Robot Manipulation Tasks
## Keywords:
- Human Factors and Human-in-the-Loop
- Manipulation Planning
- Motion and Path Planning
## Abstract:
We present a predictive system for non-prehensile, physics-based motion planning in clutter with a human-in-the-loop. Recent shared-autonomous systems present motion planning performance improvements when high-level reasoning is provided by a human. Humans are usually good at quickly identifying high-level actions in high-dimensional spaces, and robots are good at converting high-level actions into valid robot trajectories. In this paper, we present a novel framework that permits a single human operator to effectively guide a fleet of robots in a virtual warehouse. The robots are tackling the problem of Reaching Through Clutter (RTC), where they are reaching onto cluttered shelves to grasp a goal object while pushing other obstacles out of the way. We exploit information from the motion planning algorithm to predict which robot requires human help the most and assign that robot to the human. With twenty virtual robots and a single human-operator, the results suggest that this approach improves the system’s overall performance compared to a baseline with no predictions. The results also show that there is a cap on how many robots can effectively be guided simultaneously by a single human operator.
# You Are in My Way: Non-Verbal Social Cues for Legible Robot Navigation Behaviors
## Keywords:
- Robot Companions
- Gesture, Posture and Facial Expressions
- Design and Human Factors
## Abstract:
People and robots may need to cross each other in narrow spaces when they are sharing environments. It is expected that autonomous robots will behave in these contexts safely but also show social behaviors. Thereby, developing an acceptable behavior for autonomous robots in the area mentioned above is a foreseeable problem for the Human-Robot Interaction (HRI) field. Our current work focuses on integrating legible non-verbal behaviors into the robot's social navigation to make nearby humans aware of its intended trajectory. Results from a within-subjects study involving 33 participants show that deictic gestures as navigational cues for humanoid robots result in fewer navigation conflicts than the use of a simulated gaze. Additionally, an increase in the perceived anthropomorphism is found when the robot uses the deictic gesture as a cue. These findings show the importance of social behaviors for people avoidance and suggest a paradigm of such behaviors in future humanoid robotic applications.
# Robot Trajectory Adaptation to Optimise the Trade-Off between Human Cognitive Ergonomics and Workplace Productivity in Collaborative Tasks
## Keywords:
- Human Factors and Human-in-the-Loop
- Human-Centered Robotics
- Human-Robot Collaboration
## Abstract:
In hybrid industrial environments, workers' comfort and positive perception of safety are essential requirements for successful acceptance and usage of collaborative robots. This paper proposes a novel human-robot interaction framework in which the robot behaviour is adapted online according to the operator's cognitive workload and stress. The method exploits the generation of B-spline trajectories in the joint space and formulation of a multi-objective optimisation problem to online adjust the total execution time and smoothness of the robot trajectories. The former ensures human efficiency and productivity of the workplace, while the latter contributes to safeguarding the user's comfort and cognitive ergonomics. The performance of the proposed framework was evaluated in a typical industrial task. Results demonstrated its capability to enhance the productivity of the human-robot dyad while mitigating the cognitive workload induced in the worker.
# EMG-Based Hybrid Impedance-Force Control for Human-Robot Collaboration on Ultrasound Imaging
## Keywords:
- Physical Human-Robot Interaction
- Compliance and Impedance Control
- Medical Robots and Systems
## Abstract:
Ultrasound (US) imaging is a common but physically demanding task in the medical field, and sonographers may need to put in considerable physical effort for producing high-quality US images. During physical human-robot interaction on US imaging, robot compliance is a critical feature that can ensure human user safety while automatic force regulation ability can help to improve task performance. However, higher robot compliance may mean lower force regulation accuracy, and vice versa. Especially, the contact/non-contact status transition can largely affect the control system stability. In this paper, a novel electromyography (EMG)-based hybrid impedance-force control system is developed for US imaging task. The proposed control system incorporates the robot compliance and force regulation ability via a hybrid controller while the EMG channel enables the user to online modulate the trade-off between the two features as necessary. Two experiments are conducted to examine the hybrid controller and show the necessity of involving an EMG-based modulator. A proof-of-concept study on US imaging is performed with implementing the proposed EMG-based control system, and the effectiveness is demonstrated. The proposed control system is promising to ensure robot's stability and patient's safety, thus obtain high-quality US images, while monitoring and reducing sonographer's fatigue. Furthermore, it can be easily adapted to other physically demanding tasks in the field of medicine.
# Modeling Human Response to Robot Errors for Timely Error Detection
## Keywords:
- Human Factors and Human-in-the-Loop
- Physical Human-Robot Interaction
- Failure Detection and Recovery
## Abstract:
In human-robot collaboration, robot errors are inevitable---damaging user trust, willingness to work together, and task performance. Prior work has shown that people naturally respond to robot errors socially and that in social interactions it is possible to use human responses to detect errors. However, there is little exploration in the domain of non-social, physical human-robot collaboration such as assembly and tool retrieval. In this work, we investigate how people's organic, social responses to robot errors may be used to enable timely automatic detection of errors in physical human-robot interactions. We conducted a data collection study to obtain facial responses to train a real-time detection algorithm and a case study to explore the generalizability of our method with different task settings and errors. Our results show that natural social responses are effective signals for timely detection and localization of robot errors even in non-social contexts and that our method is robust across a variety of task contexts, robot errors, and user responses. This work contributes to robust error detection without detailed task specifications.
# Effects of Multiple Avatar Images Presented Consecutively with Temporal Delays on Self-Body Recognition
## Keywords:
- Human Factors and Human-in-the-Loop
- Virtual Reality and Interfaces
- Telerobotics and Teleoperation
## Abstract:
Self-body awareness refers to the recognition of one's body as one's own and consists of two senses: "sense of body ownership" and "sense of agency." In telexistence/telepresence robot operation, time delays in the robot's motion degrade self-body awareness of the robot body. We investigated how self-body recognition can be affected in a telexistence robot operation in a VR space when the robot is presented with a real robot arm that simulates a real robot with a delay and a virtual robot arm, or several virtual robot arms, with a delay less than that of the real robot. These experimental conditions include a 'Predictive Display,' which is well known as a time delay countermeasure. The results suggest that virtual robot arms presented consecutively with less delay than a real robot arm do not induce a sense of body ownership to the real robot arm, but they enhance the sense of agency to the real robot arm, and that sense of agency is stronger when the task requires precision.
# Interactive Reinforcement Learning with Bayesian Fusion of Multimodal Advice
## Keywords:
- Human Factors and Human-in-the-Loop
- Multi-Modal Perception for HRI
- Reinforcement Learning
## Abstract:
Interactive Reinforcement Learning (IRL) has shown promising results in decreasing the learning times of Reinforcement Learning algorithms by incorporating human feedback and advice. In particular, the integration of multimodal feedback channels such as speech and gestures into IRL systems can enable more versatile and natural interaction of everyday users. In this paper, we propose a novel approach to integrate human advice from multiple modalities into IRL algorithms. For each advice modality we assume an individual base classifier that outputs a categorical probability distribution and fuse these distributions using the Bayesian fusion method Independent Opinion Pool. While existing approaches rely on heuristic fusion, our Bayesian approach is theoretically founded and fully exploits the uncertainty represented in the distributions. Experimental evaluations in a simulated grid world scenario and on a real-world human-robot interaction task with a 7-DoF robot arm show that our method clearly outperforms the closest related approach for multimodal IRL. In particular, our novel approach is more robust against misclassifications of the modalities' individual base classifiers.
# A Camera-Based Deep-Learning Solution for Visual Attention Zone Recognition in Maritime Navigational Operations
## Keywords:
- Human Factors and Human-in-the-Loop
- Computer Vision for Transportation
- Deep Learning for Visual Perception
## Abstract:
The visual attention of navigators is imperative to understanding the logic of navigation and the surveillance of the navigators' status and operations. Currently, existing studies are implemented under the help of wearable eye-tracker glasses, while the high expenditure demanded by the equipment and service and the limitations on usability have impeded the relevant research to be performed extensively. In this letter, the authors propose a framework which is the first attempt in the maritime domain to provide a camera-based deep-learning (CaBDeeL) visual attention recognition solution to outperform the intrusive eye tracker in terms of the shortcomings. A wide-angle camera is configured in front of the navigator in the advanced ship-bridge simulator so that visual attention reflected by the facial and head movements is captured at the front view. A pair of eye-tracker glasses are used to classify the captured visual attention images to establish the primary database. While the camera-captured images are classified, a convolutional neural network (CNN) is built as an automatic classifier. The CNN is applied to two scenarios, and it scores an overall 95 % precision.
# Visual Learning
# Spatiotemporally Enhanced Photometric Loss for Self-Supervised Monocular Depth Estimation
## Keywords:
- Deep Learning for Visual Perception
- Visual Learning
- Deep Learning Methods
## Abstract:
Recovering depth information from a single image is a long-standing challenge, and self-supervised depth estimation methods have gradually attracted attention due to not relying on high-cost ground truth. Constructing an accurate photometric loss based on photometric consistency is crucial for these self-supervised methods to obtain high-quality depth maps. However, the photometric loss in most studies treats all pixels indiscriminately, resulting in poor performance. In this paper, we propose two modules based on the spatial and temporal cues to refine the photometric loss. Delving into the geometric model of photometric consistency, we introduce a depth-aware pixel correspondence module (DPC) inside the monocular depth estimation pipeline. It reduces the uncertainty of photometric errors by applying the homography matrix to the projection of corresponding pixels in far regions instead of the fundamental matrix. Furthermore, we design an omnidirectional auto-masking module (OA) to boost the robustness of our model, which utilizes temporal sequences to generate disturbance poses and hypothetical views to distinguish dynamic objects with different directions that violate the photometric consistency. Experiments on the KITTI and the Make3d datasets reveal that our framework achieves state-of-the-art performance.
# J-RR: Joint Monocular Depth Estimation and Semantic Edge Detection Exploiting Reciprocal Relations
## Keywords:
- Deep Learning for Visual Perception
- Visual Learning
## Abstract:
Depth estimation and semantic edge detection are two key tasks in computer vision, which have made great progress. To date, how to associatively predict the depth and the semantic edge is rarely explored. In this work, we first propose a flexible two-branch framework that can make the two tasks take advantage of each other, achieving a win-win situation. Specifically, for the semantic edge detection branch, an Enhanced Edge Weighting strategy (EEW) is designed, which learns weight information from the by-product of depth branch, depth edge, to enhance edge perception in features. Meanwhile, we make depth estimation benefit from semantic edge detection through introducing Depth Edge Semantic Classification module (DESC). Furthermore, a double reconstruction (D-reconstruction) approach is presented, together with semantic edge-guided disparity smoothing loss to mitigate the ambiguities of the self-supervised manner for depth estimation. Experiments on the Cityscapes dataset demonstrate that our framework outperforms the state-of-the-art method in depth estimation along with a significant improvement in semantic edge detection.
# Towards Two-View 6D Object Pose Estimation: A Comparative Study on Fusion Strategy
## Keywords:
- Deep Learning for Visual Perception
- Visual Learning
- Perception for Grasping and Manipulation
## Abstract:
Current RGB-based 6D object pose estimation methods have achieved noticeable performance on datasets and real world applications. However, predicting 6D pose from single 2D image features is susceptible to disturbance from changing of environment and textureless or resemblant object surfaces. Hence, RGB-based methods generally achieve less competitive results than RGBD-based methods, which deploy both image features and 3D structure features. To narrow down this performance gap, this paper proposes a framework for 6D object pose estimation that learns implicit 3D information from 2 RGB images. Combining the learned 3D information and 2D image features, we establish more stable correspondence between the scene and the object models. To seek for the methods best utilizing 3D information from RGB inputs, we conduct an investigation on three different approaches, including Early# Fusion, Mid-Fusion, and Late-Fusion. We ascertain the Mid# Fusion approach is the best approach to restore the most precise 3D keypoints useful for object pose estimation. The experiments show that our method outperforms state-of-the-art RGB-based methods, and achieves comparable results with RGBD-based methods.
# Maximizing Self-Supervision from Thermal Image for Effective Self-Supervised Learning of Depth and Ego-Motion
## Keywords:
- Deep Learning for Visual Perception
- Visual Learning
- Computer Vision for Transportation
## Abstract:
Recently, self-supervised learning of depth and ego-motion from thermal images shows strong robustness and reliability under challenging lighting and weather conditions. However, the inherent thermal image properties such as weak contrast, blurry edges, and noise hinder to generate effective self-supervision from thermal images. Therefore, most previous researches just rely on additional self-supervisory sources such as RGB video, generative models, and Lidar information. In this paper, we conduct an in-depth analysis of thermal image characteristics that degenerates self-supervision from thermal images. Based on the analysis, we propose an effective thermal image mapping method that significantly increases image information, such as overall structure, contrast, and details, while preserving temporal consistency. By resolving the fundamental problem of the thermal image, our depth and pose network trained only with thermal images achieves state-of-the-art results without utilizing any extra self-supervisory source. As our best knowledge, this work is the first self-supervised learning approach to train monocular depth and relative pose networks with only thermal images.
# Domain Invariant Siamese Attention Mask for Small Object Change Detection Via Everyday Indoor Robot Navigation
## Keywords:
- Visual Learning
- Object Detection, Segmentation and Categorization
- Data Sets for Robotic Vision
## Abstract:
The problem of image change detection via everyday indoor robot navigation is explored from a novel perspective of the self-attention technique. Detecting semantically non-distinctive and visually small changes remains a key challenge in the robotics community. Intuitively, these small non-distinctive changes may be better handled by the recent paradigm of the attention mechanism, which is the basic idea of this work. However, existing self-attention models require significant retraining cost per domain, so it is not directly applicable to robotics applications. We propose a new self-attention technique with an ability of unsupervised on-the-fly domain adaptation, which introduces an attention mask into the intermediate layer of an image change detection model, without modifying the input and output layers of the model. Experiments, in which an indoor robot aims to detect visually small changes in everyday navigation, demonstrate that our attention technique significantly boosts the state-of-the-art image change detection model. We will make this new dataset publicly available for future research in this area.
# Investigation of Factorized Optical Flows As Mid-Level Representations
## Keywords:
- Visual Learning
- Machine Learning for Robot Control
- Collision Avoidance
## Abstract:
In this paper, we introduce a new concept of incorporating factorized flow maps as mid-level representations, for bridging the perception and the control modules in modular learning based robotic frameworks. To investigate the advantages of factorized flow maps and examine their interplay with the other types of mid-level representations, we further develop a configurable framework, along with four different environments that contain both static and dynamic objects, for analyzing the impacts of factorized optical flow maps on the performance of deep reinforcement learning agents.	Based on this framework, we report our experimental results on various scenarios, and offer a set of analyses to justify our hypothesis. Finally, we validate flow factorization in real world scenarios.
# Augment-Connect-Explore: A Paradigm for Visual Action Planning with Data Scarcity
## Keywords:
- Visual Learning
- Representation Learning
- Task Planning
## Abstract:
Visual action planning particularly excels in applications where the state of the system cannot be computed explicitly, such as manipulation of deformable objects, as it enables planning directly from raw images. Even though the field has been significantly accelerated by deep learning techniques, a crucial requirement for their success is the availability of a large amount of data. In this work, we propose the Augment-Connect-Explore (ACE) paradigm to enable visual action planning in cases of data scarcity. We build upon the Latent Space Roadmap (LSR) framework which performs planning with a graph built in a low dimensional latent space. In particular, ACE is used to i) Augment the available training dataset by autonomously creating new pairs of datapoints, ii) create new unobserved Connections among representations of states in the latent graph, and iii) Explore new regions of the latent space in a targeted manner. We validate the proposed approach on both simulated box stacking and real-world folding task showing the applicability for rigid and deformable object manipulation tasks, respectively.
# Learning 6-DoF Task-Oriented Grasp Detection Via Implicit Estimation and Visual Affordance
## Keywords:
- Visual Learning
- Deep Learning in Grasping and Manipulation
## Abstract:
Currently, task-oriented grasp detection approaches are mostly based on pixel-level affordance detection and semantic segmentation. These pixel-level approaches heavily rely on the accuracy of 2D affordance mask, and the generated grasp candidates are restricted to a small workspace. To mitigate these limitations, we proposed a novel 6-DoF task-oriented grasp detection framework, which takes the observed object point cloud as input and predicts diverse 6-DoF grasp poses for different tasks. Specifically, our implicit estimation network and visual affordance network in this framework could directly predict coarse grasp candidates, and corresponding 3D affordance heatmap for each potential task, respectively. Furthermore, the grasping scores from coarse grasps are combined with heatmap values to generate more accurate and finer candidates. Our proposed framework shows significant improvements compared to baselines for existing and novel objects on our self-constructed simulation dataset. Although our framework is trained based on the simulated objects and environment, the final generated grasp candidates can be accurately and stably executed in the real robot experiments when the object is randomly placed on a support surface.
# NARF22: Neural Articulated Radiance Fields for Configuration-Aware Rendering
## Keywords:
- Visual Learning
- RGB-D Perception
- Deep Learning for Visual Perception
## Abstract:
Articulated objects pose a unique challenge for robotic perception and manipulation. Their increased number of degrees-of-freedom makes tasks such as localization computationally difficult, while also making the process of realworld dataset collection unscalable. With the aim of addressing these scalability issues, we propose Neural Articulated Radiance Fields (NARF22), a pipeline which uses a fully-differentiable, configuration-parameterized Neural Radiance Field (NeRF) as a means of providing high quality renderings of articulated objects. NARF22 requires no explicit knowledge of the object structure at inference time. We propose a two-stage parts-based training mechanism which allows the object rendering models to generalize well across the configuration space even if the underlying training data has as few as one configuration represented. We demonstrate the efficacy of NARF22 by training configurable renderers on a real-world articulated tool dataset collected via a Fetch mobile manipulation robot. We show the applicability of the model to gradient-based inference methods through a configuration estimation and 6 degree-of-freedom pose refinement task.
# Mapping 1
# Multi-Agent Relative Pose Estimation with UWB and Constrained Communications
## Keywords:
- Localization
- Multi-Robot Systems
- Range Sensing
## Abstract:
Inter-agent relative localization is critical for any multi-robot system operating in the absence of external positioning infrastructure or prior environmental knowledge. We propose a novel inter-agent relative 2D pose estimation system where each participating agent is equipped with several ultra-wideband (UWB) ranging tags. Prior work typically supplements noisy UWB range measurements with additional continuously transmitted data, such as odometry, making these approaches scale poorly with increased swarm size or decreased communication throughput. This approach addresses these concerns by using only locally collected UWB measurements with no additionally transmitted data. By modeling observed ranging biases and systematic antenna obstructions in our proposed optimization solution, our experimental results demonstrate an improved mean position error (while remaining competitive in other metrics) over a similar state-of-the-art approach that additionally relies on continuously transmitted odometry.
# Ranging-Aided Ground Robot Navigation Using UWB Nodes at Unknown Locations
## Keywords:
- Localization
- Range Sensing
- Cooperating Robots
## Abstract:
Ranging information from ultra-wideband (UWB) ranging radios can be used to improve estimated navigation accuracy of a ground robot with other on-board sensors. However, all ranging-aided navigation methods demand the locations of ranging nodes to be known, which is not suitable for time-pressed situations, dynamic cluttered environments, or collaborative navigation applications. This paper describes a new ranging-aided navigation approach that does not require the locations of ranging radios. Our approach formulates relative pose constraints using ranging readings. The formulation is based on geometric relationships between each stationary ranging node and two ranging antennas on the moving robot across time. Our experiments show that estimated navigation accuracy of the ground robot is substantially enhanced with ranging information using our approach under a variety of scenarios, when ranging nodes are placed at unknown locations. We analyze and compare our performance with a traditional ranging-aided method, which requires mapping the positions of ranging nodes. We also demonstrate the applicability of our approach for collaborative navigation in large-scale unknown environments, by using ranging information from one mobile robot to improve navigation estimation of the other robot. This application does not require the installation of ranging nodes at fixed locations.
# Efficient and Probabilistic Adaptive Voxel Mapping for Accurate Online LiDAR Odometry
## Keywords:
- Mapping
- Localization
- SLAM
## Abstract:
This paper proposes an efficient and probabilistic adaptive voxel mapping method for LiDAR odometry. The map is a collection of voxels; each contains one plane (or edge) feature that enables the probabilistic representation of the environment and accurate registration of a new LiDAR scan. We further analyze the need for coarse-to-fine voxel mapping and then use a novel voxel map organized by a Hash table and octrees to build and update the map efficiently. We apply the proposed voxel map to an iterated extended Kalman filter and construct a maximum a posteriori probability problem for pose estimation. Experiments on the open KITTI dataset show the high accuracy and efficiency of our method compared to other state-of-the-art methods. Outdoor experiments on unstructured environments with non-repetitive scanning LiDARs further verify the adaptability of our mapping method to different environments and LiDAR scanning patterns (see our attached video). Our codes and dataset are open-sourced on Github.
# 360ST-Mapping: An Online Semantics-Guided Topological Mapping Module for Omnidirectional Visual SLAM
## Keywords:
- Mapping
- Omnidirectional Vision
- SLAM
## Abstract:
As an abstract representation of the environment structure, a topological map has advantageous properties for path-planning and navigation. Here we proposed an online topological mapping method, 360ST-Mapping, using omnidirectional vision. The 360-degree field-of-view allows the agent to obtain consistent observation and incrementally extract topological environment information. Moreover, we leverage semantic information to guide topological place recognition, further improving performance. The topological map possessing semantic information has the potential to support semantics-related advanced tasks. After integrating the topological mapping module into the omnidirectional visual SLAM system, we conducted extensive experiments in several large-scale indoor scenes and validated the method’s effectiveness.
# Online Distance Field Priors for Gaussian Process Implicit Surfaces
## Keywords:
- Mapping
## Abstract:
Gaussian process (GP) implicit surface models provide environment and object representations which elegantly address noise and uncertainty while remaining sufficiently flexible to capture complex geometry. However, GP models quickly become intractable as the size of the observation set grows # a trait which is difficult to reconcile with the rate at which modern range sensors produce data. Furthermore, naive applications of GPs to implicit surface models allocate model resources uniformly, thus using precious resources to capture simple geometry. In contrast to prior work addressing these challenges though model sparsification, spatial partitioning, or ad-hoc filtering we propose introducing model bias online through the GP's mean function. We achieve more accurate distance fields using smaller models by creating a distance field prior from features which are easy to extract and have analytic distance fields. In particular, we demonstrate this approach using linear features. We show the proposed distance field halves model size in a 2D mapping task using data from a SICK S300 sensor. When applied to a single 3D scene from the TUM RGB-D SLAM dataset we achieve a fivefold reduction in model size. Our proposed prior results in more accurate GP implicit surfaces, while allowing existing models to function in larger environments or with larger spatial partitions due to reduced model size.
# An Algorithm for the SE(3)-Transformation on Neural Implicit Maps for Remapping Functions
## Keywords:
- Mapping
- SLAM
## Abstract:
Implicit representations are widely used for object reconstruction due to their efficiency and flexibility. In 2021, a novel structure named neural implicit map has been invented for incremental reconstruction. A neural implicit map alleviates the problem of inefficient memory cost of previous online 3D dense reconstruction while producing better quality. However, the neural implicit map suffers the limitation that it does not support remapping as the frames of scans are encoded into a deep prior after generating the neural implicit map. This means, that neither this generation process is invertible, nor a deep prior is transformable. The non-remappable property makes it not possible to apply loop-closure techniques. We present a neural implicit map based transformation algorithm to fill this gap. As our neural implicit map is transformable, our model supports remapping for this special map of latent features. Experiments show that our remapping module is capable to well-transform neural implicit maps to new poses. Embedded into a SLAM framework, our mapping model is able to tackle the remapping of loop closures and demonstrates high-quality surface reconstruction. Our implementation is available at githubfootnote{url{https://github.com/Jarrome/IMT_Mapping}} for the research community.
# PlaneSDF-Based Change Detection for Long-Term Dense Mapping
## Keywords:
- Mapping
- SLAM
- Range Sensing
## Abstract:
The ability to process environment maps across multiple sessions is critical for robots operating over extended periods of time. Specifically, it is desirable for autonomous agents to detect changes amongst maps of different sessions so as to gain a conflict-free understanding of the current environment. In this paper, we look into the problem of change detection based on a novel map representation, dubbed Plane Signed Distance Fields (PlaneSDF), where dense maps are represented as a collection of planes and their associated geometric components in SDF volumes. Given point clouds of the source and target scenes, we propose a three-step PlaneSDF-based change detection approach: (1) PlaneSDF volumes are instantiated within each scene and registered across scenes using plane poses; 2D height maps and object maps are extracted per volume via height projection and connected component analysis. (2) Height maps are compared and intersected with the object map to produce a 2D change location mask for changed object candidates in the source scene. (3) 3D geometric validation is performed using SDF-derived features per object candidate for change mask refinement. We evaluate our approach on both synthetic and real-world datasets and demonstrate its effectiveness via the task of changed object detection. Supplementary video is available at: [https://youtu.be/oh-MQPWTwZI](https://youtu.be/oh-MQPWTwZI)
# Efficient 2D LIDAR Based Map Updating for Long Term Operations in Dynamic Environments
## Keywords:
- Mapping
- Localization
- SLAM
## Abstract:
Long-time operations of autonomous vehicles and mobile robots in logistics and service applications are still a challenge. To avoid a continuous re-mapping, the map can be updated to obtain a consistent representation of the current environment. In this paper, we propose a novel LIDAR-based occupancy grid map updating algorithm for dynamic environments taking into account possible localisation and measurement errors. The proposed approach allows robust long-term operations as it can detect changes in the working area even in presence of moving elements. Results highlighting maps quality and localisation performance, both in simulation and experiments, are reported. We will extend localisation performance analysis to real-world experiments employing an external tracking system.
# Monocular UAV Localisation with Deep Learning and Uncertainty Propagation
## Keywords:
- Localization
- Aerial Systems: Applications
- Visual Tracking
## Abstract:
In this paper, we propose a ground-based monocular UAV localisation system that detects and localises an LED marker attached to the underside of a UAV. Our system removes the need for extensive infrastructure and calibration unlike existing technologies such as UWB, radio frequency and multi-camera systems often used for localisation in GPS-denied environment. To improve deployablity for real-world applications without the need to collect extensive real dataset, we train a CNN on synthetic binary images as opposed to using real images in existing monocular UAV localisation methods, and factor in the camera’s zoom to allow tracking of UAVs flying at further distances. We propose NoisyCutout algorithm for augmenting synthetic binary images to simulate binary images processed from real images and show that it improves localisation accuracy as compared to using existing salt-and-pepper and Cutout augmentation methods. We also leverage uncertainty propagation to modify the CNN’s loss function and show that this also improves localisation accuracy. Real-world experiments are conducted to evaluate our methods and we achieve an overall 3D RMSE of approximately 0.41m.
# Human-Centered Robotics 1
# Task Decoupling in Preference-Based Reinforcement Learning for Personalized Human-Robot Interaction
## Keywords:
- Human-Centered Robotics
- Reinforcement Learning
- Human-Robot Collaboration
## Abstract:
Intelligent robots designed to interact with humans in the real world need to adapt to the preferences of different individuals. Preference-based reinforcement learning (RL) has shown great potential for teaching robots to learn personalized behaviors from interacting with humans without a meticulous, hand-crafted reward function, replaced by learning reward based on a human's preferences between two robot trajectories. However, poor feedback efficiency and poor exploration in the state and reward spaces make current preference-based RL algorithms perform poorly in complex interactive tasks. To improve the performance of preference-based RL, we incorporate prior knowledge of the task into preference-based RL. Specifically, we decouple the task from preference in human-robot interaction. We utilize a sketchy task reward derived from task priori to instruct robots to conduct more effective task exploration. Then a learned reward from preference-based RL is used to optimize the robot's policy to align with human preferences. In addition, these two parts are combined organically via reward shaping. The experimental results show that our method is a practical and effective solution for personalized human-robot interaction. Code is available at https://github.com/Wenminggong/PbRL_for_PHRI.
# Holo-SpoK: Affordance-Aware Augmented Reality Control of Legged Manipulators
## Keywords:
- Human-Centered Robotics
- Virtual Reality and Interfaces
- Human-Robot Collaboration
## Abstract:
Although there is extensive research regarding legged manipulators, comparatively little focuses on their User Interfaces (UIs). Towards extending the state-of-art in this domain, in this work, we integrate a Boston Dynamics (BD) Spot with a light-weight 7 DoF Kinova robot arm and a Robotiq 2F-85 gripper into a legged manipulator. Furthermore, we jointly control the robotic platform using an affordance-aware Augmented Reality (AR) Head-Mounted Display (HMD) UI developed for the Microsoft HoloLens 2. We named the combined platform Holo-SpoK. Moreover, we explain how this manipulator colocalises with the HoloLens 2 for its control through AR. In addition, we present the details of our algorithms for autonomously detecting grasp-ability affordances and for the refinement of the positions obtained via vision-based colocalisation. We validate the suitability of our proposed methods with multiple navigation and manipulation experiments. To the best of our knowledge, this is the first demonstration of an AR HMD UI for controlling legged manipulators.
# Keeping Humans in the Loop: Teaching Via Feedback in Continuous Action Space Environments
## Keywords:
- Human-Centered Robotics
- Reinforcement Learning
- Human-Robot Collaboration
## Abstract:
Interactive Reinforcement Learning (IntRL) allows human teachers to accelerate the learning process of Reinforcement Learning (RL) robots. However, IntRL has largely been limited to tasks with discrete-action spaces in which actions are relatively slow. This limits IntRL’s application to more complicated and challenging robotic tasks, the very tasks that modern RL is particularly well-suited for. We seek to bridge this gap by presenting Continuous Action-space Interactive Reinforcement learning (CAIR): the first continuous action-space IntRL algorithm that is capable of using teacher feedback to out-perform state-of-the-art RL algorithms in those tasks. CAIR combines policies learned from the environment and the teacher into a single policy that proportionally weights the two policies based on their agreement. This allows a CAIR agent to learn a relatively stable policy despite potentially noisy or coarse teacher feedback. We validate our approach in two simulated robotics tasks with easy-to-design and -understand heuristic oracle teachers. Furthermore, we validate our approach in a human subjects study through Amazon Mechanical Turk and show CAIR out-performs the prior state-of-the-art in Interactive RL.
# An Adaptive, Affordable, Humanlike Arm Hand System for Deaf and Deaf Blind Communication with the American Sign Language
## Keywords:
- Human-Centered Robotics
- Physical Human-Robot Interaction
## Abstract:
To communicate, the sim1.5 million Americans living with deafblindess use tactile American Sign Language (t-ASL). To provide DeafBlind (DB) individuals with a means of using their primary communication language without the use of an interpreter, we developed an assistive technology that promotes their autonomy. The TATUM (Tactile ASL Translational User Mechanism) anthropomorphic arm hand system leverages previous developments of a fingerspelling hand to sign more complex ASL words and phrases. The TATUM hand-wrist system is attached onto a 4 DOF robot arm and a human motion recognition and human to robot gesture transfer framework is used for signing recognition and replication. In particular, signing trajectories based on vision-based motion capture data from a sign demonstrator were used to control the robot's actuators. The performance of the system was evaluated through tactile based sign recognition performed by a blinded user and for its accuracy with novice, sighted users.
# Examining Distance in UAV Gesture Perception
## Keywords:
- Human-Centered Robotics
- Gesture, Posture and Facial Expressions
- Aerial Systems: Applications
## Abstract:
Unmanned aerial vehicles (UAVs) are becoming more common, presenting the need for effective human-robot communication strategies that address the unique nature of unmanned aerial flight. Visual communication via drone flight paths, also called gestures, may prove to be an ideal method. However, the effectiveness of visual communication techniques is dependent on several factors including an observer's position relative to a UAV. Previous work has studied the maximum line-of-sight at which observers can identify a small UAV. However, this work did not consider how changes in distance may affect an observer's ability to perceive the shape of a UAV's motion. In this study, we conduct a series of online surveys to evaluate how changes in line-of-sight distance and gesture size affect observers' ability to identify and distinguish between UAV gestures. We first examine observers' ability to accurately identify gestures when adjusting a gesture's size relative to the size of a UAV. We then measure how observers' ability to identify gestures changes with respect to varying line-of-sight distances. Lastly, we consider how altering the size of a UAV gesture may improve an observer's ability to identify drone gestures from varying distances. Our results show that increasing the gesture size across varying UAV to gesture ratios did not have a significant effect on participant response accuracy. We found that between 17 m and 75 m from the observer, their ability to accurately identify a drone gesture was inversely proportional to the distance between the observer and the drone. Finally, we found that maintaining a gesture's apparent size improves participant response accuracy over changing line-of-sight distances.
# GA-STT: Human Trajectory Prediction with Group Aware Spatial-Temporal Transformer
## Keywords:
- Human-Centered Robotics
- Long term Interaction
- Modeling and Simulating Humans
## Abstract:
Human trajectory prediction is a crucial yet challenging problem, which is of fundamental importance to robotics and autonomous driving vehicles. The core challenge lies in effectively modelling the socially aware spatial interaction and complex temporal dependencies among crowds. However, previous methods either model spatial and temporal information separately or only use individual features without exploring the intra-structure of the crowds. We propose a novel trajectory prediction framework termed GA-STT, a group aware spatial-temporal transformer network to address these issues. Specifically, we first get the individual representations supervised by group-based annotations. Then, we model the complex spatial-temporal interactions with spatial and temporal transformers separately and fuse spatial-temporal embedding through the cross-attention mechanism. Results on the publicly available ETH/UCY datasets show that our model outperforms the state-of-the-art method by 19.4% in ADE and 16.9% in FDE and successfully predicts complex spatial-temporal interactions.
# Evaluating Human-Like Explanations for Robot Actions in Reinforcement Learning Scenarios
## Keywords:
- Human-Centered Robotics
- Reinforcement Learning
- Acceptability and Trust
## Abstract:
Explainable artificial intelligence is a research field that tries to provide more transparency for autonomous intelligent systems. Explainability has been used, particularly in reinforcement learning and robotic scenarios, to better understand the robot decision-making process. Previous work, however, has been widely focused on providing technical explanations that can be better understood by AI practitioners than non-expert end-users. In this work, we make use of human-like explanations built from the probability of success to complete the goal that an autonomous robot shows after performing an action. These explanations are intended to be understood by people who have no or very little experience with artificial intelligence methods. This paper presents a user trial to study whether these explanations that focus on the probability an action has of succeeding in its goal constitute a suitable explanation for non-expert end-users. The results obtained show that non-expert participants rate robot explanations that focus on the probability of success higher and with less variance than technical explanations generated from Q-values, and also favor counterfactual explanations over standalone explanations.
# A Modular and Portable Black Box Recorder for Increased Transparency of Autonomous Service Robots
## Keywords:
- Human-Centered Robotics
- Acceptability and Trust
## Abstract:
Autonomous service robots have great potential to support humans in tasks they cannot perform due to, amongst others, time constraints, work overload, or staff shortages. An important step for such service robots to be trusted or accepted by society is the provision of transparency. Its purpose is not only to communicate what a robot is doing according to the human interaction partners' needs, it should also regard social and legal requirements. A black box recorder (inspired by flight recorders) increases the system's transparency by facilitating the investigation of the cause of an incident, clarifying responsibilities, or improving the user's understanding about the robot. In this work we propose the needed requirements of such a black box recorder for increased transparency of autonomous service robots, based on the related work. Further, we present a new modular and portable black box recorder design meeting these requirements. The applicability of the system is evaluated based on real-world robot data, using the realized open-source reference implementation.
# Localization 1
# LiDAR-Aided Visual-Inertial Localization with Semantic Maps
## Keywords:
- Localization
## Abstract:
Accurate and robust localization is an essential task for autonomous driving systems. In this paper, we propose a novel 3D LiDAR-aided visual-inertial localization method. Our method fully explores the complementarity of visual and LiDAR observations. On the one hand, the association between semantic features in images and a given semantic map provides constraints for the absolute pose. On the other hand, LiDAR odometry (LO) can provide an accurate and robust 6DOF relative pose. The Error State Kalman Filter (ESKF) framework is exploited to estimate the vehicle pose relative to the semantic map, which fuses the global constraints between the image and the semantic map, the relative pose from the LO, and the raw IMU data. The method achieves centimeter-level localization accuracy in a variety of challenging scenarios. We validate the robustness and accuracy of our method in real-world scenes over 50 km. The experimental results show that the proposed method is able to achieve an average lateral accuracy of 0.059 m and longitudinal accuracy of 0.158 m, which demonstrates the practicality of the proposed system in autonomous driving applications.
# Robust Onboard Localization in Changing Environments Exploiting Text Spotting
## Keywords:
- Localization
## Abstract:
Robust localization in a given map is a crucial component of most autonomous robots. In this paper, we address the problem of localizing in an indoor environment that changes and where prominent structures have no correspondence in the map built at a different point in time. To overcome the discrepancy between the map and the observed environment caused by such changes, we exploit human-readable localization cues to assist localization. These cues are readily available in most facilities and can be detected using RGB camera images by utilizing text spotting. We integrate these cues into a Monte Carlo localization framework using a particle filter that operates on 2D LiDAR scans and camera data. By this, we provide a robust localization solution for environments with structural changes and dynamics by humans walking. We evaluate our localization framework on multiple challenging indoor scenarios in an office environment. The experiments suggest that our approach is robust to structural changes and can run on an onboard computer. We release an open source implementation of our approach (upon paper acceptance), which uses off-the-shelf text spotting, written in C++ with a ROS wrapper.Robust localization in a given map is a crucial component of most autonomous robots. In this paper, we address the problem of localizing in an indoor environment that changes and where prominent structures have no correspondence in the map built at a different point in time. To overcome the discrepancy between the map and the observed environment caused by such changes, we exploit human-readable localization cues to assist localization. These cues are readily available in most facilities and can be detected using RGB camera images by utilizing text spotting. We integrate these cues into a Monte Carlo localization framework using a particle filter that operates on 2D LiDAR scans and camera data. By this, we provide a robust localization solution for environments with structural changes and dynamics by humans walking. We evaluate our localization framework on multiple challenging indoor scenarios in an office environment. The experiments suggest that our approach is robust to structural changes and can run on an onboard computer. We release an open source implementation of our approach (upon paper acceptance), which uses off-the-shelf text spotting, written in C++ with a ROS wrapper.
# Fast Scan Context Matching for Omnidirectional 3D Scan
## Keywords:
- Localization
## Abstract:
Autonomous robots need to recognize the environment by identifying the scene. Scan context is one of global descriptors, and it encodes the three-dimensional scan data of the scene for the identification in a matrix form. Scan context is in a matrix form that is simple to store, but the matching of scan contexts can require computational effort because the descriptor is orientation-dependent. Because a scan context of an omnidirectional LiDAR scan becomes periodic in azimuth, this paper proposes to compute the scan context matching efficiently incorporating the cross-correlation with fast Fourier transform, and, hence, the method is named fast scan context matching. The effectiveness of the proposed method for computation time, accuracy, and robustness are reported in this paper. It is also shown that the method was also tested as a loop closure detector of a SLAM package as a practical application and that the proposed method outperformed the conventional scan context matching.
# Probabilistic Object Maps for Long-Term Robot Localization
## Keywords:
- Localization
- Mapping
## Abstract:
Robots deployed in settings such as warehouses and parking lots must cope with frequent and substantial changes when localizing in their environments. While many previous localization and mapping algorithms have explored methods of identifying and focusing on long-term features to handle change in such environments, we propose a different approach – can a robot understand the distribution of movable objects and relate it to observations of such objects to reason about global localization? In this paper, we present probabilistic object maps (POMs), which represent the distributions of movable objects using pose-likelihood sample pairs derived from prior trajectories through the environment and use a Gaussian process classifier to generate the likelihood of an object at a query pose. We also introduce POM-Localization, which uses an observation model based on POMs to perform inference on a factor graph for globally consistent long-term localization. We present empirical results showing that POM-Localization is indeed effective at producing globally consistent localization estimates in challenging real-world environments and that POM-Localization improves trajectory estimates even when the POM is formed from partially incorrect data.
# Level Set-Based Camera Pose Estimation from Multiple 2D/3D Ellipse-Ellipsoid Correspondences
## Keywords:
- Localization
- SLAM
## Abstract:
In this paper, we propose an object-based camera pose estimation from a single RGB image and a pre-built map of objects, represented with ellipsoidal models. We show that contrary to point correspondences, the definition of a cost function characterizing the projection of a 3D object onto a 2D object detection is not straightforward. We develop an ellipse-ellipse cost based on level sets sampling, demonstrate its nice properties for handling partially visible objects and compare its performance with other common metrics. Finally, we show that the use of a predictive uncertainty on the detected ellipses allows a fair weighting of the contribution of the correspondences which improves the computed pose. The code is released at gitlab.inria.fr/tangram/level-set-based-camera-pose-estimation.
# Optimal Localizability Criterion for Positioning with Distance-Deteriorated Relative Measurements
## Keywords:
- Localization
- Multi-Robot Systems
## Abstract:
Position estimation in Multi-Robot Systems (MRS) relies on relative angle or distance measurements between the robots, which generally deteriorate as distances increase. Moreover, the localization accuracy is strongly influenced both by the quality of the raw measurements but also by the overall geometry of the network. In this paper, we design a cost function that accounts for these two issues and can be used to develop motion planning algorithms that optimize the localizability in MRS, i.e., the ability of individual robots to localize themselves accurately. This cost function is based on computing new Cramer Rao Lower Bounds characterizing the achievable positioning performance with range and angle measurements that deteriorate with increasing distances. We describe a gradient-based motion-planning algorithm for MRS deployment that can be implemented in a distributed manner, as well as a non-myopic strategy to escape local minima. Finally, we test the proposed methodology experimentally for range measurements obtained using ultra-wide band transceivers and illustrate the improvements resulting from leveraging the more accurate measurement model in the robot placement algorithms.
# Improving Worst Case Visual Localization Coverage Via Place-Specific Sub-Selection in Multi-Camera Systems
## Keywords:
- Localization
- Autonomous Vehicle Navigation
## Abstract:
6-DoF visual localization systems utilize principled approaches rooted in 3D geometry to perform accurate camera pose estimation of images to a map. Current techniques use hierarchical pipelines and learned 2D feature extractors to improve scalability and increase performance. However, despite gains in typical recall@0.25m type metrics, these systems still have limited utility for real-world applications like autonomous vehicles because of their worst areas of performance # the locations where they provide insufficient recall at a certain required error tolerance. Here we investigate the utility of using place specific configurations, where a map is segmented into a number of places, each with its own configuration for modulating the pose estimation step, in this case selecting a camera within a multi-camera system. On the Ford AV benchmark dataset, we demonstrate substantially improved worst-case localization performance compared to using off-the-shelf pipelines # minimizing the percentage of the dataset which has low recall at a certain error tolerance, as well as improved overall localization performance. Our proposed approach is particularly applicable to the crowdsharing model of autonomous vehicle deployment, where a fleet of AVs are regularly traversing a known route.
# Hybrid Interval-Probabilistic Localization in Building Maps
## Keywords:
- Localization
## Abstract:
We present a novel online capable hybrid interval-probabilistic localization method using publicly available 2D building maps. Given an initially large uncertainty for the orientation and position derived from GNSS data, our novel interval-based approach first narrows down the orientation to a smaller interval and provides a set described by a minimal polygon for the position of the vehicle that encloses the feasible set of poses by taking the building geometry into account using 3D Light Detection and Ranging (LiDAR) sensor data. Second, we perform a probabilistic Maximum Likelihood Estimation (MLE) to determine the best solution within the determined feasible set. The MLE is converted into a least-squares problem that is solved by an optimization approach that takes the bounds of the solution set into account so that only a solution within the feasible set is selected as the most likely one. We experimentally show with real data that the novel interval-based localization provides sets of poses that contain the true pose for more than 99% of the frames and that the bounded optimization provides more reliable results compared to a classical unbounded optimization and a Monte Carlo Localization approach.
# Online Target Localization Using Adaptive Belief Propagation in the HMM Framework
## Keywords:
- Localization
- Sensor Networks
- Range Sensing
## Abstract:
This paper proposes a novel adaptive sample space-based Viterbi algorithm for target localization in an online manner. The method relies on discretizing the target's motion space into cells representing a finite number of hidden states. Then, the most probable trajectory of the tracked target is computed via dynamic programming in a Hidden Markov Model (HMM) framework. The proposed method uses a Bayesian estimation framework which is neither limited to Gaussian noise models nor requires a linearized target motion model or sensor measurement models. However, an HMM-based approach to localization can suffer from poor computational complexity in scenarios where the number of hidden states increases due to high-resolution modeling or target localization in a large space. To improve this poor computational complexity, this paper proposes a belief propagation in the most probable belief space with a low to high-resolution sequentially, reducing the required resources significantly. The proposed method is inspired by the k-d Tree algorithm (e.g., quadtree) commonly used in the computer vision field. Experimental tests using an ultra-wideband (UWB) sensor network demonstrate our results.
# Representation Learning
# Reshaping Robot Trajectories Using Natural Language Commands: A Study of Multi-Modal Data Alignment Using Transformers
## Keywords:
- Representation Learning
- Human Factors and Human-in-the-Loop
- Multi-Modal Perception for HRI
## Abstract:
Natural language is the most intuitive medium for us to interact with other people when expressing commands and instructions. However, using language is seldom an easy task when humans need to express their intent towards robots, since most of the current language interfaces require rigid templates with a static set of action targets and commands. In this work, we provide a flexible language-based interface for human-robot collaboration, which allows a user to reshape existing trajectories for an autonomous agent. We take advantage of recent advancements in the field of large language models (BERT and CLIP) to encode the user command, and then combine these features with trajectory information using multi-modal attention transformers. We train the model using imitation learning over a dataset containing robot trajectories modified by language commands, and treat the trajectory generation process as a sequence prediction problem, analogously to how language generation architectures operate. We evaluate the system in multiple simulated trajectory scenarios, and show a significant performance increase of our model over baseline approaches. In addition, our real-world experiments with a robot arm show that users significantly prefer our natural language interface over traditional methods such as kinesthetic teaching or cost-function programming. Our study shows how the field of robotics can take advantage of large pre-trained language models towards creating more intuitive interfaces between robots and machines. Project webpage: https://arthurfenderbucker.github.io/NL_trajectory_reshaper
# DreamingV2: Reinforcement Learning with Discrete World Models without Reconstruction
## Keywords:
- Reinforcement Learning
- Representation Learning
- Machine Learning for Robot Control
## Abstract:
The present paper proposes a novel reinforcement learning method with world models, DreamingV2, a collaborative extension of DreamerV2 and Dreaming. DreamerV2 is a cutting-edge model-based reinforcement learning from pixels that uses discrete world models to represent latent states with categorical variables. Dreaming is also a form of reinforcement learning from pixels that attempts to avoid the autoencoding process in general world model training by involving a reconstruction-free contrastive learning objective. The proposed DreamingV2 is a novel approach of adopting both the discrete representation of DreamingV2 and the reconstruction-free objective of Dreaming. Compared to DreamerV2 and other recent model-based methods without reconstruction, DreamingV2 achieves the best scores on five simulated challenging 3D robot arm tasks. We believe that DreamingV2 will be a reliable solution for robot learning since its discrete representation is suitable to describe discontinuous environments, and the reconstruction-free fashion well manages complex vision observations.
# Playful Interactions for Representation Learning
## Keywords:
- Representation Learning
- Bioinspired Robot Learning
- Imitation Learning
## Abstract:
One of the key challenges in visual imitation learning is collecting large amounts of expert demonstrations for a given task. While methods for collecting human demonstrations are becoming easier with teleoperation methods and the use of low-cost assistive tools, we often still require 100-1000 demonstrations for every task to learn a visual representation and policy. To address this, we turn to an alternate form of data that does not require task-specific demonstrations -# play. Playing is a fundamental method children use to learn a set of skills and behaviors and visual representations in early learning. Importantly, play data is diverse, task-agnostic, and relatively cheap to obtain. In this work, we propose to use playful interactions in a self-supervised manner to learn visual representations for downstream tasks. We collect 2 hours of playful data in 19 diverse environments and use self-predictive learning to extract visual representations. Given these representations, we train policies using imitation learning for two downstream tasks: Pushing and Stacking. We demonstrate that our visual representations generalize better than standard behavior cloning and can achieve similar performance with only half the number of required demonstrations. Our representations, which are trained from scratch, compare favorably against ImageNet pretrained representations. Finally, we provide an experimental analysis on the effects of different pretraining modes on downstream task learning.
# COMPASS: Contrastive Multimodal Pretraining for Autonomous Systems
## Keywords:
- Representation Learning
- AI-Enabled Robotics
- Deep Learning for Visual Perception
## Abstract:
Learning representations that generalize across tasks and domains is challenging yet necessary for autonomous systems. Although task-driven approaches are appealing, designing models specific to each application can be difficult in the face of limited data, especially when dealing with highly variable multimodal input spaces arising from different tasks in different environments. We introduce the first general-purpose pretraining pipeline, COntrastive Multimodal Pretraining for AutonomouS Systems (COMPASS), to overcome the limitations of task-specific models and existing pretraining approaches. COMPASS constructs a multimodal graph by considering the essential information for autonomous systems and the properties of different modalities. Through this graph, multimodal signals are connected and mapped into two factorized spatio-temporal latent spaces: a 'motion pattern space' and a 'current state space'. By learning from multimodal correspondences in each latent space, COMPASS creates state representations that models necessary information such as temporal dynamics, geometry, and semantics. We pretrain COMPASS on a large-scale multimodal simulation dataset TartanAir~cite{tartanair2020iros} and evaluate it on drone navigation, vehicle racing, and visual odometry tasks. The experiments indicate that COMPASS can tackle all three scenarios and can also generalize to unseen environments and real-world data.
# Explainable Knowledge Graph Embedding: Inference Reconciliation for Knowledge Inferences Supporting Robot Actions
## Keywords:
- AI-Enabled Robotics
- Representation Learning
- Human-Centered Robotics
## Abstract:
Learned knowledge graph representations supporting robots contain a wealth of domain knowledge that drives robot behavior. However, there does not exist an inference reconciliation framework that expresses how a knowledge graph representation affects a robot's sequential decision making. We use a pedagogical approach to explain the inferences of a learned, black-box knowledge graph representation, a knowledge graph embedding. Our interpretable model uses a decision tree classifier to locally approximate the predictions of the black-box model and provides natural language explanations interpretable by non-experts. Results from our algorithmic evaluation affirm our model design choices, and the results of our user studies with non-experts support the need for the proposed inference reconciliation framework. Critically, results from our simulated robot evaluation indicate that our explanations enable non-experts to correct erratic robot behaviors due to nonsensical beliefs within the black-box.
# Neural Scene Representation for Locomotion on Structured Terrain
## Keywords:
- Representation Learning
- Deep Learning for Visual Perception
- Legged Robots
## Abstract:
We propose a learning-based method to reconstruct the local terrain for locomotion with a mobile robot traversing urban environments. Using a stream of depth measurements from the onboard cameras and the robot's trajectory, the algorithm estimates the topography in the robot's vicinity. The raw measurements from these cameras are noisy and only provide partial and occluded observations that in many cases do not show the terrain the robot stands on. Therefore, we propose a 3D reconstruction model that faithfully reconstructs the scene, despite the noisy measurements and large amounts of missing data coming from the blind spots of the camera arrangement. The model consists of a 4D fully convolutional network on point clouds that learns the geometric priors to complete the scene from the context and an auto-regressive feedback to leverage spatio-temporal consistency and use evidence from the past. The network can be solely trained with synthetic data, and due to extensive augmentation, it is robust in the real world, as shown in the validation on a quadrupedal robot, ANYmal, traversing challenging settings. We run the pipeline on the robot's onboard low-power computer using an efficient sparse tensor implementation and show that the proposed method outperforms classical map representations.
# MO-Transformer: A Transformer-Based Multi-Object Point Cloud Reconstruction Network
## Keywords:
- Representation Learning
- Deep Learning for Visual Perception
## Abstract:
This paper proposes a new network for reconstructing multi-object point cloud. Different from previous networks which reconstruct multi-object point cloud as a whole, our network iteratively reconstructs each individual object point cloud from a frame of multi-object point cloud. To achieve this goal, we have designed MO-Transformer, a transformer-based autoregressive network. During training, MO-Transformer takes a frame of multi-object point cloud and individual object point clouds as input. During testing, MOTransformer iteratively reconstructs individual object point clouds only based on the input multi-object point cloud. To train the proposed MO-Transformer, we design a new loss function called separate Chamfer distance (SCD). In addition, we prove that SCD is an upper bound of the traditional Chamfer distance calculated based on the entire multi-object point cloud. The reconstruction experiment verifies the efficacy of our network in multi-object point cloud reconstruction. Furthermore, the reconstruction experiment also investigates the effect of different dimensions using a series of datasets. The ablation study experiment verifies the necessity of SCD in training MO-Transformer.
# Self-Supervised Feature Learning from Partial Point Clouds Via Pose Disentanglement
## Keywords:
- Representation Learning
- Object Detection, Segmentation and Categorization
- Deep Learning for Visual Perception
## Abstract:
Self-supervised learning on point clouds has gained a lot of attention recently, since it addresses the label-efficiency and domain-gap problems on point cloud tasks. In this paper, we propose a novel self-supervised framework to learn informative features from partial point clouds. We leverage partial point clouds scanned by LiDAR that contain both content and pose attributes, and we show that disentangling such two factors from partial point clouds enhances feature learning. To this end, our framework consists of three main parts: 1) a completion network to capture holistic semantics of point clouds; 2) a pose regression network to understand the viewing angle where partial data is scanned from; 3) a partial reconstruction network to encourage the model to learn content and pose features. To demonstrate the robustness of the learnt feature representations, we conduct several downstream tasks including classification, part segmentation, and registration, with comparisons against state-of-the-art methods. Our method not only outperforms existing self-supervised methods, but also shows a better generalizability across synthetic and real-world datasets.
# Efficiently Learning Manipulations by Selecting Structured Skill Representations
## Keywords:
- Deep Learning in Grasping and Manipulation
- Learning from Demonstration
- Reinforcement Learning
## Abstract:
A key challenge in learning to perform manipulation tasks is selecting a suitable skill representation. While specific skill representations are often easier to learn, they are often only suitable for a narrow set of tasks. In most prior works, roboticists manually provide the robot with a suitable skill representation to use, e.g., a neural network or DMPs. By contrast, we propose to allow the robot to select the most appropriate	skill representation for the underlying task. Given the large space of skill representations, we utilize a single demonstration to select a small set of potential task-relevant representations. This set is then further refined using reinforcement learning to select the most suitable skill representation. Experiments in both simulation and real world show how our proposed approach leads to improved sample efficiency and enables directly learning on the real robot.
# Automation and Robotics at Micro-Nano Scales
# Hierarchical Learning and Control for In-Hand Micromanipulation Using Multiple Laser-Driven Micro-Tools
## Keywords:
- Automation at Micro-Nano Scales
- Reinforcement Learning
- Robust/Adaptive Control
## Abstract:
Laser-driven micro-tools are formulated by treating highly-focused laser beams as actuators, to control the tool's motion to contact then manipulate a micro-object, which allows it to manipulate opaque micro-objects, or large cells without causing photodamage. However, most existing laser-driven tools are limited to relatively simple tasks, such as moving and caging, and cannot carry out in-hand dexterous tasks. This is mainly because in-hand manipulation involves continuously coordinating multiple laser beams, micro-tools, and the object itself, which has high degrees of freedom (DoF) and poses up the challenge for planner and controller design. This paper presents a new hierarchical formulation for the grasping and manipulation of micro-objects using multiple laser-driven micro-tools. In hardware, multiple laser-driven tools are assembled to act as a robotic hand to carry out in-hand tasks (e.g., rotating); in software, a hierarchical scheme is developed to shrunken the action space and coordinate the motion of multiple tools, subject to both the parametric uncertainty in the tool and the unknown dynamic model of the object. Such a formulation provides a potential for achieving robotic in-hand manipulation at a micro scale. The performance of the proposed system is validated in simulation studies under different scenarios.
# A Micro-Robotic Approach for the Correction of Angular Deviations in AFM Samples from Generic Topographic Data
## Keywords:
- Micro/Nano Robots
- Automation at Micro-Nano Scales
- Motion Control
## Abstract:
This article proposes a method for the correction of angular deviations caused during the fixing process of samples prepared for Atomic Force Microscopy (AFM). The correction is done using the angular control of a 6-DOF PPPS parallel platform were the sample is placed, while the AFM scan is performed by a 3-DOF serial cartesian robot with a tuning fork probe designed to perform FM-AFM. The method uses the generic x, y, and z data provided by the AFM after performing a scan on a free surface of the sample substrate. This is used to calculate the plane that closest approximates the points by solving a system of linear equations. This plane is then used to estimate the angular corrections that the 6-DOF parallel robot has to do in order to compensate the deviations. The proposed algorithm can be performed iteratively in order to refine the correction. The method also does not require any special preparation of the substrate. It only requires to have a free surface to scan. Experiments are performed using this algorithm to correct the orientation deviation of a substrate of V1 High-grade mica. The results show that the method is able to correct the angular deviation of the sample relatively to the AFM probe with an error of 0.2 ° after only two iterations of the algorithm.
# Modeling and Characterization of Artificial Bacteria Flagella with Micro-Structured Soft-Magnetic Teeth
## Keywords:
- Micro/Nano Robots
- Nanomanufacturing
- Automation at Micro-Nano Scales
## Abstract:
Sub-structures such as micro-structured magnetic teeth fabricated with an artificial bacteria flagellum (ABF) are designed for achieving more motion modes, higher precision, and better controllability. To achieve these, a more precise model considering the non-circular cross-sectional features is setup without simplifying the structure as a helical filament with a circular cross-section as having been used in previous investigations, making it possible to include the effects of the substructures into the motion equation. Analyses and experiments verified the correctness. Besides of the geometric effects, our experimental observation also shows an anomalous step-out frequency appeared in an ABF. This asynchronous motion is attributed to the lag of magnetization with respect to the external rotating magnetic field due to the geometries and the soft-magnetic materials of the ribbons, which is different from the regular asynchronous motion solely caused by low Reynolds number of fluid to microscopic swimmers. While the lag of magnetization can be further attributed initiatively to the soft magnetic materials adopted, the feasibility to arrange the easy axis will enable many new possibilities, which is of particular interest in generating more modes for swarms such as cascade stepping out of ABFs with the same nominal overall sizes and for more precise positioning using stepping motion.
# Deep Learning-Based 3D Magnetic Microrobot Tracking Using 2D MR Images
## Keywords:
- Micro/Nano Robots
- Deep Learning Methods
- Visual Servoing
## Abstract:
Magnetic resonance imaging (MRI)-guided robots emerged as a promising tool for minimally invasive medical operations. Recently, MRI scanners have been proposed for actuating magnetic microrobots and localizing them in the patient’s body using two-dimensional (2D) MR images. However, three# dimensional (3D) magnetic microrobots tracking during motion is still an untackled issue in MRI-powered microrobotics. Here, we present a deep learning-based 3D magnetic microrobot tracking method using 2D MR images during microrobot motion. The proposed method comprises a convolutional neural network (CNN) and complementary particle filter for 3D microrobot tracking. The CNN localizes the microrobot position relative to the 2D MRI slice and classifies the microrobot visibility in the MR images. First, we create an ultrasound (US) imaging-mentored MRI-based microrobot imaging and actuation system to train the CNN. Then, we trained the CNN using the MRI data generated by automated experiments using US image-based visual servoing of a microrobot with a 500 μm-diameter magnetic core. We showed that the proposed CNN can localize the microrobot and classified its visibility in an in vitro environment with ±0.56 mm and 87.5% accuracy in 2D MR images, respectively. Furthermore, we demonstrated ex-vivo 3D microrobot tracking with ±1.43 mm accuracy, improving tracking accuracy by 60% compared to the previous studies. The presented tracking strategy will enable MRI-powered microrobots to be used in high-precision targeted medical applications in the future.
# A PZT-Driven 6-DOF High-Speed Micromanipulator for Circular Vibration Simulation and Whirling Flow Generation
## Keywords:
- Dexterous Manipulation
- Micro/Nano Robots
- Biological Cell Manipulation
## Abstract:
Existing micromanipulation methods, whether contact mi-cromanipulation or non-contact micromanipulation, can hardly meet the requirements of low damage and multiple functions in the biomedical field. This study provides a high-speed mi-cromanipulator that can simulate circular vibrations and gen-erate microflow, which could be utilized to actuate non-invasive multiple operations of biological targets at the microscale. We design a PZT-driven 6-DOF micromanipulator with a hybrid structure and flexible hinges. Two 3-PRS parallel modules are serially connected in mirror style to achieve high speed, high accuracy, and a big workspace simultaneously, which enables the highly-controllable circular vibration simulation and strong whirling flow generation. The static, dynamic, and trajectory tracking performances were evaluated. The experimental result showed the 324 × 331 × 40 μm3 workspace, which was also the range of trajectories that could be generated. Trajectory track-ing performance evaluation showed that it could realize ~200 Hz circular vibration with an error of about 2.4% through open-loop control. Finally, the microflow generation experiment indicated the great potential of the proposed micromanipulator and the method of whirling flow generation in operating the biological targets at the microscale.
# Real-Time Acoustic Holography with Physics-Based Deep Learning for Acoustic Robotic Manipulation
## Keywords:
- Automation at Micro-Nano Scales
- Micro/Nano Robots
- Grippers and Other End-Effectors
## Abstract:
Acoustic holography is a newly emerging and promising technique to dynamically generate arbitrary desired holographic acoustic field in 3D space for contactless robotic manipulation. The latest technology supporting complex dynamic holographic acoustic field reconstruction is through phased transducer array (PTA), where the phase profile of emitted acoustic wave from discrete transducers is controlled independently by sophisticated circuits to modulate the acoustic interference field. While the forward kinematics of a phased array based robotic manipulation system is simple and straightforward, the inverse kinematics of the required holographic acoustic field is mathematically non-linear and unsolvable, which substantially limits the application of dynamic holographic acoustic field for robot manipulation. In this work, we propose a physics-based deep learning framework for this phase retrieval inverse kinematics problem so that the target complex hologram could be reconstructed precisely with average MAE of 0.022 and in real time with prediction time of 47 milliseconds on GPU. The accuracy and real time of the proposed method for dynamic holographic acoustic field reconstruction from PTA are demonstrated experimentally.
# On-Chip Fabrication of Micro-Chain Robot with Selective Magnetization Using Magnetically Guided Arraying Microfluidic Devices
## Keywords:
- Soft Robot Materials and Design
- Micro/Nano Robots
- Assembly
## Abstract:
The magnetic microrobot has become a promising approach in many biomedical applications due to its small volume, flexible motion, and untethered micromachines. The micro-chain robot is one of the most popular magnetic microrobots. However, the uncontrollable magnetic moment direction and quantity of the magnetic beads consisted in the existing self-assembled micro-chain robot limit their locomotion and applications. This paper proposed an on-chip micro-chain robot fabrication method to assemble the magnetic beads with controllable magnetic moment direction and quantity. The bead quantity can be controlled by the structure limits of the microchannel, and the direction of the magnetic moment can be adjusted by the integrated external magnetic field. The assembled magnetic beads are then glued by the hydrogel under UV exposure. The micro-chain robots with different quantities and magnetic moment directions of the magnetic beads were successfully fabricated and tested in experiments. Due to the array structure of the microfluidic device, batch manufacturing of low-cost magnetic robots was achieved in our method. The movement of dual-bead microrobots with two orthogonal magnetic moment directions was analyzed and compared. One of the dual-bead microrobots was applied in the transportation of the hydrogel module using pushing and pulling modes. It indicated that the proposed controllable on-chip fabrication of the magnetic micro-chain robots has the potential to enhance the microrobot ability in biomedical applications.
# On-Chip Automatic Trapping and Rotating for Zebrafish Embryo Injection
## Keywords:
- Automation at Micro-Nano Scales
- Biological Cell Manipulation
- Robotics and Automation in Life Sciences
## Abstract:
Zebrafish embryo injection is often required in biomedical research using zebrafish. In the injecting operation, trapping and rotating the zebrafish embryo to achieve a proper posture is essential for the high success rate. We proposed an on-chip platform capable of efficient and automatic trapping and rotating for the injection of zebrafish embryos. A low-cost 3D-printed microchannel is designed to trap zebrafish embryos into the cavity array. The blind-hole design at each cavity can generate microbubbles, and the bubbles exposed to the acoustic wave with a specific frequency can trap and rotate the zebrafish embryos. The progress, including trapping and rotating, can be monitored and executed automatically with computer vision assistance. Experimental results show that we realized on-chip trapping and rotating operations successfully. The success rate of trapping zebrafish embryos was up to 99%, and the time of trapping a single embryo was as low as 0.2 s. Embryo rotation could be achieved by two different modes, including continuous rotation and intermittent rotation. The accuracy and maximal velocity of rotating the embryo reached 5° and 3.5 r/s, respectively. Thus, we believe the proposed efficient automatic on-chip trapping and rotating platform could support the zebrafish embryo injection well.
# Independent Control Strategy of Multiple Magnetic Flexible Millirobots for Position Control and Path Following (I)
## Keywords:
- Micro/Nano Robots
- Multi-Robot Systems
- Motion Control
## Abstract:
Magnetically actuated small-scale robots have great potential for numerous applications in remote, confined, or enclosed environments. Multiple small-scale robots enable cooperation and increase the operating efficiency. However, independent control of multiple magnetic small-scale robots is a great challenge, because the robots receive identical control inputs from the same external magnetic field. In this article, we propose a novel strategy of completely decoupled independent control of magnetically actuated flexible swimming millirobots. A flexible millirobot shows a crawling motion on a flat plane within an oscillating magnetic field. Millirobots with different magnetization directions have the same velocity response curve to the oscillating magnetic field but with a difference of phase. We designed and fabricated a group of up to four heterogeneous millirobots with identical geometries and different magnetization directions. According to their velocity response curves, an optimal direction of oscillating magnetic field is calculated to induce a desired velocity vector for the millirobot group, one of which is nonzero and the others are approximately zero. The strategy is verified by experiments of independent position control of up to four millirobots and independent path following control of up to three millirobots with small errors. We further expect that with this independent control strategy, the millirobots will be able to cooperate to finish complicated tasks.
# Motion and Path Planning 1
# Learning Goal-Oriented Non-Prehensile Pushing in Cluttered Scenes
## Keywords:
- Manipulation Planning
- Machine Learning for Robot Control
- Reinforcement Learning
## Abstract:
Pushing objects through cluttered scenes is a challenging task, especially when the objects to be pushed have initially unknown dynamics and touching other entities has to be avoided to reduce the risk of damage. In this paper, we approach this problem by applying deep reinforcement learning to generate pushing actions for a robotic manipulator acting on a planar surface where objects have to be pushed to goal locations while avoiding other items in the same workspace. With the latent space learned from a depth image of the scene and other observations of the environment, such as contact information between the end effector and the object as well as distance to the goal, our framework is able to learn contact-rich pushing actions that avoid collisions with other objects. As the experimental results with a six degrees of freedom robotic arm show, our system is able to successfully push objects from start to end positions while avoiding nearby objects. Furthermore, we evaluate our learned policy in comparison to a state-of-the-art pushing controller for mobile robots and show that our agent performs better in terms of success rate, collisions with other objects, and continuous object contact in various scenarios.
# Transfer Learning for Machine Learning-Based Detection and Separation of Entanglements in Bin-Picking Applications
## Keywords:
- Manipulation Planning
- Deep Learning in Grasping and Manipulation
- Grasping
## Abstract:
In this paper, we present a Domain Randomization and a Domain Adaptation approach to transfer experience for entanglement detection and separation from simulation into a real-world bin-picking application. We investigate the influence of different randomization options in image processing and use a CycleGAN as a further Domain Adaptation method to synthesize simulation data as realistically as possible. On the basis of this adapted data we re-train our detection and separation methods and validate the usefulness of these Sim-to-Real methods. In numerous real-world experiments we show that we achieve a significant increase of up to 71.74% in the performance of the overall system by using the Sim-to-Real approaches as opposed to the direct transfer.
# Deep Reinforcement Learning Based on Local GNN for Goal-Conditioned Deformable Object Rearranging
## Keywords:
- Manipulation Planning
- Reinforcement Learning
- Perception for Grasping and Manipulation
## Abstract:
Object rearranging is one of the most common deformable manipulation tasks, where the robot needs to rearrange a deformable object into a goal configuration. Previous studies focus on designing an expert system for each specific task by model-based or data-driven approaches and the application scenarios are therefore limited. Some research has been attempting to design a general framework to obtain more advanced manipulation capabilities for deformable rearranging tasks, with lots of progress achieved in simulation. However, transferring from simulation to reality is difficult due to the limitation of the end-to-end CNN architecture. To address these challenges, we design a local GNN (graph neural network) based learning method, which utilizes two representation graphs to encode keypoints detected from images. Self-attention is applied for graph updating and cross-attention is applied for generating manipulation actions. Extensive experiments have been conducted to demonstrate that our framework is effective in multiple 1-D (rope, rope ring) and 2-D (cloth) rearranging tasks in simulation and can be easily transferred to a real robot by fine-tuning a keypoint detector.
# Controlling the Cascade: Kinematic Planning for N-Ball Toss Juggling
## Keywords:
- Manipulation Planning
- Dynamics
- Kinematics
## Abstract:
Dynamic movements are ubiquitous in human motor behavior as they tend to be more efficient and can solve a broader range of skill domains than their quasi-static counterparts. For decades, robotic juggling tasks have been among the most frequently studied dynamic manipulation problems since the required dynamic dexterity can be scaled to arbitrarily high difficulty. However, successful approaches have been limited to basic juggling skills, indicating a lack of understanding of the required constraints for dexterous toss juggling. We present a detailed analysis of the toss juggling task, identifying the key challenges of the switching contacts task and formalizing it as a trajectory optimization problem. Building on our state-of-the-art, real-world toss juggling platform, we reach the theoretical limits of toss juggling in simulation, evaluate a resulting real-time controller in environments of varying difficulty and achieve robust toss juggling of up to 17 balls on two anthropomorphic manipulators. https://sites.google.com/view/controlling-the-cascade
# Rearrangement-Based Manipulation Via Kinodynamic Planning and Dynamic Planning Horizons
## Keywords:
- Manipulation Planning
## Abstract:
Robot manipulation in cluttered environments often requires complex and sequential rearrangement of multiple objects in order to achieve the desired reconfiguration of the target objects. Due to the sophisticated physical interactions involved in such scenarios, rearrangement-based manipulation is still limited to a small range of tasks and is especially vulnerable to physical uncertainties and perception noise. This paper presents a planning framework that leverages the efficiency of sampling-based planning approaches, and closes the manipulation loop by dynamically controlling the planning horizon. Our approach interleaves planning and execution to progressively approach the manipulation goal while correcting any errors or path deviations along the process. Meanwhile, our framework allows the definition of manipulation goals without requiring explicit goal configurations, enabling the robot to flexibly interact with all objects to facilitate the manipulation of the target ones. With extensive experiments both in simulation and on a real robot, we evaluate our framework on three manipulation tasks in cluttered environments: grasping, relocating, and sorting. In comparison with two baseline approaches, we show that our framework can significantly improve planning efficiency, robustness against physical uncertainties, and task success rate under limited time budgets.
# Parallel Monte Carlo Tree Search with Batched Rigid-Body Simulations for Speeding up Long-Horizon Episodic Robot Planning
## Keywords:
- Manipulation Planning
- Deep Learning in Grasping and Manipulation
- Grasping
## Abstract:
We propose a novel Parallel Monte Carlo tree search with Batched Simulations (PMBS) algorithm for accelerating long-horizon, episodic robotic planning tasks. Monte Carlo tree search (MCTS) is an effective heuristic search algorithm for solving episodic decision-making problems whose underlying search spaces are expansive. Leveraging a GPU-based large-scale simulator, PMBS introduces massive parallelism into MCTS for solving planning tasks through the batched execution of a large number of concurrent simulations, which allows for more efficient and accurate evaluations of the expected cost-to-go over large action spaces. When applied to the challenging manipulation tasks of object retrieval from clutter, PMBS achieves a speedup of over 30x with an improved solution quality, in comparison to a serial MCTS implementation. We show that PMBS can be directly applied to real robot hardware with negligible sim-to-real differences. Supplementary material, including video, can be found at https://github.com/arc-l/pmbs.
# Adapting Rapid Motor Adaptation for Bipedal Robots
## Keywords:
- Humanoid and Bipedal Locomotion
- Robust/Adaptive Control
- Reinforcement Learning
## Abstract:
Recent advances in legged locomotion have enabled quadrupeds to walk on challenging terrain. However, bipedal robots are inherently more unstable and hence it's harder to design walking controllers for them. In this work, we leverage the recent advances in rapid adaptation for walking, and extend them to work on bipedal robots. Similar to existing works, we start with a base policy which produces actions while taking as input an estimated extrinsics vector from an adaptation module. This extrinsics vector contains information about the environment and enables the walking controller to rapidly adapt online. However, the extrinsics estimator could be imperfect, which might lead to poor performance of the base policy which expects a perfect estimator. We propose A-RMA (adapting RMA), which additionally adapts the base policy for the imperfect extrinsics estimator by finetuing it using model free RL. We demonstrate that A-RMA outperforms a number of RL based baseline controllers and model based controllers in simulation, and show zero-shot deployment of a single A-RMA policy to enable Cassie (a bipedal robot) to walk in a variety of different scenarios beyond what it has seen during training. Videos at url{https://ashish-kmr.github.io/a-rma/}
# Three-Dimensional Dynamic Running with a Point-Foot Biped Based on Differentially Flat SLIP
## Keywords:
- Humanoid and Bipedal Locomotion
- Whole-Body Motion Planning and Control
- Underactuated Robots
## Abstract:
This paper presents a novel framework for point-foot biped running in three-dimensional space. The proposed approach generates center of mass (CoM) reference trajectories based on a differentially flat spring-loaded inverted pendulum (SLIP) model. A foothold planner is used to select touch down location that renders optimal CoM trajectory for upcoming step in real time. Dynamically feasible trajectories of CoM and orientation are subsequently generated by a simplified single rigid body (SRB) model based model predictive control (MPC). A task-space controller is then applied online to compute whole-body joint torques which embeds these target dynamics into the robot. The proposed approach is evaluated on physical simulation of a 12 degree-of-freedom (DoF), 7.95 kg point-foot bipedal robot. The robot achieves stable running at at varying speeds with maximum value of 1.1 m/s. The proposed scheme is shown to be able to reject vertical disturbances of 8 Ns and lateral disturbance of 6.5 Ns applied at the robot base.
# A Passive Control Framework for a Bilateral Leader-Follower Robotic Surgical Setup Imposing RCM and Active Constraints
## Keywords:
- Telerobotics and Teleoperation
## Abstract:
We consider the problem of controlling a bilateral leader-follower robotic surgical set-up to allow kinesthetic haptic feedback to the user when the instrument approaches a forbidden area like sensitive organs arteries or veins that should be protected from injuries during surgery. The leader is a haptic device while the follower is a general purpose manipulator holding an elongated tool with an articulated instrument that should be manipulated through an entry port. We propose a control framework that is proved passive, incorporating a target admittance model for the follower that is designed in a way to impose a remote center of motion (RCM) while being subject to repulsive forces generated by properly designed artificial potentials associated with forbidden areas. Simulation and experimental results utilizing a virtual intraoperative environment provided as a point cloud of a kidney and its surrounding vessels characterized as forbidden areas, validate and demonstrate the performance of the proposed control scheme.
# Biologically-Inspired Robots 1
# The Flatworm-Like Mesh Robot WORMESH-II: Steering Control of Pedal Wave Locomotion
## Keywords:
- Biologically-Inspired Robots
- Motion Control
- Field Robots
## Abstract:
WORMESH is a unique robot concept inspired by flatworm locomotion and its key feature is the use of multiple traveling waves for locomotion. This paper presents the steering method for anisotropic module configuration (AMC) of WORMESH-II based on the kinematics of skid steering of mobile robots. AMC of WORMESH-II used two parallel pedal waves to generate locomotion. The kinematic model of WORMESH-II shows its longitudinal and angular velocities depend on the summation and the difference of two synchronous left and right pedal waves amplitudes Al and Ar respectively. When both pedal waves have the same amplitude, the robot moves on a straight line, whereas the trajectory becomes a curve for different wave amplitudes. The radius of curve trajectory is inversely proportional to j Al 􀀀Ar j. The proposed method was ineffective when Ai  0(i = l; r). The proposed method was confirmed by the dynamic simulation of WORMESH-II using a physics engine. Moreover, the recommended skid steering method was tested using the prototype and verified.
# In-Hand Manipulation Exploiting Bending and Compression Deformations of Caterpillar-Locomotion-Inspired Fingers
## Keywords:
- Soft Robot Applications
- Biologically-Inspired Robots
- Tendon/Wire Mechanism
## Abstract:
The paper presents a novel way to realize in-hand manipulation inspired by the peristaltic motion of a large-sized caterpillar's locomotion. The sharp contrast of the proposed soft-bodied finger to the traditional hard/rigid robotic ones is peristaltic motion with both compression and bending deformations. The design is based on the biological fact that large-size caterpillars (e.g., Bombyx mori) utilize bending and compression/extension of the body to produce crawling locomotion. Exploiting the multi-modal deformations, the prototype hand consisting of two proposed fingers can rotate and transport the grasped object, we demonstrated. We also found that the two fingers' motion's time gap is needed to stabilize in-hand manipulation. The design can shed new light on designing a gripper inspired by soft-bodied creatures.
# Embodying Rather Than Encoding: Undulation with Binary Input
## Keywords:
- Biologically-Inspired Robots
- Biomimetics
## Abstract:
Undulation is the most common gait generated by legless creatures, which enables their robust and efficient locomotion in various environments. Such advantages inspired the control design of many kinds of locomotion robots. Despite their technical details, most of them realize the undulation gait via tracking predetermined trajectories called serpenoid curves, which are a group of sinusoidal waveforms with specified phase differences. This technique, however, sounds quite redundant in terms of sensing and control. Here, we investigate the research question: whether the sinusoidal waveform is necessary to be encoded in the control signal to make the whole body an “S-shape”? We use a 4-link rigid body dynamics model as a simple example, by which numerical simulations are conducted. Together with theoretical analysis, we show that undulation gait emerges naturally based on embodied position controller and filter, where binary actuation torques are required only. Our results not only discover locomotion mechanisms for significantly reducing the sensing and control requirement of generating artificial undulation gait, but also provide additional understandings for biological systems from the mechanical engineering point of view.
# A Creeping Snake-Like Robot with Partial Actuation
## Keywords:
- Biologically-Inspired Robots
- Biomimetics
## Abstract:
Enlightened by the creeping gait of natural snakes, snake-like robots swing joints side to side at similar tracks for generating propelling forces. However, it is not always essential to control all joints of a snake-like robot to realize the creeping gait. Therefore, in this paper, a creeping snake-like robot with partially actuated joints has been investigated, towards reducing the redundancy caused by full actuation. Essentially, this approach is composed of the following two concepts: 1) joint equipped with torsion spring mechanism bridges the passive joint to generate rhythm oscillation, and 2) harmonic joint trajectories assist the robot in generating more efficient locomotion. We hereafter demonstrated that the actuated joint dominates passive dynamics of the system, which contributes to overall motion. Meanwhile, different spring stiffness affects the motion performance. Additionally, the interaction between robot and environment through Coulomb friction has been considered to reveal the contributing factors that assist the snake-like robot to yield better locomotion performance.
# Design and Experiments of Snake Robots with Docking Function
## Keywords:
- Biologically-Inspired Robots
- Mechanism Design
- Computer Vision for Manufacturing
## Abstract:
This paper presents a novel snake robot with the docking function, which can help the snake robots to connect with each other to achieve a stronger one with double length and double degrees of freedom. First, the mechanical design of the snake robot with docking function is introduced, including the body link and the head-tail passive docking mechanical structure. Second, the control system is built, and the control strategies of locomotion and docking are separately proposed. Then, the visual perception function is implemented for the target recognition during the docking process. Finally, the prototype is developed. The mobility and the docking function are fully verified and analyzed through the physical experiments.
# Modeling and Control of a Lizard Inspired Single Actuated Robot
## Keywords:
- Biologically-Inspired Robots
- Mechanism Design
- Legged Robots
## Abstract:
In this study, trajectory-tracking control for a lizard-inspired single-actuated robot (LISA) is implemented using a novel morphology. A high degree of reproducibility is obtained between the results of kinematic analysis and the behavior of the actual robot. Several 1-degree-of-freedom (DOF)-driven robots have been proposed. However, the application of these robots is severely restricted because of their inherent morphology limitations. LISA is a multilegged robot that can overcome these disadvantages and propel and turn with 1-DOF. In this study, we formulate the kinematics, such as the turning angle and stride length, of LISA. Furthermore, a unique robot coordinate is defined to enable the symmetrical representation of critical robot state quantities. Next, a trajectory-tracking control system based on the proportional-integral-derivative (PID) control is designed, and it is verified by both experiments and numerical simulations. Finally, the results of the experiments and numerical simulations are quantitatively compared according to the root mean square, and the reproducibility of the kinematics analysis and the behavior of the actual system are discussed. This study makes the following contributions: (1) The morphology of LISA facilitates analytical results with only kinematic analysis, which is considerably simpler than dynamics analysis. (2) LISA achieved sufficiently good kinematic performance for the required motions. Experiments revealed that the designed trajectory-tracking control system allows for LISA to appropriately track several types of trajectories.
# Optimal Path Following Control with Efficient Computation for Snake Robots Subject to Multiple Constraints and Unknown Frictions
## Keywords:
- Biologically-Inspired Robots
- Motion Control
## Abstract:
This letter proposes a real-time optimal robust path following control scheme for planar snake robots without sideslip constraints using model predictive control (MPC). One of the features is that a linear double-integrator model rather than the complex dynamic model of snake robots is used for the MPC design to improve calculation efficiency. Moreover, in addition to constraints on joint angles, velocity, and acceleration for security, constraints on the joint offset and velocity are also considered to keep the snake robot moving forward efficiently. And the multiple inequality constraints are handled by a novel constraints translator. Furthermore, to achieve robust path following control subject to unknown and varied friction forces and disturbances, two reduced-order structure-improved extended state observers are designed to avoid complex environmental modeling. Extensive comparative experiments were conducted to verify the constraints design and the effectiveness of the proposed control scheme.
# A Distributed Coach-Based Reinforcement Learning Controller for Snake Robot Locomotion
## Keywords:
- Biologically-Inspired Robots
- Redundant Robots
- Probability and Statistical Methods
## Abstract:
Reinforcement learning commonly suffers from slow convergence speed and requires thousands of episodes, which makes it hard to be applied for physical robotic applications. Because of the complexity of a large degree of freedom, little study has been done on snake robot control using reinforcement learning. Existing methods either adopts an asynchronous A3C structure or a joint state representation. In this paper, a fully distributed coach-based reinforcement learning method is proposed for snake robot control that can considerably accelerate training while using fewer episodes. The major contributions comprises: 1) we extend our previously presented graphical coach based RL control method into a completely distributed framework; 2) an explicit stochastic density propagation rule for each robot link is mathematically derived; 3) the various interactions with uncertainty have been well modeled and estimated to achieve an efficient and robust control for snake robots. The preliminary results of both simulation and real-world experiments have demonstrated promising performance comparing with other recent methods.
# Bio-Inspired 2D Vertical Climbing with a Novel Tripedal Robot
## Keywords:
- Biologically-Inspired Robots
- Climbing Robots
- Legged Robots
## Abstract:
Climbing robots have the potential to revolutionize the maintenance and inspection operations of many types of vertical structures. In nature, parrots exhibit a remarkable capacity for manipulation during climbing behaviors, for which robotics can benefit from studying. In this paper we present a novel tripedal robot that is inspired by the morphology of these impressive birds, which use their legs and beak in a tripedal fashion when climbing. We propose several foot placement, trajectory generation, and control methods for this system along with performance evaluation in simulation. A video of select simulations and live bird data is included in the supplementary material, and can also be found at https: //youtu.be/vRVGraIyQgQ.
# Formal Methods in Robotics and Automation
# Event-Based Signal Temporal Logic Tasks: Execution and Feedback in Complex Environments
## Keywords:
- Formal Methods in Robotics and Automation
- Hybrid Logical/Dynamical Planning and Verification
- Multi-Robot Systems
## Abstract:
In this work, we synthesize control for high-level, reactive robot tasks that include timing constraints and choices over goals and constraints. We enrich Event-based Signal Temporal Logic by adding disjunctions, and propose a framework for synthesizing controllers that satisfy such specifications. If there are multiple ways to satisfy a specification, we choose, at run-time, a controller that instantaneously maximizes robustness. During execution, we automatically generate feedback in the form of pre-failure warnings that give users insight as to why a specification may be violated in the future. We demonstrate our work through physical and simulated multi-robot systems operating in complex environments.
# Optimizing Demonstrated Robot Manipulation Skills for Temporal Logic Constraints
## Keywords:
- Formal Methods in Robotics and Automation
- Manipulation Planning
- Learning from Demonstration
## Abstract:
For performing robotic manipulation tasks, the core problem is determining suitable trajectories that fulfill the task requirements. Various approaches to compute such trajectories exist, being learning and optimization the main driving techniques. Our work builds on the learning-from-demonstration (LfD) paradigm, where an expert demonstrates motions, and the robot learns to imitate them. However, expert demonstrations are not sufficient to capture all sorts of task specifications, such as the timing to grasp an object. In this paper, we propose a new method that considers formal task specifications within LfD skills. Precisely, we leverage Signal Temporal Logic (STL), an expressive form of temporal properties of systems, to formulate task specifications and use black-box optimization (BBO) to adapt an LfD skill accordingly. We demonstrate our approach in simulation and on a real industrial setting using several tasks that showcase how our approach addresses the LfD limitations using STL and BBO.
# Classification of Time-Series Data Using Boosted Decision Trees
## Keywords:
- Formal Methods in Robotics and Automation
## Abstract:
Time-series data classification is central to the analysis and control of autonomous systems, such as robots and self-driving cars. Temporal logic-based learning algorithms have been proposed recently as classifiers of such data. However, current frameworks are either inaccurate for real-world applications, such as autonomous driving, or they generate long and complicated formulae that lack interpretability. To address these limitations, we introduce a novel learning method, called Boosted Concise Decision Trees (BCDTs), to generate binary classifiers that are represented as Signal Temporal Logic (STL) formulae. Our algorithm leverages an ensemble of Concise Decision Trees (CDTs) to improve the classification performance, where each CDT is a decision tree that is empowered by a set of techniques to generate simpler formulae and improve interpretability. The effectiveness and classification performance of our algorithm are evaluated on naval surveillance and urban-driving case studies.
# Robustness-Based Synthesis for Stochastic Systems under Signal Temporal Logic Tasks
## Keywords:
- Formal Methods in Robotics and Automation
## Abstract:
We develop a method for synthesizing control policies for stochastic, linear, time-varying systems that must perform tasks specified in signal temporal logic. We build upon an efficient, sampling-based framework that computes the probability of the system satisfying its specification. By exploiting the properties of linear systems and robustness score in temporal logic specifications, we obtain sample-efficient gradients of the satisfaction probability with respect to controller parameters. Therefore, by applying gradient descent we obtain locally optimized controllers that maximize the chances of satisfying the specification. We demonstrate our approach through examples of a mobile robot and a mobile manipulator in simulation.
# Sensor Observability Index: Evaluating Sensor Alignment for Task-Space Observability in Robotic Manipulators
## Keywords:
- Formal Methods in Robotics and Automation
- Kinematics
- Robot Safety
## Abstract:
In this paper, we propose a preliminary definition and analysis of the novel concept of sensor observability index. The goal is to analyse and evaluate the performance of distributed directional or axial-based sensors to observe specific axes in task space as a function of joint configuration in serial robot manipulators. For example, joint torque sensors are often used in serial robot manipulators and assumed to be perfectly capable of estimating end effector forces, but certain joint configurations may cause one or more task-space axes to be unobservable as a result of how the joint torque sensors are aligned. The proposed sensor observability provides a method to analyse the quality of the current robot configuration to observe the task space. Parallels are drawn between sensor observability and the traditional kinematic Jacobian for the particular case of joint torque sensors in serial robot manipulators. Although similar information can be retrieved from kinematic analysis of the Jacobian transpose in serial manipulators, sensor observability is shown to be more generalizable in terms of analysing non-joint-mounted sensors and other sensor types. In addition, null-space analysis of the Jacobian transpose is susceptible to false observability singularities. Simulations and experiments using the robot Baxter demonstrate the importance of maintaining proper sensor observability in physical interactions.
# Fair Planning for Mobility-On-Demand with Temporal Logic Requests
## Keywords:
- Formal Methods in Robotics and Automation
- Optimization and Optimal Control
- Hybrid Logical/Dynamical Planning and Verification
## Abstract:
Mobility-on-demand systems are transforming the way we think about the transportation of people and goods. Most research effort has been placed on scalability issues for systems with a large number of agents and simple pick-up/drop-off demands. In this paper, we consider fair multi-vehicle route planning with streams of complex, temporal logic transportation demands. We consider the envy-free fair allocation of demands to limited-capacity vehicles based on agents' accumulated utility over a finite time horizon, representing for example monetary reward or utilization level. We propose a scalable approach based on the construction of assignment graphs that relate agents to routes and demands and pose the problem as an Integer Linear Program (ILP). Routes for assignments are computed using automata-based methods for each vehicle and demands sets of size at most the capacity of the vehicle while taking into account their pick-up wait time and delay tolerances. In addition, we integrate utility-based weights in the assignment graph and ILP to ensure approximative fair allocation. We demonstrate the computational and operational performance of our methods in ride-sharing case studies over a large environment in mid-Manhattan and Linear Temporal Logic demands with stochastic arrival times. We show that our method significantly decreases the utility deviation between agents and the vacancy rate.
# Incremental Path Planning Algorithm Via Topological Mapping with Metric Gluing
## Keywords:
- Formal Methods in Robotics and Automation
- Motion and Path Planning
- Computational Geometry
## Abstract:
We present an incremental topology-based motion planner that, while planning paths in the configuration space, performs metric gluing on the constructed Vietoris-Rips simplicial complex of each sub-space (voxel). By incrementally capturing topological and geometric information in batches of voxel graphs, our algorithm avoids the time overhead of analyzing the properties of the entire configuration space. We theoretically prove in this paper that the simplices of all voxel graphs joined together are homotopy-equivalent to the union of the simplices in the configuration space. Experiments were carried out in seven different environments using various robots, including the articulated linkage robot, the Kuka YouBot, and the PR2 robot. In all environments, the results show that our algorithm achieves better convergence for path cost and computation time with a memory-efficient roadmap than state-of-the-art methods.
# UAV-miniUGV Hybrid System for Hidden Area Exploration and Manipulation
## Keywords:
- Hardware-Software Integration in Robotics
- Engineering for Robotic Systems
- Software-Hardware Integration for Robot Systems
## Abstract:
 We propose a novel hybrid system (both hardware and software) of an Unmanned Aerial Vehicle (UAV) carrying a miniature Unmanned Ground Vehicle (miniUGV) to perform a complex search and manipulation task. This system leverages the heterogeneous robots to accomplish a task that cannot be done using a single robot system. It enables the UAV to explore a hidden space with a narrow opening through which the miniUGV can easily enter and escape. The hidden space is assumed to be navigable for the miniUGV. The miniUGV uses Infrared (IR) sensors and a monocular camera to search an object in the hidden space. The proposed system takes advantage of a wider field of view (fov) of camera as well as the stochastic nature of the object detection algorithms to guide the robot in the hidden space to find the object. Upon finding the object the miniUGV grabs it using visual servoing and then returns back to its start point from where the UAV retracts it back and transports the object to a safe place. In case there is no object found in the hidden space, UAV continues the aerial search. The tethered miniUGV gives the UAV an ability to act beyond its reach and perform a search and manipulation task which was not possible before for any of the robots individually. The system has a wide range of applications and we have demonstrated its feasibility through repetitive experiments
# Inference of Multi-Class STL Specifications for Multi-Label Human-Robot Encounters
## Keywords:
- Formal Methods in Robotics and Automation
## Abstract:
This paper is interested in formalizing human trajectories in human-robot encounters. Inspired by robot navigation tasks in human-crowded environments, we consider the case where a human and a robot walk towards each other, and where humans have to avoid colliding with the incoming robot. Further, humans may describe different behaviors, ranging from being in a hurry/minimizing completion time to maximizing safety. We propose a decision tree-based algorithm to extract STL formulae from multi-label data. Our inference algorithm learns STL specifications from data containing multiple classes, where instances can be labelled by one or many classes. We base our evaluation on a dataset of trajectories collected through an online study reproducing human-robot encounters.
# SLAM 1
# Making Parameterization and Constrains of Object Landmark Globally Consistent Via SPD(3) Manifold and Improved Cost Functions
## Keywords:
- SLAM
- Mapping
- Computer Vision for Automation
## Abstract:
Object-level SLAM introduces semantic-meaningful and compact object landmarks that help both indoor robot applications and outdoor autonomous driving tasks. However, the back end of object-level SLAM suffers from singularity problems because existing methods parameterize object landmarks separately by their scale and pose. Under that parameterization method, the same abstract object can be represented by rotating the object coordinate frame by 90 degrees and swapping its length with width value, making the pose of the same object landmark not globally consistent. To avoid the singularity problem, we first introduce the symmetric positive-definite (SPD) matrix manifold as an improved object-level landmark representation and further improve the cost functions in the back end to make them compatible with it. Our method demonstrates a faster convergence rate and more robustness in simulation experiments. And experiments on real datasets reveal that using the same front-end data, our strategy improves mapping accuracy by 22% on average.
# ULSM: Underground Localization and Semantic Mapping with Salient Region Loop Closure under Perceptually-Degraded Environment
## Keywords:
- SLAM
- Mapping
- Localization
## Abstract:
Simultaneous Localization and Mapping (SLAM) has greatly assisted in exploring perceptually-degraded underground environments, such as human-made tunnels, mine tunnels, and caves. However, the recurring sensor failures and spurious loop closures in these scenes bring significant challenges to applying SLAM. This paper proposes an architecture for underground localization and semantic mapping (ULSM) that promotes the robustness of odometry estimation and map-building. In this architecture, a two-stage robust motion compensation method is proposed to adapt to sensor-failure situations. The proposed salient region loop closure detection contributes to avoiding spurious loop closures. Meanwhile, the 2D pose as the initial value for point cloud registration is estimated without additional input. We also design a multi-robot cooperative mapping scheme based on descriptors of the salient region. Extensive experiments are conducted on datasets collected in the Tunnel Circuit of DARPA Subterranean Challenge.
# NDD: A 3D Point Cloud Descriptor Based on Normal Distribution for Loop Closure Detection
## Keywords:
- SLAM
- Range Sensing
## Abstract:
Loop closure detection is a key technology for long-term robot navigation in complex environments. In this paper, we present a global descriptor, named Normal Distribution Descriptor (NDD), for 3D point cloud loop closure detection. The descriptor encodes both the probability density score and entropy of a point cloud as the descriptor. We also propose a fast rotation alignment process and use correlation coefficient as the similarity between descriptors. Experimental results show that our approach outperforms the state-of-the-art point cloud descriptors in both accuracy and efficency. The source code will be available and can be integrated into existing LiDAR odometry and mapping (LOAM) systems.
# FEJ-VIRO: A Consistent First-Estimate Jacobian Visual-Inertial-Ranging Odometry
## Keywords:
- SLAM
- Sensor Fusion
- Visual-Inertial SLAM
## Abstract:
In recent years, Visual-Inertial Odometry (VIO) has achieved many significant progresses. However, VIO methods suffer from localization drift over long trajectories. In this paper, we propose a First-Estimates Jacobian Visual-Inertial-Ranging Odometry (FEJ-VIRO) to reduce the localization drifts of VIO by incorporating ultra-wideband (UWB) ranging measurements into the VIO framework consistently. Considering that the initial positions of UWB anchors are usually unavailable, we propose a long-short window structure to initialize the UWB anchors' positions as well as the covariance for state augmentation. After initialization, the FEJ-VIRO estimates the UWB anchors' positions simultaneously along with the robot poses. We further analyze the observability of the visual-inertial-ranging estimators and proved that there are four unobservable directions in the ideal case, while only three unobservable directions exist in the actual case. Based on these analyses, we propose to leverage the FEJ technique to fuse ranging measurements consistently. Finally, we validate our analysis and the proposed FEJ-VIRO with both simulation and real-world experiments.
# RGB-D SLAM in Indoor Planar Environments with Multiple Large Dynamic Objects
## Keywords:
- SLAM
- Visual Tracking
- Sensor Fusion
## Abstract:
This work presents a novel dense RGB-D SLAM approach for dynamic planar environments that enables simultaneous multi-object tracking, camera localisation and background reconstruction. Previous dynamic SLAM methods either rely on semantic segmentation to directly detect dynamic objects; or assume that dynamic objects occupy a smaller proportion of the camera view than the static background and can, therefore, be removed as outliers. With the aid of camera motion prior, our approach enables dense SLAM when the camera view is largely occluded by multiple dynamic objects. The dynamic planar objects are separated by their different rigid motions and tracked independently. The remaining dynamic non-planar areas are removed as outliers and not mapped into the background. The evaluation demonstrates that our approach outperforms the state-of-the-art methods in terms of localisation, mapping, dynamic segmentation and object tracking. We also demonstrate its robustness to large drift in the camera motion prior.
# DRG-SLAM: A Semantic RGB-D SLAM Using Geometric Features for Indoor Dynamic Scene
## Keywords:
- SLAM
- Localization
- RGB-D Perception
## Abstract:
Visual SLAM methods based on point features have achieved acceptable results in texture-rich static scenes, but they often suffer from a deficiency of texture and the existence of dynamic objects in real indoor scenes, which limits the application of these methods. In this paper, we have presented DRG-SLAM, which combines line features and plane features into point features to improve the robustness of the system. We tested the proposed algorithm on publicly available datasets, and the results demonstrate that the algorithm has superior accuracy and robustness in indoor dynamic scenes compared with the state-of-the-art methods.
# Scale-Aware Direct Monocular Odometry
## Keywords:
- SLAM
- Localization
- Mapping
## Abstract:
We present a generic framework for scale-aware direct monocular odometry based on depth prediction from a deep neural network. In contrast with previous methods where depth information is only partially exploited, we formulate a novel depth prediction residual which allows us to incorporate multi-view depth information. In addition, we propose to use a truncated robust cost function which prevents considering inconsistent depth estimations. The photometric and depth-prediction measurements are integrated into a tightly-coupled optimization leading to a scale-aware monocular system which does not accumulate scale drift. Our proposal does not particularize for a concrete neural network, being able to work along with the vast majority of the existing depth prediction solutions. We demonstrate the validity and generality of our proposal evaluating it on the KITTI odometry dataset, using two publicly available neural networks and comparing it with similar approaches and the state-of-the-art for monocular and stereo SLAM. Experiments show that our proposal largely outperforms classic monocular SLAM, being 5 to 9 times more precise, beating similar approaches and having an accuracy which is closer to that of stereo systems.
# IMU Preintegration for 2D SLAM Problems Using Lie Groups
## Keywords:
- SLAM
- Localization
## Abstract:
2D SLAM is useful for mobile robots that are constrained to a 2D plane, for example in a warehouse, simplifying calculations in respect to the 3D case. The use of an IMU in such a context can enrich the estimation and make it more robust. In this paper we reformulate the IMU preintegration widely used in 3D problems for the 2D case, making use of Lie Theory. The Lie theory based formalization, first derived for a perfectly horizontal plane, allows us to easily extend it to problems where the plane is not orthogonal to the gravity vector. We implement the theory in a factor graph based estimation library, and carry out experiments to validate it on a mobile platform. Two experiments are carried out; on a horizontal and a sloped environment, and the sensor data is processed using our two 2D methods and a state-of-the-art 3D method.
# Scale Estimation with Dual Quadrics for Monocular Object SLAM
## Keywords:
- SLAM
- Mapping
- Localization
## Abstract:
The scale ambiguity problem is inherently unsolvable to monocular SLAM without the metric baseline between moving cameras. In this paper, we present a novel scale estimation approach based on an object-level SLAM system. To obtain the absolute scale of the reconstructed map, we formulate an optimization problem to make the scaled dimensions of objects conform to the distribution of their sizes in the physical world, without relying on any prior information about gravity direction. The dual quadric is adopted to represent objects for its ability to describe objects compactly and accurately, thus providing reliable dimensions for scale estimation. In the proposed monocular object-level SLAM system, semantic objects are initialized first from fitted 3-D oriented bounding boxes and then further optimized under constraints of 2-D detections and 3-D map points. Experiments on indoor and outdoor public datasets show that our approach outperforms existing methods in terms of accuracy and robustness.
# Grasping 1
# Learn from Interaction: Learning to Pick Via Reinforcement Learning in Challenging Clutter
## Keywords:
- Grasping
- Grippers and Other End-Effectors
## Abstract:
Bin picking is a challenging problem in robotics due to high dimensional action space, partially visible objects, and contact-rich environments. State-of-the-art methods for bin picking are often simplified as planar manipulation or learn policy based on human demonstration and motion primitives. The designs have escalated in complexity while still failing to reach the generality and robustness of human picking ability. Here, we present an end-to-end reinforcement learning (RL) framework to produce an adaptable and robust policy for picking objects in diverse real-world environments, including but not limited to tilted bins and corner objects. We present a novel solution to incorporate object interaction in policy learning. The object interaction is represented by the poses of objects. The policy learning is based on two neural networks with asymmetric state inputs. One acts on the object interaction information, while the other acts on the depth observation and proprioceptive signals of robots. The resulting policy demonstrates remarkable zero-shot generalization from simulation to the real world, and extensive real-world picking experiments show the effectiveness of the approach.
# GE-Grasp: Efficient Target-Oriented Grasping in Dense Clutters
## Keywords:
- Grasping
- Deep Learning in Grasping and Manipulation
- RGB-D Perception
## Abstract:
Grasping in dense clutters is a fundamental skill for autonomous robots. However, the crowdedness and occlusions in the cluttered scenario cause significant difficulties to generate valid grasp poses without collisions, which results in low efficiency and high failure rates. To address these, we present a generic framework called GE-Grasp for robotic motion planning in dense clutters, where we leverage diverse action primitives for occluded objects removal and present the generator-evaluator architecture to avoid spatial collisions. Therefore, our GE-Grasp is capable of grasping objects in dense clutters efficiently with promising success rates. Specifically, we define three action primitives: target-oriented grasping for picking up the target directly, pushing and nontarget-oriented grasping to reduce the crowdedness and occlusions. The generators select preferred action primitive set via a spatial correlation test (SCT), which effectively provides various motion candidates for target grasping in clutters. Meanwhile, the evaluators assess the selected action primitive candidates, where the optimal action is implemented by the robot. Extensive experiments in the simulated and real-world environments show that our approach outperforms the state-of-the-art methods of grasping in clutters with respect to the motion efficiency and success rates. Moreover, we achieve comparable performance in the real world as that in the simulation environment, which indicates the strong generalization ability of our GE-Grasp. Video demo is provided in the supplementary material.
# Simultaneous Object Reconstruction and Grasp Prediction Using a Camera-Centric Object Shell Representation
## Keywords:
- Perception for Grasping and Manipulation
- Grasping
- Deep Learning in Grasping and Manipulation
## Abstract:
Being able to grasp objects is a fundamental component of most robotic manipulation systems. In this paper, we present a new approach to simultaneously reconstruct a mesh and a dense grasp quality map of an object from a depth image. At the core of our approach is a novel camera-centric object representation called the ''object shell" which is composed of an observed ''entry image" and a predicted ''exit image." We present an image-to-image residual ConvNet architecture in which the object shell and a grasp-quality map are predicted as separate output channels. The main advantage of the shell representation and the corresponding neural network architecture, ShellGrasp-Net, is that the input-output pixel correspondences in the shell representation are explicitly represented in the architecture. We show that this coupling yields superior generalization capabilities for object reconstruction and accurate grasp quality estimation implicitly considering the object geometry. Our approach yields an efficient dense grasp quality map and an object geometry estimate in a single forward pass. Both of these outputs can be used in a wide range of robotic manipulation applications. With rigorous experimental validation, both in simulation and on a real setup, we show that our shell-based method can be used to generate precise grasps and the associated grasp quality with over 90% accuracy. Diverse grasps computed on shell reconstructions allow the robot to select and execute grasps in cluttered scenes with more than 93% success rate.
# Visual Manipulation Relationship Detection Based on Gated Graph Neural Network for Robotic Grasping
## Keywords:
- Grasping
- Deep Learning in Grasping and Manipulation
## Abstract:
Exploring the relationship among objects and giving the correct operation sequence is vital for robotic manipulation. However, most previous algorithms only model the relationship between pairs of objects independently, ignoring the interaction effect between them, which may generate redundant or missing relations in complex scenes, such as multi-object stacking and partial occlusion. To solve this problem, a Gated Graph Neural Network (GGNN) is designed for visual manipulation relationship detection, which can help robots detect targets in complex scenes and obtain the appropriate grasping order. Firstly, the robot extracts feature from the input image and estimate object categories. Then GGNN is used to effectively capture the dependencies between objects in the whole scene, update the relevant features, and output the grasping sequence. In addition, by embedding positional encoding into pair object features, accurate context information is obtained to reduce the adverse effects of complex scenes. Finally, the constructed algorithm is applied to the physical robot for grasping. Experiment results on the Visual Manipulation Relationship Dataset (VMRD) and the large-scale relational grasp dataset named REGRAD show that our method significantly improves the accuracy of relationship detection in complex scenes, and can be well generalized in the real world.
# Closed-Loop Next-Best-View Planning for Target-Driven Grasping
## Keywords:
- Perception for Grasping and Manipulation
## Abstract:
Picking a specific object from clutter is an essential component of many manipulation tasks. Partial observations often require the robot to collect additional views of the scene before attempting a grasp. This paper proposes a closed-loop next-best-view planner that drives exploration based on occluded object parts. By continuously predicting grasps from an up-to-date scene reconstruction, our policy can decide online to finalize a grasp execution or to adapt the robot’s trajectory for further exploration. We show that our reactive approach decreases execution times without loss of grasp success rates compared to common camera placements and handles situations where the fixed baselines fail. Code is available at https://github.com/ethz-asl/active_grasp.
# The DressGripper: A Collaborative Gripper with Electromagnetic Fingertips for Dressing Assistance
## Keywords:
- Grippers and Other End-Effectors
- Safety in HRI
- Soft Robot Applications
## Abstract:
This paper introduces a gripper designed for a safe interaction while handling clothes in wearing operations. If we consider a robotic system helping people to get dressed, we have two main goals to achieve: i) the gripper that comes in contact with the person has to be intrinsically safe and ii) the gripper should be able to keep the clothes during dressing, e.g. while passing the arm inside the sleeve of a jacket. The gripper proposed in this work solves these issues by matching a compliant and safe structure with an additional magnetic actuation at the fingertips. This combination enable a soft interaction with the robot while guaranteeing the necessary grasping tightness. We report experiment with the proposed prototype that demonstrate its applicability in robotic dressing assistance scenarios.
# A New Gripper That Acts As an Active and Passive Joint to Facilitate Prehensile Grasping and Locomotion
## Keywords:
- Grippers and Other End-Effectors
- Mechanism Design
- Actuation and Joint Mechanisms
## Abstract:
Among primates, the prehensile nature of the hand is vital for greater adaptability and a secure grip over the substrate/branches, particularly for arm-swinging motion or brachiation. Though various brachiation mechanisms that are mechanically equivalent to underactuated pendulum models are reported in the literature, not much attention has been given to the hand design that facilitates both locomotion and within-hand manipulation. In this paper, we propose a new robotic gripper design, equipped with shape conformable active gripping surfaces that can act as an active or passive joint and adapt to substrates with different shapes and sizes. A floating base serial chain, named GraspMaM, equipped with two such grippers, increases the versatility by performing a range of locomotion and manipulation modes without using dedicated systems. The unique gripper design allows the robot to estimate the passive joint state while arm-swinging and exhibits a dual relationship between manipulation and locomotion. We report the design details of the multimodal gripper and how it can be adapted for the brachiation motion assuming it as an articulated suspended pendulum model. Further, the system parameters of the physical prototype are estimated, and experimental results for the brachiation mode are discussed to validate and show the effectiveness of the proposed design.
# Design and Control of a Quasi-Direct Drive Robotic Gripper for Collision Tolerant Picking at High Speed
## Keywords:
- Grippers and Other End-Effectors
- Industrial Robots
- Failure Detection and Recovery
## Abstract:
Faster robotic picking of objects can improve industrial production throughput. A gripper design with appropriate control strategy is demonstrated to pick objects at high speed, while being tolerant to unintentional collisions. The design has a quasi–direct drive with backdrivable, rigid finger mechanism to transfer collision forces with minimal delay towards the motor side. These forces are detected based on band–pass filtered momentum and motor speed monitoring. The motor velocity is observed through Kalman filtering in order to reduce noise in the low–level control loop and band–pass momentum observer, resulting in a higher collision detection sensitivity. On a higher level, the path of the gripper is planned with respect to the trade–off picking speed versus collision tolerance, quantified by the remaining gripper stroke upon impact. The gripper collision tolerance was experimentally verified in several scenarios during high–speed object picking where it mitigated collisions up to 0.6 m/s.
# Award Session II
# Going in Blind: Object Motion Classification Using Distributed Tactile Sensing for Safe Reaching in Clutter
(Finalist for IROS Best Paper Award and ABB Best Student Paper Award)
## Keywords:
- Perception for Grasping and Manipulation
- Force and Tactile Sensing
- Robot Safety
## Abstract:
Robotic manipulators navigating cluttered shelves or cabinets may find it challenging to avoid contact with obstacles. Indeed, rearranging obstacles may be necessary to access a target. Rather than planning explicit motions that place obstacles into a desired pose, we suggest allowing incidental contacts to rearrange obstacles while monitoring contacts for safety. Bypassing object identification, we present a method for categorizing object motions from tactile data collected from incidental contacts with a capacitive tactile skin on an Allegro Hand. We formalize tactile cues associated with categories of object motion, demonstrating that they can determine with >90% accuracy whether an object is movable and whether a contact is causing the object to slide stably (safe contact) or tip (unsafe).
# PI-ARS: Accelerating Evolution-Learned Visual-Locomotion with Predictive Information Representations
(Finalist for IROS Best Paper Award and ABB Best Student Paper Award)
## Keywords:
- Representation Learning
- Reinforcement Learning
- Legged Robots
## Abstract:
Evolution Strategy (ES) algorithms have shown promising results in training complex robotic control policies due to their massive parallelism capability, simple implementation, effective parameter-space exploration, and fast training time. However, a key limitation of ES is its scalability to large capacity models, including modern neural network architectures. In this work, we develop Predictive Information Augmented Random Search (PI-ARS) to mitigate this limitation by leveraging recent advancements in representation learning to reduce the parameter search space for ES. Namely, PI-ARS combines a gradient-based representation learning technique, Predictive Information (PI), with a gradient-free ES algorithm, Augmented Random Search (ARS), to train policies that can process complex robot sensory inputs and handle highly nonlinear robot dynamics. We evaluate PI-ARS on a set of challenging visual-locomotion tasks where a quadruped robot needs to walk on uneven stepping stones, quincuncial piles, and moving platforms, as well as to complete an indoor navigation task. Across all tasks, PI-ARS demonstrates significantly better learning efficiency and performance compared to the ARS baseline. We further validate our algorithm by demonstrating that the learned policies can successfully transfer to a real quadruped robot, for example, achieving a 100% success rate on the real-world stepping stone environment, dramatically improving prior results achieving 40% success.
# Learning Visual Feedback Control for Dynamic Cloth Folding
(Finalist for IROS Best Paper Award and ABB Best Student Paper Award)
(Finalist for IROS Best RoboCup Paper Award Sponsored by RoboCup Federation)
## Keywords:
- Machine Learning for Robot Control
- Deep Learning in Grasping and Manipulation
- Reinforcement Learning
## Abstract:
Robotic manipulation of cloth is a challenging task due to the high dimensionality of the configuration space and the complexity of dynamics affected by various material properties. The effect of complex dynamics is even more pronounced in dynamic folding, for example, when a square piece of fabric is folded in two by a single manipulator. To account for the complexity and uncertainties, feedback of the cloth state using e.g. vision is typically needed. However, construction of visual feedback policies for dynamic cloth folding is an open problem. In this paper, we present a solution that learns policies in simulation using Reinforcement Learning (RL) and transfers the learned policies directly to the real world. In addition, to learn a single policy that manipulates multiple materials, we randomize the material properties in simulation. We evaluate the contributions of visual feedback and material randomization in real-world experiments. The experimental results demonstrate that the proposed solution can fold successfully different fabric types using dynamic manipulation in the real world. Code, data, and videos are available at https://sites.google.com/view/dynamic-cloth-folding.
# PCBot: A Minimalist Robot Designed for Swarm Applications
(Finalist for IROS Best Paper Award and ABB Best Student Paper Award)
(Finalist for IROS Best Paper Award on Robot Mechanisms and Design Sponsored by ROBOTIS)
## Keywords:
- Swarm Robotics
- Mechanism Design
- Multi-Robot Systems
## Abstract:
Complexity, cost, and power requirements for the actuation of individual robots can play a large factor in limiting the size of robotic swarms. Here we present PCBot, a minimalist robot that can precisely move on an orbital shake table using a bi-stable solenoid actuator built directly into its PCB. This allows the actuator to be built as part of the automated PCB manufacturing process, greatly reducing the impact it has on manual assembly. Thanks to this novel actuator design, PCBot has merely five major components and can be assembled in under 20 seconds, potentially enabling them to be easily mass-manufactured. Here we present the electro-magnetic and mechanical design of PCBot. Additionally, a prototype robot is used to demonstrate its ability to move in a straight line as well as follow given paths.
# Characterization of Real-Time Haptic Feedback from Multimodal Neural Network-Based Force Estimates During Teleoperation
(Finalist for IROS Best Paper Award and ABB Best Student Paper Award)
## Keywords:
- Haptics and Haptic Interfaces
- Telerobotics and Teleoperation
- Computer Vision for Medical Robotics
## Abstract:
Force estimation using neural networks is a promising approach to enable haptic feedback in minimally invasive surgical robots without end-effector force sensors. Various network architectures have been proposed, but none have been tested in real time with surgical-like manipulations. Thus, questions remain about the real-time transparency and stability of force feedback from neural network-based force estimates. We characterize the real-time impedance transparency and stability of force feedback rendered on a da Vinci Research Kit teleoperated surgical robot using neural networks with vision-only, state-only, and state and vision inputs. Networks were trained on an existing dataset of teleoperated manipulations without force feedback. To measure real-time stability and transparency during teleoperation with force feedback to the operator, we modeled a one-degree-of-freedom human and surgeon-side manipulandum that moved the patient-side robot to perform manipulations on silicone artificial tissue over various robot and camera configurations, and tools. We found that the networks using state inputs displayed more transparent impedance than a vision-only network. However, state-based networks displayed large instability when used to provide force feedback during lateral manipulation of the silicone. In contrast, the vision-only network showed consistent stability in all the evaluated directions. We confirmed the performance of the vision-only network for real-time force feedback in a demonstration with a human teleoperator.
# Hierarchical Reinforcement Learning for Precise Soccer Shooting Skills Using a Quadrupedal Robot
(Finalist for IROS Best RoboCup Paper Award Sponsored by RoboCup Federation)
## Keywords:
- Legged Robots
- Reinforcement Learning
- Manipulation Planning
## Abstract:
We address the problem of enabling quadrupedal robots to perform precise shooting skills in the real world using reinforcement learning. Developing algorithms to enable a legged robot to shoot a soccer ball to a given target is a challenging problem that combines robot motion control and planning into one task. To solve this problem, we need to consider the dynamics limitation and motion stability during the control of a dynamic legged robot. Moreover, we need to consider motion planning to shoot the hard-to-model deformable ball rolling on the ground with uncertain friction to a desired location. In this paper, we propose a hierarchical framework that leverages deep reinforcement learning to train (a) a robust motion control policy that can track arbitrary motions and (b) a planning policy to decide the desired kicking motion to shoot a soccer ball to a target. We deploy the proposed framework on an A1 quadrupedal robot and enable it to accurately shoot the ball to random targets in the real world.
# Learning 2
# Multi-Modal Legged Locomotion Framework with Automated Residual Reinforcement Learning
## Keywords:
- Evolutionary Robotics
- Humanoid and Bipedal Locomotion
- Legged Robots
## Abstract:
While quadruped robots usually have good stability and load capacity, bipedal robots offer a higher level of flexibility / adaptability to different tasks and environments. A multi-modal legged robot can take the best of both worlds. In this paper, we propose a multi-modal locomotion framework that is composed of a hand-crafted transition motion and a learning-based bipedal controller—learnt by a novel algorithm called Automated Residual Reinforcement Learning. This framework aims to endow arbitrary quadruped robots with the ability to walk bipedally. In particular, we 1) design an additional supporting structure for a quadruped robot and a sequential multi-modal transition strategy; 2) propose a novel class of Reinforcement Learning algorithms for bipedal control and evaluate their performances in both simulation and the real world. Experimental results show that our proposed algorithms have the best performance in simulation and maintain a good performance in a real-world robot. Overall, our multi-modal robot could successfully switch between biped and quadruped, and walk in both modes. Experiment videos and code are available at https://chenaah.github.io/multimodal/.
# Learning to Climb: Constrained Contextual Bayesian Optimisation on a Multi-Modal Legged Robot
## Keywords:
- Evolutionary Robotics
- Climbing Robots
- Bioinspired Robot Learning
## Abstract:
Controlling a legged robot to climb obstacles with different heights is challenging, but important for an autonomous robot to work in an unstructured environment. In this paper, we model this problem as a novel contextual constrained multi-armed bandit framework. We further propose a learning-based Constrained Contextual Bayesian Optimisation (CoCoBo) algorithm that can solve this class of problems efficiently. CoCoBo models both the reward function and constraints as Gaussian processes, incorporate continuous context space and action space into each Gaussian process, and find the next training samples through excursion search. The experimental results show that CoCoBo is more data-efficient and safe, compared to other related state-of-the-art optimisation methods, on both synthetic test functions and real-world experiments. Our real-world results—our robot could successfully learn to climb an obstacle higher than itself—reveal that our method has an enormous potential to allow self-adaptive robots to work in various terrains. Experiment videos and code are available at the project website https://chenaah.github.io/coco/.
# Class-Incremental Gesture Recognition Learning with Out-Of-Distribution Detection
## Keywords:
- Gesture, Posture and Facial Expressions
- Continual Learning
- AI-Based Methods
## Abstract:
Gesture recognition is a popular human-computer interaction technology, which has been widely applied in many fields (e.g., autonomous driving, medical care, VR and AR). However, 1) most existing gesture recognition methods focus on the fixed recognition scenarios with several gestures, which could lead to memory consumption and computational effort when continuously learning new gestures; 2) Meanwhile, the performance of popular class-incremental methods degrades significantly for previously learned classes (i.e., catastrophic forgetting) due to the ambiguity and variability of gestures. To tackle these challenges, we propose a novel class-incremental gesture recognition method with out-of-distribution (OOD) detection, which can continuously adapt to new gesture classes and achieve high performance for both learned and new gestures. Specifically, we construct an episodic memory with a subset of learned training samples to preserve the previous knowledge from forgetting. Moreover, the OOD detection-based memory management is developed for exploring the most representative and informative core set from the learned datasets. When a new gesture recognition task with strange classes comes, rehearsal enhancement is adopted to increase the diversity of memory exemplars for better fitting the real characteristics of gesture recognition. After deriving an effective class-incremental gesture recognition strategy, we perform experiments on two representative datasets to validate the superiority of our method. Evaluation experiments demonstrate that our proposed method substantially outperforms the state-of-the-art methods with about 2.17%-3.81% improvement under different class-incremental learning scenarios.
# PIMNet: Physics-Infused Neural Network for Human Motion Prediction
## Keywords:
- Human Detection and Tracking
- Deep Learning Methods
- AI-Based Methods
## Abstract:
Human motion prediction has recently attracted attention in computer vision and the robotic domain. Research of human motion prediction helps machines understand human behavior, plan target actions and optimize interaction strategies. Currently, existing prediction methods are based on either purely first principle or data-driven, in which the limitation of the methods restricts the performance. To overcome the limitations of both approaches, we proposed a hybrid model, term as PIMNet, which combines a physics-based and statistical model. In PIMNet, an Encoder-LSTM-Decoder based statistical model is applied. Thus, as a physics-infused machine learning model, PIMNet obtains computational efficiency and physical consistency simultaneously. With the help of the simplified human full-body dynamic model, our LSTM based machine model could accurately predict human motion not only in the short-term but in the long term. By comparing our proposed model with several state-of-the-art approaches, we conclude that our physics-infused hybrid model could help the model be physics-plausible and advance the performance.
# What Matters in Language Conditioned Robotic Imitation Learning Over Unstructured Data
## Keywords:
- Learning Categories and Concepts
- Machine Learning for Robot Control
- Representation Learning
## Abstract:
A long-standing goal in robotics is to build robots that can perform a wide range of daily tasks from perceptions obtained with their onboard sensors and specified only via natural language. While recently substantial advances have been achieved in language-driven robotics by leveraging end-to-end learning from pixels, there is no clear and well-understood process for making various design choices due to the underlying variation in setups. In this paper, we conduct an extensive study of the most critical challenges in learning language conditioned policies from offline free-form imitation datasets. We further identify architectural and algorithmic techniques that improve performance, such as a hierarchical decomposition of the robot control learning, a multimodal transformer encoder, discrete latent plans and a self-supervised contrastive loss that aligns video and language representations. By combining the results of our investigation with our improved model components, we are able to present a novel approach that significantly outperforms the state of the art on the challenging language conditioned long-horizon robot manipulation CALVIN benchmark. We have open-sourced our implementation to facilitate future research in learning to perform many complex manipulation skills in a row specified with natural language. Codebase and trained models available at http://hulc.cs.uni-freiburg.de
# Learning Solution Manifolds for Control Problems Via Energy Minimization
## Keywords:
- Machine Learning for Robot Control
- Optimization and Optimal Control
- Imitation Learning
## Abstract:
A variety of control tasks such as inverse kinematics (IK), trajectory optimization (TO), and model predictive control (MPC) are commonly formulated as energy minimization problems. Numerical solutions to such problems are well-established. However, these are often too slow to be used directly in real-time applications. The alternative is to learn solution manifolds for control problems in an offline stage. Although this distillation process can be trivially formulated as a behavioral cloning (BC) problem in an imitation learning setting, our experiments highlight a number of significant shortcomings arising due to incompatible local minima, interpolation artifacts, and insufficient coverage of the state space. In this paper, we propose an alternative to BC that is efficient and numerically robust. We formulate the learning of solution manifolds as a minimization of the energy terms of a control objective integrated over the space of problems of interest. We minimize this energy integral with a novel method that combines Monte Carlo-inspired adaptive sampling strategies with the derivatives used to solve individual instances of the control task. We evaluate the performance of our formulation on a series of robotic control problems of increasing complexity, and we highlight its benefits through comparisons against traditional methods such as behavioral cloning and Dataset aggregation (Dagger).
# First Do Not Fall: Learning to Exploit a Wall with a Damaged Humanoid Robot
## Keywords:
- Machine Learning for Robot Control
- Humanoid Robot Systems
## Abstract:
Humanoid robots could replace humans in hazardous situations but most of such situations are equally dangerous for them, which means that they have a high chance of being damaged and falling. We hypothesize that humanoid robots would be mostly used in buildings, which makes them likely to be close to a wall. To avoid a fall, they can therefore lean on the closest wall, as a human would do, provided that they find in a few milliseconds where to put the hand(s). This article introduces a method, called D-Reflex, that learns a neural network that chooses this contact position given the wall orientation, the wall distance, and the posture of the robot. This contact position is then used by a whole-body controller to reach a stable posture. We show that D-Reflex allows a simulated TALOS robot (1.75m, 100kg, 30 degrees of freedom) to avoid more than 75% of the avoidable falls and can work on the real robot.
# Learning Suction Cup Dynamics from Motion Capture: Accurate Prediction of an Object's Vertical Motion During Release
## Keywords:
- Machine Learning for Robot Control
- Contact Modeling
- Logistics
## Abstract:
Suction grippers are the most common pick-and-place end effectors used in industry. However, there is little literature on creating and validating models to predict their force interaction with objects in dynamic conditions. In this paper, we study the interaction dynamics of an active vacuum suction gripper during the vertical release of an object. Object and suction cup motions are recorded using a motion capture system. As the object’s mass is known and can be changed for each experiment, a study of the object’s motion can lead to an estimate of the interaction force generated by the suction gripper. We show that, by learning this interaction force, it is possible to accurately predict the object’s vertical motion as a function of time. This result is the first step toward 3D motion prediction when releasing an object from a suction gripper.
# Embodied Active Domain Adaptation for Semantic Segmentation Via Informative Path Planning
## Keywords:
- Perception-Action Coupling
- Integrated Planning and Learning
- Object Detection, Segmentation and Categorization
## Abstract:
This work presents an embodied agent that can adapt its semantic segmentation network to new indoor environments in a fully autonomous way. Because semantic segmentation networks fail to generalize well to unseen environments, the agent collects images of the new environment which are then used for self-supervised domain adaptation. We formulate this as an informative path planning problem, and present a novel information gain that leverages uncertainty extracted from the semantic model to safely collect relevant data. As domain adaptation progresses, these uncertainties change over time and the rapid learning feedback of our system drives the agent to collect different data. Experiments show that our method adapts to new environments faster and with higher final performance compared to an exploration objective, and can successfully be deployed to real-world environments on physical robots.
# Grasping 2
# ICK-Track: A Category-Level 6-DoF Pose Tracker Using Inter-Frame Consistent Keypoints for Aerial Manipulation
## Keywords:
- Perception for Grasping and Manipulation
- Aerial Systems: Perception and Autonomy
- Object Detection, Segmentation and Categorization
## Abstract:
Robots that are supposed to interact with or manipulate objects in the world must be able to track the poses of objects in their sensor data. Thus, Detecting and tracking the 6-DoF poses of targeted objects is important for aerial manipulation and is still in the early stage due to the high dynamics and limited onboard capacity of such systems. In this paper, we propose ICK-Track, a novel method for onboard category-level object 6-DoF pose tracking that can be applied to aerial manipulation without using any pre-defined object CAD models. It first utilizes a semi-supervised video segmentation to detect objects in the eye-in-hand RGB-D camera stream to segment the 3D points of objects. Then, canonical keypoints are extracted using iterative farthest point sampling. We propose a novel inter-frame consistent keypoints generation network to generate the corresponding keypoint pairs, which are used together with ICP to estimate the pose changes of objects for tracking. Experimental results show that our method is more robust to viewpoint changes and runs faster than the state-of-the-art methods on category-level pose tracking. We further test our proposed method on a real aerial manipulator. A demo video showing the use of our method on a real aerial manipulator and the implementation of our method are available at: https://github.com/S-JingTao/ICK-Track.
# Multi-Finger Grasping Like Humans
## Keywords:
- Grasping
- Multifingered Hands
## Abstract:
Robots with multi-fingered grippers could perform advanced manipulation tasks for us if we were able to properly specify to them what to do. In this study, we take a step in that direction by making a robot grasp an object like a grasping demonstration performed by a human. We propose a novel optimization-based approach for transferring human grasp demonstrations to any multi-fingered grippers, which produces robotic grasps that mimic the human hand orientation and the contact area with the object, while alleviating interpenetration. Extensive experiments with the Allegro and BarrettHand grippers show that our method leads to grasps more similar to the human demonstration than existing approaches, without requiring any gripper-specific tuning. We confirm these findings through a user study and validate the applicability of our approach on a real robot.
# Computation and Selection of Secure Gravity Based Caging Grasps of Planar Objects
## Keywords:
- Grasping
- Manipulation Planning
- Computational Geometry
## Abstract:
Gravity based caging grasps are robotic grasps where the robot hand passively supports an object against gravity. When a robot hand supports an object at a local minimum of the object gravitational energy, the robot hand forms a basket like grasp of the object. Any object movement in a basket grasp requires an increase of the object gravitational energy, thus allowing secure object pickup and transport with robot hands that use a small number fingers. The basket grasp depth measures the minimal additional energy the object must acquire to escape the basket grasp. This paper describes a computation scheme that determines the depth of entire sets of candidate basket grasps associated with alternative finger placements on the object boundary before pickup. The computation relies on categorization of escape stances that mark the basket grasp depth: double-support escapes are first analyzed and computed, then single-support escapes are analyzed and computed. The minimum energy combination of both types of escape stances defines the depth of entire sets of candidate basket grasps, which is then used to identify the deepest and hence most secure basket grasp. The computation scheme is fully implemented and demonstrated on several examples with reported run-times.
# F1 Hand: A Versatile Fixed-Finger Gripper for Delicate Teleoperation and Autonomous Grasping
## Keywords:
- Grippers and Other End-Effectors
- Telerobotics and Teleoperation
- Grasping
## Abstract:
Teleoperation is often limited by the ability of an operator to not only react but also predict the behavior of the robot as it interacts with the environment. For example, to grasp small objects on a table by teleoperating a multiple-linkage adaptive finger, we need to predict the position of the fingertips before the fingers are closed to avoid them hitting the table while successfully grasping the objects. For that reason, we developed the F1 Hand, a single-motor gripper that makes teleoperation intuitive due to the presence of a fixed finger. As a result, it is possible to grasp objects as thin as a paper clip and a toothpick, and as heavy and large as a cordless drill. Moreover, the applicability of the hand can be expanded by replacing the fixed finger with different shapes according to different requirements. This flexibility allows the hand to be highly versatile and developable without sacrificing much time and money. On one hand, the asymmetric design of the two-finger gripper is uncommon compared with the symmetric gripper. Therefore, it is not obvious how to control the F1 hand for autonomous grasping. Thus, we propose a controller that approximates actuation symmetry by using the motion of the whole arm. The F1 hand and its controller are compared side-by-side with the original Toyota Human Support Robot (HSR) gripper in teleoperation using 22 objects from the YCB dataset in addition to small objects. The grasping time and peak contact forces could be decreased by 20% and 70%, respectively while increasing success rates by 5%. Using an off-the-shelf grasp pose estimator for autonomous grasping, the system achieved similar success rates to the original HSR gripper, at the order of 80%.
# EfficientGrasp: A Unified Data-Efficient Learning to Grasp Method for Multi-Fingered Robot Hands
## Keywords:
- Grasping
- Deep Learning in Grasping and Manipulation
- Multifingered Hands
## Abstract:
Autonomous grasping of novel objects that are previously unseen to a robot is an ongoing challenge in robotic manipulation. In the last decades, many approaches have been presented to address this problem for specific robot hands. The UniGrasp framework, introduced recently, has the ability to generalize to different types of robotic grippers; however, this method does not work on grippers with closed-loop constraints and is data-inefficient when applied to robot hands with multigrasp configurations. In this paper, we present EfficientGrasp, a generalized grasp synthesis and gripper control method that is independent of gripper model specifications. EfficientGrasp utilizes a gripper workspace feature rather than UniGrasp’s gripper attribute inputs. This reduces memory use by 81.7% during training and makes it possible to generalize to more types of grippers, such as grippers with closed-loop constraints. The effectiveness of EfficientGrasp is evaluated by conducting object grasping experiments both in simulation and real-world; results show that the proposed method also outperforms UniGrasp when considering only grippers without closed-loop constraints. In these cases, EfficientGrasp shows 9.85% higher accuracy in generating contact points and 3.10% higher grasping success rate in simulation. The real-world experiments are conducted with a gripper with closed-loop constraints, which UniGrasp fails to handle while EfficientGrasp achieves a success rate of 83.3%. The main causes of grasping failures of the proposed method are analyzed, highlighting ways of enhancing grasp performance.
# BRL/Pisa/IIT SoftHand: A Low-Cost, 3D-Printed, Underactuated, Tendon-Driven Hand with Soft and Adaptive Synergies
## Keywords:
- Multifingered Hands
- Underactuated Robots
## Abstract:
This paper introduces the BRL/Pisa/IIT (BPI) SoftHand: a single actuator-driven, low-cost, 3D-printed, tendon-driven, underactuated robot hand that can be used to perform a range of grasping tasks. Based on the adaptive synergies of the Pisa/IIT SoftHand, we design a new joint system and tendon routing to facilitate the inclusion of both soft and adaptive synergies, which helps us balance durability, affordability and moderate dexterity of the hand. The focus of this work is on the design, simulation, synergies and grasping tests of this SoftHand. The novel phalanges are designed and printed based on linkages, gear pairs and geometric restraint mechanisms, and can be applied to most tendon-driven robotic hands. We show that the robot hand can successfully grasp and lift various target objects and adapt to hold complex geometric shapes, reflecting the successful adoption of the soft and adaptive synergies. We intend to open-source the design of the hand so that it can be built cheaply on a home 3D-printer.
# On Robotic Manipulation of Flexible Flat Cables: Employing a Multi-Modal Gripper with Dexterous Tips, Active Nails, and a Reconfigurable Suction Cup Module
## Keywords:
- Grippers and Other End-Effectors
- In-Hand Manipulation
## Abstract:
A popular solution for connecting different components in modern electronics, such as mobile phones, laptops, tablets, etc, is the use of flexible flat cables (FFC). Typically, it takes hours of repetition from a highly trained worker, or a high precision autonomous robot with specialised end effectors to reliably manage the installation of these cables. Human workers are prone to error, and cannot work endlessly without a break, while the robots often come with a significant expense, and require a substantial amount of time to program and reprogram. Additionally, the use of sophisticated sensing elements further increases the complexity of the required control system. As a result, the performance and robustness of such systems is far from sufficient, hindering their mass adoption. The manipulation of FFCs is also quite challenging. In this work, we focus on the robotic manipulation of a plethora of flexible cables, proposing a multi-modal gripper with locally-dexterous tips and active fingernails. The fingers of the gripper are equipped with: i) locally-dexterous fingertips that accommodate manipulation-capable degrees of freedom, ii) a combination of Nitinol-based active fingernails and suction cups that allow picking up and handling of cables that rest on flat surfaces, and iii) compliant finger-pads that conform to the object surface to increase grasping stability. The proposed robotic gripper is equipped with a camera and a perception system that allow for the execution of complex cable manipulation and assembly tasks in dynamic environments.
# Automated Design of Embedded Constraints for Soft Hands Enabling New Grasp Strategies
## Keywords:
- Grasping
- Grippers and Other End-Effectors
- Soft Robot Materials and Design
## Abstract:
Soft robotic hands allow to fully exploit hand-object-environment interactions to complete grasping tasks. However, their usability can still be limited in some scenarios (e.g., restricted or cluttered spaces). In this paper, we propose to enhance the versatility of soft grippers by adding special passive components to their structure, without completely altering their design, nor their control. A method for the automated design of soft-rigid scoop-shaped add-ons acting as “embedded constraints” is presented. Given a certain gripper and a large set of objects, the design parameters of the optimal scoop for each object are derived by solving an optimization problem. Also the object-environment relative pose is considered in the optimization. The obtained “optimal scoops” are clustered to get a limited set of representative scoop designs which can be prototyped and used in grasping tasks. In this work, we also introduce a data-driven method allowing a grasp planner to select the most suitable scoop to be added to the used hand, given a certain object and its configuration with respect to the surrounding environment. Experiments with two different hands validate the proposed approach.
# Scalable Learned Geometric Feasibility for Cooperative Grasp and Motion Planning
## Keywords:
- Grasping
- Manipulation Planning
- Deep Learning in Grasping and Manipulation
## Abstract:
This study proposes a novel learned feasibility estimator that considers multi-modal grasp poses for grasp and motion planning. Grasp poses have inherently multi-modal structures: continuous and discrete parameters. Mixed-integer programming (MIP) is one method that solves these multi-modal problems. However, searching all discrete parameters costs considerable time. Therefore, by learning the feasibility of each mode from geometric variables, the problem can be solved efficiently within the given time limit. The feasibility of grasp poses is related to the pose of the object and obstacles nearby the object. Utilizing this information, we introduce the learned geometric feasibility (LGF) that prioritizes the integer search of MIP. LGF is scalable to multiple robots and environments because it learns the feasibility using object-oriented information. It is demonstrated to improve the number of the solved MIP problems within the time limit and apply the LGF to various environmental settings.
# Manipulation Systems 2
# A Solution to Adaptive Mobile Manipulator Throwing
## Keywords:
- Mobile Manipulation
- Task and Motion Planning
- Representation Learning
## Abstract:
Mobile manipulator throwing is a promising method to increase the flexibility and efficiency of dynamic manipulation in factories. Its major challenge is to efficiently plan a feasible throw under a wide set of task specifications. We show that the mobile manipulator throwing problem can be simplified to a planar problem, hence greatly reducing the computational costs. Using machine learning approaches, we build a model of the object's inverted flying dynamics and the robot's kinematic feasibility, which enables throwing motion generation within 1 ms for given query of target position. Thanks to the computational efficiency of our method, we show that the system is adaptive under disturbance, via replanning on the fly for alternative solutions, instead of sticking to the original throwing plan.
# A Novel Design and Evaluation of a Dactylus-Equipped Quadruped Robot for Mobile Manipulation
## Keywords:
- Biologically-Inspired Robots
- Mobile Manipulation
- Legged Robots
## Abstract:
Quadruped robots are usually equipped with additional arms for manipulation, negatively impacting price and weight. On the other hand, the requirements of legged locomotion mean that the legs of such robots often possess the needed torque and precision to perform manipulation. In this paper, we present a novel design for a small-scale quadruped robot equipped with two leg-mounted manipulators inspired by crustacean chelipeds and knuckle-walker forelimbs. By making use of the actuators already present in the legs, we can achieve manipulation using only 3 additional motors per limb. The design enables the use of small and inexpensive actuators relative to the leg motors, further reducing cost and weight. The moment of inertia impact on the leg is small thanks to an integrated cable/pulley system. As we show in a suite of tele-operation experiments, the robot is capable of performing single# and dual-limb manipulation, as well as transitioning between manipulation modes. The proposed design performs similarly to an additional arm while weighing and costing 5 times less per manipulator and enabling the completion of tasks requiring 2 manipulators.
# Task-Oriented Contact Optimization for Pushing Manipulation with Mobile Robots
## Keywords:
- Dexterous Manipulation
- Manipulation Planning
- Multi-Robot Systems
## Abstract:
This work addresses the problem of transporting an object along a desired planar trajectory by pushing with mobile robots. More specifically, we concentrate on establishing optimal contacts between the object and the robots to execute the given task with minimum effort. We present a task-oriented contact placement optimization strategy for object pushing that allows calculating optimal contact points minimizing the amplitude of forces required to execute the task. Exploiting the optimized contact configuration, a motion controller uses the computed contact forces in feed-forward and position error feedback terms to realize the desired trajectory tracking task. Simulations and real experiments results confirm the validity of our approach.
# Articulated Object Interaction in Unknown Scenes with Whole-Body Mobile Manipulation
## Keywords:
- Mobile Manipulation
- Whole-Body Motion Planning and Control
- Collision Avoidance
## Abstract:
A kitchen assistant needs to operate human-scale objects, such as cabinets and ovens, in unmapped environments with dynamic obstacles. Autonomous interactions in such environments require integrating dexterous manipulation and fluid mobility. While mobile manipulators in different form factors provide an extended workspace by combining the dexterity of a manipulator arm with the extended reach of a mobile base, their real-world adoption has been limited. This limitation is in part due to two main reasons: 1) inability to interact with unknown human-scale objects and 2) inefficient coordination between the arm and the mobile base. Executing a high-level task for general objects requires a perceptual understanding of the object as well as adaptive whole-body control among dynamic obstacles. In this paper, we propose a two-stage architecture for autonomous interaction with large articulated objects in unknown environments. The first stage, emph{object-centric} planner, only focuses on the object to provide an action-conditional sequence of states for manipulation using RGB-D data. The second stage, emph{agent-centric} planner, formulates the whole-body motion control as an optimal control problem that ensures safe tracking of the generated plan, even in scenes with moving obstacles. We show that the proposed pipeline can handle complex static and dynamic kitchen settings for both wheel-base and legged mobile manipulators. Compared to other agent-centric planners, our proposed planner achieves a higher success rate and a lower execution time. We perform hardware tests on a legged mobile manipulator to interact with various articulated objects in a kitchen. For additional material, please check: https://www.pair.toronto.edu/articulated-mm/ .
# A Versatile Affordance Modeling Framework Using Screw Primitives to Increase Autonomy During Manipulation Contact Tasks
## Keywords:
- Mobile Manipulation
- Telerobotics and Teleoperation
- Reactive and Sensor-Based Planning
## Abstract:
Recent studies utilizing Affordance Templates to perform remote contact manipulation tasks with mobile manipulators have demonstrated their usefulness for modeling complex tasks allowing robots to work in uncertain environments. These efforts largely fall into the “supervised autonomy” paradigm where a user commands high-level actions and supervises the robot’s execution, but is not responsible for the low-level execution details such as controlling the endpoint/joints, managing contact forces, or avoiding collisions. In this work, we present a novel formulation for modeling affordances that features the versatility and generality of screw theory. We also propose a generic framework and algorithm for executing manipulation contact tasks. To thoroughly evaluate the performance of the proposed formulation and framework, we performed various sets of experiments using our mobile manipulator. We showed that this framework is generic enough to successfully manipulate a variety of articulated objects. Moreover, by performing a set of manipulation tasks on a wheel valve as our case study, we demonstrated that our approach lowers task duration (about 5 times) and applied forces and torques significantly (about 2.5 and 3 times, respectively) when compared to direct teleoperation. Further, by performing 90 trials, we show robust performance of the proposed screw-based framework even when there is significant error in the estimated position and orientation (i.e., about 10 cm and 0.35 rad) of the task objects.
# Combining Navigation and Manipulation Costs for Time-Efficient Robot Placement in Mobile Manipulation Tasks
## Keywords:
- Mobile Manipulation
- Motion and Path Planning
- Integrated Planning and Control
## Abstract:
Mobile manipulation tasks require a seamless integration of navigation and manipulation capabilities. Finding suitable robot placements to pick up and place objects in such tasks is crucial for time-efficient task execution. Sub-optimal robot placements result in infeasible solutions or require larger repositioning of the mobile base to reach target objects, increasing the overall time to complete the task. In this work, we propose an approach that, given a set of objects, autonomously selects the optimal placements of a humanoid robot in conjunction with the best grasp candidate and corresponding arm. In contrast to previous approaches, our method considers both the navigation costs between consecutive robot placements and the manipulation costs to reduce the time needed to complete the task. We evaluate our method on a simulated table clearing task that requires the robot to move between pickup and discard locations and demonstrate the applicability in a real-world experiment on the humanoid robot ARMAR-6. In addition, we perform a run-time analysis and show that our approach can integrate sensory feedback to update the optimal placement in dynamic environments.
# An Open-Source Motion Planning Framework for Mobile Manipulators Using Constraint-Based Task Space Control with Linear MPC
## Keywords:
- Mobile Manipulation
- Service Robotics
## Abstract:
We present an open source motion planning framework for ROS, which uses constraint and optimization based task space control to generate trajectories for the whole body of mobile manipulators. Motion goals are defined as constraints which are enforced on task space functions. They map the controllable degrees of freedom of a system onto custom task spaces, which can, but do not have to be, the Cartesian space. We use this expressive tool from motion control to pre-compute trajectories in order to utilize the fact that most robots offer controllers to follow such trajectories. As a result, our framework only requires a kinematic model of the robot to control it. In addition, we extend the constraint-based motion control approach with linear MPC to explicitly optimize for velocity, acceleration and jerk simultaneously, which allows us to enforce constraints on all derivatives in both joint and task space at the same time. As a result, we can reuse pre-defined motion goals on any robot without modifications. Our framework was tested on four different robots to show its generality.
# View Planning for Object Pose Estimation Using Point Clouds: An Active Robot Perception Approach
## Keywords:
- Computer Vision for Manufacturing
- Reactive and Sensor-Based Planning
- Motion and Path Planning
## Abstract:
This paper considers the object pose estimation problem for robotic tasks where the robot end-effector is mounted with a vision sensor to collect pose data from different views. The data quality, which directly affects how accurately the object's pose can be estimated, depends on view planning which is the process of sequentially placing the vision sensor in the robot workspace to continuously acquire useful data (pose information). While the pose estimation is done through point cloud registration by using existing methods, the focus of this work is on planning sensor views based on point cloud analysis to improve point cloud quality and quantity for pose estimation. To this end, we propose an active robot perception framework based on the intrinsic connection between data collection and pose estimation for a robotic task: robot motions should be guided by the task goal and the task is better completed with improved data collected through robot motion. The proposed active perception framework includes the following components: evaluating the quality and quantity of the point clouds, finding a minimum number of optimal sensor views, and calculating robot poses corresponding to the sensor views. The minimum number of sensor views required to improve the point cloud quality is found by solving a set cover problem while the optimal sensor views are obtained through mixed-integer programming. The robot poses corresponding to the sensor views are calculated by solving the robot inverse kinematics via nonlinear programming. Extensive experiments were conducted with different objects to evaluate the proposed framework, and a representative sample of the results from those experiments are provided. The overall effectiveness of the active perception strategy is shown through imp
# Planning to Build Block Structures with Unstable Intermediate States Using Two Manipulators (I)
## Keywords:
- Assembly
- Manipulation Planning
- Task and Motion Planning
## Abstract:
The work is inspired by the assembly of Soma block puzzles. Soma block puzzles usually include unstable intermediate states that require additional support to maintain stability temporarily. In the puzzles’ solution manual, we can observe that designers consider the characteristics that humans have two hands and can avoid an unstable intermediate state by using one hand to support the finished component and using the other hand to assemble an upcoming workpiece. Motivated by human behavior, this paper develops a planner that automatically finds an optimal assembly sequence for a dual-arm robot to build a woodblock structure while considering various constraints and supporting grasps from a second hand. It uses the mesh model of wood blocks and the final assembly state to generate possible assembly sequences and evaluate the optimal assembly sequence by considering the stability, graspability, assemblability, and the need for a second hand. Especially, the need for a second hand is resolved when supports from worktables and other workpieces are not enough to produce a stable assembly. A second hand can hold and support the unstable components so that the robot can further assemble new workpieces until the structure state becomes stable again. The output of the planner includes the optimal assembly orders, candidate grasps, assembly directions, and the supporting grasps (if needed). The output can help guide a dual-arm robot to perform motion planning and thus generate assembly motion. Experiments using various blocks and structures show the effectiveness of the proposed planner.
# Navigation Systems 1
# RARA: Zero-Shot Sim2Real Visual Navigation with Following Foreground Cues
## Keywords:
- Vision-Based Navigation
- AI-Enabled Robotics
- Deep Learning for Visual Perception
## Abstract:
The gap between simulation and the real-world restrains many machine learning breakthroughs in computer vision and reinforcement learning from being applicable in the real world. In this work, we tackle this gap for the specific case of camera-based navigation, formulating it as following a visual cue in the foreground with arbitrary backgrounds. The visual cue in the foreground can often be simulated realistically, such as a line, gate or cone. The challenge then lies in coping with the unknown backgrounds and integrating both. As such, the goal is to train a visual agent on data captured in an empty simulated environment except for this foreground cue and test this model directly in a visually diverse real world. In order to bridge this big gap, we show it's crucial to combine following techniques namely: Randomized augmentation of the fore# and background, regularization with both deep supervision and triplet loss and finally abstraction of the dynamics by using waypoints rather than direct velocity commands. The various techniques are ablated in our experimental results both qualitatively and quantitatively finally demonstrating a successful transfer from simulation to the real world.
# Navigation among Movable Obstacles with Object Localization Using Photorealistic Simulation
## Keywords:
- Vision-Based Navigation
- Motion and Path Planning
- Autonomous Vehicle Navigation
## Abstract:
While mobile navigation has been focused on obstacle avoidance, Navigation Among Movable Obstacles (NAMO) via interaction with the environment, is a problem that is still open and challenging. This paper, presents a novel system integration to handle NAMO using visual feedback. In order to explore the capabilities of our introduced system, we explore the solution of the problem via graph-based path planning in a photorealistic simulator (NVIDIA Isaac Sim), in order to identify if the simulation-to-reality (sim2real) problem in robot navigation can be resolved. We consider the case where a wheeled robot navigates in a warehouse, in which movable boxes are common obstacles. We enable online real-time object localization and obstacle movability detection, to either avoid objects or, if it is not possible, to clear them out from the robot planned path by using pushing actions. We firstly test the integrated system in photorealistic environments, and we then validate the method on a real-world mobile wheeled robot (UCL MPPL) and its on-board sensory and computing system.
# Navigating Underground Environments Using Simple Topological Representations
## Keywords:
- Autonomous Vehicle Navigation
- Field Robots
## Abstract:
Underground environments are some of the most challenging for autonomous navigation. The long, featureless corridors, loose and slippery soils, bad illumination and unavailability of global localization make many traditional approaches struggle. In this work, a topological-based navigation system is presented that enables autonomous navigation of a ground robot in mine-like environments relying exclusively on a high-level topological representation of the tunnel network. The topological representation is used to generate high-level topological instructions used by the agent to navigate through corridors and intersections. A Convolutional Neural Network (CNN) is used to detect all the galleries accessible to a robot from its current position. The use of a CNN proves to be a reliable approach to this problem, capable of detecting the galleries correctly in a wide variety of situations. The CNN is also able to detect galleries even in the presence of obstacles, which motivates the development of a reactive navigation system that can effectively exploit the predictions of the gallery detection.
# Teaching Agents How to Map: Spatial Reasoning for Multi-Object Navigation
## Keywords:
- Vision-Based Navigation
- Deep Learning Methods
- Deep Learning for Visual Perception
## Abstract:
In the context of visual navigation, the capacity to map a novel environment is necessary for an agent to exploit its observation history in the considered place and efficiently reach known goals. This ability can be associated with spatial reasoning, where an agent is able to perceive spatial relationships and regularities, and discover object characteristics. Recent work introduces learnable policies parametrized by deep neural networks and trained with Reinforcement Learning (RL). In classical RL setups, the capacity to map and reason spatially is learned end-to-end, from reward alone. In this setting, we introduce supplementary supervision in the form of auxiliary tasks designed to favor the emergence of spatial perception capabilities in agents trained for a goal-reaching downstream objective. We show that learning to estimate metrics quantifying the spatial relationships between an agent at a given location and a goal to reach has a high positive impact in Multi-Object Navigation settings. Our method significantly improves the performance of different baseline agents, that either build an explicit or implicit representation of the environment, even matching the performance of incomparable oracle agents taking ground-truth maps as input. A learning-based agent from the literature trained with the proposed auxiliary losses was the winning entry to the Multi-Object Navigation Challenge, part of the CVPR 2021 Embodied AI Workshop.
# NAUTS: Negotiation for Adaptation to Unstructured Terrain Surfaces
## Keywords:
- Vision-Based Navigation
- Autonomous Vehicle Navigation
- Field Robots
## Abstract:
When robots operate in real-world off-road environments with unstructured terrains, the ability to adapt their navigational policy is critical for effective and safe navigation. However, off-road terrains introduce several challenges to robot navigation, including dynamic obstacles and terrain uncertainty, leading to inefficient traversal or navigation failures. To address these challenges, we introduce a novel approach for adaptation by negotiation that enables a ground robot to adjust its navigational behaviors through a negotiation process. Our approach first learns prediction models for various navigational policies to function as a terrain-aware joint local controller and planner. Then, through a new negotiation process, our approach learns from various policies' interactions with the environment to agree on the optimal combination of policies in an online fashion to adapt robot navigation to unstructured off-road terrains on the fly. Additionally, we implement a new optimization algorithm that offers the optimal solution for robot negotiation in real-time during execution. Experimental results have validated that our method for adaptation by negotiation outperforms previous methods for robot navigation, especially over unseen and uncertain dynamic terrains.
# Resilient Detection and Recovery of Autonomous Systems Operating under On-Board Controller Cyber Attacks
## Keywords:
- Autonomous Vehicle Navigation
- Failure Detection and Recovery
- Motion and Path Planning
## Abstract:
Cyber-attacks, failures, and implementation errors inside the controller of an autonomous system can affect its correct behavior leading to unsafe states and degraded performance. In this paper, we focus on such problems specifically on cyber-attacks that manipulate controller parameters like the gains in a feedback controller or that triggers different behaviors or block inputs based on specific values of the state and tracking error. If such attacks are undetected, they can lead to the partial or complete loss of system's control authority, resulting in a hijacking and leading the autonomous system towards unforeseen states. To deal with this problem, we propose a runtime monitoring and recovery scheme in which: 1) we leverage the residual between the expected and the received measurements to detect inconsistencies in the generated inputs and 2) provide a recovery method for counteracting the malicious effects to allow for resilient operations by manipulating the reference signal and state vector provided to the system to avoid the affected regions in the state and error space. We validate our approach with Matlab simulations and experiments on unmanned ground vehicles resiliently performing operations in the presence of malicious attacks to on-board controllers.
# Benchmarking Augmentation Methods for Learning Robust Navigation Agents: The Winning Entry of the 2021 iGibson Challenge
## Keywords:
- Vision-Based Navigation
- Autonomous Agents
- Reinforcement Learning
## Abstract:
Recent advances in deep reinforcement learning and scalable photorealistic simulation have led to increasingly mature embodied AI for various visual tasks, including navigation. However, while impressive progress has been made for teaching embodied agents to navigate static environments, much less progress has been made on more dynamic environments that may include moving pedestrians or movable obstacles. In this study, we aim to benchmark different augmentation techniques for improving the agent's performance in these challenging environments. We show that adding several dynamic obstacles into the scene during training confers significant improvements in test-time generalization, achieving much higher success rates than baseline agents. We find that this approach can also be combined with image augmentation methods to achieve even higher success rates. Additionally, we show that this approach is also more robust to sim-to-sim transfer than image augmentation methods. Finally, we demonstrate the effectiveness of this dynamic obstacle augmentation approach by using it to train an agent for the 2021 iGibson Challenge at CVPR, where it achieved 1st place for Interactive Navigation.
# Robotic Interestingness Via Human-Informed Few-Shot Object Detection
## Keywords:
- Vision-Based Navigation
- Object Detection, Segmentation and Categorization
- Human Factors and Human-in-the-Loop
## Abstract:
Interestingness recognition is crucial for decision making in autonomous exploration for mobile robots. Previous methods proposed an unsupervised online learning approach that can adapt to environments and detect interesting scenes quickly, but lack the ability to adapt to human-informed interesting objects. To solve this problem, we introduce a human-interactive framework, AirInteraction, that can detect human-informed objects via few-shot online learning. To reduce the communication bandwidth, we first apply an online unsupervised learning algorithm on the unmanned vehicle for interestingness recognition and then only send the potential interesting scenes to a base-station for human inspection. The human operator is able to draw and provide bounding box annotations for particular interesting objects, which are sent back to the robot to detect similar objects via few-shot learning. Only using few human-labeled examples, the robot can learn novel interesting object categories during the mission and detect interesting scenes that contain the objects. We evaluate our method using various interesting scene recognition datasets. To the best of our knowledge, it is the first human-informed few-shot object detection framework for autonomous exploration.
# Map-Free Lidar Odometry (MFLO) Using a Range Flow Constraint and Point Patch Covariances
## Keywords:
- Localization
- Range Sensing
- Mining Robotics
## Abstract:
We present a lightweight real-time method to extract 3D ego-motion using a range flow constraint equation, point patch covariance, and a least squares solution. Our method exploits the structured data provided by range sensors, like rotating LiDARs, to attain 6 DOF odometry without building a map or scan-matching. To evaluate the performance of MFLO, a quadrotor was flown in various environments, and results indicate that MFLO matches and sometimes exceeds the performance of other LiDAR-based odometry methods while using fewer computational resources. In underground environments, MFLO captured 95.7% of the total vertical displacement for a 17.5m translation upwards through a missile silo, the most of any other LiDAR algorithm evaluated in this study, and captured 92.8% of the total translation for a 42m translation through an underground mine. In a motion capture lab, MFLO performed with only a 0.89-2.87% displacement percent error and 1.03-2.97% in final position error comparing to ground truth, making it the most consistent LiDAR odometry algorithm without mapping.
# Aerial Systems 2
# Rotor Array Synergies for Aerial Modular Reconfigurable Robots
## Keywords:
- Aerial Systems: Applications
- Cellular and Modular Robots
- Aerial Systems: Mechanics and Control
## Abstract:
Aerial Modular Reconfigurable Robots (AMRRs) are scalable systems consisting of rotor modules capable of rearrangement during flight. The potential to dynamically change any shape for a given task poses the question: what arrangements offer the most aerodynamic benefit for the task of flying? Answering this requires understanding how adjacent rotors in various configurations influence each another. Intuitively, aerodynamic models such as momentum theory suggest that close rotor proximity decreases performance due to the upstream rotor flow fields interacting. However, effects such as vortex interaction or viscous flow entrainment (used by the Dyson bladeless fan) may offer benefits not captured by the modelling assumptions of computational analysis or simulation. Thus, this work takes an experimental approach, testing thrust performance of rotors in independent configurations of lines, square lattices, and hexagons with various inter-rotor spacings. It was found that inter-rotor spacing did not significantly change thrust performance, but that hexagonal arrangements outperformed line and grid lattices. Smoke tests indicated that hexagon configurations entrained air in the central cavity resulting in a thrust improvement. An inter-rotor spacing of 1.51 rotor diameters gave the best performance increase, roughly equal to that of an additional rotor. This suggests that by placing rotors in an array of six hollow hexagonal honeycombs, thrust performance could theoretically be increased by up to 27.3 per cent, for no additional mass.
# Precise Position Control of a Multi-Rotor UAV with a Cable-Suspended Mechanism During Water Sampling
## Keywords:
- Aerial Systems: Applications
- Sensor Fusion
- Sensor-based Control
## Abstract:
This paper addresses the problem of water sampling by using a multirotor UAV with a cable-suspended mechanism. In order to ensure the safe execution of the sampling procedure and the stabilization of the vehicle, the disturbances, induced by the water flow and transferred through the cable, have to be identified. Specifically, an estimate of the disturbances is extracted by integrating a depth sensor, a load cell, an ultrasonic sensor and a downward-looking camera into the UAV’s sensor suite and fusing the respective measurements. Gaussian Processes are afterwards employed so as to learn the uncertain disturbances in real time and in a non-parametric manner. The predicted disturbances are incorporated into a geometric control scheme which is capable of stabilizing the UAV above the desired sampling position while compensating for the aforementioned disturbances. The performance of the proposed control strategy is demonstrated through both simulation and experimental results.
# Multirotor Long-Reach Aerial Pruning with Wire-Suspended Saber Saw
## Keywords:
- Aerial Systems: Applications
- Field Robots
- Mobile Manipulation
## Abstract:
Pruning work at high altitude is a dangerous work with a high risk of accidents for human workers. In this research, we propose a multirotor flying robot that is equipped with a wire-suspended device and performs pruning task. We use a saber saw as a cutting tool. If the cutting tool is installed on the body of the multirotor platform, it is difficult for the flying robot to approach the desired work point if there are obstacles such as other branches around the target branch to be pruned. Therefore, in this study, we propose a saber saw suspended from the body of the multirotor platform with two wires. The wire-suspended device is equipped with a saber saw and four ducted fans that produces thrust in any direction on the horizontal plane. This ducted fan system can be used to suppress the swing of the wire-suspended device to make positioning of the saber saw blade to the target point easier, and to improve the efficiency of the cutting and reduce the cutting time by providing a pushing force to the saber saw. As a result, the pruning work could be performed efficiently. Experiments have demonstrated that aerial pruning is possible using the long-reach wire-suspended saber saw.
# Unmanned Aircraft System-Based Radiological Mapping of Buildings
## Keywords:
- Aerial Systems: Applications
- Robotics in Hazardous Fields
- Simulation and Animation
## Abstract:
The article focuses on acquiring a 3D radiation map of a building via a two-phase survey performed with an unmanned aircraft system (UAS). First, a model of the studied building is created by means of photogrammetry. Then, radiation data are collected using a 2-inch NaI(Tl) detector in a regular grid at a distance of 2 m from all accessible surfaces of the building (i.e., the walls and the roof). The data are then georeferenced, filtered, projected to the building model, and interpolated to yield the detailed radiation map. A method to estimate the parameters of the radiation sources located inside is introduced and successfully tested, providing a localization accuracy in the order of meters. This task is aimed to deliver the proof of concept for employing such a mapping technique within nuclear safeguards. The acquisition of the radiation data was performed via a manual flight to ensure an appropriate safety level; in this context, it should be noted that the autonomous flight mode still requires major improvements in terms of safety.
# Towards Edible Drones for Rescue Missions: Design and Flight of Nutritional Wings
## Keywords:
- Aerial Systems: Applications
- Search and Rescue Robots
## Abstract:
Drones have shown to be useful aerial vehicles for unmanned transport missions such as food and medical supply delivery. This can be leveraged to deliver life-saving nutrition and medicine for people in emergency situations. However, commercial drones can generally only carry 10 % ~ 30 % of their own mass as payload, which limits the amount of food delivery in a single flight. One novel solution to noticeably increase the food carrying ratio of a drone, is recreating some structures of a drone, such as the wings, with edible materials. We thus propose a drone, which is no longer only a food-transporting aircraft, but itself is partially edible, increasing its food-carrying mass ratio to 50 %, owing to its edible wings. Furthermore, should the edible drone be left behind in the environment after performing its task in an emergency situation, it will be more biodegradable than its non-edible counterpart, leaving less waste in the environment. Here we describe the choice of materials and scalable design of edible wings, and validate the method in a flight-capable prototype that can provide 300 kcal and carry a payload of 80 g of water.
# Data-Efficient Collaborative Decentralized Thermal-Inertial Odometry
## Keywords:
- Aerial Systems: Applications
- Space Robotics and Automation
- Multi-Robot SLAM
## Abstract:
We propose a system solution to achieve data-efficient, decentralized state estimation for a team of flying robots using thermal images and inertial measurements. Each robot can fly independently, and exchange data when possible to refine its state estimate. Our system front-end applies an online photometric calibration to refine the thermal images so as to enhance feature tracking and place recognition. Our system back-end uses a covariance-intersection fusion strategy to neglect the cross-correlation between agents so as to lower memory usage and computational cost. The communication pipeline uses Vector of Locally Aggregated Descriptors (VLAD) to construct a request-response policy that requires low bandwidth usage. We test our collaborative method on both synthetic and real-world data. Our results show that the proposed method improves by up to 46 % trajectory estimation with respect to an individual-agent approach, while reducing up to 89 % the communication exchange. Datasets and code are released to the public, extending the already-public JPL xVIO library.
# Enforcing Vision-Based Localization Using Perception Constrained N-MPC for Multi-Rotor Aerial Vehicles
## Keywords:
- Aerial Systems: Perception and Autonomy
- Aerial Systems: Applications
- Aerial Systems: Mechanics and Control
## Abstract:
This work introduces a Nonlinear Model Predictive Control (N-MPC) for camera-equipped Unmanned Aerial Vehicles (UAVs), which controls at the motor level the UAV motion to ensure the quality of vision-based state estimation while performing other tasks. The controller ensures visibility over a sufficient amount of features, while optimizing their coverage, based on an assessment of the estimation quality. The controller works for the very broad class of generic multi-rotor UAVs, including platforms with any number of propellers, which can be both collinear, as in the quadrotor, and fixedly-tilted. The low-level inputs are computed in real-time and realistically constrained, in terms of maximum motor torque. This allows the platform to exploit its full actuation capabilities to maintain the visibility over the set of points of interest. Our implementation is tested in Gazebo simulations and in mocap-free real experiments, and features a visual-inertial state estimation based on Kalman filter. The software is provided open-source.
# Visual Loop Closure Detection for a Future Mars Science Helicopter
## Keywords:
- Aerial Systems: Perception and Autonomy
- Space Robotics and Automation
## Abstract:
Future Mars Rotorcrafts will require the ability to precisely navigate to previously visited locations in order to return to a safe landing site or execute precise scientific measurements such as sample acquisition or targeted sensing. To enable a future Mars Science Helicopter to perform in-flight loop closures, we present an on-board visual loop closure detection system based on a Bag-of-Words (BoW) approach that is efficient enough to run in real-time on the anticipated computationally constrained flight avionics. Our system establishes image-to-image associations between incoming images of a downward-looking navigation camera and previously observed geo-tagged keyframes stored in a database. The system extracts ORB features which are quantized into a BoW histogram using a custom 1 million words hierarchical vocabulary, trained on synthetic images from a Mars simulation. An efficient database query using an inverted index produces a set of candidate frames which we check for geometrical consistency. For efficient feature matching, we leverage the vocabulary to perform fast approximate nearest neighbor search. The geometrical check accepts loop closure pairs whose essential matrix is supported by a minimum number of feature matches, which are pre-selected based on a rotational consistency check. The vocabulary and the methods used for the geometrical consistency checks were chosen to maximize the performance while allowing real-time execution on a computationally constrained embedded processor. We demonstrate and evaluate the proposed system both on simulated and real-world data, including flight data from the Mars Helicopter Ingenuity.
# PencilNet: Zero-Shot Sim-To-Real Transfer Learning for Robust Gate Perception in Autonomous Drone Racing
## Keywords:
- Aerial Systems: Perception and Autonomy
- Aerial Systems: Applications
- Aerial Systems: Mechanics and Control
## Abstract:
In autonomous and mobile robotics, one of the main challenges is the robust on-the-fly perception of the environment, which is often unknown and dynamic, like in autonomous drone racing. In this work, we propose a novel deep neural network-based perception method for racing gate detection -# PencilNet-# which relies on a lightweight neural network backbone on top of a pencil filter. This approach unifies predictions of the gates' 2D position, distance, and orientation in a single pose tuple. We show that our method is effective for zero-shot sim-to-real transfer learning that does not need any real-world training samples. Moreover, our framework is highly robust to illumination changes commonly seen under rapid flight compared to state-of-art methods. A thorough set of experiments demonstrates the effectiveness of this approach in multiple challenging scenarios, where the drone completes various tracks under different lighting conditions.
# Medical Robots and Systems 2
# Force-Guided Alignment and File Feedrate Control for Robot-Assisted Endodontic Treatment
## Keywords:
- Medical Robots and Systems
- Compliance and Impedance Control
- Force and Tactile Sensing
## Abstract:
Due to the precise manipulations required in dental surgery, robotic technologies have been applied to dentistry. So far, most dental robots are designed for implant surgery, helping dentists accurately place the implant to the desired position and depth. This paper presents the DentiBot, the first robot designed for dental endodontic treatment. Without visual feedback, the DentiBot is integrated with a force and torque sensor to monitor the contact between the root canal and endodontic file. Additionally, DentiBot is implemented with force-guided alignment and file feedrate control to autonomously adjust surgical path and compensate for patient movement in real-time while protecting against endodontic file fracture. The feasibility of robot-assisted endodontic treatment is verified by the pre-clinical evaluation performed on acrylic root canal models.
# A Training-Evaluation Method for Nursing Telerobot Operator with Unsupervised Trajectory Segmentation
## Keywords:
- Telerobotics and Teleoperation
- Service Robotics
- Learning from Demonstration
## Abstract:
To cope with the difficulty of training and evaluation for nursing telerobot operator. This paper proposes a training-evaluation method for operator with unsupervised trajectory segmentation. To evaluate the dexterity and procedural knowledge of the operators objectively, we propose a new unsupervised model TSC-CRP that can automatically segment trajectory from nursing robotic training sessions. By comparing the segmented sub-trajectories and the standard sub-trajectory process, the method can provide objective evaluation and meaningful feedback without the intervention from experts. Experiments show that TSC-CRP has higher segmentation accuracy than other unsupervised methods, and it can identify the operators with different skill levels. In practical, the proposed training-evaluation system allows to provide an in-depth analysis of operator action to assess their skills precisely.
# Visual Servo Control of COVID-19 Nasopharyngeal Swab Sampling Robot
## Keywords:
- Medical Robots and Systems
- Visual Servoing
- Computer Vision for Automation
## Abstract:
In this study, we present a visual servo control framework for fully automated nasopharyngeal swab robots. The proposed framework incorporates a deep learning-based nostril detection with a cascade approach to reliably identify the nostrils with high accuracy in real time. In addition, a partitioned visual servoing scheme that combines image-based visual servoing with axial control is formulated for accurately positioning the sampling swabs at the nostril with a multi-DOF robot arm. As the visual servoing is designed to minimize an error between the detected nostril and the swab, it can compensate for potential errors in real operation, such as positioning error by inaccurate camera-robot calibration and kinematic error by unavoidable swab deflection. The performance of the visual servo control was tested on a head phantom model for 30 unusedswabs, and then compared with a method referring to only the 3D nostril target for control. Consequently, the swabs reached the nostril target with less than an average error of 1.2±0.5 mm and a maximum error of 2.0 mm via the visual servo control, while the operation without visual feedback yielded an average error of 10.6±2.3 mm and a maximum error of 16.2 mm. The partitioned visual servoing allows the swab to rapidly converge to the nostril target within 1.0 s without control instability. Finally, the swab placement at the nostril among the entire procedure of fully automated NP swab was successfully demonstrated on a human subject via the visual servo control.
# Development of a Cable-Driven Growing Sling to Assist Patient Transfer
## Keywords:
- Medical Robots and Systems
- Physically Assistive Devices
- Tendon/Wire Mechanism
## Abstract:
As the aging of society continues to accelerate, the number of elderly patients is increasing, as is the demand for manpower to care for them. In particular, there is an urgent need for bedridden patient care. However, limitations in the supply of human resources have caused an increase in the burden for care. In particular, nursing personnel often experience inconvenience and difficulties owing to the great deal of effort required to transfer a patient from bed to wheelchair, or vice versa. The most difficult process during the patient transfer is inserting the sling under the patient. Aiming to solve this problem, a mechanical Growing Sling was devised. The proposed sling adapts a growing mechanism comprising a low-friction fabric and steel shafts, and the sling is inserted under the patient by towing the steel shafts with cables connected to a motor. For the comfort and safety of the sling insertion, the required towing force was analyzed to find the minimum diameter of the shaft. The results from experimental evaluations using the proposed sling verified that it can be inserted under the patient without moving the patient, and with an acceptable level of pressure being applied to the patient.
# Development of an Inherently Safe Nasopharyngeal Swab Sampling Robot Using a Force Restriction Mechanism
## Keywords:
- Medical Robots and Systems
- Mechanism Design
- Compliant Joints and Mechanisms
## Abstract:
The demand for autonomous nasopharyngeal swab sampling robot systems is increasing owing to the recent outbreak of the respiratory virus pandemic. To protect the medical staff from infection, automatic upper respiratory sample collecting robotic systems are needed. The nasopharyngeal swab sampling robot proposed in this study is composed of a unique force restriction mechanism, a precise 3-axis force sensor, and a compact remote center of motion (RCM) mechanism, which are designed to enhance safety and efficiency. The proposed force restriction mechanism has a constant repulsive force finely adjustable using specially designed leaf spring structures. The force sensor is a capacitance-type 3-axis force sensor based on flexure mechanisms. Owing to the RCM mechanism, the distal end of the swab remains stationary. The effectiveness of the proposed robot was verified by various experiments, including restriction force measurement and a sampling success rate test.
# On the Design of Integrated Tele-Monitoring/Operation System for Therapeutic Devices in Isolation Intensive Care Unit
## Keywords:
- Telerobotics and Teleoperation
- Medical Robots and Systems
- Mechanism Design
## Abstract:
We design a central controller system (CCS) and a tele-controlled system (TCS) with an aim of developing the integrated tele-monitoring/operation system that can enable the medical staff to tele-monitor the state of therapeutic devices utilized in the isolation intensive care unit (ICU) and to tele-operate its user interfaces. To achieve this aim, we survey the medical staff for medical requirements first and define the design guideline for tele-monitoring/operation functionality and field applicability. In designing the CCS, we focus on realizing the device having intuitive and user-friendly interfaces so that the medical staff can use the device conveniently without pre-training. Further, we attempt to implement the TCS capable of manipulating various types of user interfaces of the therapeutic device (e.g., touch screen, buttons, and knobs) without failure. As two core components of the TCS, the precision XY-positioner having a maximum positioning error of about 0.695 mm and the end-effector having three-degrees-of# freedom motion (i.e., pressing, gripping, and rotating) are applied to the system. In the experiment conducted for assessing functionality, it is investigated that the time taken to complete the tele-operation after logging into the CCS is less than 1 minute. Furthermore, the result of field demonstration for focus group shows that the proposed system could be applied practically to the medical fields when the functional reliability is improved.
# Tactile Robotic Telemedicine for Safe Remote Diagnostics in Times ofCorona: System Design, Feasibility and Usability Study
## Keywords:
- Telerobotics and Teleoperation
- Medical Robots and Systems
- Human Factors and Human-in-the-Loop
## Abstract:
The current crisis surrounding the COVID-19pandemic demonstrates the amount of responsibility and the workload on our healthcare system and, above all, on the medical staff around the world. In this work, we propose a promising approach to overcome this problem using robot-assisted telediagnostics, which allows medical experts to examine patients from distance. The designed telediagnostic system consists of two robotic arms. Each robot is located at the doctor and patient sites. Such a system enables the doctor to have a direct conversation via telepresence and to examine patients through robot-assisted inspection (guided tactile and audiovi-sual contact). The proposed bilateral teleoperation system is redundant in terms of teleoperation control algorithms and visual feedback. Specifically, we implemented two main control modes: joint-based and displacement-based teleoperation. The joint-based mode was implemented due to its high transparency and ease of mapping between Leader and Follower whereas the displacement-based is highly flexible in terms of relative pose mapping and null-space control. Tracking tests between Leader and Follower were conducted on our system using both wired and wireless connections. Moreover, our system was tested by seven medical doctors in two experiments. User studies demonstrated the system’s usability and it was successfully validated by the medical experts.
# Novel Supernumerary Robotic Limb Based on Variable Stiffness Actuators for Hemiplegic Patients Assistance
## Keywords:
- Medical Robots and Systems
- Compliant Joints and Mechanisms
- Safety in HRI
## Abstract:
 Loss in upper extremity motor control and function is an unremitting symptom in post-stroke patients. This would impose hardships in accomplishing their Daily-Life-Activities. Supernumerary-Robotic-Limbs (SRLs) were introduced as a solution to regain the lost degrees-of-freedom (DoFs) by introducing an independent new-limb. The actuation systems in SRL can be categorized into rigid and soft actuators. Soft Actuators have proven advantageous over their rigid counterparts through their intrinsic safety, cost and energy efficiency. However, they suffer from low stiffness which jeopardizes their accuracy. Variable-Stiffness-Actuators (VSAs) are newly developed technologies that has been proven to ensure both accuracy and safety. In this paper, we introduce the novel Supernumerary-Robotic-Limb based on Variable-Stiffness-Actuators. Based on our knowledge, the proposed proof-of-concept SRL is the first which utilizes Variable Stiffness Actuators. The developed SRL would assist post-stroke patients in Bi-manual tasks e.g. eating-with-fork-and-knife. The modeling, design and realization of the system are illustrated. The proposed SRL was evaluated and verified for its accuracy via predefined trajectories. The safety was verified through the utilization of the momentum observer for collision detection and several post-collision reaction strategies were evaluated through the Soft-Tissue-Injury Test. The assistance process is qualitatively verified through standard user-satisfaction questioners.
# Mechanism Design 2
# Plate Harmonic Reducer with a Profiled Groove Wave Generator
## Keywords:
- Mechanism Design
- Actuation and Joint Mechanisms
- Engineering for Robotic Systems
## Abstract:
In this study, a mechanism that realizes a novel structural form of the harmonic reducer is introduced. Conventional robots often use various mechanical reducers owing to low torque and high-speed characteristics of electric motors. Among them, harmonic reducers are frequently used because of their compact size and backlash-free precision. The plate harmonic reducer which uses the same topological geometry and reducing mechanism as the conventional harmonic reducer is a novel type of strain gear that changes its shape to a plate form for axial deformation. It has unique differences in terms of axial thickness, torsional stiffness, and efficiency due to its morphological characteristics. This study introduces and analyzes the reducing principle of the plate harmonic reducer and describes the methodological solutions for realization. Finally, the theoretical performance improvement and operating feasibility of the plate harmonic reducer are analyzed using finite element method and a 3D-printed prototype model.
# Experimental Study of the Mechanical Properties of a Spherical Parallel Link Mechanism with Arc Prismatic Pairs
## Keywords:
- Mechanism Design
- Actuation and Joint Mechanisms
- Parallel Robots
## Abstract:
A two-degrees-of-freedom spherical parallel link mechanism (2-DOF SPM) was designed to ensure that it only has rotational degrees of freedom in two directions around a fixed center. In general, 2-DOF SPM includes passive rotating pairs, and at least two actuators are needed to change the end-effector posture. The arrangement of the links and pairs determines the characteristics and performance of SPM, so 2-DOF SPMs were designed considering various requirements, such as output torque, accuracy, and space constraints for applications. To satisfy these requirements, arc prismatic pairs can be used in SPMs. In order to use in SPMs, as for arc prismatic pairs, the concrete configuration and design methods for arc prismatic pairs have been studied. Furthermore, in order to compensate for the influence of friction on the positioning error, the control model considering the friction has been proposed by constructing a feedback loop containing experimentally found parameters. However, the conventional model is not a mechanical model of friction. Therefore, it is not suitable for calculating the friction force and understanding how the limit of the workspace changes due to the influence of friction. In this study, we construct a mechanical friction model considering the intersection angle change between the input and the rail slide direction. In addition, using the friction model, we clarify the influences of friction on the workspace and driving the SPM to realize high-performance 2-DOF SPM. First, we theoretically clarified the influence of friction on the workspace by considering the case of a slider-type differential-drive 2-DOF SPM. Second, the driving torque was experimentally measured, and the influence of friction on driving was examined.
# Manipulator Equipped with Differential Wrist Mechanism to Combine the Torque of Two Motors to Increase Fingertip Force and Wrist Torque
## Keywords:
- Mechanism Design
- Actuation and Joint Mechanisms
- Multifingered Hands
## Abstract:
Abstract—A lightweight and high-output manipulator is introduced in this study. The manipulator comprises two parts: a robot hand part and a wrist part. The total weight of the robot hand part is approximately 450 g, and its size is almost the same as that of a human hand. Furthermore, a design concept of a differential mechanism is presented in this study. In contrast to traditional mechanisms, in which the movement of a single motor corresponds to a single module, the proposed differential mechanism can superimpose the output forces of multiple motors and act on the movement of single or multiple modules; consequently, the output force is doubled, the low-power requirement of the motor, which drives the robot hand as the end effector to rotate around the wrist, is met, and the driving force amplification mechanism amplifies the gripping force of the fingers. The proposed differential mechanism is incorporated in the wrist part. The robot hand part is responsible for the fast grasping of objects. The wrist part is responsible for increasing the output force of the fingers to ensure a firm grasp. In addition, it enables the robot hand to rotate around the wrist. It takes 0.32 s for the fingers to transition from moving to touching the object. It takes approximately 0.9 s to grasp the object firmly, and the output force of the fingertips can reach 25.5 N. The robot hand can rotate 135 °around the wrist, and the rotation speed is 118 deg/s.
# Design of a Modular Continuum Robot with Alterable Compliance Using Tubular-Actuation
## Keywords:
- Mechanism Design
- Compliant Joints and Mechanisms
- Soft Robot Applications
## Abstract:
Compliance is good. However, it is challenging for one compliant continuum robot to finish both high precision manipulation and environmental-adapted motions. In this paper, a modular con-tinuum robot with the alterable compliance characteristic is pro-posed. Besides, an actuation module is also proposed using a tubular-screw mechanism for non-slippage transmission. Kine-matic analyses and dynamic co-simulation are performed to study the continuum robot. Furthermore, two potential applica-tion scenarios of pick-and-place manipulation and confined space navigating are carried out to demonstrate the advantages of the alterable compliance design. This study presents a capable con-tinuum robotic solution for non-structural inspection tasks, with potential for in-situ applications in restricted and hazardous en-vironments.
# 3D-Printable Low-Reduction Cycloidal Gearing for Robotics
## Keywords:
- Actuation and Joint Mechanisms
- Mechanism Design
## Abstract:
The recent trend towards low reduction gearing in robotic actuation has revitalised the need for high-performance gearing concepts. In this work we propose compact low-reduction cycloidal gearing, that is 3D-printable and combined with off-the-shelf components. This approach presents an enormous potential for high performance-to-cost implementations. After discussing parameter selection and design considerations, we present a prototype that is combined with a low-cost brushless motor to demonstrate its potential. Extensive experimental results demonstrate high performance, including >40 Nm torque, low friction and play, and high impact robustness. The results show that the proposed approach can yield viable gearbox designs.
# Fold-Based Complex Joints for a 3 DoF 3R Parallel Robot Design
## Keywords:
- Actuation and Joint Mechanisms
- Parallel Robots
- Kinematics
## Abstract:
This contribution demonstrates the usage of fold-based joints to create a novel 3 DoF 3R(RPaR) parallel robot design. Multiple folding mechanisms are introduced, fulfilling the function of revolute, prismatic, and spherical joints. Folding mechanisms are here tested regarding their applicability in parallel kinematic robots taking advantage of beneficial properties such as increased stiffness, flat-foldability and compressed states, easy cleaning as well as lightweight designs. The designed delta robot structure is then analysed for its motion behaviour, workspace dimensions and validated by a 3D printed model. Further, scalability possibilities are presented.
# A 4-DoF Parallel Robot with a Built-In Gripper for Waste Sorting
## Keywords:
- Mechanism Design
- Parallel Robots
- Industrial Robots
## Abstract:
This article presents a new robot concept dedicated to fast and energy-efficient waste sorting applications. This parallel robot can provide at the same time the three translations in space (3-DoF) and the opening/closing of a built-in gripper (1 additional DoF). The movement of the clamp is enabled thanks to a configurable platform at the end of the parallel structure. This platform is composed of a two-gear train gripper which is directly controlled by the 4 actuators attached to the base of the manipulator. The inverse kinematic, as well as the differential models, have been developed. A first prototype has been realized to validate this new parallel architecture for pick-and-toss tasks.
# Adjustable Lever Mechanism with Double Parallel Link Platforms for Robotic Limbs
## Keywords:
- Mechanism Design
- Parallel Robots
## Abstract:
For universal robotic limbs, having a large workspace with high stiffness and adjustable output properties is important to adapt to various situations. A combination of parallel mechanisms that can change output characteristics is promising to meet these demands. As such, we propose a lever mechanism with double parallel link platforms. This mechanism is composed of a lever mechanism with the effort point and the pivot point; each is supported by a parallel link mechanism. First, we calculated the differential kinematics of this mechanism. Next, we investigated the workspace of the mechanism. The proposed mechanism can reach nearer positions than the posture with the most shrinking actuators thanks to the three-dimensional movable effort point. Then, we confirmed that this mechanism could change the output force profile at the end-effector by changing the lever ratio. The main change is the directional change of the maximum output force. The change range is larger when the squatting depth is larger. The changing tendency of the shape of the maximum output force profile by the position of the pivot plate depends on the force balance of the actuators. These analytical results show the potential of the proposed mechanism and would aid in the design of this mechanism for robotic limbs.
# Design and Characterization of 3D Printed, Open-Source Actuators for Legged Locomotion
## Keywords:
- Mechanism Design
- Methods and Tools for Robot System Design
## Abstract:
Impressive animal locomotion capabilities are mediated by the co-evolution of the skeletal morphology and muscular properties. Legged robot performance would also likely benefit from the co-optimization of actuators and leg morphology. However, development of custom actuators for legged robots is expensive and time consuming, discouraging application-specific actuator optimization. This paper presents open-source designs for two quasi-direct-drive actuators with performance regimes appropriate for an 8-15 kg robot, built from off the shelf and 3D-printed components for less than 200 USD each. The mechanical, electrical, and thermal properties of each actuator are characterized and compared to benchmark data. Actuators subjected to 420k strides of gait data experienced only a 2% reduction in efficiency and 26 mrad in backlash growth, demonstrating viability for rigorous and sustained research applications. We present a thermal solution that nearly doubles the thermally-driven torque limits of our plastic actuator design. The performance results are comparable to traditional metallic actuators for use in high-speed legged robots of the same scale. These 3D printed designs demonstrate an approach for designing and characterizing low-cost, highly customizable and reproducible actuators, democratizing the field of actuator design and enabling co-design and optimization of actuators and robot legs.
# Object Detection, Segmentation and Categorization 2
# Real-Time IMU-Based Learning: A Classification of Contact Materials
## Keywords:
- Object Detection, Segmentation and Categorization
- AI-Enabled Robotics
## Abstract:
In modern highly dynamic robot manipulation, collisions between a robot and objects may be intentionally executed to improve performance. To distinguish between these deliberate contacts and accidental collisions beyond the limit of state-of-the-art human-robot interactions, new sensing approaches are required. This work seeks an easy-to-implement and real-time capable solution to detect the identity of the impacted material. We developed an inertial measurement unit (IMU) based setup that records vibration signals occurring after collisions. Furthermore, a data-set was generated in an unsupervised learning manner using the measurements of collision experiments with several materials commonly used in realistic applications. The data-set was used to train an artificial neural network to classify the type of material involved. Our results show that the neural net detects collisions and a detailed distinction between materials is achieved, even with estimating different human body parts.	The unsupervised data-set generation allows for a simple integration of new classes, which provides broader applicability of our approach. As the calculations are running faster than the control cycle of the robot, the output of our classifier can be used in real-time to decide about the robot’s reaction behavior.
# New Objects on the Road? No Problem, We’ll Learn Them Too
## Keywords:
- Object Detection, Segmentation and Categorization
- Autonomous Vehicle Navigation
- Vision-Based Navigation
## Abstract:
Object detection plays an essential role in providing localization, path planning, and decision making capabilities in autonomous navigation systems. However, existing object detection models are trained and tested on a fixed number of known classes. This setting makes the object detection model difficult to generalize well in real-world road scenarios while encountering an unknown object. We address this problem by introducing our framework that handles the issue of unknown object detection and updates the model when unknown object labels are available. Next, our solution includes three major components that address the inherent problems present in the road scene datasets. The novel components are a) Feature-Mix that improves the unknown object detection by widening the gap between known and unknown classes in latent feature space, b) Focal regression loss handling the problem of improving small object detection and intra-class scale variation, and c) Curriculum learning further enhances the detection of small objects. We use Indian Driving Dataset (IDD) and Berkeley Deep Drive (BDD) dataset for evaluation. Our solution provides state-of-the-art performance on open-world evaluation metrics. We hope this work will create new directions for open-world object detection for road scenes, making it more reliable and robust autonomous systems.
# Conditional Patch-Based Domain Randomization: Improving Texture Domain Randomization Using Natural Image Patches
## Keywords:
- Object Detection, Segmentation and Categorization
- Deep Learning for Visual Perception
- Data Sets for Robotic Vision
## Abstract:
Using Domain Randomized synthetic data for training deep learning systems is a promising approach for addressing the data and the labeling requirements for supervised techniques to bridge the gap between simulation and the real world. We propose a novel approach for generating and applying class-specific Domain Randomization textures by using randomly cropped image patches from real-world data. In evaluation against the current Domain Randomization texture application techniques, our approach outperforms the highest performing technique by 4.94 AP and 6.71 AP when solving object detection and semantic segmentation tasks on the YCB-M real-world robotics dataset. Our approach is a fast and inexpensive way of generating Domain Randomized textures while avoiding the need to handcraft texture distributions currently being used.
# CloudAttention: Efficient Multi-Scale Attention Scheme for 3D Point Cloud Learning
## Keywords:
- Object Detection, Segmentation and Categorization
- Deep Learning for Visual Perception
- RGB-D Perception
## Abstract:
Processing 3D data efficiently has always been a challenge. Spatial operations on large-scale point clouds, stored as sparse data, require extra cost. Attracted by the success of transformers, researchers are using multi-head attention for vision tasks. However, attention calculations in transformers come with quadratic complexity in the number of inputs and miss spatial intuition on sets like point clouds. We redesign set transformers in this work and incorporate them into a hierarchical framework for shape classification and part and scene segmentation. We propose our local attention unit, which captures features in a spatial neighborhood. We also compute efficient and dynamic global cross attentions by leveraging sampling and grouping at each iteration. Finally, to mitigate the non-heterogeneity of point clouds, we propose an efficient Multi-Scale Tokenization (MST), which extracts scale-invariant tokens for attention operations. The proposed hierarchical model achieves state-of-the-art shape classification in mean accuracy and yields results on par with the previous segmentation methods while requiring significantly fewer computations. Our proposed architecture predicts segmentation labels with around half the latency and parameter count of the previous most efficient method with comparable performance. The code is available at https://github.com/YigeWang-WHU/CloudAttention.
# Fast Hierarchical Learning for Few-Shot Object Detection
## Keywords:
- Object Detection, Segmentation and Categorization
- Incremental Learning
## Abstract:
Transfer learning based approaches have recently achieved promising results on the few-shot detection task. These approaches however suffer from ``catastrophic forgetting'' issue due to finetuning of base detector, leading to sub-optimal performance on the base classes. Furthermore, the slow convergence rate of stochastic gradient descent (SGD) results in high latency and consequently restricts real-time applications. We tackle the aforementioned issues in this work. We pose few-shot detection as a hierarchical learning problem, where the novel classes are treated as the child classes of existing base classes and the background class. The detection heads for the novel classes are then trained using a specialized optimization strategy, leading to significantly lower training times compared to SGD. Our approach obtains competitive novel class performance on few-shot MS-COCO benchmark, while completely retaining the performance of the initial model on the base classes. We further demonstrate the application of our approach to a new class-refined few-shot detection task.
# Improving Single-View Mesh Reconstruction for Unseen Categories Via Primitive-Based Representation and Mesh Augmentation
## Keywords:
- Object Detection, Segmentation and Categorization
- Representation Learning
- Deep Learning for Visual Perception
## Abstract:
As most existing works of single-view 3D recon# struction aim at learning the better mapping functions to directly transform the 2D observation into the corresponding 3D shape for achieving state-of-the-art performance, there often comes a potential concern on having the implicit bias towards the seen classes learnt in their models (i.e. recon# struction intertwined with the classification) thus leading to poor generalizability for the unseen object categories. Moreover, such implicit bias typically stemmed from adopting the object# centered coordinate in their model designs, in which the reconstructed 3D shapes of the same class are all aligned to the same canonical pose regardless of different view-angles in the 2D observations. To this end, we propose an end-to-end framework to reconstruct the 3D mesh from a single image, where the reconstructed mesh is not only view-centered (i.e. its 3D pose respects the viewpoint of the 2D observation) but also preliminarily represented as a composition of volumetric 3D primitives before being further deformed into the fine# grained mesh to capture the shape details. In particular, the usage of volumetric primitives is motivated from the assumption that there generally exists some similar shape parts shared across various object categories, learning to estimate the primitive-based 3D model thus becomes more generalizable to the unseen categories. Furthermore, we advance to propose a novel mesh augmentation strategy, CvxRearrangement, to enrich the distribution of training shapes, which contributes to increasing the robustness of our proposed model and achieves better generalization. Extensive experiments demonstrate that our proposed method provides superior performance on both unseen and seen classes in comparison to several representative baselines of single-view 3D reconstruction.
# Instance Segmentation with Cross-Modal Consistency
## Keywords:
- Object Detection, Segmentation and Categorization
- Visual Learning
- Deep Learning Methods
## Abstract:
Segmenting object instances is a key task in machine perception, with safety-critical applications in robotics and autonomous driving. We introduce a novel approach to instance segmentation that jointly leverages measurements from multiple sensor modalities, such as cameras and LiDAR. Our method learns to predict embeddings for each pixel or point that give rise to a dense segmentation of the scene. Specifically, our technique applies contrastive learning to points in the scene both across sensor modalities and the temporal domain. We demonstrate that this formulation encourages the models to learn embeddings that are invariant to viewpoint variations and consistent across sensor modalities. We further demonstrate that the embeddings are stable over time as objects move around the scene. This not only provides stable instance masks, but can also provide valuable signals to downstream tasks, such as object tracking. We evaluate our method on the Cityscapes and KITTI-360 datasets. We further conduct a number of ablation studies, demonstrating benefits when applying additional inputs for the contrastive loss.
# Early Recall, Late Precision: Multi-Robot Semantic Object Mapping under Operational Constraints in Perceptually-Degraded Environments
## Keywords:
- Object Detection, Segmentation and Categorization
## Abstract:
Semantic object mapping in uncertain, perceptually degraded environments during long-range multi-robot autonomous exploration tasks such as search-and-rescue is important and challenging. During such missions, high recall is desirable to avoid missing true target objects and high precision is also critical to avoid wasting valuable operational time on false positives. Given recent advancements in visual perception algorithms, the former is largely solvable autonomously, but the latter is difficult to address without the supervision of a human operator. However, operational constraints such as mission time, computational requirements and mesh network bandwidth can make the operator's task infeasible unless properly managed. We propose the Early Recall, Late Precision (EaRLaP) semantic object mapping pipeline to solve this problem. EaRLaP was used by Team CoSTAR in DARPA Subterranean Challenge, where it successfully detected all the artifacts encountered by the team of robots. We will discuss these results and the performance of the EaRLaP on various datasets.
# Sparse PointPillars: Maintaining and Exploiting Input Sparsity to Improve Runtime on Embedded Systems
## Keywords:
- Object Detection, Segmentation and Categorization
- Deep Learning for Visual Perception
- Deep Learning Methods
## Abstract:
Bird's Eye View (BEV) is a popular representation for processing 3D point clouds, and by its nature is fundamentally sparse. Motivated by the computational limitations of mobile robot platforms, we create a fast, high-performance BEV 3D object detector that maintains and exploits this input sparsity to decrease runtimes over non-sparse baselines and avoids the tradeoff between pseudoimage area and runtime. We present results on KITTI, a canonical 3D detection dataset, and Matterport-Chair, a novel Matterport3D-derived chair detection dataset from scenes in real furnished homes. We evaluate runtime characteristics using a desktop GPU, an embedded ML accelerator, and a robot CPU, demonstrating that our method results in significant detection speedups (2X or more) for embedded systems with only a modest decrease in detection quality. Our work represents a new approach for practitioners to optimize models for embedded systems by maintaining and exploiting input sparsity throughout their entire pipeline to reduce runtime and resource usage while preserving detection performance. All models, weights, experimental configurations, and datasets used are publicly available at https://vedder.io/sparse_point_pillars.
# Force and Tactile Sensing
# Pose-Based Tactile Servoing: Controlled Soft Touch Using Deep Learning (I)
## Keywords:
- Force and Tactile Sensing
## Abstract:
This article describes a new way of controlling robots using soft tactile sensors: pose-based tactile servo (PBTS) control. The basic idea is to embed a tactile perception model for estimating the sensor pose within a servo control loop that is applied to local object features, such as edges and surfaces. PBTS control is implemented with a soft, curved optical tactile sensor (the BRL TacTip) using a convolutional neural network trained to be insensitive to shear. As a consequence, robust and accurate controlled motion over various complex 3D objects is attained.
# Mapping Mid-Air Haptics with a Low-Cost Tactile Robot
## Keywords:
- Force and Tactile Sensing
- Haptics and Haptic Interfaces
## Abstract:
Mid-air haptics create a new mode of feedback to allow people to feel tactile sensations in the air. Ultrasonic arrays focus acoustic radiation pressure in space, to induce tactile sensation from the resulting skin deflection. In this work, we present a low-cost tactile robot to test mid-air haptics. By combining a desktop robot arm with a 3D-printed biomimetic tactile sensor, we developed a system that can sense, map, and visualize mid-air haptic sensations created by an ultrasonic transducer array. We evaluate our tactile robot by testing it on a variety of mid-air haptic stimuli, including unmodulated and modulated focal points that create a range of haptic shapes. We compare the mapping of the stimuli to another method used to test mid-air haptics: Laser Doppler Vibrometry, highlighting the advantages of the tactile robot including far lower cost, a small lightweight form-factor, and ease-of-use. Overall, these findings indicate our method has multiple benefits for sensing mid-air haptics and opens up new possibilities for expanding the testing to better emulate human haptic perception.
# Autonomous Tactile Localization and Mapping of Objects Buried in Granular Materials
## Keywords:
- Force and Tactile Sensing
- Mapping
- Contact Modeling
## Abstract:
Robots are expected to operate autonomously in unstructured, real-world environments, for tasks such as locating buried objects in search and rescue applications. When robots operate within opaque granular materials, tactile and proprioceptive feedback can be more informative than visual feedback. However, since tactile measurements are local and sparse, it can be difficult to efficiently build a global, tactile-based model of a search area. In this work, we developed a framework for tactile perception, mapping, and haptic exploration for the autonomous localization of objects buried in granular materials. Haptic exploration was performed within a densely packed sand mixture using a sensor model that accounts for granular material characteristics and aids in the interpretation of interaction forces between the robot and its environment. The haptic exploration strategy was designed to efficiently locate a buried object and refine its outline while simultaneously minimizing potentially damaging physical interactions with the buried object. Coverage path planning techniques were used to select haptic exploration movements from candidates that aimed to reduce map uncertainty. A continuous occupancy map was generated that fused local, sparse tactile information into a global Bayesian Hilbert Map. We demonstrated our framework in simulation and with a real robot with granular materials.
# Tactile Gym 2.0: Sim-To-Real Deep Reinforcement Learning for Comparing Low-Cost High-Resolution Robot Touch
## Keywords:
- Force and Tactile Sensing
- Reinforcement Learning
## Abstract:
High-resolution optical tactile sensors are increasingly used in robotic learning environments due to their ability to capture large amounts of data directly relating to agent-environment interaction. However, there is a high barrier of entry to research in this area due to the high cost of tactile robot platforms, specialised simulation software, and sim-to-real methods that lack generality across different sensors. In this letter we extend the Tactile Gym simulator to include three new optical tactile sensors (TacTip, DIGIT and DigiTac) of the two most popular types, Gelsight-style (image-shading based) and TacTip-style (marker based). We demonstrate that a single sim-to-real approach can be used with these three different sensors to achieve strong real-world performance despite the significant differences between real tactile images. Additionally, we lower the barrier of entry to the proposed tasks by adapting them to an inexpensive 4-DoF robot arm, further enabling the dissemination of this benchmark. We validate the extended environment on three physically-interactive tasks requiring a sense of touch: object pushing, edge following and surface following. The results of our experimental validation highlight some differences between these sensors, which may help future researchers select and customize the physical characteristics of tactile sensors for different manipulations scenarios. Code and videos are available at https://sites.google.com/my.bristol.ac.uk/tactilegym2.
# Bioinspired, Multifunctional, Active Whisker Sensors for Tactile Sensing of Mobile Robots
## Keywords:
- Force and Tactile Sensing
- Sensor-based Control
- Collision Avoidance
## Abstract:
Whiskers of some animals, such as rats and cats, can actively sense stimuli from their surrounding environment. Such a capability is attractive for intelligent mobile robots. However, an artificial whisker with similar abilities has not been fully developed so that the robots acquire their surrounding environment information in an active approach such as rats. In this paper, we propose a new bioinspired active whisking tactile sensor (MAWS) capable of sensing the distance, shape, size, and orientation of caves and environmental conditions. Two orthogonally distributed linear Hall sensors are mounted beneath a circular permanent magnet for spatial localization of the whisker. The whisker is then actuated and controlled by an array of nine electromagnetic coils by tuning the excitation current and phase sequence. Conical pendulum and bidirectional sweeping strategies were designed to mimic the simultaneous perception behavior of rats. A reactive obstacle avoidance experiment was also conducted to evaluate the performance of the proposed MAWS installed on a mobile robot.
# Deep Active Cross-Modal Visuo-Tactile Transfer Learning for Robotic Object Recognition
## Keywords:
- Force and Tactile Sensing
- Transfer Learning
- Recognition
## Abstract:
We propose for the first time, a novel deep active visuo-tactile cross-modal full-fledged framework for object recognition by autonomous robotic systems. Our proposed network xAVTNet is actively trained with labelled point clouds from a vision sensor with one robot and tested with an active tactile perception strategy to recognise objects never touched before using another robot. We propose a novel visuo-tactile loss (VTLoss) to minimise the discrepancy between the visual and tactile domains for unsupervised domain adaptation. Our framework leverages the strengths of deep neural networks for cross-modal recognition along with active perception and active learning strategies for increased efficiency by minimising redundant data collection. Our method is extensively evaluated on a real robotic system and compared against baselines and other state-of-art approaches. We demonstrate clear outperformance in recognition accuracy compared to the state-of-art visuo-tactile cross-modal recognition method.
# DigiTac: A DIGIT-TacTip Hybrid Tactile Sensor for Comparing Low-Cost High-Resolution Robot Touch
## Keywords:
- Force and Tactile Sensing
## Abstract:
Deep learning combined with high-resolution tactile sensing could lead to highly capable dexterous robots. However, progress is slow because of the specialist equipment and expertise. The DIGIT tactile sensor offers low-cost entry to high-resolution touch using GelSight-type sensors. Here we customize the DIGIT to have a 3D-printed sensing surface based on the TacTip family of soft biomimetic optical tactile sensors. The DIGIT-TacTip (DigiTac) enables direct comparison between these distinct tactile sensor types. For this comparison, we introduce a tactile robot system comprising a desktop arm, mounts and 3D-printed test objects. We use tactile servo control with a PoseNet deep learning model to compare the DIGIT, DigiTac and TacTip for edge# and surface-following over 3D-shapes. All three sensors performed similarly at pose prediction, but their constructions led to differing performances at servo control, offering guidance for researchers selecting or innovating tactile sensors. All hardware and software for reproducing this study will be openly released.
# Semi-Supervised Disentanglement of Tactile Contact Geometry from Sliding-Induced Shear
## Keywords:
- Force and Tactile Sensing
## Abstract:
The sense of touch is fundamental to human dexterity. When mimicked in robotic touch, particularly by use of soft optical tactile sensors, it suffers from distortion due to motion-dependent shear. This complicates tactile tasks like shape reconstruction and exploration that require information about contact geometry. In this work, we pursue a semi-supervised approach to remove shear while preserving contact-only information. We validate our approach by showing a match between the model-generated unsheared images with their counterparts from vertically tapping onto the object. The model-generated unsheared images give faithful reconstruction of contact-geometry otherwise masked by shear, along with robust estimation of object pose then used for sliding exploration and full reconstruction of several planar shapes. We show that our semi-supervised approach achieves comparable performance to its fully supervised counterpart across all validation tasks with an order of magnitude less supervision. The semi-supervised method is thus more computational and labeled sample-efficient. We expect it will have broad applicability to wide range of complex tactile exploration and manipulation tasks performed via a shear-sensitive sense of touch.
# Multi-Purpose Tactile Perception Based on Deep Learning in a New Tendon-Driven Optical Tactile Sensor
## Keywords:
- Force and Tactile Sensing
- Deep Learning Methods
- Tendon/Wire Mechanism
## Abstract:
In this paper, we create a new tendon-connected multi-functional optical tactile sensor, MechTac, for object perception in the field of view (TacTip) and location of touching points in the blind area of vision (TacSide). In a multi-point touch task, the information of the TacSide and the TacTip are overlapped to commonly affect the distribution of papillae pins on the TacTip. Since the effects of TacSide are much less obvious to those affected on the TacTip, a perceiving out-of-view neural network (O^2VNet) is created to separate the mixed information with unequal affection. To reduce the dependence of the O^2VNet on the grayscale information of the image, we create one new binarized convolutional (BConv) layer in front of the backbone of the O^2VNet. The O^2VNet can not only achieve real-time temporal sequence prediction (34 ms per image), but also attain the average classification accuracy of 99.06%. The experimental results show that the O^2VNet can hold a high classification accuracy even facing the image contrast changes.
# Human-Robot Collaboration
# A Multi-Granularity Scene Segmentation Network for Human-Robot Collaboration Environment Perception
## Keywords:
- Human-Robot Collaboration
- Computer Vision for Manufacturing
- Deep Learning for Visual Perception
## Abstract:
Human-robot collaboration (HRC) has been considered as a promising paradigm towards futuristic humancentric smart manufacturing, to meet the thriving needs of mass personalization. In this context, existing robotic systems normally adopt a single-granularity semantic segmentation scheme for environment perception, which lacks the flexibility to be implemented to various HRC situations. To fill the gap, this study proposes a multi-granularity scene segmentation network. Inspired by some recent network designs, we construct an encoder network with two ConvNext-T backbones for RGB and depth respectively, and an decoder network consisting of multi-scale supervision and multi-granularity segmentation branches. The proposed model is demonstrated in a human-robot collaborative battery disassembly scenario and further evaluated in comparison with state-of-the-art RGB-D semantic segmentation methods on the NYU-Depth V2 dataset.
# Controller Design of a Robotic Assistant for the Transport of Large and Fragile Objects
## Keywords:
- Human-Robot Collaboration
- Physical Human-Robot Interaction
- Control Architectures and Programming
## Abstract:
This paper deals with the design of a robotic assistant for the transport of large and fragile objects. We propose a new collaborative robotic controller that fulfills the main requirements of co-transportation tasks of large and fragile objects: to execute any trajectory in a collaborative mode while minimizing the stress applied on the object by both partners in order to avoid damaging it. This controller prevents the robot from applying torques on the object while maintaining a desired orientation of the object along the transport trajectory in order to follow the operator. An original feature of our approach is to care about torques applied by both partners (not only by operator) during any co-manipulation trajectory execution. It leads to a novel outcome: the minimization of stress applied by both partners on a large and fragile object during its transport on any trajectory. We demonstrate the effectiveness of this approach in a collaborative transportation task.
# Safety-Based Dynamic Task Offloading for Human-Robot Collaboration Using Deep Reinforcement Learning
## Keywords:
- Human-Robot Collaboration
- Networked Robots
- Reinforcement Learning
## Abstract:
Robots with constrained hardware resources usually rely on Multi-access Edge Computing infrastructures to offload computationally expensive tasks to meet real-time and safety requirements. Offloading every task might not be the best option due to dynamic changes in the network conditions and can result in network congestion or failures. This work proposes a task offloading strategy for mobile robots in a Human-Robot Collaboration scenario that optimizes the edge resource usage and reduces network delays, leading to safety enhancement. The solution utilizes a Deep Reinforcement Learning (DRL) agent that observes safety and network metrics to dynamically decide at runtime if (i) a less accurate model should run on the robot; (ii) a more complex model should run on the edge; or (iii) the previous output should be reused through temporal coherence verification. Experiments are performed in a simulated warehouse where humans and robots have close interactions and safety needs are high. Our results show that the proposed DRL solution outperforms the baselines in several aspects. The edge is used only when the network performance is reliable, reducing the number of failures (up to 47%). The latency is not only decreased (up to 68%) but also adapted to the safety requirements (risk×latency reduced up to 48%), avoiding unnecessary network congestion in safe situations and letting other devices use the network. Overall, the safety metrics get improved, such as the increased time in the safe zone by up to 3.1%.
# "I'm Confident This Will End Poorly": Robot Proficiency Self-Assessment in Human-Robot Teaming
## Keywords:
- Human-Robot Teaming
- Human-Robot Collaboration
- Human Factors and Human-in-the-Loop
## Abstract:
Human-robot teams are expected to accomplish complex tasks in high-risk and uncertain environments. In domains such as space exploration or search & rescue, a human operator may not be a robotics expert, but will need to establish a baseline understanding of the robot’s capabilities with respect to a given task in order to appropriately utilize and rely on the robot. This willingness to rely, also known as trust, is based partly on the operator’s belief in the robot’s task proficiency. If trust is too high, the operator may unknowingly push the robot beyond its capabilities. If trust is too low, the operator may not utilize it when they otherwise could have, wasting precious time and resources. In this work, we discuss results from an online human-subjects study investigating how a robot communicated report of its task proficiency with respect to an operators expectations affects trust and performance in a navigation task. Our results show that communication of a robot self-assessment helped operators understand when reliance on the robot was appropriate given the task and conditions. This led to improvements in task performance, informed choices of autonomy level, and increased trust.
# RILI: Robustly Influencing Latent Intent
## Keywords:
- Human-Robot Collaboration
- Representation Learning
- Reinforcement Learning
## Abstract:
When robots interact with human partners, often these partners change their behavior in response to the robot. On the one hand this is challenging because the robot must learn to coordinate with a dynamic partner. But on the other hand --# if the robot understands these dynamics --# it can harness its own behavior, influence the human, and guide the team towards effective collaboration. Prior research enables robots to learn to influence other robots or simulated agents. In this paper we extend these learning approaches to now influence humans. What makes humans especially hard to influence is that --# not only do humans react to the robot --# but the way a single user reacts to the robot may change over time, and different humans will respond to the same robot behavior in different ways. We therefore propose a robust approach that learns to influence changing partner dynamics. Our method first trains with a set of partners across repeated interactions, and learns to predict the current partner's behavior based on the previous states, actions, and rewards. Next, we rapidly adapt to new partners by sampling trajectories the robot learned with the original partners, and then leveraging those existing behaviors to influence the new partner dynamics. We compare our resulting algorithm to state-of-the-art baselines across simulated environments and a user study where the robot and participants collaborate to build towers. We find that our approach outperforms the alternatives, even when the partner follows new or unexpected dynamics.
# Multimodal Object Categorization with Reduced User Load through Human-Robot Interaction in Mixed Reality
## Keywords:
- Human-Robot Collaboration
- Virtual Reality and Interfaces
## Abstract:
Enabling robots to learn from interactions with users is essential to perform service tasks. However, as a robot categorizes objects from multimodal information obtained by its sensors during interactive onsite teaching, the inferred names of unknown objects do not always match the human user's expectation, especially when the robot is introduced to new environments. Confirming the learning results through natural speech interaction with the robot often puts an additional burden on the user who can only listen to the robot to validate the results. Therefore, we propose a human-robot interface to reduce the burden on the user by visualizing the inferred results in mixed reality (MR). In particular, we evaluate the proposed interface on the system usability scale (SUS) and the NASA task load index (NASA-TLX) with three experimental object categorization scenarios based on multimodal latent Dirichlet allocation (MLDA) in which the robot: 1) does not share the inferred results with the user at all, 2) shares the inferred results through speech interaction with the user (baseline), and 3) shares the inferred results with the user through an MR interface (proposed). We show that providing feedback through an MR interface significantly reduces the temporal, physical, and mental burden on the human user compared to speech interaction with the robot.
# Learning and Executing Re-Usable Behaviour Trees from Natural Language Instruction
## Keywords:
- Human-Robot Collaboration
- Learning from Demonstration
- Task Planning
## Abstract:
Domestic and service robots have the potential to transform industries such as health care and small-scale manufacturing, as well as the homes in which we live. However, due to the overwhelming variety of tasks these robots will be expected to complete, providing generic out-of-the-box solutions that meet the needs of every possible user is clearly intractable. To address this problem, robots must therefore not only be capable of learning how to complete novel tasks at run-time, but the solutions to these tasks must also be informed by the needs of the user. In this paper we demonstrate how behaviour trees, a well established control architecture in the fields of gaming and robotics, can be used in conjunction with natural language instruction to provide a robust and modular control architecture for instructing autonomous agents to learn and perform novel complex tasks. We also show how behaviour trees generated using our approach can be generalised to novel scenarios, and can be re-used in future learning episodes to create increasingly complex behaviours. We validate this work against an existing corpus of natural language instructions, demonstrate the application of our approach on both a simulated robot solving a toy problem, as well as two distinct real-world robot platforms which, respectively, complete a block sorting scenario, and a patrol scenario.
# ProTAMP: Probabilistic Task and Motion Planning Considering Human Action for Harmonious Collaboration
## Keywords:
- Human-Robot Collaboration
- Task and Motion Planning
- Modeling and Simulating Humans
## Abstract:
For the proper functioning of mobile manipulator-type autonomous robot performing complicated tasks in a human-robot coexistence environment, tasks and motions must be planned simultaneously. In such environments, a human and robot should collaborate with each other. Therefore, the robot must act in accordance with the human and avoid useless actions duplicated with those of humans. However, any action undertaken by a human has uncertainty, and thus, predicting them correctly is challenging. This study proposed probabilistic task and motion planning considering both deterministic and probabilistic environment changes caused by robot and human actions temporarily and spatially, respectively. First, the environmental changes were modeled, where the robot is capable of recognizing the possibility of environmental changes. Second, in task planning, the probabilities of each environmental change owing to human actions was minimized. Finally, in motion planning, a movement path connecting each task in a planned order was planned, thereby enabling the robot to perform actions not duplicated with those by a human. Furthermore, the plans generated were compared without considering possibility of human actions and the effectiveness of the proposed method was verified. Consequently, the proposed method was confirmed to reduce the time required for finishing the tasks.
# VR Facial Animation for Immersive Telepresence Avatars
## Keywords:
- Gesture, Posture and Facial Expressions
- Telerobotics and Teleoperation
- Virtual Reality and Interfaces
## Abstract:
VR Facial Animation is necessary in applications requiring clear view of the face, even though a VR headset is worn. In our case, we aim to animate the face of an operator who is controlling our robotic avatar system. We propose a real-time capable pipeline with very fast adaptation for specific operators. In a quick enrollment step, we capture a sequence of source images from the operator without the VR headset which contain all the important operator-specific appearance information. During inference, we then use the operator keypoint information extracted from a mouth camera and two eye cameras to estimate the target expression and head pose, to which we map the appearance of a source still image. In order to enhance the mouth expression accuracy, we dynamically select an auxiliary expression frame from the captured sequence. This selection is done by learning to transform the current mouth keypoints into the source camera space, where the alignment can be determined accurately. We, furthermore, demonstrate an eye tracking pipeline that can be trained in less than a minute, a time efficient way to train the whole pipeline given a dataset that includes only complete faces, show exemplary results generated by our method, and discuss performance at the ANA Avatar XPRIZE semifinals.
# Visual Servoing
# An Offline Geometric Model for Controlling the Shape of Elastic Linear Objects
## Keywords:
- Visual Servoing
- Sensor-based Control
## Abstract:
We propose a new approach to control the shape of deformable objects with robots. Specifically, we consider a fixed-length elastic linear object lying on a 2D workspace. Our main idea is to encode the object’s deformation behavior in an offline constant Jacobian matrix. To derive this Jacobian, we use geometric deformation modeling and combine recent work from the fields of deformable object control and multirobot systems. Based on this Jacobian, we then propose a robotic control law that is capable of driving a set of shape features on the object toward prescribed values. Our contribution relative to existing approaches is that at run-time we do not need to measure the full shape of the object or to estimate/simulate a deformation model. This simplification is achieved thanks to having abstracted the deformation behavior as an offline model. We illustrate the proposed approach in simulation and in experiments with real deformable linear objects.
# Skeleton-Based Adaptive Visual Servoing for Control of Robotic Manipulators in Configuration Space
## Keywords:
- Visual Servoing
- Robust/Adaptive Control
- Sensor-based Control
## Abstract:
This paper presents a novel visual servoing method that controls a robotic manipulator in the configuration space as opposed to the classical vision-based control methods solely focusing on the end effector pose. We first extract the robot's shape from depth images using a skeletonization algorithm and represent it using parametric curves. We then adopt an adaptive visual servoing scheme that estimates the Jacobian online relating the changes of the curve parameters and the joint velocities. The proposed scheme does not only enable controlling a manipulator in the configuration space, but also demonstrates a better transient response while converging to the goal configuration compared to the classical adaptive visual servoing methods. We present simulations and real robot experiments that demonstrate the capabilities of the proposed method and analyze its performance, robustness, and repeatability compared to the classical algorithms.
# Conditional Visual Servoing for Multi-Step Tasks
## Keywords:
- Visual Servoing
- Learning from Demonstration
- Perception for Grasping and Manipulation
## Abstract:
Visual Servoing has been effectively used to move a robot into specific target locations or to track a recorded demonstration. It does not require manual programming, but it is typically limited to settings where one demonstration maps to one environment state. We propose a modular approach to extend visual servoing to scenarios with multiple demonstration sequences. We call this conditional servoing, as we choose the next demonstration conditioned on the observation of the robot. This method presents an appealing strategy to tackle multi-step problems, as individual demonstrations can be combined flexibly into a control policy. We propose different selection functions and compare them on a shape-sorting task in simulation. With the reprojection error yielding the best overall results, we implement this selection function on a real robot and show the efficacy of the proposed conditional servoing.
# Optimal Shape Servoing with Task-Focused Convergence Constraints
## Keywords:
- Visual Servoing
- Optimization and Optimal Control
- Industrial Robots
## Abstract:
Most deformable object manipulation tasks still rely on skillful human operators. To automate such tasks, a robotic system should not only be able to deform an object to a desired shape but also servo its deformation along a specific path towards the desired shape. We propose a shape servoing control scheme to automate such tasks. Our scheme controls the deformation trajectory towards the desired shape by imposing task-focused convergence constraints. The constraints impose how fast the different regions of the object converge to the desired shape. Integrating such a behavior in shape servoing forms our main contribution. Experiments, carried out on rubber layer assembly tasks, show that our control scheme outperforms a state-of-the-art shape servoing scheme.
# An Event-Triggered Visual Servoing Predictive Control Strategy for the Surveillance of Contour-Based Areas Using Multirotor Aerial Vehicles
## Keywords:
- Visual Servoing
- Visual Tracking
- Sensor-based Control
## Abstract:
In this paper, an Event-triggered Image-based Visual Servoing Nonlinear Model Predictive Controller (ET-IBVS-NMPC) for multirotor aerial vehicles is presented. The proposed scheme is developed for the autonomous surveillance of contour-based areas with different characteristics (e.g. forest paths, coastlines, road pavements). For this purpose, an appropriately trained Deep Neural Network (DNN) is employed for the accurate detection of the contours. In an effort to reduce the remarkably large computational cost required by an IBVS-NMPC algorithm, a triggering condition is designed to define when the Optimal Control Problem (OCP) should be resolved and new control inputs will be calculated. Between two successive triggering instants, the control input trajectory is applied to the robot in an open-loop way, which means no visual measurements or control input computations are required at that moment. As a result, the system's computing effort and energy consumption are lowered, while its autonomy and flight duration are increased. The visibility and input constraints, as well as the external disturbances, are all taken into account throughout the control design. The efficacy of the proposed strategy is demonstrated through a series of real-time experiments using a quadrotor and an octorotor both equipped with a monocular downward looking camera.
# Vision-Based Rotational Control of an Agile Observation Satellite
## Keywords:
- Visual Servoing
- Space Robotics and Automation
## Abstract:
Recent Earth observation satellites are now equipped with new instrument that allows image feedback in real-time. Problematic such as ground target tracking, moving or not, can now be addressed by controlling precisely the satellite attitude. In this paper, we propose to consider this problem using a visual servoing (VS) approach. While focusing on the target, the control scheme has also to take into account the satellite motion induced by its orbit, Earth rotational velocities, potential target own motion, but also rotational velocities and accelerations constraints of the system. We show the efficiency of our system using both simulation (considering real Earth image) and experiments on a robot that replicates actual high resolution satellite constraints.
# DIJE: Dense Image Jacobian Estimation for Robust Robotic Self-Recognition and Visual Servoing
## Keywords:
- Visual Servoing
- Model Learning for Control
- Semantic Scene Understanding
## Abstract:
For robots to move in the real world, they must first correctly understand the state of its own body and the tools that it holds. In this research, we propose DIJE, an algorithm to estimate the image Jacobian for every pixel. It is based on an optical flow calculation and a simplified Kalman Filter that can be efficiently run on the whole image in real time. It does not rely on markers nor knowledge of the robotic structure. We use the DIJE in a self-recognition process which can robustly distinguish between movement by the robot and by external entities, even when the motion overlaps. We also propose a visual servoing controller based on DIJE, which can learn to control the robot's body to conduct reaching movements or bimanual tool-tip control. The proposed algorithms were implemented on a physical musculoskeletal robot and its performance was verified. We believe that such global estimation of the visuomotor policy has the potential to be extended into a more general framework for manipulation.
# Self-Supervised Wide Baseline Visual Servoing Via 3D Equivariance
## Keywords:
- Visual Servoing
- Representation Learning
- Perception-Action Coupling
## Abstract:
One of the challenging input settings for visual servoing is when the initial and goal camera views are far apart. Such settings are difficult because the wide baseline can cause drastic changes in object appearance and cause occlusions. This paper presents a novel self-supervised visual servoing method for wide baseline images which does not require 3D ground truth supervision. Existing approaches that regress absolute camera pose with respect to an object require 3D ground truth data of the object in the forms of 3D bounding boxes or meshes. We learn a coherent visual representation by leveraging a geometric property called 3D equivariance-the representation is transformed in a predictable way as a function of 3D transformation. To ensure that the feature-space is faithful to the underlying geodesic space, a geodesic preserving constraint is applied in conjunction with the equivariance. We design a Siamese network that can effectively enforce these two geometric properties without requiring 3D supervision. With the learned model, the relative transformation can be inferred simply by following the gradient in the learned space and used as feedback for closed-loop visual servoing. Our method is evaluated on objects from the YCB dataset, showing meaningful outperformance on a visual servoing task, or object alignment task with respect to state-of-the-art approaches that use 3D supervision. Ours yields more than 35% average distance error reduction and more than 90% success rate with 3cm error tolerance.
# Visibility Maximization Controller for Robotic Manipulation
## Keywords:
- Visual Servoing
- Sensor-based Control
- Mobile Manipulation
## Abstract:
Occlusions caused by a robot's own body is a common problem for closed-loop control methods employed in eye-to-hand camera setups. We propose an optimization-based reactive controller that minimizes self-occlusions while achieving a desired goal pose. The approach allows coordinated control between the robot's base, arm and head by encoding the line-of-sight visibility to the target as a soft constraint along with other task-related constraints, and solving for feasible joint and base velocities. The generalizability of the approach is demonstrated in simulated and real-world experiments, on robots with fixed or mobile bases, with moving or fixed objects, and multiple objects. The experiments revealed a trade-off between occlusion rates and other task metrics. While a planning-based baseline achieved lower occlusion rates than the proposed controller, it came at the expense of highly inefficient paths and a significant drop in the task success. On the other hand, the proposed controller is shown to improve visibility to the line target object(s) without sacrificing too much from the task success and efficiency. Videos and code can be found at: rhys-newbury.github.io/projects/vmc/.
# Mapping 2
# Multi-Camera-LiDAR Auto-Calibration by Joint Structure-From-Motion
## Keywords:
- Mapping
## Abstract:
Multiple sensors, especially cameras and LiDARs, are widely used in autonomous vehicles. In order to fuse data from different sensors accurately, precise calibrations are required, including camera intrinsic parameters, and relative poses between multiple cameras and LiDARs. However, most existing camera-LiDAR calibration methods need to place manually designed calibration objects in multiple locations and multiple times, which are time-consuming and labor-intensive, and are not suitable for frequent use. To address that, in this paper we proposed a novel calibration pipeline that can automatically calibrate multiple cameras and multiple LiDARs in a Structure-from-Motion (SfM) process. In our pipeline, we first perform a global SfM on all images with the help of rough LiDAR data to get the initial poses of all sensors. Then, feature points on lines and planes are extracted from both SfM point cloud and LiDARs. With these features, a global Bundle Adjustment is performed to minimize the point reprojection errors, point-to-line errors, and point-to-plane errors together. During this minimization process, camera intrinsic parameters, camera and LiDAR poses, and SfM point cloud are refined jointly. The proposed method uses the characteristics of natural scenes, does not require manually designed calibration objects, and incorporates all calibration parameters into a unified optimization framework. Experiments on autonomous vehicles with different sensor configurations demonstrate the effectiveness and robustness of the proposed method.
# GeoROS: Georeferenced Real-Time Orthophoto Stitching with Unmanned Aerial Vehicle
## Keywords:
- Mapping
- SLAM
- Aerial Systems: Perception and Autonomy
## Abstract:
Simultaneous orthophoto stitching during the flight of Unmanned Aerial Vehicles (UAV) can greatly promote the practicability and instantaneity of diverse applications such as emergency disaster rescue, digital agriculture, and cadastral survey, which is of remarkable interest in aerial photogrammetry. However, the inaccurately estimated camera poses and intuitive fusion strategy of existing methods lead to misalignment and distortion artifacts in orthophoto mosaics. To address these issues, we propose a Georeferenced Real-time Orthophoto Stitching method (GeoROS), which can achieve efficient and accurate camera pose estimation through exploiting geolocation information in monocular visual simultaneous localization and mapping (SLAM) and fuse transformed images via orthogonality-preserving criterion. Specifically, in the SLAM process, georeferenced tracking is employed to acquire high-quality initial camera poses with a geolocation based motion model and facilitate non-linear pose optimization. Meanwhile, we design a georeferenced mapping scheme by introducing robust geolocation constraints in joint optimization of camera poses and the position of landmarks. Finally, aerial images warped with localized cameras are fused by considering both the orthogonality of camera orientation relative to the ground plane and the pixel centrality to fulfill global orthorectification. Besides, we construct two datasets with global navigation satellite system (GNSS) information of different scenarios and validate the superiority of our GeoROS method compared with state-of-the-art methods in accuracy and efficiency.
# Learning to Complete Object Shapes for Object-Level Mapping in Dynamic Scenes
## Keywords:
- Mapping
- RGB-D Perception
- SLAM
## Abstract:
In this paper, we propose a novel object-level mapping system that can simultaneously segment, track, and reconstruct objects in dynamic scenes. It can further predict and complete their full geometries by conditioning on reconstructions from depth inputs and a category-level shape prior with the aim that completed object geometry leads to better object reconstruction and tracking accuracy. For each incoming RGB-D frame, we perform instance segmentation to detect objects and build data associations between the detection and the existing object maps. A new object map will be created for each unmatched detection. For each matched object, we jointly optimise its pose and latent geometry representations using geometric residual and differential rendering residual towards its shape prior and completed geometry. Our approach shows better tracking and reconstruction performance compared to methods using traditional volumetric mapping or learned shape prior approaches. We evaluate its effectiveness by quantitatively and qualitatively testing it in both synthetic and real-world sequences.
# Robot-Aided Microbial Density Estimation and Mapping
## Keywords:
- Mapping
- Engineering for Robotic Systems
- Service Robotics
## Abstract:
Estimating the microbial infestation profile of an area is essential for an effective cleaning process. However, current methods used to inspect the microbial infestation within a spatial region are manual and laborious. For large regions that require automated cleaning, conventional methods of microbial examination are not practical. We propose a novel robotaided microbial density estimation and mapping framework using an in-house developed biosensor payload onboard a mobile robot. The biosensor estimates the degree of microbial infestation in Relative Light Units (RLU) using the natural bio-luminescence reaction. The global distribution of microbial infestation is approximated through the Radial Basis Function (RBF) and Nearest Neighbour (NN) interpolation algorithms. The proposed method is implemented on an in-house developed mobile robot called Beluga. The framework’s validation and usefulness are demonstrated quantitatively through real-world experiment trials.
# Elevation Mapping for Locomotion and Navigation Using GPU
## Keywords:
- Mapping
- Legged Robots
- Autonomous Vehicle Navigation
## Abstract:
Perceiving the surrounding environment is crucial for autonomous mobile robots. An elevation map provides a memory-efficient and simple yet powerful geometric representation of the terrain for ground robots. The robots can use this information for navigation in an unknown environment or perceptive locomotion control over rough terrain. Depending on the application, various post processing steps may be incorporated, such as smoothing, inpainting or plane segmentation. In this work, we present an elevation mapping pipeline leveraging GPU for fast and efficient processing with additional features both for navigation and locomotion. We demonstrated our mapping framework through extensive hardware experiments. Our mapping software was successfully deployed for underground exploration during DARPA Subterranean Challenge and for various experiments of quadrupedal locomotion.
# LODM: Large-Scale Online Dense Mapping for UAV
## Keywords:
- Mapping
- Aerial Systems: Perception and Autonomy
## Abstract:
This paper proposes a method for online large-scale dense mapping. The UAV is within a range of 150-250 meters, combining GPS and visual odometry to estimate the scaled pose and sparse points. In order to use the depth of sparse points for depth map, we propose Sparse Confidence Cascade View-Aggregation MVSNet (SCCVA-MVSNet), which projects the depth-converged points in the sliding window on keyframes to obtain a sparse depth map. The photometric error constructs sparse confidence. The coarse depth and confidence through normalized convolution use the images of all keyframes, coarse depth, and confidence as the input of CVA-MVSNet to extract features and construct 3D cost volumes with adaptive view aggregation to balance the different stereo baselines between the keyframes. Our proposed network utilizes sparse features point information, the output of the network better maintains the consistency of the scale. Our experiments show that MVSNet using sparse feature point information outperforms image-only MVSNet, and our online reconstruction results are comparable to offline reconstruction methods.To benefit the research community, we open-source our code at https://github.com/hjxwhy/LODM.git
# Roadside HD Map Object Reconstruction Using Monocular Camera
## Keywords:
- Mapping
- SLAM
- Computer Vision for Transportation
## Abstract:
The traditional HD map production based on mapping vehicles equipped with expensive sensors (e.g. LiDAR) struggles to keep the frequently changing HD maps up-to-date, thus calling for great research efforts in the HD map reconstruction using low-cost vision sensors. However, most existing works in this area limit their focus on reconstructing the landmarks on the road surface. This paper widens this limited scope by focusing on the roadside object reconstruction with a monocular camera. We proposed a novel object-level reconstruction framework that boasts two advantageous features: 1) a novel 3D model estimation methods to directly reconstruct the specific roadside objects in a vectorized format using their prior geometric knowledge, and 2) a novel data association method to solve the complex tracking problem of road-side objects that often yield thin and coherent observations. The proposed framework is evaluated on both typical highway and urban scenarios in public KAIST Urban dataset. The results demonstrate that our algorithm can reconstruct the roadside objects at high accuracy and recall, and outperforms classic Structure from Motion (SfM) and deep-learning-based method by a large margin.
# Adaptive-Resolution Field Mapping Using Gaussian Process Fusion with Integral Kernels
## Keywords:
- Mapping
- Aerial Systems: Perception and Autonomy
## Abstract:
Unmanned aerial vehicles are rapidly gaining popularity in many environmental monitoring tasks. A prerequisite for their autonomous operation is the ability to perform efficient and accurate mapping online, given limited on-board resources constraining operation time and computational capacity. To address this, we present an online adaptive-resolution approach for field mapping based on Gaussian Process fusion, a strategy in which Bayesian fusion is applied to update a Gaussian Process prior map. A key aspect of our approach is an integral kernel encoding spatial correlation over the areas of grid cells. This enables efficient information compression in uninteresting areas to achieve a compact map representation while maintaining spatial correlations in a theoretically sound fashion. We evaluate the performance of our approach on both synthetic and real-world data. Results show that our method is more efficient in terms of mapping time and memory consumption without compromising on map quality. Further, we integrate our mapping strategy into an adaptive path planning framework to show that it facilitates information gathering efficiency in online settings.
# Make It Dense: Self-Supervised Geometric Scan Completion of Sparse 3D LiDAR Scans in Large Outdoor Environments
## Keywords:
- Mapping
- AI-Enabled Robotics
## Abstract:
Mapping systems that turn sensor data into a model of the environment are standard components in mobile robotics. Outdoor robots are often equipped with 3D LiDAR sensors to obtain accurate range measurements at a high frame rate. The price for a robotic LiDAR sensor scales roughly linearly with the number of beams and thus the vertical resolution of the scanner. In general, the cheaper the sensors, the sparser the point cloud. In this paper, we address the problem of building dense models from sparse range data. Instead of requiring the vehicle to move slowly through the environment or to traverse the scene multiple times to cover the space densely, we investigate geometric scan completion through a learning-based approach. We revisit the traditional volumetric fusion pipeline based on truncated signed distance fields (TSDF) and propose a neural network to aid the 3D reconstruction on a frame-to-frame basis by completing each scan towards a dense TSDF volume. We propose a geometric scan completion network that is trained in a self-supervised fashion without labels. Our experiments illustrate that such frame-wise completion leads to maps that are on-par or even better compared to maps generated using a higher resolution LiDAR sensor. We additionally show that our system can be used to improve the performance of SLAM systems.
# Human-Centered Robotics 2
# Learning Causal Relationships of Object Properties and Affordances through Human Demonstrations and Self-Supervised Intervention for Purposeful Action in Transfer Environments
## Keywords:
- Learning Categories and Concepts
- Learning from Demonstration
- Cognitive Modeling
## Abstract:
Learning object affordances enables robots to plan and perform purposeful actions. However, a fundamental challenge for the utilization of affordance knowledge lies in its generalization to unknown objects and environments. In this paper we present a new method for learning causal relationships between object properties and object affordances which can be transferred to other environments. Our approach, implemented on a PR2 robot, generates hypotheses of property-affordance models in a toy environment based on human demonstrations that are subsequently tested through interventional experiments. The system relies on information theory to choose experiments for maximal information gain, performs them self-supervised and uses the observed outcome to iteratively refine the set of candidate causal models. The learned causal knowledge is human-interpretable in the form of graphical models, stored in the knowledge graph. We validate our method through a task requiring affordance knowledge transfer to three different unknown environments. Our results show that extending learning from human demonstrations by causal learning through interventions led to a 71.7% decrease in model uncertainty and improved affordance classification in the transfer environments on average by 47.49%.
# Robotic Powder Grinding with a Soft Jig for Laboratory Automation in Material Science
## Keywords:
- Robotics and Automation in Life Sciences
- Compliant Joints and Mechanisms
- Grippers and Other End-Effectors
## Abstract:
Mixing and grinding materials into a fine powder is a time-consuming task in material science that is generally performed by hand, as current automated grinding machines do not ensure complete mixing. This study presents a robotic powder grinding method for laboratory automation in material science applications which observes the state of the powder to improve the grinding outcome. We developed a soft jig consisting of off-the-shelf gel materials and 3D-printed parts, which can be used with any robot arm to perform powder grinding. The physical softness of the jig allows for safe grinding without force sensing. In addition, we developed a visual feedback system that observes the powder distribution to decide where to grind and when to gather. The results showed that our system could grind 79 percent of the powder to a particle size smaller than 200~mum by using the soft jig and visual feedback. Using only the soft jig and no feedback, this ratio was 57%. Our system can be used immediately to alleviate the workload of researchers. In the future, we will improve the prototype and ensure the complete mixing of materials. Our robotic system with a soft jig will significantly alleviate the workload of researchers preparing sample materials by spending many hours.
# Prediction of Whole-Body Velocity and Direction from Local Leg Joint Movements in Insect Walking Via LSTM Neural Networks
## Keywords:
- Robotics and Automation in Life Sciences
- Neurorobotics
- Deep Learning Methods
## Abstract:
Extracting motion information from videos is important for quantifying data from behavioral experiments to deepen the understanding of generation mechanisms of animal behavior. For insect walking, inter-leg coordination plays a crucial role, and the thorax-coxa (ThC) and femur-tibia (FTi) joint motions of six legs reflect the walking velocity and direction. This suggests that joint-motion information based on a continuous time series is beneficial for dynamic behavior prediction. Since pose estimation from markerless videos has been extensively studied, the joint angle can be calculated accurately from videos via deep-learning algorithms such as DeepLabCut. Herein, we propose a method for the single-step and multi-step prediction of whole-body velocity and direction using leg joint angles. The method constructs models using long short-term memory (LSTM) and Hammerstein LSTM (HLSTM), with joint data as input, to predict the whole-body velocity and direction of insect walking. We investigated motion prediction with ThC and FTi joint angles using LSTM and HLSTM. The trained models predicted single-step motion information with the accuracy in the range of 73.28%--92.12% for velocity and 66.66%--87.46% for direction. Multi-step prediction for the next 10 steps showed the accuracy in the range of 99.56%--99.99% for velocity and 99.43%--99.95% for direction.
# Core Processes in Intelligent Robotic Lab Assistants: Flexible Liquid Handling
## Keywords:
- Robotics and Automation in Life Sciences
- Hardware-Software Integration in Robotics
- Human-Robot Collaboration
## Abstract:
Laboratory automation is a suitable solution to establish higher reproducibility with less manual work and thus higher quality standards in life sciences. To date, mobile robots are capable of performing autonomous pick-and-place tasks in the laboratory, and specialized pipetting machines can be used for sequenced liquid handling. However, the complex and creative process of developing new research protocols requires flexible robotic systems that can perform tasks such as pipetting in more versatile ways. In addition, the correct technique, according to ISO standards, has a great influence on precision and accuracy and therefore on reproducibility. This paper introduces our Intelligent Robotic Lab Assistants in the framework of our holistic, human-like, but standardized paradigm for collaborative lab automation, AI.Laboratory. Our system demonstrates mastery of pipetting following ISO 8655 as a force-sensitive robotic manipulation skill, which is a key component of our taxonomy of cell culture skills and the first steps toward true intelligent robotic laboratory assistants. This intelligent robotic pipetting skill is a versatile tool for general handling of micro liter-liquids, using only standard laboratory equipment that can be flexibly positioned in the robot's workspace. To demonstrate its pipetting performance, flexible handling of small volumes from 10 micro liter to 1000 micro liter was experimentally validated to the ISO 8655 standard, demonstrating superhuman performance that outperformed laymen, human experts, and other commercial and non-commercial robotic pipetting systems.
# Registering Articulated Objects with Human-In-The-Loop Corrections
## Keywords:
- Human-Centered Automation
- Telerobotics and Teleoperation
- Space Robotics and Automation
## Abstract:
Remotely programming robots to execute tasks often relies on registering objects of interest in the robot’s environment. Frequently, these tasks involve articulating objects such as opening or closing a valve. However, existing human-in-the-loop methods for registering objects do not consider articulations and the corresponding impact to the geometry of the object, which can cause the methods to fail. In this work, we present an approach where the registration system attempts to automatically determine the object model, pose, and articulation for user-selected points using nonlinear fitting and the iterative closest point algorithm. When the fitting is incorrect, the operator can iteratively intervene with corrections after which the system will refit the object. We present an implementation of our fitting procedure for one degree-of-freedom (DOF) objects with revolute joints and evaluate it with a user study that shows that it can improve user performance, in measures of time on task and task load, ease of use, and usefulness compared to a manual registration approach. We also present a situated example that integrates our method into an end-to-end system for articulating a remote valve.
# Learning-Based Approach for a Soft Assistive Robotic Arm to Achieve Simultaneous Position and Force Control
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Model Learning for Control
- Optimization and Optimal Control
## Abstract:
Soft robotics have demonstrated great advantages in assisting elderly/disabled people during daily tasks, owing to their highly dexterous motions and safe human-robot interactions. However, simultaneously controlling the position and force of soft robots is still a challenging task due to soft actuators' nonlinearity, system uncertainty, and high-dimensional control space. Classical control methods are usually based on first-principle/analytical models that are
difficult to derive for soft robots without making significant simplifications. To overcome such control challenges, the central concept of this work is to introduce a learning-based data-driven approach. The approach employs a probabilistic model to explicitly capture system nonlinearity and uncertainty. Besides, nonparametric local learning methods are investigated to deal with redundant high-dimensional control space. The approach is applied in a soft robotic arm interacting with a manikin to simulate the bathing task. Experimental results demonstrate that the soft robotic arm could be well controlled to track the desired position and force simultaneously (maximum error of position and force is 6mm and 0.037N). Meanwhile, our
method outperforms another typical data-driven approach (maximum error of position and force is 10mm and 0.058N). The results indicate that our approach is helpful for soft robots because of the physical interactions needed in assistive tasks.
# Egocentric Human Trajectory Forecasting with a Wearable Camera and Multi-Modal Fusion
## Keywords:
- Deep Learning for Visual Perception
- Vision-Based Navigation
- Data Sets for Robotic Vision
## Abstract:
In this paper, we address the problem of forecasting the trajectory of an egocentric camera wearer (ego-person) in crowded spaces. The trajectory forecasting ability learned from the data of different camera wearers walking around in the real world can be transferred to assist visually impaired people in navigation, as well as to instill human navigation behaviours in mobile robots, enabling better human-robot interactions. To this end, a novel egocentric human trajectory forecasting dataset was constructed, containing real trajectories of people navigating in crowded spaces wearing a camera, as well as extracted rich contextual data. We extract and utilize three different modalities to forecast the trajectory of the camera wearer, i.e., his/her past trajectory, the past trajectories of nearby people, and the environment such as the scene semantics or the depth of the scene. A Transformer-based encoder-decoder neural network model, integrated with a novel cascaded cross-attention mechanism that fuses multiple modalities, has been designed to predict the future trajectory of the camera wearer. Extensive experiments have been conducted, with results showing that our model outperforms state-of-the-art methods in egocentric human trajectory forecasting.
# Social Attitude towards a Robot Is Promoted by Motor-Induced Embodiment Independently of Spatial Perspective
## Keywords:
- Embodied Cognitive Science
- Acceptability and Trust
- Social HRI
## Abstract:
Humans can enter into social relations with robots through different spatial perspectives. In the telepresence perspective, the human sees through the eyes of the robot. In the face-to-face perspective the human faces the robot and interacts in a self-other relation. During robotic telepresence, we have shown that embodiment into robots can be promoted by reciprocal and synchronous stimuli in the form of intentional movements or passive tactile stimulations. Here we investigate the impact of different spatial perspectives coupled to these sensory-motor manipulations on human subjects’ social perception of robots. Through a series of experiments, we demonstrate that independent of the telepresence vs. face-to-face self-perspective, the sense of agency as induced by synchronous human-robot movements is crucial for generating positive changes of robot acceptability. We suggest that motor intentionality most clearly influences our social perception of robots.
# Spatial Computing and Intuitive Interaction: Bringing Mixed Reality and Robotics Together (I)
## Keywords:
- Virtual Reality and Interfaces
- Telerobotics and Teleoperation
- Localization
## Abstract:
Spatial computing---the ability of devices to be aware of their surroundings and to represent this digitally---offers novel capabilities in human-robot interaction. In particular, the combination of spatial computing and egocentric sensing on mixed reality devices enables them to capture and understand human actions and translate these to actions with spatial meaning, which offers exciting new possibilities for collaboration between humans and robots. This paper presents several human-robot systems that utilize these capabilities to enable novel robot use cases: mission planning for inspection, gesture-based control, and immersive teleoperation. These works demonstrate the power of mixed reality as a tool for human-robot interaction, and the potential of spatial computing and mixed reality to drive the future of human-robot interaction.
# Sensor Fusion 1
# Generalized Laplace Particle Filter on Lie Groups Applied to Ambiguous Doppler Navigation
## Keywords:
- Sensor Fusion
- Aerial Systems: Perception and Autonomy
- Autonomous Vehicle Navigation
## Abstract:
Particle filters are suited to solve nonlinear and non-Gaussian estimation problems which find numerous applications in autonomous systems navigation. Previous works on Laplace Particle Filter on Lie groups (LG-LPF) demonstrated its robustness and accuracy on challenging navigation scenarios compared to classic particle filters. Nevertheless, the previously proposed LG-LPF is applicable when the prior probability density and the likelihood have a predominant mode, which narrows the scope of applications of this method. Thus, this paper proposes a generalized strategy to use LG-LPF while keeping its benefits. The core idea is to compute an accurate multimodal importance function based on local optimizations and resample the particles accordingly. This approach is compared to a Laplace Particle Filter (LPF) designed in the Euclidean space, on a UAV navigation scenario with ambiguous Doppler-aiding measurements. The Lie group approach shows improved accuracy and robustness in every case, even with a reduced number of particles.
# Towards Autonomous Control of Surgical Instruments Using Adaptive-Fusion Tracking and Robot Self-Calibration
## Keywords:
- Sensor Fusion
- Calibration and Identification
- Surgical Robotics: Laparoscopy
## Abstract:
The ability to track surgical instruments in real-time is crucial for autonomous Robotic Assisted Surgery (RAS). Recently, the fusion of visual and kinematic data has been proposed to track surgical instruments. However, these methods assume that both sensors are equally reliable, and cannot successfully handle cases where there are significant perturbations in one of the sensors’ data. In this paper, we address this problem by proposing an enhanced fusion-based method. The main advantage of our method is that it can adjust fusion weights to adapt to sensor perturbations and failures. Another problem is that before performing an autonomous task, these robots have to be repetitively recalibrated by a human for each new patient to estimate the transformations between the different robotic arms. To address this problem, we propose a self-calibration algorithm that empowers the robot to autonomously calibrate the transformations by itself in the beginning of the surgery. We applied our fusion and self-calibration algorithms for autonomous ultrasound tissue scanning and we showed that the robot achieved stable ultrasound imaging when using our method. Our performance evaluation shows that our proposed method outperforms the state-of-art both in normal and challenging situations.
# AFT-VO: Asynchronous Fusion Transformers for Multi-View Visual Odometry Estimation
## Keywords:
- Sensor Fusion
- Deep Learning for Visual Perception
## Abstract:
Motion estimation approaches typically employ sensor fusion techniques, such as the Kalman Filter, to handle individual sensor failures. More recently, deep learning-based fusion approaches have been proposed, increasing the performance and requiring less model-specific implementations. However, current deep fusion approaches often assume that sensors are synchronised, which is not always practical, especially for low-cost hardware. To address this limitation, in this work, we propose AFT-VO, a novel transformer-based sensor fusion architecture to estimate VO from multiple sensors. Our framework combines predictions from asynchronous multi-view cameras and accounts for the time discrepancies of measurements coming from different sources. 
Our approach first employs a Mixture Density Network (MDN) to estimate the probability distributions of the 6-DoF poses for every camera in the system. Then a novel transformer-based fusion module, AFT-VO, is introduced, which combines these asynchronous pose estimations, along with their confidences. More specifically, we introduce Discretiser and Source Encoding techniques which enable the fusion of multi-source asynchronous signals.
We evaluate our approach on the popular nuScenes and KITTI datasets. Our experiments demonstrate that multi-view fusion for VO estimation provides robust and accurate trajectories, outperforming the state of the art in both challenging weather and lighting conditions.
# A Portable Multiscopic Camera for Novel View and Time Synthesis in Dynamic Scenes
## Keywords:
- Sensor Fusion
- Deep Learning for Visual Perception
- Range Sensing
## Abstract:
We present a portable multiscopic camera system with a dedicated model for novel view and time synthesis in dynamic scenes. Our goal is to render high-quality images for a dynamic scene from any viewpoint at any time using our portable multiscopic camera. To achieve such novel view and time synthesis, we develop a physical multiscopic camera equipped with five cameras to train a neural radiance field (NeRF) in both time and spatial domains for dynamic scenes. Our model maps a 6D coordinate (3D spatial position, 1D temporal coordinate, and 2D viewing direction) to view-dependent and time-varying emitted radiance and volume density. Volume rendering is applied to render a photo-realistic image at a specified camera pose and time. To improve the robustness of our physical camera, we propose a camera parameter optimization module and a temporal frame interpolation module to promote information propagation across time. We conduct experiments on both real-world and synthetic datasets to evaluate our system, and the results show that our approach outperforms alternative solutions qualitatively and quantitatively.
# HD-CCSOM: Hierarchical and Dense Collaborative Continuous Semantic Occupancy Mapping through Label Diffusion
## Keywords:
- Sensor Fusion
- Intelligent Transportation Systems
- Semantic Scene Understanding
## Abstract:
The collaborative operation of multiple robots can make up for the shortcomings of a single robot, such as limited field of perception or sensor failure. Multi-robots collaborative semantic mapping can enhance their comprehensive contextual understanding of the environment. However, existing multi-robots collaborative semantic mapping algorithms mainly apply discrete occupancy map inference, and do not compensate for inconsistent labels of local maps caused by differences in robot perspectives, which leads to greatly reduced availability and accuracy of the final global map. To address the challenges of discontinuous maps and inconsistent semantic labels, this paper proposes a novel hierarchical and dense collaborative continuous semantic occupancy mapping algorithm (HD-CCSOM). This work decomposes and formulates robot collaborative continuous semantic occupancy mapping problem at two levels. At the single robot level, the multi-entropy kernel inference method smoothly processes the registered semantic point cloud and infers a local continuous semantic occupancy map for each robot. At the collaborative robots level, the local maps are fused into a global enhanced and consistent semantic map via the label diffusion method based on a graph model. The proposed algorithm has been validated on public datasets and in simulated and real scenes, demonstrating significant improvements in mapping accuracy and efficiency.
# Scalable and Modular Ultra-Wideband Aided Inertial Navigation
## Keywords:
- Sensor Fusion
- Localization
- Range Sensing
## Abstract:
Navigating accurately in potentially GPS-denied environments is a perquisite of autonomous systems. Relative localization based on ultra-wideband (UWB) is – especially indoors – a promising technology. In this paper, we present a probabilistic filter based Modular Multi-Sensor Fusion (MMSF) approach with the capability of using efficiently all information in a fully meshed UWB ranging network. This allows an accurate mobile agent state estimation and network geometry calibration. We advocate a new paradigm that includes elements from Collaborative State Estimation (CSE) and allows us considering all stationary UWB anchors and the mobile agent as a decentralized set of estimtors. With this, our method can include all meshed (inter-)sensor observations tightly coupled in a modular estimator. We show that the application of our CSE-inspired method in such a context breaks the computational barrier that would otherwise prohibit the use of all available information or would lead to significant estimator inconsistencies due to coarse approximations for complexity-reduction. We compare the proposed approach against different MMSF strategies in terms of execution time, accuracy, and credibility on both synthetic data and on a dataset from real Unmanned Aerial Vehicles (UAVs).
# Optimal Multi-Robot Formations for Relative Pose Estimation Using Range Measurements
## Keywords:
- Sensor Fusion
- Multi-Robot Systems
- Probability and Statistical Methods
## Abstract:
In multi-robot missions, relative position and attitude information between robots is valuable for a variety of tasks such as mapping, planning, and formation control. In this paper, the problem of estimating relative poses from a set of inter-robot range measurements is investigated. Specifically, it is shown that the estimation accuracy is highly dependent on the true relative poses themselves, which prompts the desire to find multi-robot formations that provide the best estimation performance. By direct maximization of Fischer information, it is shown in simulation and experiment that large improvements in estimation accuracy can be obtained by optimizing the formation geometry of a team of robots.
# Monocular Event Visual Inertial Odometry Based on Event-Corner Using Sliding Windows Graph-Based Optimization
## Keywords:
- Sensor Fusion
- Vision-Based Navigation
- Visual-Inertial SLAM
## Abstract:
Event cameras are biologically-inspired vision sensors that capture pixel-level illumination changes instead of the intensity frame at a fixed frame rate. They offer many advantages over the standard cameras, such as high dynamic range, high temporal resolution (low latency), no motion blur, etc. Therefore, developing odometry algorithms based on event cameras offers exciting opportunities for autonomous systems and robots. In this paper, we propose monocular visual-inertial odometry for event cameras based on event-corner feature detection and matching with well-designed feature management. More specifically, two different kinds of event representations based on time surface are proposed to realize event-corner feature tracking (for front-end incremental estimation) and matching (for loop closure detection). Furthermore, the proposed event representations are used to set mask for detecting the event-corner feature based on the raw event-stream, which ensures the uniformly distributed and spatial consistency characteristic of the event-corner feature. Finally, a tightly coupled, graph-based optimization framework is designed to obtain high-accurate event visual-inertial odometry (EVIO) by fusing pre-integrated IMU measurements and event-corner observations. We validate quantitatively the performance of our system on different resolution event cameras: DAVIS240C (240*180, public dataset, achieve state-of-the-art), DAVIS346 (346*240, real-test), DVXplorer (640*480 real-test). Furthermore, we demonstrate qualitatively the accuracy, robustness, loop closure, and re-localization performance of our framework on different large-scale datasets, and an autonomous quadrotor flight using our EVIO state estimation. Videos of all the evaluations are presented on the project website.
# Multical: Spatiotemporal Calibration for Multiple IMUs, Cameras and LiDARs
## Keywords:
- Sensor Fusion
- SLAM
- Range Sensing
## Abstract:
Spatiotemporal calibration of sensors, especially of those which do not share their fields of view, is becoming increasingly important in the fields of autonomous driving and robotics. This paper presents a general sensor calibration method, named Multical, that makes use of multiple planar calibration targets whose poses will be estimated alongside spatiotemporal calibration. Multical exploits continuous-time curves to represent the state of the sensor platform during data collection, and thus is a general framework to calibrate different kinds of sensors and deal with both spatial as well as temporal offsets. Multical includes algorithms to estimate the initial guesses of spatial transformations between sensors, and also the relative poses between calibration targets. Users do not need to provide any extrinsic priors. We apply the proposed calibration approach to both simulated and real-world experiments, and the results demonstrate the high fidelity of the proposed method.
# Reinforcement Learning 1
# Safe Reinforcement Learning for Legged Locomotion
## Keywords:
- Reinforcement Learning
- Robot Safety
## Abstract:
Designing control policies for legged locomotion is complex due to the under-actuated and non-continuous robot dynamics. Model-free reinforcement learning provides promising tools to tackle this challenge. However, a major bottleneck of applying model-free reinforcement learning in real world is safety. In this paper, we propose a safe reinforcement learning framework that switches between a safe recovery policy that prevents the robot from entering unsafe states, and a learner policy that is optimized to complete the task. The safe recovery policy takes over the control when the learner policy violates safety constraints, and hands over the control back when there are no future safety violations. We design the safe recovery policy so that it ensures safety of quadruped locomotion while minimally intervening in the learning process. Furthermore, we theoretically analyze the proposed framework and provide an upper bound on the task performance. We verify the proposed framework in four tasks on a simulated and real quadrupedal robot: efficient gait, catwalk, two-leg balance, and pacing. On average, our method achieves 48.6% fewer falls and comparable or better rewards than the baseline methods in simulation. When deployed it on real-world quadruped robot, our training pipeline enables 34% improvement in energy efficiency for the efficient gait, 40.9% narrower of the feet placement in the catwalk, and two times more jumping duration in the two-leg balance. Our method achieves less than five falls over the duration of 115 minutes of hardware time.
# Safety Guided Policy Optimization
## Keywords:
- Reinforcement Learning
- Robot Safety
## Abstract:
In reinforcement learning (RL), exploration is essential to achieve a globally optimal policy but unconstrained exploration can cause damages to robots and nearby people. To handle this safety issue in exploration, safe RL has been proposed to keep the agent under the specified safety constraints while maximizing cumulative rewards. This paper introduces a new safe RL method which can be applied to robots to operate under the safety constraints while learning. The key component of the proposed method is the safeguard module. The safeguard predicts the constraints in the near future and corrects actions such that the predicted constraints are not violated. Since actions are safely modified by the safeguard during exploration and policies are trained to imitate the corrected actions, the agent can safely explore. Additionally, the safeguard is sample efficient as it does not require long horizontal trajectories for training, so constraints can be satisfied within short time steps. The proposed method is extensively evaluated in simulation and experiments using a real robot. The results show that the proposed method achieves the best performance while satisfying safety constraints with minimal interaction with environments in all experiments.
# How to Spend Your Robot Time: Bridging Kickstarting and Offline Reinforcement Learning for Vision-Based Robotic Manipulation
## Keywords:
- Reinforcement Learning
- Imitation Learning
- Deep Learning in Grasping and Manipulation
## Abstract:
Reinforcement learning (RL) has been shown to be effective at learning control from experience. However, RL typically requires a large amount of online interaction with the environment. This limits its applicability to real-world settings, such as in robotics, where such interaction is expensive. In this work we investigate ways to minimize online interactions in a target task, by reusing a suboptimal policy we might have access to, for example from training on related prior tasks, or in simulation. To this end, we develop two RL algorithms that can speed up training by using not only the action distributions of teacher policies, but also data collected by such policies on the task at hand. We conduct a thorough experimental study of how to use suboptimal teachers on a challenging robotic manipulation benchmark on vision-based stacking with diverse objects. We compare our methods to offline, online, offline-to-online, and kickstarting RL algorithms. By doing so, we find that training on data from both the teacher and student, enables the best performance for limited data budgets. We examine how to best allocate a limited data budget -# on the target task -# between the teacher and the student policy, and report experiments using varying budgets, two teachers with different degrees of suboptimality, and five stacking tasks that require a diverse set of behaviors. Our analysis, both in simulation and in the real world, shows that our approach is the best across data budgets, while standard offline RL from teacher rollouts is surprisingly effective when enough data is given.
# A Contact-Safe Reinforcement Learning Framework for Contact-Rich Robot Manipulation
## Keywords:
- Reinforcement Learning
- Robot Safety
- Compliance and Impedance Control
## Abstract:
Reinforcement learning shows great potential to solve complex contact-rich robot manipulation tasks. However, the safety of using RL in the real world is a crucial problem, since unexpected dangerous collisions might happen when the RL policy is imperfect during training or in unseen scenarios. In this paper, we propose a contact-safe reinforcement learning framework for contact-rich robot manipulation, which maintains safety in both the task space and joint space. When the RL policy causes unexpected collisions between the robot arm and the environment, our framework is able to immediately detect the collision and ensure the contact force to be small. Furthermore, the end-effector is enforced to perform contact-rich tasks compliantly, while keeping robust to external disturbances. We train the RL policy in simulation and transfer it to the real robot. Real world experiments on robot wiping tasks show that our method is able to keep the contact force small both in task space and joint space even when the policy is under unseen scenario with unexpected collision, while rejecting the disturbances on the main task.
# Learning Skills to Navigate without a Master: A Sequential Multi-Policy Reinforcement Learning Algorithm
## Keywords:
- Reinforcement Learning
- Deep Learning Methods
- Collision Avoidance
## Abstract:
Solving complex problems using reinforcement learning necessitates breaking down the problem into manageable tasks, and learning policies to solve these tasks. These policies, in turn, have to be controlled by a master policy that takes high-level decisions. Hence learning policies involves hierarchical decision structures. However, training such methods in practice may lead to poor generalization, with either sub-policies executing actions for too few time steps or devolving into a single policy altogether. In our work, we introduce an alternative approach to learn such skills **sequentially** without using an overarching hierarchical policy. We propose this method in the context of environments where a major component of the objective of a learning agent is to prolong the episode for as long as possible. We refer to our proposed method as **Sequential Soft Option Critic**. We demonstrate the utility of our approach on navigation and goal-based tasks in a flexible simulated 3D navigation environment that we have developed. We also show that our method outperforms prior methods such as Soft Actor-Critic and Soft Option Critic on various environments, including the Atari River Raid environment and the Gym-Duckietown self-driving car simulator.
# Ordinal Inverse Reinforcement Learning Applied to Robot Learning with Small Data
## Keywords:
- Reinforcement Learning
- Probabilistic Inference
- Imitation Learning
## Abstract:
Over the last decade, the ability to teach actions to robots in a user-friendly way has gained relevance, and a practical way of teaching robots a new task is to use Inverse reinforcement Learning (IRL). In IRL, an expert teacher shows the robot a desired behaviour and an agent builds a model of the reward. The agent can also infer a policy that performs in an optimal way within the limitations of the knowledge provided to it. However, most IRL approaches assume an (almost) optimal performance of the teaching agent, which might become unpractical if the teacher is not actually an expert. In addition, most IRL focus on discrete state-action spaces that limit their applicability to certain real-world problems such as within the context of direct Policy Search (PS) reinforcement learning. Therefore, in this paper we introduce Ordinal Inverse Reinforcement Learning (OrdIRL) for continuous state variables, in which the teacher can qualitatively evaluate robot performance by selecting one among the predefined performance levels (e.g. tbad, medium, goodu for three tiers of performance). Once the OrdIRL has fit an ordinal distribution to the data, we propose to use Bayesian Optimization (BO) to either gain knowledge on the inferred model (exploration) or find a policy or action that maximizes the expected reward given the prior knowledge on the reward (exploitation). In the case of large-dimensional state-action spaces, we use Dimensionality Reduction (DR) techniques and perform the BO in the latent space. Experimental results on simulation and with an anthropomorphic robot show how this approach allows for learning the reward function with a small amount of data.
# Advanced Skills by Learning Locomotion and Local Navigation End-To-End
## Keywords:
- Reinforcement Learning
- Legged Robots
- Machine Learning for Robot Control
## Abstract:
The common approach for local navigation on challenging environments with legged robots requires path planning, path following and locomotion, which usually requires a locomotion control policy that accurately tracks a commanded velocity. However, by breaking down the navigation problem into these sub-tasks, we limit the robot's capabilities since the individual tasks do not consider the full solution space. In this work, we propose to solve the complete problem by training an end-to-end policy with deep reinforcement learning. Instead of continuously tracking a precomputed path, the robot needs to reach a target position within a provided time. The task's success is only evaluated at the end of an episode, meaning that the policy does not need to reach the target as fast as possible. It is free to select its path and the locomotion gait. Training a policy in this way opens up a larger set of possible solutions, which allows the robot to learn more complex behaviors. We compare our approach to velocity tracking and additionally show that the time dependence of the task reward is critical to successfully learn these new behaviors. Finally, we demonstrate the successful deployment of policies on a real quadrupedal robot. The robot is able to cross challenging terrains, which were not possible previously, while using a more energy-efficient gait and achieving a higher success rate. Supplementary videos can be found on the project website: https://sites.google.com/ leggedrobotics.com/end-to-end-loco-navigation
# NavDreams: Towards Camera-Only RL Navigation among Humans
## Keywords:
- Reinforcement Learning
- Human-Aware Motion Planning
- Deep Learning Methods
## Abstract:
Autonomously navigating a robot in everyday crowded spaces requires solving complex perception and planning challenges.
When using only monocular image sensor data as input, classical two-dimensional planning approaches cannot be used. While images present a significant challenge when it comes to perception and planning, they also allow capturing potentially important details, such as complex geometry, body movement, and other visual cues.
In order to successfully solve the navigation task from only images, algorithms must be able to model the scene and its dynamics using only this channel of information.
We investigate whether the world model concept, which has shown state-of-the-art results for modeling and learning policies in Atari games as well as promising results in 2D LiDAR-based crowd navigation, can also be applied to the camera-based navigation problem.
To this end, we create simulated environments where a robot must navigate past static and moving humans without colliding in order to reach its goal.
We find that state-of-the-art methods are able to achieve success in solving the navigation problem, and can generate dream-like predictions of future image-sequences which show consistent geometry and moving persons.
We are also able to show that policy performance in our high-fidelity sim2real simulation scenario transfers to the real world by testing the policy on a real robot.
We make our simulator, models and experiments available at https://github.com/danieldugas/NavDreams.
# Impact Makes a Sound and Sound Makes an Impact: Sound Guides Representations and Explorations
## Keywords:
- Reinforcement Learning
- Representation Learning
- Sensor Fusion
## Abstract:
Sound is one of the most informative and abundant modalities in the real world while being robust to sense without contacts by small and cheap sensors that can be placed on mobile devices. Although deep learning is capable of extracting information from multiple sensory inputs, there has been little use of sound for the control and learning of robotic actions. For unsupervised reinforcement learning, an agent is expected to actively collect experiences and jointly learn representations and policies in a self-supervised way. We build realistic robotic manipulation scenarios with physics-based sound simulation and propose the Intrinsic Sound Curiosity Module (ISCM). The ISCM provides feedback to a reinforcement learner to learn robust representations and to reward a more efficient exploration behavior. We perform experiments with sound enabled during pre-training and disabled during adaptation, and show that representations learned by ISCM outperform the ones by vision-only baselines and pre-trained policies can accelerate the learning process when applied to downstream tasks.
# Micro/Nano Robots
# Origami Robot Self-Folding by Magnetic Induction
## Keywords:
- Soft Robot Materials and Design
- Soft Sensors and Actuators
- Micro/Nano Robots
## Abstract:
Inspired by the traditional art of paper folding, origami, autonomous production of 3D structures from 2D sheets can be achieved by the implementation of self-folding techniques. One technique to achieve such transformation is the usage of thermo-responsive smart materials such as self-folding polymeric films, which can be controlled by heat to shrink. Achieving remote self-folding with a practical approach remains a major challenge due to the requirement for specific environments, or having to accompany electronics on origami, which limits the complexity of the origami design. In this paper, we present a wireless method to trigger the thermo-responsive self-folding process of the origami robots through magnetic induction. The proposed method is applicable for all electrically conductive materials and can wirelessly fold a mobile origami robot with a size of 32×30 mm². This method eliminates the need for inclusion of electronics on the origami or usage of complicated trigger methods and environmental conditions, allowing the robot to fold in a wider range of applications such as in constrained spaces.
# A Passive, Asymmetrically-Compliant Knee Joint Improves Obstacle Traversal in an Insect-Scale Legged Robot
## Keywords:
- Micro/Nano Robots
- Legged Robots
- Biologically-Inspired Robots
## Abstract:
Insects can locomote readily in challenging environments, such as over steep inclines and across obstacle-laden terrains, which still frustrate robots of similar size. In this work, inspired by the passive compliant properties of insect limbs, we use the insect-scale Harvard Ambulatory Microrobot and multilayer microfabrication techniques as platform to study the ability of passive mechanisms to improve open-loop running in rough terrains. We tested the performance of different limb designs in vivo, exploring how the magnitude, directionality, and distribution of compliance incorporated into the leg impacted robot performance. Limbs were evaluated on both a featureless substrate and an increasingly-adversarial 3D-printed terrain designed to mimic natural environments. We tested the limbs using a trotting gait in the quasi-static (2 Hz) and body dynamics (25 Hz) stride frequency regimes. Performance was reported as bodylengths traveled per gait cycle on the featureless substrate, and as the largest feature height the robot was able to overcome in the terrain. The work presented here provides design principles for a passive limb that expands the terrain accessible to small robot; we find a limb with a single asymmetrical joint is able to improve quasi-static terrain traversal by 203% relative to a rigid limb.
# Passive Compliant Foot Design for Improved Micororobotic Mobility on Rough Terrains
## Keywords:
- Micro/Nano Robots
- Legged Robots
- Biologically-Inspired Robots
## Abstract:
To deploy robots outside of laboratory environments, they must be able to locomote on natural, unstructured terrain. While perception and control strategies for terrain navigation and obstacle avoidance have been developed for human-scale robots, microrobots are often too small to carry the sensors, computing power, and energy required to implement such techniques. Instead, this work presents passive foot designs for improving open-loop, quasi-static locomotion of a 1.6 g, 45 mm quadruped robot over rough terrains. The feet were evaluated by tracking the distance travelled on an uneven terrain of progressively increasing feature heights. Our insect tarsi inspired rigid foot designs improved performance somewhat, and by adding passive compliance via a viscoelastic hinge on the heel and toe, we increased the distance travelled by 168% over the original design. By exploring the design space of foot geometries and compliance, this work lays the foundation for understanding how passive foot design facilitates locomotion over uneven terrains.
# Torque-Actuated Multimodal Locomotion of Ferrofluid Robot with Environment and Task Adaptability
## Keywords:
- Micro/Nano Robots
- Automation at Micro-Nano Scales
- Soft Robot Materials and Design
## Abstract:
Soft microrobotics have recently been an active field that advances the microrobotics with new robot design, locomotion and applications. In this paper, we study the ferrofluid robot (FR), which has soft nature and exhibits paramagnetism. Currently, the FR locomotion is usually realized by magnetic force. To enable the FR with more locomotion modes for environment and task adaptability, we program three dynamic field forms and realize three corresponding torque-actuated locomotion modes: Rolling, Wobbling, and Oscillating. The torque actuation of the FR is formulated and the three locomotion modes are characterized. With implementation of automated tracking and control algorithms, the controllability of these modes is testified. We then fabricate different environments to validate the adaptability of the FR that can switch its locomotion mode accordingly. Finally, utilizing the oscillating mode and wobbling mode, we demonstrate the transport of lipophilic and hydrophilic cargoes, respectively, showing the task adaptability.
# Versatile Motion Generation of Magnetic Origami Spring Robots in the Uniform Magnetic Field
## Keywords:
- Biologically-Inspired Robots
- Soft Robot Materials and Design
- Motion Control
## Abstract:
Magnetic soft robots have attracted widespread attention for their untethered, remotely operated, and compliant deformation characteristics. Earlier work has demonstrated magnetic origami robots’ diverse locomotion capabilities. This paper will focus on the motion generation and open-loop control of an untethered magnetic flexible robot with a stretchtwist coupling origami spring (OS) skeleton only using uniform magnetic field control. We investigate the associated motion generation mechanism and the corresponding control signals for the magnetic spring robot (MSR). The MSR can perform in-plane crawling (Worm Crawling) and perpendicular in-plane crawling (Crab Crawling) under two-dimensional magnetic signal inputs. Moreover, the OS’s stretch-twist coupling characteristic is utilized to achieve axial Rolling Motion with axial magnetization configuration. We further experimentally tested the performance of three motions with average normalized velocities of 0.34±0.039(body length/s), 0.054±0.0066(body length/s), and 1.46±0.069(body length/s), respectively.
# OCTOANTS: A Heterogeneous Lightweight Intelligent Multi-Robot Collaboration System with Resource-Constrained IoT Devices
## Keywords:
- Micro/Nano Robots
- Multi-Robot Systems
- SLAM
## Abstract:
As the focus on highly intelligent robots continues, a problem that cannot be ignored has emerged: resource constraints. Considering the game problem of resource limitation and the level of intelligence, we focus on lightweight intelligence. This work is a further refinement of our previous work, a heterogeneous lightweight intelligent multi-Robot system. Inspired by the nature creatures "octopus" and "ants". First, we propose a heterogeneous centralized-distributed architecture, which can make robots collaboration more flexible and non-redundant. Second, to reflect lightweight intelligence, we use the Raspberry Pi, a low computing and power consumption internet of things (IoT) device, as a processing platform and first propose a quantitative definition of the lightweight intelligent system. Then, combining the centralized-distributed architecture and the lightweight computing platform, we propose an adapted algorithm called OCTOANTS and apply it to the simultaneous localization and mapping (SLAM) field. The OCTOANTS architecture consists of one brain and eight tentacles, which can achieve complex things with proper collaboration between them. Finally, we use heterogeneous cameras and heterogeneous algorithms to form a lightweight intelligent collaborative system that can run in the real world. On the low-grade platform Raspberry Pi our heterogeneous tentacles frame rate can reach 41fps and 99.8fps respectively, power consumption is only 2W and 1.2W. Meanwhile, our heterogeneous system is on average 7.2% more accurate than the state-of-the-art homogeneous system, proving the superiority and feasibility of our OCTOANTS.
# Insect-Scale SMAW-Based Soft Robot with Crawling, Jumping, and Loading Locomotion
## Keywords:
- Micro/Nano Robots
- Soft Robot Materials and Design
- Flexible Robotics
## Abstract:
The work develops an insect-scale soft robot capable of fast directional locomotion actuated by itself spring-like body composed of shape memory alloy wires (SMAWs)-based composite. The soft composite is fabricated integrating polydimethylsiloxane (PDMS) matrix, 3D printed acrylonitrile-butadienestyrene(ABS) substrate, and parallel multi-SMAWs with the diameter of 0.075mm. Since it can implant the thermal-induced SMAW deformation and rapidly cause the elastic recovery feature of ABS resin material, the soft composite can act as the insect-scale robotic actuator to imitate the longitudinal muscle. The designed structure can convert the repetitive contraction-stretch behavior of the embedded SMAWs to the bending-expanding deformation of the robotic soft body,which forms the robotic different gaits. With the excitation of pulse-width modulation (PWM) voltages with various frequencies,different characteristics of the designed robot are compared. The experimental results validate that the designed soft robot can reach a movement speed of ~29.87 mm/s with jumping locomotion, greater than one-time body-length/s, and afford a load of ~11.1g, about 24.1 times the weight of itself.
# Characterization of the Variable Stiffness Actuator Fabricated of SMA/SMP and MWCNT/IL: PDMS Strain-Sensitive Heater Electrode
## Keywords:
- Micro/Nano Robots
- Soft Robot Materials and Design
- Soft Sensors and Actuators
## Abstract:
A microactuator that exhibited the variable stiffness function and the strain control were demonstrated by using the shape memory alloy (SMA), shape memory polymer (SMP), and the stretchable heater polymer of multi-walled carbon nanotube MWCNT / ionic liquid (IL) : polydimethylsiloxane (PDMS). The SMA filaments exerted the principal driving force of the microactuator for the posture control with high power and speed. The SMP films shaped were utilized to modulate the elasticity of the actuator. We fist fabricated a stretchable heater electrode, which accomodate 100% of the strain and low resistivity of 3.75 mΩ·cm for the temperature control. The effect of thermal transfer from the heater to the SMP film elucidated that the SMP was immediately heated. The elasticity change of the SMP film was successfully realized by electrical heating, and the response were characterized. The self-sensing actuation of the SMP film was demonstrated and strain measurement was achieved while modulating the elasticity. Finally, we demonstrated the weight lifting of a microarm, typical example of the variable stiffness actuation.
# Adaptive Autonomous Navigation of Multiple Optoelectronic Microrobots in Dynamic Environments
## Keywords:
- Micro/Nano Robots
- Multi-Robot Systems
- Visual Servoing
## Abstract:
The optoelectronic microrobot is an advanced light-controlled micromanipulation technology which has particular promise for collecting and transporting sensitive microscopic objects such as biological cells. However, wider application of the technology is currently limited by a reliance on manual control and a lack of methods for simultaneous manipulation of multiple microrobotic actuators. In this article, we present a computational framework for autonomous navigation of multiple optoelectronic microrobots in dynamic environments. Combining closed-loop visual-servoing, SLAM, real-time visual detection of microrobots and obstacles, dynamic path-finding and adaptive motion behaviors, this approach allows microrobots to avoid static and moving obstacles, and perform a range of tasks in real-world dynamic environments. The capabilities of the system are demonstrated through micromanipulation experiments in simulation and in real conditions using a custom built optoelectronic tweezer system.
# Motion Control
# Beyond the Limit Automated Driving with Performance Constrained Reachability Analysis
## Keywords:
- Motion Control
- Collision Avoidance
- Motion and Path Planning
## Abstract:
Professional human drivers usually have more than one driving strategy to handle incoming traffic situations. These different strategies activate different performance characteristics of the vehicle, enabling the driver to minimize the risk in a variety of situations by optimizing the strategy selection. In the same spirit, we define a novel concept of strategy-wise performance metric and creatively combine this performance metric with reachability analysis to evaluate candidate control strategies. Such a performance evaluation produces solid guarantees on which strategies will not qualify for the given traffic scenario. Then we automate the strategy selection process by weighing and minimizing the overall risk of each strategy candidate.
# Simultaneous Motion Tracking and Joint Stiffness Control of Bidirectional Antagonistic Variable-Stiffness Actuators
## Keywords:
- Motion Control
- Compliance and Impedance Control
## Abstract:
Since safe human-robot interaction is naturally linked to compliance in these robots, this requirement presents a challenge for the positioning accuracy. The class of variable-stiffness robots features intrinsically soft contact behavior where the physical stiffness can even be altered during operation. Here we present a control scheme for bidirectional, antagonistic variable-stiffness actuators that achieve high-precision link-side trajectory tracking while simultaneously ensuring compliance during physical contact. Furthermore, the approach enables to regulate the pretension in the antagonism. The theoretical claims are confirmed by formal analyses of passivity during physical interaction and the proof of uniform asymptotic stability of the desired link-side trajectories. Experiments on the forearm joint of the DLR robot David verify the proposed approach.
# Planar Magnetic Actuation for Soft and Rigid Robots Using a Scalable Electromagnet Array
## Keywords:
- Motion Control
- Modeling, Control, and Learning for Soft Robots
- Software-Hardware Integration for Robot Systems
## Abstract:
Magnetic actuation system manipulates micro soft or rigid robots by a controllable magnetic field to move them freely in the narrow or enclosed space, which has demonstrated its huge potential in medical interventional surgery and drug delivery. However, the limited working space of paired or area-centered electromagnets restricts its practical applications. In this paper, we propose a convenient coils drive scheme for the scalable electromagnet array, and present an efficient planar magnetic actuation system with a spacious workspace. During the actuation process, our system activates selectively the effective electromagnets neighboring to the magnetic robot by coil selectors, and generates an alternating magnetic field with sufficient gradients to guide the robot's orientation and position. For the soft magnetic pipe, our system can push it to perform the continuous deflections around the stand columns on the plane. For the rigid magnetic cube, the designed magnetic-quadrupole structure allows it to receive various forces from different directions, and achieve a stable displacement in the heterogeneous magnetic field.
# Kinematic Control of Redundant Robots with Online Handling of Variable Generalized Hard Constraints
## Keywords:
- Motion Control
- Redundant Robots
- Kinematics
## Abstract:
We present a generalized version of the Saturation in the Null Space (SNS) algorithm for task control of redundant robots when hard inequality constraints are simultaneously present both in the joint and in the Cartesian space. These hard bounds should never be violated, are treated equally and in a unified way by the algorithm, and may also be varied, inserted or deleted online. When a joint/Cartesian bound saturates, the robot redundancy is exploited to continue fulfilling the primary task. If no feasible solution exists, an optimal scaling procedure is applied to enforce directional consistency with the original task. Simulation and experimental results on different robotic systems demonstrate the efficiency of the approach.
# Set-Point Control for a Ground-Based Reconfigurable Robot
## Keywords:
- Motion Control
- Wheeled Robots
- Collision Avoidance
## Abstract:
Reconfigurable mobile robots are well suited for inspection tasks in legacy nuclear facilities where access is restricted and the environment is often cluttered. A reconfigurable snake robot, MIRRAX, has previously been developed to investigate such facilities. The joints used for the robot's reconfiguration introduce additional constraints on the robot's control, such as balance, on top of the existing actuator and collision constraints. This paper presents a set-point controller for MIRRAX using vector-field inequalities to enforce hard constraints on the robot's balance, actuator limits, and collision avoidance in a single quadratic programming formulation. The controller has been evaluated in simulation and early experiments in some scenarios. The results show that the controller generates feasible control inputs that enable the robot to retain its balance while moving with less oscillation and operating within the actuation and collision constraints.
# Enhanced Quadruped Locomotion of a Rat Robot Based on the Lateral Flexion of a Soft Actuated Spine
## Keywords:
- Motion Control
- Legged Robots
- Biologically-Inspired Robots
## Abstract:
In nature, the movement of quadrupeds is completed under the combined action of the spine and the legs. Inspired by this, this paper explores the effect of a lateral flexing spine on the locomotion of a rat robot. Benefiting from the regular lateral flexion of a soft actuated spine, the rat robot exhibits enhance step length of its hind legs and increased translational velocity by coordinating the opposite movements of the left and right sides. Furthermore, this paper introduces a mathematical model of the effect of the flexible spine on the robot velocity. Finally, extensive experiments are conducted in simulations and on the physical rat robot. Compared with the locomotion without a flexing spine, the simulation results show that the velocity of the robot can be increased up to 218.29%, which is in line with the theoretical results from the proposed mathematical model. Limited by the gap between simulation and the real world, the experiment results of the physical rat robot show a slight performance than the theoretical results. But the physical rat robot can still enhance its translational velocity with the help of a lateral flexing spine.
# Shape and Motion Optimization of Rigid Planar Effectors for Contact Trajectory Satisfaction
## Keywords:
- Methods and Tools for Robot System Design
- Grippers and Other End-Effectors
- Engineering for Robotic Systems
## Abstract:
We propose a framework for co-optimizing the shape and motion of rigid robotic effectors for planar tasks. While planning object and robot-object contact trajectories is extensively studied, designing an effector that can execute the planned trajectories receives less attention. As such, our framework synthesizes an object trajectory and object-effector contact trajectory into an effector trajectory and shape that (a) does not penetrate the object, (b) makes contact with the object as specified, and (c) optimizes a user-specified objective. This simplifies manipulator control by encoding task-specific contact information in the effector’s geometry. Our key insight is posing these requirements as constraints in the effector’s reference frame, preventing the need for explicit parameterization of the effector shape. This prevents artificial restrictions on the shape design space. Importantly, it also facilitates posing the shape and motion design problem as a tractable nonlinear program. Our method is particularly useful for problems where the shape of the effector surface must be precisely chosen to achieve a task. We apply our method to several such problems, including jar-opening and picking up objects in constrained spaces. We evaluate the performance and computational cost of our method, and provide a physical experiment of a robotic arm picking up a screwdriver from a table with a designed tool.
# Co-Optimization of Acrobot Design and Controller for Increased Certifiable Stability
## Keywords:
- Methods and Tools for Robot System Design
- Underactuated Robots
- Optimization and Optimal Control
## Abstract:
Unlike fully actuated systems, the control of un# deractuated robots necessitates the use of passive dynamics to fulfill control objectives. Hence, there is an increased interdependence between their design parameters and the closed loop performance. This paper proposes a novel approach for co-optimization of robot design and controller parameters for increased certifiable stability obtained with means of region of attraction analysis and gradient free optimization. In particular, it discusses the co-optimization problem of a gymnastic acrobot robot where the design and the controller are optimized to have a large region of attraction (ROA) taking into account the closed loop dynamics of the non-linear system stabilized by a linear quadratic regulator (LQR) controller. The results are validated by extensive simulation of the acrobot’s closed loop dynamics.
# RoSA: A Mechatronically Synthesized Dataset for Rotodynamic System Anomaly Detection
## Keywords:
- Sustainable Production and Service Automation
- Failure Detection and Recovery
- Big Data in Robotics and Automation
## Abstract:
The time-series datasets commonly applied for anomaly detection research showcase specific unideal properties. This work novelly conceptualizes condition state synthesis to improve the data-synthetic pipeline of an anomalous-event dataset. We demonstrate two technical contributions in this study. First, we propose a methodology to formulate, accelerate and enrich the condition state synthetic process. The proposed method includes three critical phases: analysis of a rotodynamic plant, systematic design of its condition state space, and development of a Markovian model for controlled state transitions. Second, a Rotodynamic System with Synthetic Anomaly dataset is constructed. It is a large-scale time-series dataset featuring controlled, abundant and diverse anomalous condition states, and per-time-step condition state labels. A comprehensive learning-based case study is conducted to illustrate that these unique features tangibly benefit anomaly detection research. Potential usages of the proposed dataset as an anomaly detection study benchmark are discussed.
# Biologically-Inspired Robots 2
# Toward Dexterous Flapping Flight: Effective Large Yaw Torque Generation by 2 × 2-Degrees-Of-Freedom Flapping Wings
## Keywords:
- Biologically-Inspired Robots
- Biomimetics
## Abstract:
Through the efforts of robotic engineers and inspired by the flapping flight of smaller creatures (e.g., insects and hummingbirds), the untethered stable hovering of flapping micro-aerial vehicles (FMAVs) has been achieved. Now, engineers are evaluating how to improve the mobility of these vehicles. The maneuverability of insects and birds in flight, such as their sharp turns and their takeoffs and landings from vertical walls, is what researchers originally expected from FMAVs. However, in previous studies, just one active (or one active plus one passive) degree of freedom (DoF) was given to the main actuation of the wing, and the range of movement of the wings was small. In addition, the magnitude of the attitude control torque that could be generated was relatively small when compared with multi-rotors. However, with the recent developments of small motors and drive-circuit technology, the realization of untethered flight by FMAVs equipped with four or more motors seems possible. This study utilized numerical calculation to investigate the advantage of a flapping-flight robot equipped with two pairs of left and right wings capable of stroke and twisting movements with two independent DoFs (2 × 2-DoF FMAV). The results of the numerical studies confirmed that, compared with the split-factor method widely used in past studies, the 2 × 2-DoF FMAV can generate higher yaw torque without the need for additional large driving torque. This shows that various agile flight functions are possible.
# End-To-End Design of Bespoke, Dexterous Snake-Like Surgical Robots: A Case Study with the RAVEN II (I)
## Keywords:
- Biologically-Inspired Robots
- Surgical Robotics: Steerable Catheters/Needles
- Surgical Robotics: Planning
## Abstract:
Keyhole surgery requires highly dexterous snake-like robotic arms capable of bending around anatomical obstacles to access clinical targets that diverge from the direct port-of-access. Design optimization for these robots under patient-specific anatomical constraints is still lacking, particularly concerning the critical metric of dexterity. In this article, we propose an end-to-end design and production workflow for patient-specific surgical manipulators, assessing dexterity using orientability constrained by task space obstacles. In our work, parametric evolutionary optimization maximizes dexterity in patient-specific task spaces for challenging knee arthroscopy operations. We implement our framework in the design of SnakeRaven—a 3-D printed tool to be attached to the RAVEN II surgical robot in a phantom study for knee arthroscopy. The solution achieved more than three times the dexterity of a state-of-the-art rigid instrument and more than twice the dexterity of a volume-based approach for the same task. We further assemble and validate this design by teleoperating the robot to reach the desired clinical targets in a phantom. We also investigate the changes in the design morphology to changes in the task objectives and found an advantage in task specialization. We also observe guidelines for achieving a dexterous design produced by our algorithms.
# Comparative Model Evaluation with a Symmetric Three-Link Swimming Robot
## Keywords:
- Biologically-Inspired Robots
## Abstract:
In this paper we present swimming and modeling for Trident, a three-link lamprey-inspired robot that is able to climb on flat smooth walls. We explore two gaits proposed to work for linear swimming, and three gaits for turning maneuvers. We compare the experimental results obtained from these swimming experiments with two different reduced order fluid interaction models, one a previously published potential flow model, and the other a slender cylinder model we developed. We find that depending on the the parameters of swimming chosen, we are able to move forward, backward and sideways with a peak speed of 2.5 cm/s. We identify the conditions when these models apply and aspects that will require additional complexity.
# Development of a Stingray-Inspired High-Frequency Propulsion Platform with Variable Wavelength
## Keywords:
- Biologically-Inspired Robots
- Biomimetics
- Marine Robotics
## Abstract:
Undulatory fin motions in fish-like robots are typically created using intricate arrays of servo motors. Motor arrays offer impressive versatility in terms of kinematics, but their complexity leads to constraints on size, hydrodynamic force production, and power consumption, particularly when studying propulsive performance at high-frequencies. Here we present an alternative design that uses a single motor and a tunable rotary cam-train system to achieve a spectrum of fin motions running from oscillation (wavenumber < 1) to undulation (wavenumber > 1). Our platform enables thrust, lift, power, and wake measurements at prescribed pitch amplitudes, frequencies, and wavenumbers. We demonstrated the platform’s oscillating and undulating capabilities via force and wake measurements in a water tank. Studies of fin wavenumber offer design insights for fish-like underwater robots, particularly those with stingray-inspired designs.
# Amoeba-Inspired Swimming through Isoperimetric Modulation of Body Shape
## Keywords:
- Biologically-Inspired Robots
- Compliant Joints and Mechanisms
- Soft Robot Materials and Design
## Abstract:
In this work we present the design of a swimming robot that is inspired by the body shape modulation of small microorganisms. Amoebas are small single celled organisms that locomote through deformation and shape change of their body. To achieve similar shape modulation for swimming propulsion in a robot we developed a novel flexible appendage using tape springs. A tape spring is an elongated strip of metal with a curved cross-section that can act as a stiff structure when loaded against the curvature, while it can easily buckle when loaded with the curvature. We develop a tape spring appendage that is capable of freely deforming its perimeter through two actuation inputs. In the first portion of this paper we develop the kinematics of the appendage mechanisms and compare with experiment. Next we present the design of a surface locomoting robot that uses two appendages for propulsion. From the appendage kinematics we derive the local connection vector field for locomotion kinematics and study the optimal gait for forward swimming. Lastly, we demonstrate robot swimming performance in open water conditions. The novel appendage design in this robot is advantageous because it enables omnidirectional movement, the appendages will not tangle in debris, and they are robust to collisions and contact with structures.
# Compliant Thorax Design for Robustness and Elastic Energy Exchange in Flapping-Wing Robots
## Keywords:
- Biologically-Inspired Robots
- Robot Safety
- Aerial Systems: Applications
## Abstract:
Flapping wing insects benefit from a compliant thorax that provides elastic energy exchange and resiliency to wing collisions. In this paper, we present a flapping wing robot that uses an underactuated compliant transmission inspired by the insect thorax. We developed a novel fabrication method that combines carbon fiber (CF) laminate and soft robotics fabrication techniques for transmission construction. The transmission design is optimized to achieve desired wingstroke requirements and to allow for independent motion of each wing. We validate these design choices in bench-top tests measuring transmission compliance and kinematics. We integrate the transmission with laminate wings and two types of actuation, demonstrating elastic energy exchange and limited lift-off capabilities Lastly, we tested collision mitigation through flapping wing experiments that obstructed the motion of a wing. These experiments demonstrate that an underactuated compliant, transmission can provide resilience and robustness to flapping wing robots.
# Event-Triggered Control of Robotic Fish with Reduced Communication Rate
## Keywords:
- Biologically-Inspired Robots
- Marine Robotics
- Motion Control
## Abstract:
Underwater robots often need to communicate with external localization sensors. The low bandwidth in such communications is one of the bottlenecks in achieving accurate tracking control. Toward this end, we adopt a novel periodic event-triggered control (PETC) which allows a robotic fish to reduce its communication load in tracking a desired heading angle with position feedback from an external sensor. To design the PETC, a linear state-space model is derived from a nonlinear dynamic model of the robotic fish with a small perturbation assumption. The PETC consists of an observer, state-feedback controller, integrator, event-trigger rule, and predictor. The observer and state-feedback controller are designed to drive the tracking error to zero. The integrator reduces the steady-state error. The event-trigger rule determines when communication is needed while ensuring the efficacy of the state-feedback controller, and the predictor predicts the state vector for the state-feedback controller when communication is not available. For comparison, an observer-based state feedback control (OSFC) and a proportional-integral-derivative (PID) control are implemented in real-time experiments. Simulations and experimental results show that the PETC can dramatically reduce the number of communication instances without significantly degrading tracking performance, thereby saving communication energy and reducing the need for high bandwidth underwater communication.
# Design and Testing of a Bioinspired Lightweight Perching Mechanism for Flapping-Wing MAVs Using Soft Grippers
## Keywords:
- Biologically-Inspired Robots
- Mechanism Design
- Aerial Systems: Applications
## Abstract:
Flapping-wing MAVs are starting to emulate the advanced flight maneuverability of insects and birds, however they struggle to achieve a similar aptitude for taking off and landing in challenging cluttered environments. The ability to perch on objects such as tree branches or metal struts would result in a wide range of potential landing sites, both indoors and outdoors, and would increase the achievable mission duration, thus allowing a more versatile usage of MAVs. While perching is particularly challenging with flapping-wing MAVs, these vehicles are highly promising for complex missions in confined spaces. In this paper a systematic bioinspiration approach was adopted to design a new lightweight perching solution suitable for bird-size flapping-wing MAVs. The proposed concept combines a four-bar linkage mechanism with an active-passive actuation method to achieve a large gripping power at low energy consumption. Additionally it relies on compliant soft grippers inspired by the Fin Rayr effect, which lead to a high adaptability to different perching surface textures and shapes. A prototype of the proposed concept was manufactured and tested experimentally in gripping tests and rail-guided perching tests. With a total mass of 45 g the concept is suited for bird-size MAVs in the weight range of 150-300 g. Flight tests on a surrogate (multirotor) platform demonstrate the approach functions successfully in realistic free-flight conditions.
# Factory Automation and Logistics
# Image Translation Based Synthetic Data Generation for Industrial Object Detection and Pose Estimation
## Keywords:
- Computer Vision for Manufacturing
- AI-Based Methods
- Deep Learning for Visual Perception
## Abstract:
Deep learning-based methods have shown excellent potential on object detection and pose estimation with vast amounts of training data to achieve good performance. Obtaining enough comprehensive manual labeling training data is a time-consuming and error-prone task in industrial scenes, and most current time-saving synthetic data generation methods require detailed high-quality CAD models. Instead, we introduce an image-to-image translation based synthetic data generation approach, which requires only untextured CAD models and a small number of real images. The proposed approach starts with edge maps extracted by mesh model projection. And each edge map is provided with realistic appearance learned from real images through image-to-image translation to achieve patch-level realism, and then superimposed on randomly selected backgrounds with a simple Cut-and-Paste strategy. Experiments on our custom dataset and T-LESS dataset show that our synthetic data is competitive with uncomprehensive real data and gives a considerable improvement when compared to the same degree of model rendering images. In addition, the proposed approach allows for extensibility to accommodate new parts with similar texture and structure. And it shows the potential to train image translation model on only one single object and synthesize data for multiples in one take.
# Reconstructed Student-Teacher and Discriminative Networks for Anomaly Detection
## Keywords:
- Computer Vision for Manufacturing
- Computer Vision for Automation
## Abstract:
Anomaly detection is an important problem in computer vision; however, the scarcity of anomalous samples makes this task difficult. Thus, recent anomaly detection methods have used only normal images for training. In this work, a powerful anomaly detection method is proposed based on student-teacher feature pyramid matching (STPM), which consists of a student and teacher network. Generative models are another approach to anomaly detection. They reconstruct normal images from an input and compute the difference between the predicted normal and the input. Unfortunately, STPM does not have the ability to generate normal images. To improve the accuracy of STPM, this work uses a student network, as in generative models, to reconstruct normal features. This improves the accuracy; however, the anomaly maps for normal images are not clean because STPM does not use anomaly images for training, which decreases the accuracy of the image-level anomaly detection. To further improve accuracy, a discriminative network trained with pseudo-anomalies from anomaly maps is used in our method, which consists of two pairs of student-teacher networks and a discriminative network. The method displayed high accuracy on the MVTec anomaly detection dataset.
# Systematic Evaluation and Analysis on Hybrid Strategies of Automatic Agent Last Mile Delivery
## Keywords:
- Logistics
- Agent-Based Systems
- Performance Evaluation and Benchmarking
## Abstract:
This paper focuses on problems associated with the deployment of automatic agents for last-mile delivery. We propose a framework and methodology to systematically evaluate and compare different hybrid strategies. Performance metrics in agent noise, delivery time, energy consumption, coverage rate, package throughput, and system costs are defined rigorously and modeled mathematically. Using the methodology, we conduct a case study in the city of Boston for four agent delivery strategies, including a hybrid strategy proposed in this paper. The proposed strategy utilizes available space in public transits' cabins during off-peak hours to relocate the agent traveling start locations. Simulations and analyses show that hybrid strategies outperform the Agent-Only delivery strategy in terms of noise exposure, energy consumption, and coverage rate. The performance of hybrid strategies highly depends on the characteristics of the ground transportation methods accompanying agents. Thus, the methods of ground transportation should carefully be examined and selected for each case and strategy in real-world applications.
# Multi-Object Grasping -# Efficient Robotic Picking and Transferring Policy for Batch Picking
## Keywords:
- Logistics
- Grasping
- Service Robotics
## Abstract:
In a typical fulfillment center, the order fulfilling process is managed by a warehouse management system (WMS). For efficiency, WMS usually applies batch picking, also called multi-order picking, to collect the same items for multiple orders. Suppose an item appears in multiple orders, instead of repeatedly revisiting the exact picking location multiple times, a picker will be instructed to pick up multiple same items at once and bring them to a sorting station, also called a re-bin station. It is at the re-bin station, where the workers sort the picked items into separate orders. We have seen many robotic technologies being developed for sorting. However, we have not seen any feasible robotic technology for batch picking. Transferring multiple objects between bins is a common task. In robotics, a standard approach is to transfer a single object at a time. However, grasping multiple objects and transferring them at once is more efficient. This paper presents a set of novel strategies for efficiently grasping and transferring multiple objects. The grasping strategies enable a robotic hand to grasp multiple objects by identifying an optimal ready hand configuration (pre-grasp), calculating a flexion synergy based on the desired quantity of objects to be grasped, and utilizing a deep learning model to signal the completion of a grasp. The transferring strategies demonstrate an approach that models the problem as a Markov decision process (MDP) and defines specific grasping actions to efficiently transfer objects when the required quantity is larger than the capability of a single grasp. Using the MDP model, the approach can generate an optimal pick-transfer policy that minimizes the number of transfers. The complete proposed approach has been evaluated in both a simulation environment and on a real robotic system. The proposed approach reduces the number of transfers by 59% and the number of lifts by 58% compared to an optimal single object pick-transfer solution.
# AssembleRL: Learning to Assemble Furniture from Their Point Clouds
## Keywords:
- Computer Vision for Manufacturing
- Assembly
- Reinforcement Learning
## Abstract:
The rise of simulation environments has enabled learning-based approaches for assembly planning, which is otherwise a labor-intensive and daunting task. Assembling furniture is especially interesting since furniture are intricate and pose challenges for learning-based approaches. Surprisingly, humans can solve furniture assembly mostly given a 2D snapshot of the assembled product. Although recent years have witnessed promising learning-based approaches for furniture assembly, they assume the availability of correct connection labels for each assembly step, which are expensive to obtain in practice. In this paper, we alleviate this assumption and aim to solve furniture assembly with as little human expertise and supervision as possible. To be specific, we assume the availability of the assembled point cloud, and comparing the point cloud of the current assembly and the point cloud of the target product, obtain a novel reward signal based on two measures: Incorrectness and incompleteness. We show that our novel reward signal can train a deep network to successfully assemble different types of furniture. Code and networks available here: https://github.com/METU-KALFA/AssembleR
# FASTDLO: Fast Deformable Linear Objects Instance Segmentation
## Keywords:
- Computer Vision for Manufacturing
- Deep Learning for Visual Perception
- Recognition
## Abstract:
In this paper, an approach for fast and accurate segmentation of Deformable Linear Objects (DLOs) named FASTDLO is presented. A deep convolutional neural network is employed for background segmentation, generating a binary mask that isolates DLOs in the image. Thereafter, the obtained mask is processed with a skeletonization algorithm and the intersections between different DLOs are solved with a similarity-based network. Apart from the usual pixel-wise color-mapped image, FASTDLO also describes each DLO instance with a sequence of 2D coordinates, enabling the possibility of modeling the DLO instances with splines curves, for example. Synthetically generated data are exploited for the training of the data-driven methods, avoiding expensive collection and annotations of real data. FASTDLO is experimentally compared against both a DLO-specific approach and general-purpose deep learning instance segmentation models, achieving better overall performances and a processing rate higher than 20 FPS.
# MS-Cubic: A Modularized Manufacturing System with Scalability, Portability and Parallelism
## Keywords:
- Industrial Robots
- Cellular and Modular Robots
- Product Design, Development and Prototyping
## Abstract:
The existing manufacturing systems based on processes involving the transportation of workpiece are unsuitable for large products such as air mobility systems. This study proposes a novel ultra-complex manufacturing system called the ``Modularized-Structure and Multiple-Points Simultaneous Machining System (MS-cubic)'' based on the concept of intelligent space, which simultaneously performs multiple types of machining processes without moving a workpiece. The system can simultaneously process multiple points and flexibly change its workspace by modularizing its structure. This paper presents a discussion on the requirements and constraints to generate a feasible design of the rail module and the machining unit, which are two main elements of MS-cubic. The performance of the prototype MS-cubic is evaluated, and its stiffness is observed to be sufficient to perform drilling. Furthermore, the modularized design of system enables the fluid and electric power supply for the machining process.
# Optimal Partitioning of Non-Convex Environments for Minimum Turn Coverage Planning
## Keywords:
- Motion and Path Planning
- Optimization and Optimal Control
- Service Robotics
# SLAM 2
# DH-LC: Hierarchical Matching and Hybrid Bundle Adjustment towards Accurate and Robust Loop Closure
## Keywords:
- SLAM
- Visual-Inertial SLAM
- Localization
## Abstract:
A loop closure module plays an important role in visual SLAM systems, which can reduce the accumulated drift. This task faces the challenges of large viewpoint changes and expensive computational costs when optimizing the global map. This paper proposes DH-LC, a novel accurate and robust loop closure method that consists of hierarchical spatial feature matching (HSFM) and hybrid bundle adjustment (HBA). HSFM estimates a reliable relative pose between the query image and the retrieval image in a coarse-to-fine way. Specifically, 3D points are firstly triangulated and then clustered according to the spatial distribution. The cluster centers estimate coarse cube-level matching pairs in a larger perception field which can tolerate large viewpoint changes. HBA optimizes the global map efficiently by adaptively selecting incremental bundle adjustment or full bundle adjustment according to the accumulated drift and relative pose verification in the temporal window. Experimental results demonstrate that our proposed method easily detects loops in large viewpoint changes and efficiently optimizes the global map. When compared with the state-of-the-art methods, our method increases loop closure recall and improves SLAM localization accuracy with reducing the accumulated drift.
# One RING to Rule Them All: Radon Sinogram for Place Recognition, Orientation and Translation Estimation
## Keywords:
- SLAM
- Localization
## Abstract:
LiDAR-based global localization is a fundamental problem for mobile robots. It consists of two stages, place recognition and pose estimation, which yields the current orientation and translation, using only the current scan as query and a database of map scans. Inspired by the definition of a recognized place, we consider that a good global localization solution should keep the pose estimation accuracy with a lower place density. Following this idea, we propose a novel framework towards sparse place-based global localization, which utilizes a unified and learning-free representation, Radon sinogram (RING), for all sub-tasks. Based on the theoretical derivation, a translation invariant descriptor and an orientation invariant metric are proposed for place recognition, achieving certifiable robustness against arbitrary orientation and large translation between query and map scan. In addition, we also utilize the property of RING to propose a global convergent solver for both orientation and translation estimation, arriving at global localization. Evaluation of the proposed RING based framework validates the feasibility and demonstrates a superior performance even under a lower place density.
# Keyframe Selection with Information Occupancy Grid Model for Long-Term Data Association
## Keywords:
- SLAM
- Vision-Based Navigation
- Visual Learning
## Abstract:
As the basics of Visual Simultaneous Localization And Mapping (VSLAM), keyframes play an essential role. In previous works, keyframes are selected according to a series of view change-based strategies for short-term data association (STDA). However, the texture enrichment of frames is always ignored, resulting in the failure of long-term data association (LTDA). In this paper, we propose an information enrichment selection strategy with an information occupancy grid model and a deep descriptor. Frame is expressed by a deep global descriptor for a statistical explainable abstraction, in which the texture enrichment is indicated. Based on the abstraction, an information occupancy grid model is established to measure the information enrichment and the potential LTDA ability. Evaluations on variant datasets are conducted, showing the advantage of our proposed method in terms of keyframe selection and tracking precision. Also, the statistical explainability of the deep descriptor is provided. The proposed keyframe selection strategy can improve LTDA and tracking precision, especially in situations with repeated observations and loop-closures.
# PLC-LiSLAM: LiDAR SLAM with Planes, Lines and Cylinders
## Keywords:
- SLAM
- Mapping
- Range Sensing
## Abstract:
Planes, lines, and cylinders widely exist in man-made environments. This paper introduces a LiDAR simultaneous localization and mapping (SLAM) system using those three types of landmarks. Our algorithm has three components including local mapping, global mapping, and localization. The local and global mapping jointly adjust planes, lines, and cylinders with LiDAR poses to minimize the point-to-model cost, which is referred to as plane-line-cylinder adjustment (PLCA). We prove that, with some preprocessing, PLCA is independent of the number of points captured from the three types of landmarks, which makes efficiently solving a large-scale PLCA problem feasible. The localization component conducts real-time pose estimation through registering local planes, lines, and cylinders to the global ones, which is referred to as plane-line-cylinder registration (PLCR). We present an efficient solution for PLCR. The detection and data association may introduce errors. We correct these errors through checking the cost in the back-end. It is difficult for the registration-based algorithm, such as LOAM and ICP, to correct these errors, as they do not maintain the data association. Experimental results show that out algorithm outperforms the state-of-the-art LiDAR SLAM algorithms and achieves real-time performance.
# Thermal Inertial SLAM for the Environments with Challenging Illumination
## Keywords:
- SLAM
- Visual-Inertial SLAM
- Localization
## Abstract:
In recent years, longwave infrared (LWIR) cameras have become potential in visual simultaneous localization and mapping (SLAM) research since the delivered thermal images can provide information beyond the visible spectrum and are robust to environment illumination. However, due to modality differences, SLAM methods designed for visible cameras cannot be directly applied to thermal data. In this paper, we propose a thermal-inertial SLAM method for all-day autonomous systems. To overcome the challenge of the thermal data association, the proposed method represents several improvements, including singular-value-decomposition-based (SVD-based) image processing and ThermalRAFT tracking methods. Based on the characteristics of the thermal images, the SVD-based image processing method can exploit the fixed noise pattern of thermal images and enhance the image quality to improve the performance of subsequent steps, including thermal feature extraction and loop detection. To achieve real-time and robust feature tracking, we develop ThermalRAFT, an efficient optical flow network with iterative optimization. Moreover, the system introduces a bag-of-words-based loop detection method to maintain global consistency in long-term operation. The experimental results demonstrate that the proposed method can provide competitive performance in indoor and outdoor environments and is robust under challenging illumination conditions.
# Are We Ready for Robust and Resilient SLAM? a Framework for Quantitative Characterization of SLAM Datasets
## Keywords:
- SLAM
- Performance Evaluation and Benchmarking
- Data Sets for Robotic Vision
## Abstract:
Reliability of SLAM systems is considered one of the critical requirements in modern autonomous systems. This directed the efforts to developing many state-of-the-art systems, creating challenging datasets, and introducing rigorous metrics to measure SLAM performance. However, the link between datasets and performance in the robustness/resilience context has rarely been explored. In order to fill this void, characterization of the operating conditions of SLAM systems is essential in order to provide an environment for quantitative measurement of robustness and resilience. In this paper, we argue that for proper evaluation of SLAM performance, the characterization of SLAM datasets serves as a critical first step. The study starts by reviewing previous efforts for quantitative characterization of SLAM datasets. Then, the problem of perturbation characterization is discussed and the linkage to SLAM robustness/resilience is established. After that, we propose a novel, generic and extendable framework for quantitative analysis and comparison of SLAM datasets. Additionally, a description of different characterization parameters is provided. Finally, we demonstrate the application of our framework by presenting the characterization results of three SLAM datasets: KITTI, EuroC-MAV, and TUM-VI highlighting the level of insights achieved by the proposed framework.
# Robust Change Detection Based on Neural Descriptor Fields
## Keywords:
- SLAM
- Visual Learning
## Abstract:
The ability to reason about changes in the environment is crucial for robots operating over extended periods of time. Agents are expected to capture changes during operation so that actions can be followed to ensure a smooth progression of the working session. However, varying viewing angles and accumulated localization errors make it easy for robots to falsely detect changes in the surrounding world due to low observation overlap and drifted object associations. In this paper, based on the recently proposed category-level Neural Descriptor Fields (NDFs), we develop an object-level online change detection approach that is robust to partially overlapping observations and noisy localization results. Utilizing the shape completion capability and SE(3)-equivariance of NDFs, we represent objects with compact shape codes encoding full object shapes from partial observations. The objects are then organized in a spatial tree structure based on object centers recovered from NDFs for fast queries of object neighborhoods. By associating objects via shape code similarity and comparing local object-neighbor spatial layout, our proposed approach demonstrates robustness to low observation overlap and localization noises. We conduct experiments on both synthetic and real-world sequences and achieve improved change detection results compared to multiple baseline methods.
# LayoutSLAM: Object Layout Based Simultaneous Localization and Mapping for Reducing Object Map Distortion
## Keywords:
- SLAM
- Mapping
- Probability and Statistical Methods
## Abstract:
There is an increasing demand for robots that can be substituted for humans in various tasks. Mobile robots are being introduced in factories, stores, and public facilities for tasks such as carrying goods and cleaning. In factories and stores, desks and shelves are arranged such that the work and movement of personnel are reduced. The surrounding furniture is also arranged to ensure that a single task can be performed in the same place. It is essential to study the intelligence of robots using information from such layouts, wherein human labor and movements are optimized. However, there is no established method for applying such an object layout to robot intelligence. Therefore, this study proposes a method for object mapping using layouts that exist in crowded workspaces. The certainty of the nodes of the graph indicates the layout strength. 
The types of objects related to the work and their network is expressed using a graph structure. The study formulates SLAM using the layout information represented by the graph structure and uses simulation to evaluate the accuracy of SLAM using the object layout as constraints. By integrating the layout constraints with SLAM, the accuracy of ''LayoutSLAM`` is improved by 60.49% in self-positioning and 50.44% in object map construction. It also corrects the positions of unobserved objects.
# SLAM-Supported Self-Training for 6D Object Pose Estimation
## Keywords:
- SLAM
- Deep Learning for Visual Perception
## Abstract:
Recent progress in object pose prediction provides a promising path for robots to build object-level scene representations during navigation. However, as we deploy a robot in novel environments, the out-of-distribution data can degrade the prediction performance. To mitigate the domain gap, we can potentially perform self-training in the target domain, using predictions on robot-captured images as pseudo labels to fine-tune the object pose estimator. Unfortunately, the pose predictions are typically outlier-corrupted, and it is hard to quantify their uncertainties, which can result in low-quality pseudo-labeled data. To address the problem, we propose a SLAM-supported self-training method, leveraging robot understanding of the 3D scene geometry to enhance the object pose inference performance. Combining the pose predictions with robot odometry, we formulate and solve pose graph optimization to refine the object pose estimates and make pseudo labels more consistent across frames. We incorporate the pose prediction covariances as variables into the optimization to automatically model their uncertainties. This automatic covariance tuning (ACT) process can fit 6D pose prediction noise at the component level, leading to higher-quality pseudo training data. We test our method with the deep object pose estimator (DOPE) on the YCB video dataset and in real robot experiments. It achieves respectively 34.3% and 17.8% accuracy enhancements in pose prediction on the two tests. Our code is available at https://github.com/520xyxyzq/slam-super-6d.
# Localization 2
# ROLL: Long-Term Robust LiDAR-Based Localization with Temporary Mapping in Changing Environments
## Keywords:
- Localization
- SLAM
## Abstract:
Long-term scene changes pose challenges to localization systems using a pre-built map. This paper presents a LiDAR-based system that provides robust localization against those challenges. Our method starts with activation of a mapping process temporarily when global matching towards the pre-built map is unreliable. The temporary map will be merged onto the pre-built map for later localization sessions once reliable matching is obtained again. We further integrate a LiDAR inertial odometry (LIO) to provide motion-compensated LiDAR scans and a reliable pose initial estimate for the global matching module. To generate a smooth real-time trajectory for navigation purposes, we fuse poses from odometry and global matching by solving a pose graph optimization problem. We evaluate our localization system with extensive experiments on the NCLT dataset including a variety of changing indoor and outdoor environments, and the results demonstrate a robust and accurate long-term localization performance. The implementations are open sourced on GitHub
# Indirect Point Cloud Registration: Aligning Distance Fields Using a Pseudo Third Point Set
## Keywords:
- Localization
- Mapping
- SLAM
## Abstract:
In recent years, implicit functions have drawn attention in the field of 3D reconstruction and have successfully been applied with Deep Learning. But for incremental reconstruction, implicit function-based registrations have been rarely explored. Inspired by the high precision of deep learning global feature registration, we propose to combine this with distance fields. We generalize the algorithm to a non-Deep Learning setting while retaining the accuracy. Our algorithm is more accurate than conventional models while, without any training, it achieves a competitive performance and faster speed, compared to Deep Learning based registration models. Our implementation is available at githubfootnote{url{https://github.com/Jarrome/IFR}} for the research community.
# Semantic Topological Descriptor for Loop Closure Detection within 3D Point Clouds in Outdoor Environment
## Keywords:
- Localization
- Mapping
- SLAM
## Abstract:
Loop closure detection has the potential to correct the drift of trajectories and build a global consistent map in LiDAR SLAM, however it remains a challenging problem in outdoor environment due to the sparsity of 3D point clouds data, large-scale scenes and moving objects. Inspired by the way humans perceive the environment through recognizing objects and identifying their relations, this paper presents a novel descriptor that contains semantic and topological information for loop closure detection. Unlike most existing methods that extract features from the raw point clouds or use all semantic objects, we directly discard point clouds representing pedestrians and vehicles after semantic segmentation. Then, we propose a semantic topological graph representation from the remaining point clouds and convert this graph into a descriptor. Additionally, we propose a two-stage algorithm for matching descriptors to efficiently determine the loop. Our method has been extensively evaluated using the KITTI dataset and outperforms state-of-the-art methods, especially in the challenging situations such as viewpoint changes and dynamic scenes.
# P3-VINS: Tightly Coupled PPP/INS/Visual SLAM Based on Optimization Approach
## Keywords:
- Localization
- Sensor Fusion
- SLAM
## Abstract:
Precise Point Positioning (PPP), a cutting edge GNSS technology, can achieve high precision positioning accuracy without base station assistance. Visual-Inertial Odometry (VIO) realizes a more robust local pose estimation than VisualSLAM. Based on these two technologies, we propose P3-VINS: tightly-coupled PPP/INS/Visual SLAM that fuses GNSS raw measurements (pseudorange, carrier phase, and Doppler) with visual and inertial information for accurate and robust state estimation. All raw data is modelled and optimized under a factor graph framework. To eliminate ionospheric effects and utilize carrier phase measurements, P3-VINS uses the ionosphere-free (IF) model by dual-frequency observations and adds phase ambiguity into the estimated states. Finally, P3-VINS is evaluated on both public datasets and real-world experiments. It significantly outperforms benchmarks (GVINS and PPP) in terms of accuracy and smoothness. This result demonstrates that the high precision carrier phase substantially helps GNSS/INS/Visual SLAM system reduce noise and improve accuracy.
# Gaussian Variational Inference with Covariance Constraints Applied to Range-Only Localization
## Keywords:
- Localization
## Abstract:
Accurate and reliable state estimation is becoming increasingly important as robots venture into the real world. Gaussian variational inference (GVI) is a promising alternative for nonlinear state estimation, which estimates a full probability density for the posterior instead of a point estimate as in maximum a posteriori (MAP)-based approaches. GVI works by optimizing for the parameters of a multivariate Gaussian (MVG) that best agree with the observed data. However, such an optimization procedure must ensure the parameter constraints of a MVG are satisfied; in particular, the inverse covariance matrix must be positive definite. In this work, we propose a tractable algorithm for performing state estimation using GVI that guarantees that the inverse covariance matrix remains positive definite and is well-conditioned throughout the optimization procedure. We evaluate our method extensively in both simulation and real-world experiments for range-only localization. Our results show GVI is consistent on this problem, while MAP is over-confident.
# Point Cloud Registration Leveraging Structural Regularity in Manhattan World
## Keywords:
- Localization
## Abstract:
Point cloud registration is an essential technique for many tasks including autonomous navigation, augmented/virtual reality and scene reconstruction. In man-made environments, abundant plane features with structural regularities are commonly seen, which is actually beneficial for point cloud registration. This paper presents an accurate and robust registration method that formulates the registration problem as a maximum likelihood estimation (MLE) problem where the useful structure information is also leveraged. To align two point sets efficiently, one point set is first represented as a Gaussian mixture models (GMM) tree, and then the Manhattan frame (MF) with dominant planes are estimated and the degenerated nodes corresponding to the dominant planes in the GMM tree are clustered to embody the structure information. The proposed MLE problem is solved by an Expectation Maximization (EM) framework. In the E step, the probabilistic data association between the GMM and another point set is estimated, and the structure information in this point set is also extracted by clustering the coplanar points and inferring the MF and plane parameters. Then the data association is further refined with the rotation and translation estimation that are obtained by aligning the MF and planes in two point sets respectively. In the M step, an optimization problem using Mahalanobis distance is solved by a linear least square algorithm. Experimental results on both indoor room and hybrid man-made environments show that the proposed method not only achieves a good balance between accuracy and speed, but also provides robust performance in sequence registration process compared with the existing state-of-the-art methods.
# Pose Refinement with Joint Optimization of Visual Points and Lines
## Keywords:
- Localization
- Deep Learning for Visual Perception
- Mapping
## Abstract:
High-precision camera re-localization technology in a pre-established 3D environment map is the basis for many tasks, such as Augmented Reality, Robotics and Autonomous Driving. The point-based visual re-localization approaches are well-developed in recent decades, but are insufficient in some feature-less cases. In this paper, we design a complete pipeline for camera pose refinement with points and lines, which contains the innovatively designed line extracting CNN named VLSE, the line matching and the pose optimization approaches. We adopt a novel line representation and customize a hybrid convolution block based on the Stacked Hourglass network, to detect accurate and stable line features on images. Then we apply a geometric-based strategy to obtain precise 2D-3D line correspondences using epipolar constraint and reprojection filtering. A following point-line joint cost function is constructed to optimize the camera pose with the initial coarse pose from the pure point-based localization. Sufficient experiments are conducted on open datasets, i.e, line extractor on Wireframe and YorkUrban, localization performance on InLoc duc1 and duc2, to confirm the effectiveness of our point-line joint pose optimization method.
# Closed-Form Error Propagation on SEn(3) Group for Invariant EKF with Applications to VINS
## Keywords:
- Localization
- Visual-Inertial SLAM
- SLAM
## Abstract:
 Pose estimation is important for robotic perception, path planning, etc. Robot poses can be modeled on matrix Lie groups and are usually estimated via filter-based methods. In this paper, we establish the closed-form formula for the error propagation for the Invariant extended Kalman filter (IEKF) in the presence of random noises and apply it to vision-aided inertial navigation. We evaluate our algorithm via numerical simulations and experiments on the OPENVINS platform. Both simulations and the experiments performed on the public EuRoC MAV datasets demonstrate that our algorithm in certain parameters settings outperforms some state-of-art filter-based methods such as the quaternion-based EKF, first estimates Jacobian EKF, etc. The techniques of choice on the parameters are worth further investigating.
# Motion and Path Planning 2
# Comprehensive Reactive Safety: No Need for a Trajectory If You Have a Strategy
## Keywords:
- Motion and Path Planning
- Autonomous Vehicle Navigation
- Robot Safety
## Abstract:
Safety guarantees in motion planning for autonomous driving typically involve certifying the trajectory to be collision-free under any motion of the uncontrollable participants in the environment, such as the human-driven vehicles on the road. As a result they usually employ a conservative bound on the behavior of such participants, such as reachability analysis. We point out that planning trajectories to rigorously avoid the entirety of the reachable regions is unnecessary and too restrictive, because observing the environment in the future will allow us to prune away most of them; disregarding this ability to react to future updates could prohibit solutions to scenarios that are easily navigated by human drivers. We propose to account for the autonomous vehicle’s reactions to future environment changes by a novel safety framework, Comprehensive Reactive Safety. Validated in simulations in several urban driving scenarios such as unprotected left turns and lane merging, the resulting planning algorithm called Reactive ILQR demonstrates strong negotiation capabilities and better safety at the same time.
# Modeling and Control of Morphing Covers for the Adaptive Morphology of Humanoid Robots (I)
## Keywords:
- Kinematics
- Motion Control
- Humanoid Robot Systems
## Abstract:
This article takes a step to provide humanoid robots with adaptive morphology abilities. We present a systematic approach for enabling robotic covers to morph their shape, with an overall size fitting the anthropometric dimensions of a humanoid robot. More precisely, we present a cover concept consisting of two main components: a skeleton, which is a repetition of a basic element called node, and a soft membrane, which encloses the cover and deforms with its motion. This article focuses on the cover skeleton and addresses the challenging problems of node design, system modeling, motor positioning, and control design of the morphing system. The cover modeling focuses on kinematics, and a systematic approach for defining the system kinematic constraints is presented. Then, we apply genetic algorithms to find the motor locations so that the morphing cover is fully actuated. Finally, we present control algorithms that allow the cover to morph into a time-varying shape. The entire approach is validated by performing kinematic simulations with four different covers of square dimensions and having 3x3, 4x8, 8x8, and 20x20 nodes, respectively. For each cover, we apply the genetic algorithms to choose the motor locations and perform simulations for tracking a desired shape. The simulation results show that the presented approach ensures the covers to track a desired shape with good tracking performances.
# Terrain-Aware Learned Controllers for Sampling-Based Kinodynamic Planning Over Physically Simulated Terrains
## Keywords:
- Motion and Path Planning
- Nonholonomic Motion Planning
- Machine Learning for Robot Control
## Abstract:
This paper explores learning an effective controller for improving the efficiency of kinodynamic planning for vehicular systems navigating uneven terrains. This work describes the pipeline for training the corresponding controller and using it for motion planning purposes. The training process uses a soft actor-critic approach with hindsight experience replay to train a model, which is parameterized by the incline of the robot's local terrain. This trained model is then used during the expansion process of an asymptotically optimal kinodynamic planner to generate controls that allow the robot to reach desired local states. It is also used to define a heuristic cost-to-go function for the planner via a wavefront operation that estimates the cost of reaching the global goal. The cost-to-go function is used both for selecting nodes for expansion as well as for generating local goals for the controller to expand towards. The accompanying experimental section applies the integrated planning solution on models of all-terrain robots in a variety of physically simulated terrains.	It shows that the proposed terrain-aware controller and the proposed wavefront function based on the cost-to-go model enable motion planners to find solutions in less time and with lower cost than alternatives. An ablation study emphasizes the benefits of a learned controller that is parameterized by the incline of the robot's local terrain as well as of an incremental training process for the controller.
# Risk-Aware Off-Road Navigation Via a Learned Speed Distribution Map
## Keywords:
- Motion and Path Planning
- Machine Learning for Robot Control
- Learning from Experience
## Abstract:
Motion planning in off-road environments requires reasoning about both the geometry and semantics of the scene (e.g., a robot may be able to drive through soft bushes but not a fallen log). In many recent works, the world is classified into a finite number of semantic categories that often are not sufficient to capture the ability (i.e., the speed) with which a robot can traverse off-road terrain. Instead, this work proposes a new representation of traversability based exclusively on robot speed that can be learned from data, offers interpretability and intuitive tuning, and can be easily integrated with a variety of planning paradigms in the form of a costmap. Specifically, given a dataset of experienced trajectories, the proposed algorithm learns to predict a distribution of speeds the robot could achieve, conditioned on the environment semantics and commanded speed. The learned speed distribution map is converted into costmaps with a risk-aware cost term based on conditional value at risk (CVaR). Numerical simulations demonstrate that the proposed risk-aware planning algorithm leads to faster average time-to-goals compared to a method that only considers expected behavior, and the planner can be tuned for slightly slower, but less variable behavior. Furthermore, the approach is integrated into a full autonomy stack and demonstrated in a high-fidelity Unity environment and is shown to provide a 30% improvement in the success rate of navigation.
# Dynamic Replanning with Posterior Sampling
## Keywords:
- Motion and Path Planning
- Probabilistic Inference
## Abstract:
When navigating to a goal in an uncertain environment, a robot must simultaneously navigate the exploration-exploitation tradeoff: should it aim to gain information and reduce uncertainty, or should it simply brave the unknown? We formalize this as the Bayesian dynamic motion planning problem, and we analyze how several strategies from the literature balance these concerns via determinization and planning. Within the framework of determinization in the face of uncertainty, we shift the burden of exploration to determinization rather than planning. Dynamic Replanning with Posterior Sampling (DRPS) is very efficient: each iteration consists of a single posterior update and a shortest path query. Relative to comparative baselines across seven datasets of 2D planning problems, DRPS has a higher percentage of success, traverses lower or comparable total distances, and accelerates total planning time by 4-7x. Across a dataset of larger 7D Baxter manipulator planning problems, DRPS reduces total distance by 40% and total planning time by 18x.
# Energy-Aware Planning-Scheduling for Autonomous Aerial Robots
## Keywords:
- Motion and Path Planning
- Energy and Environment-Aware Automation
## Abstract:
In this paper, we present an online planning-scheduling approach for battery-powered autonomous aerial robots. The approach consists of simultaneously planning a coverage path and scheduling onboard computational tasks. We further derive a novel variable coverage motion robust to airborne constraints and an empirically motivated energy model. The model includes the energy contribution of the schedule based on an automatic computational energy modeling tool. Our experiments show how an initial flight plan is adjusted online as a function of the available battery, accounting for uncertainty. Our approach remedies possible in-flight failure in case of unexpected battery drops, e.g., due to adverse atmospheric conditions, and increases the overall fault tolerance.
# Learning to Herd Amongst Obstacles from an Optimized Surrogate
## Keywords:
- Motion and Path Planning
- Task and Motion Planning
- Reinforcement Learning
## Abstract:
In the robotic shepherding problem, an external robot guides a group of coherent agents from the start region to the goal region by placing itself intelligently in the vicinity of the group. It was been shown that a model trained by deep reinforcement learning is able to guide a small number (2-4) of agents among obstacles. However, herding more agents (more than 7) in obstacle-filled environments is challenging because larger group exhibits deformable quality, the shepherding system is dynamic and the problem is highly underactuated. In this work, we show that a model trained by deep reinforcement learning with the optimized potential field of the workspace, in which the potential field optimizes the objectives of control quality for navigation the group, can herd a larger group in obstacle-filled environments. In addition, we use pixel blobs to represent the group of sheep and show the efficiency of the trained controller. Our experiments demonstrated the trained model is robust to noise in group behaviors and in environments. Compared to the rule-based method, the proposed approach maintains a higher probability of guiding the sheep and better control quality.
# Geometric Savitzky-Golay Filtering of Noisy Rotations on SO(3) with Simultaneous Angular Velocity and Acceleration Estimation
## Keywords:
- Methods and Tools for Robot System Design
- Software Architecture for Robotic and Automation
## Abstract:
This paper focuses on the problem of smoothing a rotation trajectory corrupted by noise, while simultaneously estimating its corresponding angular velocity and angular acceleration. To this end, we develop a geometric version of the Savitzky-Golay filter on SO(3) that avoids following the conventional practice of first converting the rotation trajectory into Euler-like angles, performing the filtering in this new set of local coordinates, and finally converting the result back on SO(3). In particular, the estimation of the angular acceleration requires the computation of the right-trivialized second covariant derivative of the exponential map on SO(3) with respect to the (+) Cartan-Schouten connection. We provide an explicit expression for this derivative, creating a link to seemingly unrelated existing results concerning the first derivative of the exponential map on SE(3). A numerical example is provided in which we demonstrate the effectiveness and straightforward applicability of the proposed approach. An open implementation of the new geometric Savitzky-Golay filter is also provided.
# Late Breaking Results Poster 1
# An Inverted V-Belt and Pulley for Compact, Continuously or Infinitely Variable Robotic Transmissions
## Keywords:
- Actuation and Joint Mechanisms
- Mechanism Design
- Compliant Joints and Mechanisms
## Abstract:
Despite advancements in electromagnetic motors for robotic applications, torque-amplifying transmissions are still ubiquitous in both fixed and mobile robots. In almost all cases, the transmission ratio is fixed, necessitating design-time tradeoffs between torque and speed and resulting in lower efficiencies and thermal management challenges. Variable ratio transmissions promise to eliminate these tradeoffs and enable higher performance at lower costs. Robotic applications particularly benefit from continuously varying transmission (CVT), avoiding transient gaps in transmission due to shifting.
SRI’s Robotics Lab has developed several unique configurations of variable pulley CVTs with coaxial input and output shafts and a compact form factor that enables robotic applications. In new work presented here, we report an insight that eliminates the need for the complex belts while retaining compactness and high ratio range. Our new design inverts both the belt and variable pulley to enable new belt mechanisms that can be inexpensively produced but retain metal construction. The belt runs inside an inverted V-pulley and transmits the working power through compressive forces. When the belt passes between the two pulleys, small shear forces maintain its stability. The belts tested so far are made of discrete elements (“wedges”) as in automotive CVTs, but without the expensive tension bands. We have experimented with toothed and linkage-based methods for supporting shear forces during belt transition. We tested several variations of inverted drive in a non-orbiting configuration on an instrumented testbench, finding up to 95% efficiency and smooth, quiet operation. A torque-sensitive loading mechanism maintained high efficiency across a wide range of loading conditions.
# Dual Pulley Drive: Single Actuator System with Adjustable Profile Overlapping Range in 2-DOF Assistance for Exosuits
## Keywords:
- Actuation and Joint Mechanisms
- Mechanism Design
- Engineering for Robotic Systems
## Abstract:
Reducing the system weight while keeping the assistance performance is important to reduce the metabolic penalty in exosuits. Several researchers have suggested a bi-directional cable-driven actuator that can operate two degrees of freedom (DOF) assistance using a single motor. However, such systems have limitations related to the controllability of the assistance. This study proposes a novel type of BCDA, a dual pulley drive, that is single actuator system with adjustable profile overlapping range in 2-DOF assistance for exosuits.
# Decoupling Adaptive Control of Multi-Task Aerial Manipulator Using NSB Approach
## Keywords:
- Aerial Systems: Applications
- Aerial Systems: Mechanics and Control
- Mobile Manipulation
## Abstract:
In this work, a control scheme for an aerial manipulator consisting of an unmanned aerial vehicle (UAV) and a robotic arm is investigated. To reduce the computational burden, the dynamic model is decoupled into the parts of the UAV and the robotic arm. The tracking controllers using an adaptive backstepping strategy are proposed for the UAV and the robotic arm separately. Moreover, the redundancy of the system is used to implement null-space behavioral (NSB) control for sub-tasks. The efficiency of the proposed method is validated through the numerical simulation and experimental result.
# Virtual Reality from Pose Estimation and Active Learning for Bilateral Teleoperation of Aerial Manipulators
## Keywords:
- Aerial Systems: Applications
- Aerial Systems: Perception and Autonomy
- Telerobotics and Teleoperation
## Abstract:
We present a novel teleoperation system for advancing aerial manipulation in dynamic and unstructured environments. The proposed system not only features a haptic device, but also a virtual reality (VR) interface that provides real-time 3D displays of the robot’s workspace as well as a haptic guidance to its remotely located operator. We realize the system by solely relying on the robot’s on-board sensors and computations, i.e., no external motion tracking sensors or any pre-generated maps are required. To this end, we propose pose estimation pipelines for industrial objects of both known and unknown geometries, and we further devise an active learning pipeline for deploying Deep Neural Networks (DNNs) in the real world. All these algorithms are designed to address the challenges during the execution of tasks in industrial scenarios. In the experiments, ablation studies are provided to validate the proposed pipelines, and outdoor experiments are conducted to evaluate the effectiveness of the overall system in enhancing aerial manipulation capabilities. In particular, with flight campaigns over days and nights, from spring to winter, and with different users and locations, we demonstrate over 70 robust executions of pick-and-place, force application and peg-in-hole tasks with the DLR cable-Suspended Aerial Manipulator (SAM). As a result, we show the viability of the proposed system for aerial manipulation in future industrial applications
# Dynamic Minimum Energy Trajectory Generation through Predictive Wind Forecasting
## Keywords:
- Aerial Systems: Applications
- Path Planning for Multiple Mobile Robots or Agents
- Aerial Systems: Mechanics and Control
## Abstract:
Local wind conditions in the environment can have a significant impact on aerial vehicles. With recently completed work using multirotor vehicles as a method of wind sampling for meteorology, access to this local wind information is becoming more readily available. It has been shown that through modelling the dynamics of the vehicle with relation to the experienced airspeed is it possible to extract data on the wind speed and direction from the environment at a given location to a level of accuracy often within approximately 1m/s. Coupling this available information with work on wind forecasting using statistical methods it becomes possible to predict the short term variation in the wind the vehicle will experience during flight. In this paper we show that this information can be used to determine a minimum energy safe optimal trajectory dynamically in flight. This approach can be used in a number of ways, from improving the performance of a vehicle over short flights and ensuring a safe descent with regards to vortex ring states to larger rerouting tasks over long distances experiencing changes in wind conditions.
# Valve Turning Work Utilizing a Multirotor Aerial Robot with Add-On Thrust Vectoring Device
## Keywords:
- Aerial Systems: Mechanics and Control
- Aerial Systems: Applications
- Robotics in Hazardous Fields
## Abstract:
Aerial manipulation aims to combine the versatility and the agility of aerial platforms with the manipulation capabilities of robotic arms. Their fast deployment allows for their implementation in maintenance tasks and support during disaster situations. However, the under-actuated nature of multirotor UAVs limit the magnitude and direction of the forces an aerial vehicle can safely exert during manipulation tasks. In this paper, the problems associated with UAVs and torsional tasks constraints regarding valve turning are addressed. An add-on thrust vectoring system which enhances manipulation options available to a conventional multirotor UAV is developed and described. The proposed system allows a partial decoupling of the attitude and velocity vector of a multirotor. This permits stable translational motion and higher torque capabilities for torsional tasks. The separation of attitude and the velocity vector allows for the design of a passive mechanism for valve operation, presented in this paper as well. The experimental results illustrate the forces and torques that can be generated while the multirotor maintains its hover state.
# Accurate Transportation Control System for Flexible Cable Suspended Load Carried by a Multi-Copter
## Keywords:
- Aerial Systems: Mechanics and Control
- Optimization and Optimal Control
- Intelligent Transportation Systems
## Abstract:
Multi-copters are at the forefront of robotics and aviation technology and have been integrated into various applications, including aerial delivery. The primary multi-copter delivery system’s disadvantage is the lack of controlled and accurate delivery. This research introduces a solution with the design of an advanced control system for a multi-copter aerial platform transporting a payload connected by a modeled flexible cable. Aerial transportation of a cable-suspended load has been researched for cranes and multi-copter. However, these researches are based on a simplified dynamic model without considering the non-linear profiles caused by aerodynamics disturbances, forces, and their flexibility. As such, those solutions may not be suitable for tasks where the dynamics of the payload can affect the motion significantly, the cable is deformed, and the tension along the cable is low. Furthermore, these solutions do not present controlled, and accurate cable suspended payload transportation, thereby restricting its applicability. We aim to accurately transport the payload to the destination site while controlling the payload spatial oscillations by controlling the multi-copter movement. We designed a unique end unit containing the payload and equipped with a sensor suit that provides the multi-copters control unit with feedback on the payload location and angular velocity. The main challenge is preventing payload oscillations while deploying the system, especially during the final approach. The cable-suspended payload may suffer from position disturbances and unwanted movement, e.g., wind gusts disturbances. Furthermore, during maneuvers or long cable deployments, the cable profile may become non-linear and thus cannot be approximated without measurements of the end unit configuration and state. Consider a multi-copter with a payload connected in its center of mass by a flexible cable modeled as a chain of n-links, lowered by a winch to the destination site. We derived our system model based on the equations developed by Goodarzi et al., adding the aerodynamic forces to the integrated dynamics of the multi-copter and the flexible cable. We are using a multi-shooting scheme, solving the following discretized non-linear optimal control problem based on the complete system model. A Non-Linear MPC (Model Predictive Control) control system is constructed for a multi-copter transporting a cable-suspended load as a Sequential Quadratic Program (SQP). Our research simulations show such a multi-copter ability to accurately deliver payloads within the accuracy of the GPS receiver mounted at the end unit.
# Model-Based Reinforcement Learning for Fixed-Wing Flight Control
## Keywords:
- Aerial Systems: Perception and Autonomy
- Reinforcement Learning
- Model Learning for Control
## Abstract:
Fixed-wing uncrewed aerial vehicles (UAVs) are capable of highly agile flight, due to their high thrust-to-weight and large control surfaces. These capabilities can be exploited for useful flight manoeuvres, such as rapid obstacle avoidance. Conventional UAV flight controllers are designed for limited flight envelopes, and are typically unable to control an aircraft in post-stall flight. 
% Reinforcement learning (RL) methods have shown success across several domains, including training controllers for robotics of various modalities. vspace{-0.3cm} A key challenge for robot learning is the transfer of simulated learning to the real world, known as the reality gap. Fixed-wing simulators utilise several modelling simplifications, especially for post-stall behaviour and turbulence. Model-based reinforcement learning (MBRL) tends to have greater sample efficiency than model-free methods, enabling real-world learning that can help overcome the sim-to-real issues. This work looks to apply MBRL methods to the flight control of an aerobatic UAV to learn aerobatic manoeuvres in the real world, without pre-training in simulation.
# Modeling and Control of Multi-UAV System for Tributary Mapping Based on Hybrid Automata
## Keywords:
- Agricultural Automation
- Discrete Event Dynamic Automation Systems
- Multi-Robot Systems
## Abstract:
Tributary is the situation changes each time depending on environmental factor (e.g., weather) and the work must be performed and managed in an unstructured environment. For these reasons, unmanned aerial vehicles (UAVs) are utilized for tributary management with remote sensing. However, a single UAV cannot ensure enough coverage area for a large-scale tributary. To overcome this, it can be extended to multiple UAV systems, will increase the control complexity. In multi-UAV systems, classical control theory based on differential equations has some limitations in handling large# scale complex dynamics systems. Other modeling methods and control theory should be introduced instead of traditional control theory. Therefore, this study proposes a multi-UAV system which is modeled hybrid automata method and controlled supervisory controller for tributary mapping.
# Posture Estimation from Crop Lines for Night Planting Robot Using a Single Camera with Night Vision Mode
## Keywords:
- Agricultural Automation
- Vision-Based Navigation
- Robotics and Automation in Agriculture and Forestry
## Abstract:
This paper presents an agricultural automation using a robot performing a straight navigation for planting. We pay attention to all day work, i.e., not only daytime but also night planting. Thus, an image processing algorithm is proposed to apply only a single camera with night vision mode for its posture estimation from crop lines at both daytime and night. In the proposed algorithm, crop line regions are extracted based greenness enhancement and NIR image generation from a RGB color image for daytime and night plantings, respectively.	The rest except this process are common. Experiments were conducted to detect straight lines fit to the crop lines and estimate the camera posture from a vanishing point determined from the straight lines, using daytime and night images.
# Application of Deep Stable Koopman Operator to Long-Term Prediction
## Keywords:
- AI-Based Methods
- AI-Enabled Robotics
## Abstract:
Numerous natural systems are believed to be stable because the energy of a physical system must be conserved. Therefore, imposing stability to a data-driven model would be a promising approach to enhance the prediction accuracy of the model. However, stability is difficult to define in a non-linear system with machine learning models such as a neural network-based model. In this paper, we introduce a deep Koopman model that can transform a non-linear system into a linear system. Once a system is transformed into a linear system, the stability constraint can be efficiently applied with eigenvalue decomposition. The proposed stable deep Koopman operator shows that it can model a simple autonomous dynamical system and consistently predict long-term future states.
# Solving Geduld-Spiele Cubes with a Virtually Trained Robotic Agent
## Keywords:
- AI-Based Methods
- Simulation and Animation
- Virtual Reality and Interfaces
## Abstract:
This paper presents an approach to solve simple geduld-spiele cubes with a virtually trained robotic agent. A key idea of the presented approach is to train a virtual robotic agent based on a reinforcement learning and deploy the trained agent to a real robotic system. During the training, the virtual robotic agent was supposed to learn a policy to place a ball at a center hole on a plane. Three different geduld-spiele cubes (of which plane curvature is flat, convex, and concave) were employed in pseudo-randomized order so that the virtual robotic agent could learn the policy to handle various plane curvatures. The results showed that the virtually trained robotic agent was able to solve simple geduld-spiele cubes in the real world as well.
# Towards Safe Autonomous Driving: Decision Making with Observation-Robust Reinforcement Learning
## Keywords:
- Autonomous Vehicle Navigation
- Reinforcement Learning
- Autonomous Agents
## Abstract:
This paper presents a novel observation-robust reinforcement learning against observation uncertainties to realize safe lane change decision making for autonomous driving. The proposed approach is evaluated in the stochastic mixed traffic flow. The results demonstrate that our method can ensure autonomous driving performance and the policy robustness against adversarial observation perturbations.
# Autonomous Mobile Robot Navigation with IRL and DQN in Narrow Corridor Environments
## Keywords:
- Autonomous Vehicle Navigation
- Reinforcement Learning
- Deep Learning Methods
## Abstract:
This paper deals with the autonomous mobile robot navigation in narrow corridor environments. This paper proposes a combination of Inverse Reinforcement Learning (IRL) with Deep Q-Network (DQN) to enable the smooth navigation. IRL is applied for training the agent which is the mobile robot to adapt the environment i.e., to accumulate the average reward function for the certain action or policy and DQN is a backbone to the system as it initializes the reward and generate the future state along with the next action/policy the robot needs to acquire. Simulation results showed that the proposed method combining IRL with DQN showed the higher attitude for navigation within narrow corridor environments.
# Modeling of Nonlinear Stiffness for Wall Painting Manipulator
## Keywords:
- Calibration and Identification
- Manipulation Planning
- Service Robotics
## Abstract:
This paper presents the design and nonlinear stiffness model identification of a three-degree-of-freedom (DOF) painting manipulator. It is designed to draw pictures of various thicknesses on a flat surface through force control with a minimum DOF. For precise force control, a nonlinear model identification of the stiffness of the end-effector brush is approximated into a third-order equation.
# Back-Stepping Control of a Transformable Wheel-Based Robot
## Keywords:
- Climbing Robots
- Body Balancing
- Wheeled Robots
## Abstract:
Abstract—This paper presents the back-stepping based control strategy of two-wheel balancing robot with transformable wheels. The transformable wheel is a new mechanism that can overcome stairs. It drives in the form of a normal wheel on the ground, and when it encounters step obstacles, it can be optimally transformed to overcome it effectively. Since the balancing robot with transformable wheels has non-linear and discontinuous dynamic model, a control strategy in which two backs-tepping controllers are switched is used for control.
I. INTRODUCTION Recently, as robots are applied to human life, robots capable of overcoming step obstacles such as stairs and threshold are required. The STEP[1] is a robot having a transformable wheel capable of 2-DOF transformation by adapting to the shape of the step obstacle. It can have both the advantages of a round wheel that can drive fast on the ground and a curved spoke wheel that can effectively overcome stairs. This study proposes a control strategy using a fixed shape of spoke wheel dynamic model assuming a limited situation in which STEP overcomes the stairs.
II. STATE DEFINITION AND CONTROLLER DESIGN When the wheel is transformed, there are three states. When a robot makes single point contact with the floor, dynamic models can be divided into two, normal contact state and edge contact state.
III. CONTROL STRATEGY Both states are nonlinear, and because each state is switched, the overall state is discontinuous. Therefore, the robot can be continuously controlled and made into a stable double contact state. In this process, reference shaping and control constants variation are included.
IV. CONCLUSIONS This research suggest a control strategy of a balancing robot with a transformable wheel based on back-stepping control, and it was verified through simulation that it was possible to stably overcome the step obstacles. In a future work, this will be verified through experiments.
# Soft Material-Based Adaptable Four-Bar Linkage Stair Climbing Robot
## Keywords:
- Climbing Robots
- Flexible Robotics
- Field Robots
## Abstract:
Climbing stairs has been a challenge for robots for a long time. The four-bar linkage robot can climb stairs with blades. However, since the shape of the blade is fixed, the robot can climb only stairs with limited dimensions. Therefore, compliant mesh that can be freely deformable is applied to the robot so that it can climb various stairs. The compliant meshes to be analyzed are arc, honeycomb, and spoke patterns. Arc is used in Michelin's advanced airless tire. The arc shape can be easily deformed and restored. The honeycomb pattern can form a solid structure with little material and has excellent fatigue resistance. The last pattern is a simple spoke form and it is for comparison. To compare each pattern, all patterns are made of TPU equally 2 mm thick and 13 mm spaced. Experiments were conducted through Ansys simulation. The horizontal and vertical forces received by pressing the stair block were measured. And the arc pattern showed the lowest reaction force ratio. We decided to make a compliant mesh with an arc pattern that receives the most minor horizontal reaction force based on the experimental results. We will experiment by manufacturing a blade that can withstand the robot.
# Analysis on the Wheel-Leg Mechanism’s Locomotion on a 3D Shaped Surface
## Keywords:
- Compliance and Impedance Control
- Dynamics
- Legged Robots
## Abstract:
This paper presented wheel-leg mechanism control mounted on rope used facade cleaning robot. The wheel leg is driven like a spring damper through impedance control to offset external impact to minimize robot vibration. Work in High-rise buildings is essential, but it is accompanied by danger. So many research have been conducted to replace it with robot. One of the methods is a robot that moves and works on the outer wall of a building using an ascender, a device for winding rope.[1] However, since the past research assumes movement on a flat wall, the work performance of amorphous buildings is limited. For effective movement and work on 3D curved surfaces, the wheel leg mechanism was selected. The purpose of the research is to minimize movement of the robot in the vertical direction on the wall surface so that the work can be performed stably. If there is a small bend on the outer wall of the building while moving, the impedance control that can absorb the impact is used by measuring the external force. The constant used for impedance control is determined by optimal control that minimizes distance of the robot center, vertical direction on the wall surface. As shown in Fig. 1, q1 is hip joint motor’s angle, and q2 is knee joint motor’s angle. m1, m2, l1, l2, I1, I2 are properties of the each leg part, and are the mass, length, inertia moment. r1, r2 are distance between center of gravity and motor joint. Dynamic modeling of wheel leg is as follow. To control system in response to an external force, disturbance torque measurement is essential. Although it can also be measured by directly mounting a force sensor on leg's wheel, there are problems that the sensor has weak durability, increases hardware complexity, and system can be divergence by a momentary impact on the floor. Therefore, we decided to estimate the ground contact force by measuring the torque at the joint motor without using a force sensor. GMO(Generalized Momentum Observers) is selected to be used as a general method of estimating disturbance torque generated by ground contact force. In order to absorb the impact caused by the floor topography, impedance control is used to operate similarly to the spring damper. Desired motor torque is as follows. Kdesired, Cdesired is a user-configurable constant. Use optimal control to determine constants that can minimize robot movement during movement. This research suggest control strategy of wheel leg to minimize robot's vibration in vertical direction to wall surface. In future research, wheel-leg with a controller will be operated on a test bench to measure and evaluate vertical movement.
# Development of Actuator with Adjustable Compliance for the Polishing Process
## Keywords:
- Compliant Joints and Mechanisms
- Optimization and Optimal Control
- Service Robotics
## Abstract:
This paper presents the mechanism of a rotational actuator with adjustable compliance (stiffness and damping) for the robotic polishing process. The mechanism of adjustable compliance is achieved using elastic elements and friction. In this study, polishing conditions that minimize vibration were investigated.
# Template-Based Category-Agnostic Instance Detection with Human Guidance for Adaptive Robotic Manipulation
## Keywords:
- Computer Vision for Automation
- Industrial Robots
- Humanoid Robot Systems
## Abstract:
Most existing object detection studies have mainly focused on category-specific objects and have achieved impressive performance. However, robotic systems, particularly in industrial scenarios, typically interact with many category-agnostic objects, which the robot must detect instantly without re-training. Traditional template matching techniques can be quite brittle for complex objects. Another typical template-based approach utilizes pre-defined textured 3D models to match images. Inspired by the existing works, which employed a philosophy sharing resemblance to meta-learning, this study implicitly embedded template features by taking advantage of the representation capability of the deep learning.
# Micro-Scale Defect Detection with Deep Learning on Embedded Visual Inspection Systems
## Keywords:
- Computer Vision for Manufacturing
- Factory Automation
- Deep Learning for Visual Perception
## Abstract:
When the inspection process of facial masks is conducted by human in mask manufacturing systems, it may frequently cause human errors due to their fatigue. Besides, if the defects are micro-scale, it is hard to be conducted by human. Thus, a vision system with the defect detection algorithm is highly required to improve the reliability of the mask manufacturing systems. Also, the defect detection algorithm needs to be implemented on embedded systems since it should be applied to a real mask production system which consists of various real-time embedded systems. Therefore, our motivation is to implement an accurate micro-scale defect detection algorithm on embedded systems.
# Extended Adaptive Inverse Perspective Mapping for Ground Representation of Autonomous Mobile Robot
## Keywords:
- Computer Vision for Transportation
- Autonomous Vehicle Navigation
- Mapping
## Abstract:
This paper proposes an Extended Adaptive Inverse Perspective Mapping (EA-IPM) model that can obtain an accurate bird’s-eye view (BEV) from the forward-looking camera on the sidewalk with various curves.
# Image & Video Anonymization Framework for Ethical Autonomous Trains
## Keywords:
- Computer Vision for Transportation
- Object Detection, Segmentation and Categorization
- Ethics and Philosophy
## Abstract:
Autonomous vehicle has been a trendy research subject for the past decade. Due to its high capacity and low environmental impact, railway is also concerned with this infatuation. The autonomous train global system relies on its ability to see and understand its surroundings, as well as to extract meaningful information. It may include signaling recognition, obstacle detection or environment and condition monitoring. At the moment, in open-world circumstances, only prototypes of autonomous trains are on tracks for tests. They record, store and process enormous amount of data, in particular LiDAR point clouds and RGB images. They cover tracks and their surroundings as well as platform and passengers. These data are essential for the development of perception and security related algorithms. However, worldwide regulations are evolving to protect personal data. If the autonomous vehicle is to be ethical (including trains), it must preserve and protect people’s identities and their right to stay anonymous. In that context, every biometric data must be permanently deleted, and personal data reduced to a minimum. In this work, we propose a framework for face detection and robust anonymization. Our results demonstrated the feasibility of real time anonymization on Ultra High-Definition videos
# Detail-Guided Image Enhancement for Underwater Robot Vision
## Keywords:
- Deep Learning for Visual Perception
- Marine Robotics
- Robotics in Hazardous Fields
## Abstract:
Conventional robot vision has limited performance on underwater images. This paper proposes an underwater image enhancement model using Generative Adversarial Network (GAN) and Laplacian loss. Qualitative and quantitative evaluations show that proposed method increases the detail and contrast of the image, making it applicable to robot vision.
# Noise-Aware Stochastic Gradient Optimization with AdaTerm
## Keywords:
- Deep Learning Methods
## Abstract:
As the problems to be optimized with deep learning become more practical, their datasets inevitably contain a variety of noise, such as mislabeling and substitution by estimated inputs/outputs, which would have negative impacts on the optimization results. As a safety net, it is a natural idea to improve a stochastic gradient descent (SGD) optimizer, which updates the network parameters as the final process of learning, to be more robust to noise. The related work revealed that the first momentum utilized in the Adam-like SGD optimizers can be modified based on the noise-robust student’s t-distribution, resulting in inheriting the robustness to noise. In this paper, we propose AdaTerm, which derives not only the first momentum but also all the involved statistics based on the student’s t-distribution. If the computed gradients seem to probably be aberrant, AdaTerm is expected to exclude the computed gradients for updates, and reinforce the robustness for the next updates; otherwise, it updates the network parameters normally, and can relax the robustness for the next updates. With this noise-adaptive behavior, the excellent learning performance of AdaTerm was confirmed via typical optimization problems with several cases where the noise ratio would be different.
# Switching Funnel UNITER: Multimodal Instruction Comprehension for Object Manipulation Tasks
## Keywords:
- Deep Learning Methods
- Deep Learning for Visual Perception
- Domestic Robotics
## Abstract:
In this paper, we present a multimodal language understanding method that allows domestic service robots to comprehend object fetching and carrying instructions. We extend Target-dependent UNITER by introducing a Switcher module and multi-task learning so that both target objects and destinations can be predicted individually using a single model, which reduces the computational cost.
# Collision Prediction and Visual Explanation Generation Using Structural Knowledge in Object Placement Tasks
## Keywords:
- Deep Learning Methods
- Deep Learning for Visual Perception
- Domestic Robotics
## Abstract:
This paper presents a collision prediction method for placement tasks. We extend PonNet by introducing a novel Structural Causal Encoder, and introduced an object placement policy. The proposed method outperformed a baseline method in accuracy on a newly-built dataset.
# Learning Scheme Based on Bayesian Optimization for Throwing Manipulation with Stochastic Noise
## Keywords:
- Dexterous Manipulation
- Manipulation Planning
## Abstract:
Non-prehensile manipulation, such as throwing manipulation, is expected to improve the skill of robot manipulation. Still, it is sensitive to modeling errors such as object state, shape, mass, and stochastic noise such as control errors and friction. However, to our knowledge, there is less learning scheme for throwing manipulation, which accounts explicitly for stochastic noise. Therefore, this study proposes a learning scheme based on Bayesian optimization and experimentally verifies the robustness of the proposed method against stochastic noise, such as wind disturbance, by comparing the conventional method based on the iterative learning control.
# Robot Thruster Control for Robust Adhesion Control on a Facade
## Keywords:
- Dynamics
- Engineering for Robotic Systems
- Body Balancing
## Abstract:
This paper presented thruster control for rope used facade cleaning robot.Thruster control was selected H-infinity control and Disturbance Observer (DOB).Based on these research, experiment will have conducted at the future work.
Recently, with the development of building technology,the height of the building is increasing.The maintenance/repair of the building is done by people, so the higher the building, the greater the difficulty and risk.Therefore,research on building maintenance/repair through robots called facade cleaning robot has been conducted to reduce the risk of building cleaning.There are many types of facade cleaning robots, but the most of cleaning robot is using a rope because of workspace's freedom.However, rope used facade cleaning robot has a big disadvantage.If rope is used, the robot vibrate because the robot cannot attach to the building, and the vibration of the robot makes it difficult to control.Therefore, a control method using thruster has been proposed to compensate the disadvantage.
# AR Training App for Energy Optimal Programming of Cobots
## Keywords:
- Energy and Environment-Aware Automation
- Manipulation Planning
- Dynamics
## Abstract:
Worldwide most factories aim for low-cost and fast production ignoring resources and energy consumption. But, high revenues have been accompanied by environmental degradation. The United Nations reacted to the ecological problem and proposed the Sustainable Development Goals, and one of them is Sustainable Production (Goal 12). In addition, the participation of lightweight robots, such as collaborative robots, in modern industrial production is increasing. The energy consumption of a single collaborative robot is not significant, however, the consumption of more and more cobots worldwide is representative. Consequently, our research focuses on strategies to reduce the energy consumption of lightweight robots aiming for sustainable production. Firstly, the energy consumption of the lightweight robot UR10e is assessed by a set of experiments. We analyzed the results of the experiments to describe the relationship between the energy consumption and the evaluation parameters, thus paving the way to optimization strategies. Next, we propose four strategies to reduce energy consumption: 1) optimal standby position, 2) optimal robot instruction, 3) optimal motion time, and 4) reduction of dissipative energy. The results show that cobots potentially reduce from 3% up to 37% of their energy consumption, depending on the optimization technique. To disseminate the results of our research, we developed an AR game in which the users learn how to energy-efficiently program cobots.
# Mobile Robot Mechanism with Wheel Switching Primitives
## Keywords:
- Field Robots
- Mechanism Design
- Climbing Robots
## Abstract:
ABSTRACT : This paper proposes a mobile robotic platform, LEVO, which uses a normal wheel and a curved-spoke tri-wheel (CSTW). The normal wheel is used for driving on flat terrain, and the CSTW is used for stair climbing. In order to use the two mechanisms independently, a switching mechanism that consists of ball screw, linear motion (LM) guide, and actuator is added.] are already defined on the style sheet, as illustrated by the portions given in this document.
INTRODUCTION : Last-mile delivery is emerging as a focal point in the logistic industry. Therefore, mobile robots best suited for last-mile delivery services such as Postbot and Amazon's Scout are increasingly being discovered. These robots have wheels, which are suited for use in detached-house environments. However, in apartments, overcoming various obstacles to provide last-mile service using a wheeled-robot is not easy. Among obstacles, stairs are considered to be one of the most difficult for wheeled-robots to overcome. Thus, several mechanisms proposed for overcoming stairs. The stair overcoming mechanisms : Legged-robot, Tracked-robot and the curved-spoke tri-wheel(CSTW) are mainly examined in this paper. This paper proposes a mobile robot(LEVO) that uses both CSTW mechanism and wheel mechanism. In order to use the systems effectively, CSTW driving and wheel-driving must be independent. So switching mechanism is added to the robot, which separates the operation of the robot into the CSTW mode and wheel mode.
DESIGN TOBOTIC PLATFORM:LEVO : First, determine the parametric design of CSTW. Based on this parameters, make static and kinematic analysis of stair-climbing model. And static and kinematic analysis of switching model is also performed.
EXPERIMENT AND DISCUSSIONS : A prototype robot is assembled by substituting analysis variables into the 3D modeling of Figure ref{fig:LEVO_overview_structure}. And experiments on mode-switching, stair-climbing, and wheel-driving ability were conducted. The experiment was conducted in the robot's delivery scenario. An experimental example is shown in paper. In the experiment, the robot that overcomes both flat ground and stairs through the switching proposed in this paper shows satisfactory performance.
CONCLUSION : LEVO can convert to wheel mode and CSTW mode by using a switching mechanism. The CSTW mode can be used to overcome various sizes stairs. In wheel-mode, it is possible to stably drive and steer on flat terrain using normal wheels. Therefore, LEVO has potential applicability as a mobile robot platform because it has a mechanism that enables handling both stairs and flat terrain.
# Mobile Robot Guidance from Known to Unknown Environment
## Keywords:
- Field Robots
- Task and Motion Planning
- Vision-Based Navigation
## Abstract:
This paper proposes a navigation method for a mobile robot that combines the occupancy grid map with the topology map. The occupancy grid map is defined as the known environment, whereas the topology map is defined as the unknown environment since the topology map is not directly drawn by the robot. A practical approach for combining two maps in real world navigation is introduced.
# Exploring the Next Dimension: Can Data-Efficient Tactile Online Learning in 2D Be Transferred to 3D?
## Keywords:
- Force and Tactile Sensing
## Abstract:
When training an optical tactile sensor to complete edge following tasks, methods developed in 2D with an emphasis on data efficiency are transferred to 3D to try to overcome the curse of dimensionality and to retain the advantages of data efficiency. It is found that the extra dimension can be learnt on a select subset of stimuli. Further advancements are proposed to increase generality of the methods.
# A Soft Tactile Sensor for Tasks Requiring High Spatial Resolution
## Keywords:
- Force and Tactile Sensing
- Soft Robot Materials and Design
## Abstract:
Soft tactile sensors have a trade off between a high sensitivity and operating over a large sensitive range. In this work, we explore extending an existing mechanism to work in the high spatial acuity, low force regime. The mechanism is based on the translocation of liquid via tubing from a thin elastomeric membrane to a location that is monitored by a camera for a readout of the stress at locations across the membrane. Here, we demonstrate that the mechanism is straightforwardly scaled to a small footprint (11mm diameter) and a large number of sensitive channels (19) simultaneously, significantly improving the sensor's acuity. We demonstrate that the sensor is able to sense the shape of small items and also able to output the signal necessary to read a set of Braille letters prepared for a human.
# Analysis of Human Gaze Behavior in Conversation While Walking: Toward Application to Mobile Social Robots
## Keywords:
- Gesture, Posture and Facial Expressions
- Design and Human Factors
- Social HRI
## Abstract:
For social robots, gaze control is important for a smooth conversation with humans. However, most research on robot gaze design has focused on tasks in which the human and robot remain in one place and has not envisioned tasks in which the human and robot converse while moving. As the first step of studies of robot gaze design in conversation during a walk, we measured two humans’ gaze direction while walking and talking. We paired eight participants and had them perform a role-play in which they conversed while walking according to several conditions. We recorded the scenes with a video camera and coded the participants’gaze direction and utterance duration from the video recordings. We measured the percentage of the listeners looking at the speaker and the speakers looking at the listeners, respectively. We found that the listeners looked at the speakers from 30% to 46% and that the speakers looked at the listeners from 29% to 58%. These results are different from previous research that assumed two-person or multi-party conversations in one place. It suggests that more in-depth research of gaze direction in walking conversations is necessary.
# Conveying Intentions for Attentive Listening by Facial Motions Using an Android
## Keywords:
- Gesture, Posture and Facial Expressions
- Natural Dialog for HRI
- Social HRI
## Abstract:
Conversational robots with human-like appearances, such as android robots, are expected to appropriately combine verbal and nonverbal expressions to realize intelligent and natural behaviors in human-robot conversations. To realize intelligent conversations by the robots, it is important to generate appropriate nonverbal motions linking the robots' intentions from their utterances. In this paper, we realize nonverbal behaviors and utterances, linking intentions from the utterances using an android to show its intentions clearly. Specifically, first, we extract facial motion patterns from a multimodal dialogue corpus where a human listens to speeches. Next, we implement the extracted motions using a novel android Nikola to show its intentions for attentive listening. Finally, we conduct a subjective evaluation of how the intention from the implemented facial motions is conveyed to a human where the android attentively listens to a human's speech. From our evaluation results, we confirmed that the facial motions using an android might be able to convey its intentions including attentive listening to a human.
# Grasping Curved Objects with an Electroadhesion Soft Gripper
## Keywords:
- Grasping
- Grippers and Other End-Effectors
- Soft Robot Applications
## Abstract:
This work addresses the problem of grasping curved objects with an Electroadhesion Soft Gripper, aiming to detect the dependence of the wrapping/zipping angle and the holding force on the applied voltage.
# An Origami-Inspired Suction Cup of Robotic Gripper for Autonomous Cucumber Harvesting
## Keywords:
- Grippers and Other End-Effectors
- Robotics and Automation in Agriculture and Forestry
- Agricultural Automation
## Abstract:
In this paper, we propose a suction cup of a robotic gripper for cucumber harvesting, as shown in Fig. 1. The gripper for the robotic harvesting system requires cutting, which is an essential specification, and grasping, which aids the stable cutting, is required. In a previous study, we proposed a gripper that satisfies both specifications and can respond to various crops. However, to expand the robotic gripper with cucumber, grasping specifications must be satisfied and that is a challenge with a general cone-type suction cup. To satisfy the requirement, we designed a cucumber# specific suction cup that is optimized for the curvature of the cucumber simplified into a cylinder.
# Stiffening Iron Powder to Grasp Objects
## Keywords:
- Grippers and Other End-Effectors
- Soft Robot Materials and Design
- Grasping
## Abstract:
We propose a novel variable stiffness mechanism that can be used to grasp objects with various sizes and shapes. The proposed system is actuated by electromagnet to apply magnetic attraction against inner soft magnetic particles (i.e., iron powder) so that they are physically coupled only at jammed state. To enclose iron powder, outer membrane that has magneto-rheological property is fabricated with dispersed iron powder. The jamming system can be applied to robotic solutions that have fast jamming transition and modularized structure. For gripping tasks, robotic palm and phalange module can be developed.
# CoaxHaptics-3RRR: A Novel Coaxial Spherical Parallel Haptic Device
## Keywords:
- Haptics and Haptic Interfaces
- Mechanism Design
## Abstract:
This paper presents a novel coaxial haptic interaction device based on a 3-RRR spherical parallel mechanism with three active degrees of freedom (DoF). The benefit of the presented parallel mechanism, which is particularly important for haptic applications, is that its dynamic moment of inertia is low while it has high structural stiffness. The mechanical design was optimized in terms of kinematics, dynamics and stiffness using a multi-criteria optimization method based on a genetic algorithm. The rotational workspace of the mechanism is unlimited for rotations in z direction and covers a range of +/# 55 degrees in the other two rotational DoF. Thus, it covers a large portion of the workspace of human wrist rotations. First tests on a functional demonstrator confirm the validity of the concept.
# Optimization-Based Positioning of Redundant Robot Arms for a Bimanual Haptic Interface
## Keywords:
- Haptics and Haptic Interfaces
- Physical Human-Robot Interaction
## Abstract:
There exists no available commercialized haptic interface for bimanual operation. Thus, utilizing redundant robot arms as a haptic device can be a proper solution. Given two redundant robot arms for a bimanual haptic interface, the location of their bases should be carefully decided because it highly affects the performance in terms of workspace and feedback force/torque rendering capability. In this study, we propose a systematic, optimization-based method to determine the setup configuration of robot arms for a bimanual haptic interface. The proposed method is applied with two Franka Emika Panda robot arms to check the validity of this study.
# Semi-Bilateral Control of 2-DOF Haptic Feedback Control Stick
## Keywords:
- Haptics and Haptic Interfaces
- Telerobotics and Teleoperation
- Physical Human-Robot Interaction
## Abstract:
When an operator feels a haptic reproduced force from a control stick by bilateral control, it is disturbed by asynchronization of position control. It includes not only a force applied to a rover’s wheel but also a restoring force.	This restoring force occurs when the position control performs asynchronously. In order to feel the reproduced force accurately, this study developed a 2-DOF haptic feedback control stick to separate it from the restoring force, proposed a semi-bilateral control, and experimented our control stick.
# A Novel High-Level Human-Machine Collaboration Method for Autonomous Vehicles Using Spatial Projection of Hand Gestures
## Keywords:
- Human-Robot Collaboration
- Human-Robot Teaming
- Human-Centered Automation
## Abstract:
In this work, we propose a tactical human-vehicle collaboration framework by leveraging the hand-landmark extraction algorithm and the augmented reality visual feedback technology. The proposed vision-based interface projects the gesture, as the driver's intention, onto the ground and feeds the projection back to the driver through the visual feedback interface. The projected intention functions as a strategical decision or planning suggestion to the vehicle while the collision avoidance, traffic rules compliance, and precise control are realized by the automation algorithm. We validate the feasibility of the framework through an integrated self-driving algorithm combining the risk field, learning-based trajectory prediction, and model predictive control.
# Changing the Consumer Panel Game with Robot Imitation Learning
## Keywords:
- Imitation Learning
- Learning from Demonstration
## Abstract:
Scalable consumer insights are a key prerequisite for creating superior physical world products (mops in this case) through a nuanced understanding of the consumer job in terms of humans and their interactions with surfaces of relevance. Both video and AI have strong roles to play in this regard # video in offering velocity of data collection that enables panels at scale, and AI in interpreting them for product efficacy in performing the job and follow-on impacts on product design. In this paper, we identify the Imitation Learning challenges in turning mopping videos into product efficacy insights by creating kinematically faithful imitations of the actions. We discuss both areas of progress around reward design for narrow tasks, as well as ongoing work on melding ML with control-theoretic methods for some contact-related metrics that significantly impact human comfort and device wear and tear.	Overall it is our goal to convince the reader that Imitation Learning has a large role to play in step-changing product design in the large market space of `narrow' everyday tasks, where nevertheless a great deal of precision in mechanistic understanding is required to create meaningful consumer benefit.
# Intrinsic Guidance Learning and Reinforcement Learning for Manipulator
## Keywords:
- Imitation Learning
- Reinforcement Learning
- Manipulation Planning
## Abstract:
Reinforcement learning (RL) has achieved good performance in various fields since its ability to solve the long-term horizon and complex non-linear problems. Despite this advantage, Applying RL to manipulators is a challenge by exploration costs such as time and damage. Imitation learning has been applied to overcome these shortcomings. However, most methods require an expert's action and must recollect the expert's demonstration depending on the platform. Humans easily mimic demonstrators no matter how they act and what they are. Like this attribute, Our method separates the actions and purpose necessary for the task. In this paper, intrinsic guidance learning (IGL) to learn the purpose of the expert and may help to train policy for a warm start are presented.
# A Low-Cost Reconfigurable Industrial Robot Design Utilising Additively Manufactured Components
## Keywords:
- Industrial Robots
- Product Design, Development and Prototyping
- Additive Manufacturing
## Abstract:
MOTIVATION Robots are increasingly being deployed for numerous applications in various industries. They are playing an increased role in creating smart factories of the future fostered by the industry 4.0 principles. The recent growth in the adoption of robots has led to some reduction in initial costs and overall operational cost of ownership. However, initial investment costs are still high, particularly when many robots must be deployed in an industrial manufacturing or processing chain. A significant reason for the increased cost in such scenarios is the use of a similar type of robot, such as a 6-DOF robot with surplus payload capacity and capability, utilised throughout the process chain. Such commercial robotic systems are often over-engineered and redundant for various tasks that render them expensive. There are sustainability concerns with these robotic solutions as they are not reusable post decommissioning.
PROBLEM STATEMENT Over-specified robotic solutions form additional overheads in terms of cost and sustainability for both low and high-payload industrial automation applications. Software optimisation improves operational efficiency and reduces the overall operational cost of the robot, but the initial investment and costs related to downtime and reusability post decommissioning of the robotic system remain high. Potentially bespoke robotic hardware emerges as a possible solution but has additional research, development, and fabrication costs. Inherent modularity and reconfigurability of design prove to be economical and sustainable options for task agnostic scenarios. To address this, in the poster, we present our in-house developed modular and reconfigurable robot, which is also reusable post-decommissioning.
MAIN RESULTS Additive Manufacturing was employed to prototype and demonstrate our modular robotic system after several design iterations. Tangible results include the design of standard and modular components which are repeatable, adaptive, and intuitive to assemble and disassemble. These components were optimised for the smallest possible footprint and accommodate standard off-the-shelf actuators using generatively designed mountings. A software framework is also presented where reachability maps combined with payload-dependent torque and inertia estimations are used to guide the optimal assembly of the modular components to achieve tasks for various industrial applications. Three different robot configurations of the modular components are demonstrated as a proof of concept: a 3DOF configuration for Visual Servoing, an articulated 6DOF for basic spatial tasks and a 7DOF redundant manipulator for better dexterity. The project is focused on ensuring that the whole system is economically viable whilst maintaining robust and reliable performance. The study indicates that the modularity and reconfigurability of the design enable the integration of off-the-shelf parts and the reuse of (... please see the uploaded document)
# 6D Instantaneous Velocity for Legged Robot Using Rolling Motion
## Keywords:
- Legged Robots
- SLAM
- Kinematics
## Abstract:
Recent works in quadruped robot simultaneous localization and mapping (SLAM) have shown advances by incorporating the contact sensor and joint sensor. Whereas existing methods assumed the contact frame to be fixed to the ground on the contact state, ignoring the effect of rolling motion and its drift, we propose using rolling motion of contact frame to calculate the 6D instantaneous velocity of a legged robot’s base about the world frame. Using this derivation, we estimate 6D velocity exploiting IMU preintegration and forward kinematics.
# Localization for Mobile Robots with a Multi-ToF Camera System
## Keywords:
- Localization
- Range Sensing
- Autonomous Vehicle Navigation
## Abstract:
Time-of-Flight(ToF) camera, thanks to its low price and small size, can play a major role in the commercialization of low-cost autonomous mobile robots. However, due to the limitations, such as mixed pixel effect and multipath interference, the measurement of the ToF camera is noisy and inaccurate. Therefore, in order to obtain high-quality pose estimation with the low-cost ToF camera, a preprocessing process and localization algorithm considering the characteristics of the ToF camera are essential. In this paper, we experimented with the possibility of localization using a multi-ToF camera system. The scan data was analyzed by comparing it with the high-resolution map acquired with the high-precision 3D LiDAR, and a preprocessing process for localization was implemented, taking account of the analyzed characteristics. The capability of localization using the multi-ToF camera system was demonstrated by implementing the localization algorithm using the ICP algorithm.
# Pointclouds Integration from Aerial and Ground View Exploiting Normal Vector and Pose Graph Optimization
## Keywords:
- Localization
- Range Sensing
- Multi-Robot SLAM
## Abstract:
Recent advances in simultaneous localization and mapping (SLAM) have enabled the construction of accurate maps through various systems. In particular, unmanned aerial vehicles (UAV) and unmanned ground vehicles (UGV) are two of the systems being utilized. Using two platforms necessitates the combining of each map to alleviate disadvantages and exploit advantages. In this paper, we propose a method for integrating UAV and UGV maps exploiting normal vector and Pose Graph Optimization (PGO). Our method creates a scan context using a normal vector, finding an overlapping area between the two maps. Furthermore, the trajectory of UGV is placed on the UAV map by utilizing the anchor node and PGO. Then, the partial map from UGV is combined with the UAV map to integrate them. We validate our method at a large construction site.
# Compressive Self-Localization Using Relative Attribute Embedding
## Keywords:
- Localization
- Recognition
- Visual Learning
## Abstract:
Most current state-of-the-art visual place recognition (VPR) algorithms employ absolute attribute (e.g., color, shape, texture) -based image embedding for image feature description and image similarity search. In this study, we are interested in relative attributes (e.g., beautiful, safe, convenient)-based image embedding, as it is a domain-adaptive compact image description and it is orthogonal to existing absolute attributes-based embeddings. Specifically, we present two different solutions based on binary and real-valued relative attribute strength and experimentally evaluate them via cross-season VPR experiments.
# Robust Visual Localization for Low-Textured Indoor Environments
## Keywords:
- Localization
- Vision-Based Navigation
## Abstract:
Robust visual localization in indoor environments is essential for long-term autonomy. This paper introduces visual localization method in low-textured and ambiguous indoor environments such as corridors.
# Robotic Control in Adversarial and Sparse Reward Environments: A Robust Goal-Conditioned Reinforcement Learning Approach
## Keywords:
- Machine Learning for Robot Control
- Reinforcement Learning
- Robust/Adaptive Control
## Abstract:
This paper presents a novel robust goal-conditioned reinforcement learning (RGCRL) approach for robotic control in adversarial and sparse reward environments. The proposed method is evaluated on three tasks with adversarial attacks and sparse reward settings. The results show that our scheme can ensure robotic control performance and policy robustness on the adversarial and sparse reward tasks.
# Dual Arm Manipulation Strategy of Flexible Cables for the Wiring Harness Assembly Automation
## Keywords:
- Manipulation Planning
- Dual Arm Manipulation
- Dexterous Manipulation
## Abstract:
The wiring harness assembly process is mostly carried out manually, because the recognition with the vision system and robotic manipulation are very difficult due to the flexibility of cables. Nowadays, there is an increasing demand for robotic automation for manufacturing process innovation in spite of its challenges. In the paper, the multi-robot-based automation cell is designed for the wiring harness assembly task on the assembly board. The robotic assembly strategy was automatically generated from the standard drawing and process instructions through the assembled information. The primitive motion-based multi-robot cooperative task for complex flexible arrangement was proposed and was verified through simulations and experiments.
# Parsing Indoor Manhattan Scenes Using Four-Point LiDAR on a Micro UAV
## Keywords:
- Mapping
- SLAM
- Aerial Systems: Applications
## Abstract:
This paper presents the first 3D mapping algorithm that parses the Manhattan scenes using low-cost four-point LiDAR suitable for micro UAV. We evaluate the proposed method with other mapping algorithms on the various Manhattan world structures from room-size to building-size.
# Robust Sonar-Based Place Recognition in Underwater Environments
## Keywords:
- Marine Robotics
- Localization
- SLAM
## Abstract:
In the underwater, visual place recognition (PR) is difficult because of low visibility. In contrast, SOund Navigation And Ranging (Sonar) is robust for turbid water, therefore sonar-based PR is more appropriate in underwater. However, sonar measurements often suffer from noise and low resolution. In this paper, we propose a robust sonar-based PR method called sonar context (SC) for the global descriptor.
# A New General Approach for Model-Based Control of Underactuated AUV Based on Kinematic Coupling
## Keywords:
- Marine Robotics
- Underactuated Robots
- Autonomous Vehicle Navigation
## Abstract:
In this work, a new control strategy for underactuated autonomous underwater vehicles is introduced. This new method relies on the kinematic coupling between nonactuated and actuated degrees of freedom. It uses the new “Handy matrix H” introduced in this paper which allows for the exploitation of the kinematic couplings in the control law. The algorithm and design rules leading to the construction of H are also provided in details. Two different solutions based on matrix H are compared on the usual seabed scanning task.
# Robotic Rope Ascender Design and Analysis for 3D Shape Surface Operation
## Keywords:
- Mechanism Design
- Actuation and Joint Mechanisms
- Climbing Robots
## Abstract:
This late-breaking poster paper presents a mobile robot on a 3D convex surface such as a cylindrical building or a dome-shaped structure. The robot can move two fiber ropes up and down in a convex surface using an inside mounted ascender. The rope ascender uses a differential gear sysmtem to minimize problems caused by slip between the rope and the sheave. In addition, the differential gear system is implemented using spur gears, making it extremely light and compact. The accessibility analysis of the robot on the 3D surface was performed through static analysis based on Dijkstra’s algorithm.
# Stabilization Mechanism for Shoulder Mounted Supernumerary Robotic Limb
## Keywords:
- Mechanism Design
- Body Balancing
- Human Performance Augmentation
## Abstract:
Supernumerary Robotic Limbs (SRL) are medium to large scale robotic limbs, often designed to be mounted on a user’s upper body. As part of the present work, we developed a robot arm with 3 Degrees of Freedom and a total weight of 5kg to be mounted on the shoulder. The designed robot was designed for extended reach and multi# tasking. When considering wearable robotics, one of the main factor impacting the comfort of the wearer and the quality of the tasks completed by the robot arm and its user is the bio-mechanical loads induced during motion of either (or both) parties on the other. These manifest themselves as disturbances in the robot arm’s planned trajectory, or sudden shifts in user posture (or even loss of balance) as the robot arm moves. Some studies have chosen to address the issue through the use of deep learning, by anticipating how they will affect the robot arm’s trajectory. In this study however, we chose to take a hardware design approach, and designed a backpack-inspired wearing system which includes a stabilization mechanism aimed at minimizing these disturbances. The backpack-like design of the overall system, allows for a dissipation of the weight to back and lower-back muscles (use of a waist belt) and avoiding backlash between the harness and the body , while the stabilization mechanism compensates torsional and translational movements.
# A Study on Robotic Tail Mechanisms for Stair-Climbing Application
## Keywords:
- Mechanism Design
- Climbing Robots
- Wheeled Robots
## Abstract:
Abstract
 This study proposed several tail mechanisms to solve the limitations of tri-wheel-based stair-climbing robots. Through comparative analysis using dynamic simulations based on various performance indices, it was observed that the tail mechanisms improved the stability and stair-climbing performance of the robot.
I. Introduction
 Numerous robots have been studied to overcome stairs, including robots with legs, wheels, tracks, and linkage mechanisms. Several studies have been conducted on tri-wheel-based robots for stair climbing. However, these robots have several drawbacks such as impact during locomotion, and damage and friction problems owing to contact with the nosing of the stairs. These drawbacks degrade the performance of tri-wheel-based stair-climbing robots, specifically their stability and climbing ability. In this study, several tail mechanisms were proposed to solve the limitations of tri-wheel-based stair climbing robots. Furthermore, this study sought to create tail mechanisms that could improve stair-climbing performance while being simple and passive without applying an actuator or complex mechanism, and that could also enable flat driving.
II. Tail mechanism design
 Curved-spoke tri-wheel(CSTW) based stair climbing robot has a conventional simple rod-shaped tail mechanism cite{kim2019curved}, and the aforementioned limitations exist due to this form of tail mechanism. The tail mechanisms proposed to solve these problems include the curved linkage mechanism, tri-wheel mechanism, compliant mechanism with torsion spring and rotary damper(CPL-SD), and compliant mechanism with translational spring(CPL-S). Each tail mechanism was designed using various design parameters for stable stair-climbing and flat terrain driving.
III. Comparison with dynamic simulation
 Comparative analysis was carried out to evaluate the proposed tail mechanisms for tri-wheel-based robots through dynamic simulation using a commercial dynamic simulation tool based on various performance indices such as mechanical complexity, center of mass(CM) trajectory, acceleration of CM, friction requirement, torque requirement, climbing speed, and a normalized single performance index.
IV. Conclusions
 Comparative analysis confirmed that applying these tail mechanisms can not only ensure that the tri-wheel-based stair-climbing robots have excellent stair climbing stability and performance but also solve problems that tend to affect stair climbing.
# Energy Saving of Actuator Via Integration of Variable Gravity Compensation Module
## Keywords:
- Mechanism Design
- Engineering for Robotic Systems
- Kinematics
## Abstract:
This paper proposes a new type of energy-efficient actuator called variable gravity compensation module integrated actuator (VGCA). VGCA improves the energy efficiency by compensating the gravitational torque at the target joint. Additionally, the variability of compensation torque can further improve the energy efficiency by dealing with the variation of payload, which is required in many robotic applications. As a core part of the VGCA, a compact variable gravity compensation module, called CVGCm, is a cylindrical compact modular unit based on the cam and variable pivot of the lever mechanism. The experimental results showed that the CVGCm achieved a rapid change of the compensation torque in the compact module. Furthermore, compared to the actuator without CVGCm, VGCA showed a reduction of current and power in static and dynamic motion, respectively.
# Screw Robot with Switching Primitives
## Keywords:
- Mechanism Design
- Field Robots
- Service Robotics
## Abstract:
Abstract In this study, we propose a mobile robot that can be driven in various environments through a robot in the form of a combination of a normal circular wheel and a screw-based wheel. The robot determines and drives a movement mechanism suitable for the environment through a switching mechanism. 1.Introduction With the development of mobile robots, the need for mobile robots that can operate in various environments is increasing, and related research is being actively conducted. Screw-based wheel mechanisms are promising solutions in rough terrain such as snow, mud, and granular surfaces. The screw-based wheel platform takes the form of a spiral blade attached to a cylindrical wheel. The two wheels are paired and operated to determine the next driving direction. However, screw-based wheels exhibit slow driving speed and high output requirements due to the weight of the wheels and the special methods of wheel operation. Therefore, the screw-based mechanism cannot be used as an independent operation method. In this study, we propose a mobile robot that uses both regular and screw-based wheels and selects them according to the external environment through a switching mechanism. 2.Mechanism of robot When a robot travels on a general road, it is in a wheel mode state and can travel at a high speed. When a robot faces an environment in which it cannot proceed with a normal circular wheel such as sand while driving, it is converted into a screw-mode by stretching its folded arms using a DC motor. After that, the screw-based wheel is rotated, and the blade pushes the sand and moves forward. 3.Conclusions The need for robots that can move in various environments has emerged. This research conducted an experiment by designing a robot using ordinary wheels and screw-based wheels. Experiments show that robot move forward by the screw-based wheel rotates and the blade of the wheel pushes the sand.
# Design of a Wheel-Leg Mechanism for a Façade Operation
## Keywords:
- Mechanism Design
- Legged Robots
- Climbing Robots
## Abstract:
According to 3D-shaped building being built in these days, Façade cleaning and maintenance of 3D-shaped buildings has been an important issue and many studies have been conducted for this issue. The robot using 2-DoF rope rider mechanism for façade operation showed the easy-installation and omni-directional movement on high-rise vertical facade. But this robot has some limitation for 3D-façade operation. In the case of low slope, the rope cannot pull the robot properly since the friction of the passive wheels supporting the facade increases. Also, it is difficult to overcome obstacles on the wall such as step and snow guard. Therefore, a wheel-leg mechanism is proposed to solve this 3D-façade operation. The active wheel assists the movement of the rope in the case of low slope and can overcome obstacles using the leg mechanism.
The proposed wheel leg mechanism is attached to the bottom side of the rope rider robot and consists of 3-DoF leg and an active mecanum wheel and 1-DoF turret. Since the 2-DoF Rope Rider mechanism has omni-directional movement, a mecanum wheel is proposed as an active wheel. Also, A turret mechanism is proposed in order to keep the rope direction toward top side and to rotate only wheel leg mechanism. With 3-DoF leg, the robot can overcome high obstacle such as step, and With 3-DoF leg and active mecanum wheel, the robot can overcome low obstacle compliantly.
In the future, we will conduct 3D-facade operation including overcoming obstacles and verify the proposed mechanism.
# Award Session III
# 1-Degree-Of-Freedom Robotic Gripper with Infinite Self-Twist Function
(Finalist for IROS Best Paper Award on Robot Mechanisms and Design Sponsored by ROBOTIS)
## Keywords:
- Grippers and Other End-Effectors
- Mechanism Design
- Grasping
## Abstract:
This study proposes a novel robotic gripper that can achieve grasping and infinite wrist twisting motions using a single actuator. The gripper was equipped with a differential gear mechanism that enabled switching between the grasping and twisting motions according to the magnitude of the tip force applied to the finger. The grasping motion is enabled when the tip force is below a set value and the wrist twisting motion is activated when the tip force exceeds the set value. "Twist grasping", which is a special grasping mode that allows the wrapping of a flexible thin object around the fingers of the gripper, can be achieved through the twisting motion. Twist grasping is effective for handling an object with flexible thin parts, such as laminated packaging pouches, which are difficult to grasp using conventional antipodal grasping. In this study, the gripper design is presented, and twist grasping is analyzed. The gripper performance is experimentally validated.
# Aerial Grasping and the Velocity Sufficiency Region
(Finalist for IROS Best Paper Award on Robot Mechanisms and Design Sponsored by ROBOTIS)
## Keywords:
- Grasping
- Mechanism Design
- Aerial Systems: Applications
## Abstract:
A largely untapped potential for aerial robots is to capture airborne targets in flight. We present an approach in which a simple dynamic model of a quadrotor/target inter# action leads to the design of a gripper and associated velocity sufficiency region with a high probability of capture. A model of the interaction dynamics maps the gripper force sufficiency region to an envelope of relative velocities for which capture should be possible without exceeding the capabilities of the quadrotor controller. The approach motivates a gripper design that emphasizes compliance and is passively triggered for a fast response. The resulting gripper is lightweight (23g) and closes within 12 ms. With this gripper, we demonstrate in-flight experiments that a 550g drone can capture an 85g target at various relative velocities between 1m/s and 2.7m/s.
# Automated Design of Task Specific Additively Manufacturable Coupled Serial Chain Mechanisms for Tracing Predefined Planar Trajectories
(Finalist for IROS Best Paper Award on Robot Mechanisms and Design Sponsored by ROBOTIS)
## Keywords:
- Mechanism Design
- Additive Manufacturing
- Kinematics
## Abstract:
This work presents the automatic design of additively manufacturable serially linked one degree of freedom manipulators whose end effectors move along individually prescribed 2D trajectories. The kinematic coupling of the links is done by using gear stages consisting of spur gears and toothed belt gears. The basic design parameters of these mechanisms are determined using a Fourier series. The calculated Fourier elements with their respective frequency, amplitude and phase are interpreted as rotating 2D vectors which represent the manipulator links. Based on this, the kinematic coupling of the links is calculated and the corresponding gears are designed. All parts of these mechanisms, including the toothed belts, can be manufactured using a low cost 3D printing process. The software for the automated design of these manipulators from Fourier decomposition to CAD file generation has been implemented in MATLAB. To validate the automated design process, various test mechanisms were manufactured and examined for accuracy and precision.
# Robot Learning to Paint from Demonstrations
(Finalist for IROS Best Entertainment and Amusement Paper Award Sponsored by JTCF)
## Keywords:
- Learning from Demonstration
- Continual Learning
- Art and Entertainment Robotics
## Abstract:
Robotic painting tasks in the real world are often made complicated by the highly complex and stochastic nature of the dynamics that underlie, e.g., physical contact between the painting tool and a canvas, color blendings between painting mediums, and many more. Simulation-based inverse graphics algorithms, for example, can not be directly transferred to the real-world due in large to the considerable gap in the viable range of painting strokes the robot can accurately generate onto the physical canvas. In this paper, we aim at minimizing this gap by appealing to a data-driven skill learning approach. The core idea lies in allowing the robot to learn continuous stroke-level skills that jointly encodes action trajectories and painted outcomes from an extensive collection of human demonstrations. We demonstrate the efficacy of our method through extensive real-world experiments using a 4-dof torque-controllable manipulator with a digital canvas(iPad).
# The Wheelbot: A Jumping Reaction Wheel Unicycle
(Finalist for IROS Best Entertainment and Amusement Paper Award Sponsored by JTCF)
## Keywords:
- Wheeled Robots
- Underactuated Robots
- Nonholonomic Mechanisms and Systems
## Abstract:
Combining off-the-shelf components with 3D-printing, the Wheelbot is a symmetric reaction wheel unicycle that can jump onto its wheels from any initial position. With nonholonomic and under-actuated dynamics, as well as two coupled unstable degrees of freedom, the Wheelbot provides a challenging platform for nonlinear and data-driven control research. This paper presents the Wheelbot’s mechanical and electrical design, its estimation and control algorithms, as well as experiments demonstrating both self-erection and disturbance rejection while balancing.
# Robot Dance Generation with Music Based Trajectory Optimization
(Finalist for IROS Best Entertainment and Amusement Paper Award Sponsored by JTCF)
## Keywords:
- Art and Entertainment Robotics
- Optimization and Optimal Control
- Humanoid Robot Systems
## Abstract:
Musical dancing is an ubiquitous phenomenon in the human society. Providing robots the ability to dance has the potential to make the human robot co-existence more acceptable in our society. Hence, dancing robots have generated a considerable research interest in the recent years. In this paper, we present a novel formalization of robot dancing as planning and control of optimally timed actions based on beat timings and additional features extracted from the music. We showcase the use of this formulation in three different variations: with input of human expert choreography, imitation of a predefined choreography, and automated generation of a novel choreography. Our method has been validated on four different musical pieces, both in simulation and on a real robot, using the upper-body humanoid robot RH5 Manus.
# Award Session IV
# Learning on the Job: Long-Term Behavioural Adaptation in Human-Robot Interactions
(Finalist for IROS Best Paper Award on Cognitive Robotics Sponsored by KROS)
## Keywords:
- Social HRI
- Reinforcement Learning
- Art and Entertainment Robotics
## Abstract:
In this work, we propose a framework for allowing autonomous robots deployed for extended periods of time in public spaces to adapt their own behaviour online from user interactions. The robot behaviour planning is embedded in a Reinforcement Learning (RL) framework, where the objective is maximising the level of overall user engagement during the interactions. We use the Upper-Confidence-Bound Value-Iteration (UCBVI) algorithm, which gives a helpful way of managing the exploration-exploitation trade-off for real-time interactions. An engagement model trained end-to-end generates the reward function in real-time during policy execution. We test this approach in a public museum in Lincoln (UK), where the robot is deployed as a tour guide for the visitors. Results show that after a couple of months of exploration, the robot policy learned to maintain the engagement of users for longer, with an increase of 22.8% over the initial static policy in the number of items visited during the tour and a 30% increase in the probability of completing the tour. This work is a promising step toward behavioural adaptation in long-term scenarios for robotics applications in social settings.
# Robotic Detection of a Human-Comprehensible Gestural Language for Underwater Multi-Human-Robot Collaboration
(Finalist for IROS Best Paper Award on Cognitive Robotics Sponsored by KROS)
## Keywords:
- Marine Robotics
- Multi-Robot Systems
- Visual Learning
## Abstract:
In this paper, we present a motion-based robotic communication framework that enables non-verbal communication among autonomous underwater vehicles (AUVs) and human divers. We design a gestural language for AUV-to-AUV communication which can be easily understood by divers observing the conversation — unlike typical radio frequency, light, or audio-based AUV communication. To allow AUVs to visually understand a gesture from another AUV, we propose a deep network (RRCommNet) which exploits a self-attention mechanism to learn to recognize each message by extracting maximally discriminative spatio-temporal features. We train this network on diverse simulated and real-world data. Our experimental evaluations, both in simulation and in closed-water robot trials, demonstrate that the proposed RRCommNet architecture is able to decipher gesture-based messages with an average accuracy of 88-94% on simulated data and 73-83% on real data (depending on the version of the model used). Further, by performing a message transcription study with human participants, we also show that the proposed language can be understood by humans with an overall transcription accuracy of 88%. Finally, we discuss the inference runtime of RRCommNet on embedded GPU hardware, for real-time use on board AUVs in the field.
# Intuitive & Efficient Human-Robot Collaboration Via Real-Time Approximate Bayesian Inference
(Finalist for IROS Best Paper Award on Cognitive Robotics Sponsored by KROS)
## Keywords:
- Human-Robot Collaboration
- Intention Recognition
- Probabilistic Inference
## Abstract:
The combination of collaborative robots and end-to-end AI, promises flexible automation of human tasks in factories and warehouses. However, such promise seems a few breakthroughs away. In the meantime, humans and cobots will collaborate helping each other. For these collaborations to be effective and safe, robots need to model, predict and exploit human's intents for responsive decision making processes.
Approximate Bayesian Computation (ABC) is an approach to perform probabilistic predictions upon uncertain quantities. ABC includes priors conveniently, leverages sampling algorithms for inference and is flexible to benefit from complex models, e.g. via simulators. However, ABC is known to be computationally too intensive to run at interactive frame rates required for effective human-robot collaboration tasks.
In this paper, we formulate human intent prediction as an ABC problem and describe two key performance innovations which allow computations at interactive rates. Our real-world experiments with a collaborative robot set-up, demonstrate the viability of our proposed approach. Experimental evaluations convey the advantages and value of human intent prediction for packing cooperative tasks. Qualitative results show how anticipating human's intents improves human-robot collaboration without compromising safety. Quantitative task fluency metrics confirm the qualitative claims.
# Gesture2Vec: Clustering Gestures Using Representation Learning Methods for Co-Speech Gesture Generation
(Finalist for IROS Best Paper Award on Cognitive Robotics Sponsored by KROS)
## Keywords:
- Gesture, Posture and Facial Expressions
- Social HRI
- Representation Learning
## Abstract:
Co-speech gestures are a principal component in conveying messages and enhancing interaction experiences between humans and critical ingredients in human-agent interaction, including virtual agents and robots. Existing machine learning approaches have yielded only marginal success in learning speech-to-motion at the frame level. Current methods generate repetitive gesture sequences that lack appropriateness with respect to the speech context. To tackle this challenge, we take inspiration from successes in natural language processing on context and long-term dependencies, and propose a new framework that views text-to-gesture as machine translation, where gestures are words in another (non-verbal) language. We propose a vector-quantized variational autoencoder structure as well as training techniques to learn a rigorous representation of gesture sequences. We then translate input text into a discrete sequence of associated gesture chunks in the learned gesture space. Ultimately, we use translated gesture tokens from the input text as an input to the autoencoder’s decoder to produce gesture sequences. Subjective and objective evaluations confirm the success of our approach in terms of appropriateness, human-likeness, and diversity. We also introduce new objective metrics using the quantized gesture representation.
# Robowflex: Robot Motion Planning with MoveIt Made Easy
(Finalist for IROS Best Paper Award for Industrial Robotics Research with Real-World Applications Sponsored by Mujin Inc.)
## Keywords:
- Software, Middleware and Programming Environments
- Software Tools for Benchmarking and Reproducibility
- Motion and Path Planning
## Abstract:
Robowflex is a software library for robot motion planning in industrial and research applications, leveraging the popular MoveIt library and Robot Operating System (ROS) middleware. Robowflex provides an augmented API for crafting and manipulating motion planning queries within a single program, making motion planning with MoveIt easy. Robowflex’s high-level API simplifies many common use-cases while still providing low-level access to the MoveIt library when needed. Robowflex is particularly useful for 1) developing new motion planners, 2) evaluating motion planners, and 3) complex problems that use motion planning as a subroutine (e.g., task and motion planning). Robowflex also provides visualization capabilities, integrations to other robotics libraries (e.g., DART and Tesseract), and is complementary to other robotics packages. With our library, the user does not need to be an expert at ROS or MoveIt to set up motion planning queries, extract information from results, and directly interface with a variety of software components. We demonstrate its efficacy through several example use-cases.
# Absolute Position Detection in 7-Phase Sensorless Electric Stepper Motor
(Finalist for IROS Best Paper Award for Industrial Robotics Research with Real-World Applications Sponsored by Mujin Inc.)
## Keywords:
- Actuation and Joint Mechanisms
- Failure Detection and Recovery
- Industrial Robots
## Abstract:
Absolute position detection in sensorless electric stepper motors potentially allows for higher space efficiency, improved shock resistance, simplified installation, reduced number of parts and lowered cost.
A prototype is demonstrated measuring 42 x 52 x 34 mm³ with seven coils arranged in a star configuration. The rotor is ø25.8 x 12.5 mm² and has 51 teeth which are irregularly spaced. The coil currents are measured during motion in order to reconstruct the absolute position of the motor. Calibration and smoothing techniques are used to reduce systematic and stochastic measurement errors, respectively. 
The motor is able to detect and correct its position after externally-induced stalls at the tested motor speeds from 40 rpm to 108 rpm. The holding torque is 0.23 Nm at an armature current of 1 A; on average the torque is 7% lower than that of a reference bipolar stepper motor with the same dimensions.
The results show that dynamic position sensing and correction are possible for a range of velocities, but not at standstill. The driver requires seven current sensors and sufficient computational power, and proper calibration of motor intrinsics is required beforehand. The presented technology could make existing 3-D printers and other machines with open-loop stepper motors more robust and increase the range of operating speeds and accelerations, without the adverse side-effects of increased complexity and cost associated with dedicated position sensors.
# Grasping 3
# A Novel Simulation-Based Quality Metric for Evaluating Grasps on 3D Deformable Objects
## Keywords:
- Grasping
## Abstract:
Evaluation of grasps on deformable 3D objects is a little-studied problem, even if the applicability of rigid object grasp quality measures for deformable ones is an open question. A central issue with most quality measures is their dependence on contact points, which for deformable objects depend on the deformations. This paper proposes a grasp quality measure for deformable objects that uses information about object deformation to calculate the grasp quality. Grasps are evaluated by simulating the deformations during grasping and predicting the contacts between the gripper and the grasped object. The contact information is then used as input for a new grasp quality metric to quantify the grasp quality. The approach is benchmarked against two classical rigid-body quality metrics on over 600 grasps in the Isaac gym simulation and over 50 real-world grasps. Experimental results show an average improvement of 18% in the grasp success rate for deformable objects compared to the classical rigid-body quality metrics. Furthermore, the proposed approach is approximately fifteen times faster to calculate than the shake, which, to date, is one of the most reliable approaches to quantify a grasp on a deformable object.
# Optimal Nonprehensile Interception Strategy for Objects in Flight
## Keywords:
- Dexterous Manipulation
- Optimization and Optimal Control
- Compliance and Impedance Control
## Abstract:
Intercepting an object in flight through nonprehensile manipulation is a challenging problem, which is aimed at catching and stopping a flying object using little contacts without completely restraining its relative motion to the robot. This paper presents a two-stage optimal trajectory generation method to tackle this problem. At the pre-catching stage, optimal position and attitude trajectories of the robot's end-effector to approach the object are generated by a variational method. At the post-catching stage, the end-effector's trajectories are generated to optimally eliminate the translational and rotational motion of the object and a convex-MPC algorithm combined with admittance control is used to realize the trajectory tracking. A series of simulations and experiments have been conducted to verify the effectiveness of the proposed method.
# MasKGrasp: Mask-Based Grasping for Scenes with Multiple General Real-World Objects
## Keywords:
- Perception for Grasping and Manipulation
- Deep Learning in Grasping and Manipulation
- Deep Learning for Visual Perception
## Abstract:
 In this paper, we introduce a mask-based grasping method that discerns multiple objects within the scene regardless of transparency or specularity, and finds the optimal grasp position avoiding clutter. Conventional vision-based robotic grasping approaches often fail to extend to the scenes containing transparent objects due to the different visual appearance. To handle their different visual characteristics, we first segment objects into instance masks, which serve as the domain-agnostic intermediate representations of both types of objects, using a neural network. The neural network is trained to stably segment both transparent and opaque objects. While there exists no labelled dataset strongly representing both types of objects, we overcome the limitation by augmenting transparent objects on an existing large-scale dataset. Then, given the output object instance masks, our method selects the top K discrete masks and robustly estimates grasp poses avoiding clutter. Through experiments, we verify that the instance masks are light-weight yet provide sufficient information for vision-based grasping agnostic of various appearances. On an unseen realworld test environment with complex real-world objects, our method substantially outperforms previous methods without fine-tuning.
# Development of Pneumatically Driven Tensegrity Manipulator without Mechanical Springs
## Keywords:
- Flexible Robotics
- Biologically-Inspired Robots
- Redundant Robots
## Abstract:
This paper reports a tensegrity manipulator driven by 40 pneumatic cylinders without mechanical springs. In general, tensegrity robots use mechanical springs to achieve a stable/curved tensegrity structure, and this is true even when a component extends/retracts with an actuator. The stiffness of the mechanical spring should be high to increase the stiffness of the entire structure and improve the control response, but low to deform the structure. This fact means that the introduction of mechanical springs causes serious trade-offs in its design and control. In this study, we use pneumatic actuators not only for active deformation but also for passive. In this paper, we introduce the design and control system and then show the difference in response characteristics between the case with and without a spring, demonstrating the importance of the approach without a mechanical spring.
# Fixture-Aware DDQN for Generalized Environment-Enabled Grasping
## Keywords:
- Grasping
- Perception for Grasping and Manipulation
- Deep Learning in Grasping and Manipulation
## Abstract:
This paper expands on the problem of grasping an object that can only be grasped by a single parallel gripper when a fixture (e.g., wall, heavy object) is harnessed. Preceding work that tackle this problem are limited in that the employed networks implicitly learn specific targets and fixtures to leverage. However, the notion of a usable fixture can vary in different environments, at times without any outwardly noticeable differences. In this paper, we propose a method to relax this limitation and further handle environments where the fixture location is unknown. The problem is formulated as visual affordance learning in a partially observable setting. We present a self-supervised reinforcement learning algorithm, Fixture-Aware Double Deep Q-Network (FA-DDQN), that processes the scene observation to 1) identify the target object based on a reference image, 2) distinguish possible fixtures based on interaction with the environment, and finally 3) fuse the information to generate a visual affordance map to guide the robot to successful Slide-to-Wall grasps. We demonstrate our proposed solution in simulation and in real robot experiments to show that in addition to achieving higher success than baselines, it also performs zero-shot generalization to novel scenes with unseen object configurations.
# Learning Push-Grasping in Dense Clutter
## Keywords:
- Perception for Grasping and Manipulation
- Grasping
## Abstract:
Robotic grasping in highly cluttered environments remains a challenging task due to the lack of collision free grasp affordances. In such conditions, non-prenhensile actions could help to increase such affordances. We propose a multi-fingered push-grasping policy that creates enough space for the fingers to wrap around the target object to perform a stable power grasp, using a single primitive action. Our approach learns a direct mapping from visual observations to actions and is trained in a fully end-to-end manner. To achieve a more efficient learning, we decouple the action space by learning separately the robot hand pose and finger configuration. Experiments in simulation demonstrate that the proposed push-grasping policy achieves higher grasp success rate over baselines and that can generalize to unseen objects. Furthermore, although training is performed in simulation the learned policy is robustly transferred to a real environment without a significant drop in success rate.
# Grasping Strategy for Unknown Objects Based on Real-Time Grasp-Stability Evaluation Using Proximity Sensing
## Keywords:
- Perception for Grasping and Manipulation
- Multifingered Hands
- Reactive and Sensor-Based Planning
## Abstract:
This letter proposes a robust grasping strategy for unknown objects by performing non-contact grasp-stability evaluation based on proximity sensing. First, we developed a proximity sensor for a multi-fingered hand. Its features are sensor mounting on a spherical fingertip and coating with transparent resin, which are advantageous for nearest point estimation and fingertip motion generation. Next, we realized consecutive evaluation of grasp-stability based on force-closure with assuming the nearest points to be the contact points. By introducing a high-speed sensing and calculation method, the grasp-stability can be consecutively evaluated and updated as the hand moves around the object. Then, we implemented a grasping strategy that adaptively activates multiple motion-primitives based on the information on the nearest points and the grasp-stability. It executes unknown-object grasping by searching for a pose with high grasp-stability and approaching the fingertip to realize the pose. The effectiveness of the methods was confirmed by actual experiments.
# Resonant Pneumatic Tactile Sensing for Soft Grippers
## Keywords:
- Soft Sensors and Actuators
- Grasping
- Force and Tactile Sensing
## Abstract:
Soft robots capable of dexterous manipulation can enable the exploration of extreme environments. Equipping these robots with tactile sensing is a challenge, as sensors must be flexible, stretchable, and robust to environmental conditions. We present a tactile sensor design with a pneumatically driven acoustic resonator, without electronics near from the end-effector. For applications to soft grippers, we measure the resonant frequency of a soft tube undergoing stretching and bending. A small hole along the resonant tube enables contact sensing and pretouch up to 2mm away. We also measure resonant frequency for a rigid uni-axial force sensing probe. Grasping tasks utilize three sensing modalities of a soft gripper; finger pose, fingertip contact, and force in the palm all provide feedback for dexterous manipulation. We discuss and address in future work the effects of atmosphere and air flow rate on resonant frequency as well as limitations in signal processing of this sensor design.
# A Mechanical Screwing Tool for 2-Finger Parallel Grippers -# Design, Optimization, and Manipulation Policies (I)
## Keywords:
- Grasping
- Grippers and Other End-Effectors
- Manipulation Planning
## Abstract:
This paper develops a mechanical screwing tool and its manipulation policies for 2-finger parallel robotic grippers. The tool is based on a combined Scissor-Like Element (SLE) and a double-ratchet mechanism that converts the gripping motion of 2-finger parallel grippers into a continuous rotation to realize tasks like fastening screws. The tool is entirely mechanical. There is no need for external cable connections. The manuscript includes two parts. For one thing, it shows the details of the tool design, optimizes the tool's dimensions and effective stroke lengths, and studies the contacts and forces to achieve stable grasping and screwing. For another, it presents the related manipulation and control policies, including recognizing the tool, changing tool poses, and completing screw fastening tasks. The designed tool, together with the related manipulation and control policies, are analyzed and verified in several real-world applications. The results show that the tool has satisfying mechanical properties. Robots with parallel grippers can robustly and flexibly use the tool to fasten screws. The tool can also be used collaboratively with other tools to finish difficult tasks. In the future, similar tools are expected to replace special-purpose end-effectors or tool changers for more flexible robot integration.
# Manipulation Systems 3
# Tactile-Guided Dynamic Object Planar Manipulation
## Keywords:
- Manipulation Planning
- Contact Modeling
- Sensor-based Control
## Abstract:
Planar pushing is a fundamental robot manipulation task with most algorithms built upon the quasi-static assumption. Under this assumption the end-effector should apply force on the pushed object along the full moving trajectory. This means that the target position must lie in the robot's workspace. To enable a robot to deliver objects outside of its workspace and facilitate faster delivery, the quasi-static assumption should be lifted in favour of dynamical manipulation. In this work, we propose a two-staged data-driven manipulation method to hit an unknown object to reach a target position. This expands the reachability of the manipulated object beyond the robot's workspace. The robot equipped with a tactile sensor first explores for the stable pushing region (SPR) on the given object by using a gain-scheduling PD control with the contact centre estimated to maintain full contact between the object and the end-effector. In the second stage, a learning-based approach is used to generate the impulse the object should receive at the SPR to reach a target sliding distance. The performance of proposed method is evaluated on a KUKA LBR iiwa 14 R820 robot manipulator and a XELA tactile sensor.
# 3D Visual-Based Tension Control in Strip-Like Deformable Objects Using a Catenary Model
## Keywords:
- Perception for Grasping and Manipulation
- Visual Servoing
- Force Control
## Abstract:
In recent years, there has been a growing interest in robotic manipulation of deformable objects. In order to perform certain tasks, the robot must control the shape of the object while taking care not to apply excessive stresses so as not to deform it irreversibly. This is the case when extracting elasto-plastic objects in strips from an industrial reel. In order to control the mechanical stresses within the object, we propose a vision-based control scheme to minimize tension by regulating the angular velocity of a motorized reel on which they are wound. In this paper, we propose a method, based on a catenary model and visual feedback from a low-cost RGB-D camera, to estimate the tension distribution along a rubber strip. Thus, the control strategy aims to achieve a desired tension value by varying the length of the suspended portion of the manipulated strip. Simulation and experimental results validate the proposed approach for strip-like objects of various dimensions.
# DGBench: An Open-Source, Reproducible Benchmark for Dynamic Grasping
## Keywords:
- Perception for Grasping and Manipulation
- Performance Evaluation and Benchmarking
- Grasping
## Abstract:
This paper introduces DGBench, a fully reproducible open-source testing system to enable benchmarking of dynamic grasping in environments with unpredictable relative motion between robot and object. We use the proposed benchmark to compare several visual perception arrangements. Traditional perception systems developed for static grasping are unable to provide feedback during the final phase of a grasp due to sensor minimum range, occlusion, and a limited field of view. A multi-camera eye-in-hand perception system is presented that has advantages over commonly used camera configurations. We quantitatively evaluate the performance on a real robot with an image-based visual servoing grasp controller and show a significantly improved success rate on a dynamic grasping task.
# Sim2Real Instance-Level Style Transfer for 6D Pose Estimation
## Keywords:
- Perception for Grasping and Manipulation
- Deep Learning for Visual Perception
- Simulation and Animation
## Abstract:
In recent years, synthetic data has been widely used in the training of 6D pose estimation networks, in part because it automatically provides perfect annotation at low cost. However, there are still non-trivial domain gaps, such as differences in textures/materials, between synthetic and real data. These gaps have a measurable impact on performance. To solve this problem, we introduce a simulation to reality (sim2real) instance-level style transfer for 6D pose estimation network training. Our approach transfers the style of target objects individually, from synthetic to real, without human intervention. This improves the quality of synthetic data for training pose estimation networks. We also propose a complete pipeline from data collection to the training of a pose estimation network and conduct extensive evaluation on a real-world robotic platform. Our evaluation shows significant improvement achieved by our method in both pose estimation performance and the realism of images adapted by the style transfer.
# Simultaneous Contact Location and Object Pose Estimation Using Proprioception and Tactile Feedback
## Keywords:
- Perception for Grasping and Manipulation
- Force and Tactile Sensing
- Dual Arm Manipulation
## Abstract:
Joint estimation of grasped object pose and extrinsic contacts is central to robust and dexterous manipulation. In this paper, we propose a novel state-estimation algorithm that jointly estimates contact location and object pose in 3D using exclusively proprioception and tactile feedback. Our approach leverages two complementary particle filters: one to estimate contact location (CPFGrasp) and another to estimate object poses (SCOPE). We implement and evaluate our approach on real-world single-arm and dual-arm robotic systems. We demonstrate that by bringing two objects into contact, the robots can infer contact location and object poses simultaneously. Our proposed method can be applied to a number of downstream tasks that require accurate pose estimates, such as tool use and assembly. Code and data can be found at https://github.com/MMintLab/scope.
# All You Need Is LUV: Unsupervised Collection of Labeled Images Using UV-Fluorescent Markings
## Keywords:
- Perception for Grasping and Manipulation
- Object Detection, Segmentation and Categorization
- Deep Learning for Visual Perception
## Abstract:
Learning-based perception systems in robotics often requires large-scale image segmentation annotation. Current approaches rely on human labelers, which can be expensive, or simulation data, which can visually differ from real data. This paper proposes Labels from UltraViolet (LUV), a novel framework that enables rapid, automated, inexpensive, high quality data collection in real. LUV uses transparent, UV-fluorescent paint with programmable UV LEDs to collect paired images of a scene in standard and UV lighting. This makes it possible to autonomously extract segmentation masks and keypoints via color thresholding. We apply LUV to a suite of diverse robot perception tasks: locating fabric keypoints, cable segmentation, and surgical needle detection to evaluate its labeling quality, flexibility, and data collection rate. Results suggest that LUV is 180-2500 times faster than a human labeler across the tasks while retaining accuracy and strong task performance. Code, datasets, visualizations, and supplementary material can be found at https://sites.google.com/berkeley.edu/luv.
# Voting and Attention-Based Pose Relation Learning for Object Pose Estimation from 3D Point Clouds
## Keywords:
- Perception for Grasping and Manipulation
- Computer Vision for Automation
- Computer Vision for Manufacturing
## Abstract:
Estimating the 6DOF pose of objects is an important function in many applications, such as robot manipulation or augmented reality. However, accurate and fast pose estimation from 3D point clouds is challenging, because of the complexity of object shapes, measurement noise, and presence of occlusions. We address this challenging task using an end-to-end learning approach for object pose estimation given a raw point cloud input. Our architecture pools geometric features together using a self-attention mechanism and adopts a deep Hough voting scheme for pose proposal generation. To build robustness to occlusion, the proposed network generates candidates by casting votes and accumulating evidence for object locations. Specifically, our model learns higher-level features by leveraging the dependency of object parts and object instances, thereby boosting the performance of object pose estimation. Our experiments show that our method outperforms state-of-the-art approaches in public benchmarks including the Sil'eane dataset [1] and the Fraunhofer IPA dataset [2]. We also deploy our proposed method to a real robot pick-and-place based on the estimated pose.
# Acoustic Balance: Weighing in Ultrasonic Non-Contact Manipulators
## Keywords:
- Perception for Grasping and Manipulation
- Grippers and Other End-Effectors
- Embedded Systems for Robotic and Automation
## Abstract:
Acoustic traps and levitation systems can lift, translate and manipulate a wide range of objects and materials without contact. This enables new manipulation capabilities for robots that may not be possible otherwise. This paper presents an acoustic balance, a contactless method for weighing acoustically trapped objects in air. The method works by measuring a step response: the system commands a change in the phase of the acoustic emitters, which results in a sudden change in the equilibrium position of the trap. The object held within the acoustic trap undergoes damped oscillation as it settles into the new equilibrium point. The mass of the trapped object can be determined from the frequency of oscillation. Combined with methods for adding and merging materials in the trap, the method presented here can potentially enable a robot to operate a closed-loop process to acquire or maintain a desired quantity of material. Using weight as an error signal, material could be added by the acoustic system until the required quantity is in the trap.
# The Probabilistic Robot Kinematics Model and Its Application to Sensor Fusion
## Keywords:
- Perception for Grasping and Manipulation
- Kinematics
- Probability and Statistical Methods
## Abstract:
Robots with elasticity in structural components can suffer from undesired end-effector positioning imprecision, which exceeds the accuracy requirements for successful manipulation. We present the Probabilistic-Product-Of-Exponentials robot model, a novel approach for kinematic modeling of robots. It does not only consider the robot's deterministic geometry but additionally models time-varying and configuration-dependent errors in a probabilistic way. Our robot model allows to propagate the errors along the kinematic chain and to compute their influence on the end-effector pose. We apply this model in the context of sensor fusion for manipulator pose correction for two different robotic systems. The results of a simulation study, as well as of an experiment, demonstrate that probabilistic configuration-dependent error modeling of the robot kinematics is crucial in improving pose estimation results.
# Navigation Systems 2
# On the Coupling of Depth and Egomotion Networks for Self-Supervised Structure from Motion
## Keywords:
- Deep Learning for Visual Perception
- Localization
- Vision-Based Navigation
## Abstract:
Structure from motion (SfM) has recently been formulated as a self-supervised learning problem, where neural network models of depth and egomotion are learned jointly through view synthesis. Herein, we address the open problem of how to best couple, or link, the depth and egomotion network components, so that information such as a common scale factor can be shared between the networks. Towards this end, we introduce several notions of coupling, categorize existing approaches, and present a novel tightly-coupled approach that leverages the interdependence of depth and egomotion at training time and at test time. Our approach uses iterative view synthesis to recursively update the egomotion network input, permitting contextual information to be passed between the components. We demonstrate through substantial experiments that our approach promotes consistency between the depth and egomotion predictions at test time, improves generalization, and leads to state-of-the-art accuracy on indoor and outdoor depth and egomotion evaluation benchmarks.
# Spatio-Temporal Graph Localization Networks for Image-Based Navigation
## Keywords:
- Vision-Based Navigation
- Localization
- Visual Learning
## Abstract:
Localization in topological maps is essential for image-based navigation using an RGB camera. Localization using only one camera can be challenging in medium-to-large-sized environments because similar-looking images are often observed repeatedly, especially in indoor environments. To overcome this issue, we propose a learning-based localization method that simultaneously utilizes the spatial consistency from topological maps and the temporal consistency from time-series images captured by a robot. Our method combines a convolutional neural network (CNN) to embed image features and a recurrent-type graph neural network to perform accurate localization. When training our model, it is difficult to obtain the ground truth~(GT) pose of the robot when capturing images in real-world environments. Hence, we propose a sim2real transfer approach with semi-supervised learning that leverages simulator images with the GT pose in addition to real images. We evaluated the proposed method quantitatively and qualitatively and compared it with several state-of-the-art baselines. The proposed method outperformed the baselines in environments where the map contained similar images. Moreover, we evaluated an image-based navigation system incorporating our localization method and confirmed that navigation accuracy significantly improved in the simulator and real environments compared to the other baseline methods.
# Stubborn: A Strong Baseline for Indoor Object Navigation
## Keywords:
- Vision-Based Navigation
- Object Detection, Segmentation and Categorization
- Collision Avoidance
## Abstract:
We present a strong baseline that surpasses the performance of previously published methods on the Habitat Challenge task of navigating to a target object in indoor environments. Our method is motivated from primary failure modes of prior state-of-the-art: poor exploration, inaccurate object identification, and agent getting trapped due to imprecise map construction. We make three contributions to mitigate these issues: (i) First, we show that existing map-based methods fail to effectively use semantic clues for exploration. We present a semantic-agnostic exploration strategy (called Stubborn) without any learning that surprisingly outperforms prior work. (ii) We propose a strategy for integrating temporal information to improve object identification. (iii) Lastly, due to inaccurate depth observation the agent often gets trapped in small regions. We develop a multi-scale collision map for obstacle identification that mitigates this issue.
# VI-IKD: High-Speed Accurate Off-Road Navigation Using Learned Visual-Inertial Inverse Kinodynamics
## Keywords:
- Vision-Based Navigation
- Model Learning for Control
- Deep Learning for Visual Perception
## Abstract:
One of the key challenges in high-speed off-road navigation on ground vehicles is that the kinodynamics of the vehicle-terrain interaction can differ dramatically depending on the terrain. Previous approaches to addressing this challenge have considered learning an inverse kinodynamics (IKD) model, conditioned on inertial information of the vehicle to sense the kinodynamic interactions. In this paper, we hypothesize that to enable accurate high-speed off-road navigation using a learned IKD model, in addition to inertial information from the past, one must also anticipate the kinodynamic interactions of the vehicle with the terrain in the future. To this end, we introduce Visual-Inertial Inverse Kinodynamics (VI-IKD), a novel learning-based IKD model that is conditioned on visual information from a terrain patch ahead of the robot in addition to past inertial information, enabling it to anticipate kinodynamic interactions in the future. We validate the effectiveness of VI-IKD in accurate high-speed off-road navigation experimentally on a scale 1/5 UT-AlphaTruck off-road autonomous vehicle in both indoor and outdoor environments and show that compared to other state-of-the-art approaches, VI-IKD enables more accurate and robust off-road navigation on a variety of different terrains at speeds of up to 3.5m/s
# H-VLO: Hybrid LiDAR-Camera Fusion for Self-Supervised Odometry
## Keywords:
- Autonomous Vehicle Navigation
- Vision-Based Navigation
- Sensor Fusion
## Abstract:
In this paper, we propose a hybrid visual-LiDAR odometry (H-VLO) framework that fuses predicted visual depth map and completed LiDAR map. Compared to previous visual-LiDAR odometry methods, our approach leverages 2D feature matching and 3D association by utilizing deep depth map, deep flow map and deep LiDAR depth completion networks. Rather than extraction of the depth values from LiDAR measurements for each visual feature, our method first densifies a LiDAR scan with a deep depth completion network and then fuses it with visual deep depth map estimation in a Bayesian framework. This method reduces pose estimation drift by improving feature-to-feature and point-to-feature matching, as well as scale recovery. The evaluations on the public KITTI odometry benchmark show that our technique achieves better or at least comparable estimates than the state-of-the-art visual-LiDAR and monocular visual odometry approaches.
# B-GAP: Behavior-Rich Simulation and Navigation for Autonomous Driving
## Keywords:
- Autonomous Vehicle Navigation
- Agent-Based Systems
## Abstract:
We address the problem of ego-vehicle navigation in dense simulated traffic environments populated by road agents with varying driver behaviors. Navigation in such environments is challenging due to unpredictability in agents' actions caused by their heterogeneous behaviors. We present a new simulation technique consisting of enriching existing traffic simulators with behavior-rich trajectories corresponding to varying levels of aggressiveness. We generate these trajectories with the help of a driver behavior modeling algorithm. We then use the enriched simulator to train a deep reinforcement learning (DRL) policy that consists of a set of high-level vehicle control commands and use this policy at test time to perform local navigation in dense traffic. Our policy implicitly models the interactions between traffic agents and computes safe trajectories for the ego-vehicle accounting for aggressive driver maneuvers such as overtaking, over-speeding, weaving, and sudden lane changes. Our enhanced behavior-rich simulator can be used for generating datasets that consist of trajectories corresponding to diverse driver behaviors and traffic densities, and our behavior-based navigation scheme can be combined with state-of-the-art navigation algorithms.
# Memory-Augmented Reinforcement Learning for Image-Goal Navigation
## Keywords:
- Vision-Based Navigation
- Reinforcement Learning
- Deep Learning for Visual Perception
## Abstract:
In this work, we present a memory-augmented approach for image-goal navigation. Earlier attempts, including RL-based and SLAM-based approaches have either shown poor generalization performance, or are heavily-reliant on pose/depth sensors. Our method is based on an attention-based end-to-end model that leverages an episodic memory to learn to navigate. First, we train a state-embedding network in a self# supervised fashion, and then use it to embed previously-visited states into the agent’s memory. Our navigation policy takes advantage of this information through an attention mechanism. We validate our approach with extensive evaluations, and show that our model establishes a new state of the art on the challenging Gibson dataset. Furthermore, we achieve this impressive performance from RGB input alone, without access to additional information such as position or depth, in stark contrast to related work.
# Exploring Event Camera-Based Odometry for Planetary Robots
## Keywords:
- Vision-Based Navigation
- Space Robotics and Automation
- Visual-Inertial SLAM
## Abstract:
Due to their resilience to motion blur and high robustness in low-light and high dynamic range conditions, event cameras are poised to become enabling sensors for vision-based exploration on future Mars helicopter missions. However, existing event-based visual-inertial odometry (VIO) algorithms either suffer from high tracking errors or are brittle, since they cannot cope with significant depth uncertainties caused by an unforeseen loss of tracking or other effects. In this work, we introduce EKLT-VIO, which addresses both limitations by combining a state-of-the-art event-based frontend with a filter-based backend. This makes it both accurate and robust to uncertainties, outperforming event# and frame-based VIO algorithms on challenging benchmarks by 32%. In addition, we demonstrate accurate performance in hover-like conditions (outperforming existing event-based methods) as well as high robustness in newly collected Mars-like and high-dynamic-range sequences, where existing frame-based methods fail. In doing so, we show that event-based VIO is the way forward for vision-based exploration on Mars. We plan on releasing the code and our Mars-analog datasets upon acceptance.
# GA-Nav: Efficient Terrain Segmentation for Robot Navigation in Unstructured Outdoor Environments
## Keywords:
- Vision-Based Navigation
- AI-Enabled Robotics
## Abstract:
We propose GA-Nav, a novel group-wise attention mechanism to identify safe and navigable regions in unstructured environments from RGB images. Our group-wise attention method extracts multi-scale features from each type of terrain independently and classifies terrains based on their navigability levels using coarse-grained semantic segmentation. Our novel loss can be embedded within any backbone network to explicitly focus on the different groups' features, at a low spatial resolution. Our design leads to efficient inference while maintaining a high level of accuracy compared to existing SOTA methods. Our extensive evaluations on the RUGD and RELLIS-3D datasets shows that GA-Nav achieves the state-of-the-art performance on RUGD and RELLIS-3D datasets. We interface GA-Nav with a deep reinforcement learning-based navigation algorithm and highlight its benefits in terms of navigation in real-world unstructured terrains. We integrate our GA-Nav-based navigation algorithm with ClearPath Jackal and Husky robots, and observe an improvement in terms of navigation success rate and better trajectory selections. Code, videos, and a full technical report are available at https://gamma.umd.edu/offroad/.
# Aerial Systems 3
# Automated Aerial Screwing with a Fully Actuated Aerial Manipulator
## Keywords:
- Aerial Systems: Applications
- Aerial Systems: Mechanics and Control
- Compliance and Impedance Control
## Abstract:
The tasks that unmanned aerial vehicles (UAVs) have taken upon have progressively grown in complexity over the years, alongside with the level of autonomy with which they are carried out. In this work, we present an example of aerial screwing operations with a fully-actuated tilt-rotor platform. Key contributions include a new control framework to automate screwing operations through a robust hole search and in-hole detection algorithm. These are achieved without a-priori knowledge of the exact hole location, and without the use of external tools, such as vision based hole detection or force sensors. Wrench coupling is implemented to account for the platform's kinematic constraints during screwing. The application of a constant contact force and a compliant response to induced disturbances are obtained with the use of admittance control. The full framework is validated with extensive flight experiments that demonstrate the effectiveness of each sub-system, as well as the complete architecture. We also validate the robustness of the detection algorithm against false positives. Within the results we demonstrate the ability to perform the automated task with a 86% success rate over 35 flights, and measured hole search time of 9 s (median value).
# Automatic Parameter Adaptation for Quadrotor Trajectory Planning
## Keywords:
- Aerial Systems: Applications
- Aerial Systems: Perception and Autonomy
- Autonomous Vehicle Navigation
## Abstract:
Online trajectory planners enable quadrotors to safely and smoothly navigate in unknown cluttered environments. However, tuning parameters is challenging since modern planners have become too complex to mathematically model and predict their interaction with unstructured environments. This work takes humans out of the loop by proposing a planner parameter adaptation framework that formulates objectives into two complementary categories and optimizes them asynchronously. Objectives evaluated with and without trajectory execution are optimized using Bayesian Optimization (BayesOpt) and Particle Swarm Optimization (PSO), respectively. By combining two kinds of objectives, the total convergence rate of the black-box optimization is accelerated while the dimension of optimized parameters can be increased. Benchmark comparisons demonstrate its superior performance over other strategies. Tests with changing obstacle densities validate its real-time environment adaption, which is difficult for prior manual tuning. Real-world flights with different drone platforms, environments, and planners show the proposed framework's scalability and effectiveness.
# Efficient Sampling-Based Multirotors Kinodynamic Planning with Fast Regional Optimization and Post Refining
## Keywords:
- Aerial Systems: Applications
- Aerial Systems: Perception and Autonomy
- Autonomous Vehicle Navigation
## Abstract:
For real-time multirotor kinodynamic planning, the efficiency of sampling-based methods is usually hindered by difficult-to-sample homotopy classes like narrow passages. In this paper, we address this issue by a hybrid scheme. We firstly propose a fast regional optimizer exploiting the information of local environments and then integrate it into a bidirectional global sampling process. The incorporation of the local optimization shows significantly improved success rates and less planning time in various types of challenging environments. We further present a refinement module utilizing the same framework as the regional optimizer. It comprehensively investigates the resulting trajectory of the global sampling and improves its smoothness with nearly negligible computation effort. Benchmark results illustrate that our proposed method can better exploit a previous trajectory compared to the state-of-the-art ones. The planning methods are applied to generate trajectories for a quadrotor system in simulation and real-world, and their capability is validated in real-time applications.
# DIDO: Deep Inertial Quadrotor Dynamical Odometry
## Keywords:
- Localization
- Visual-Inertial SLAM
- Sensorimotor Learning
## Abstract:
In this work, we propose an interoceptive-only state estimation system for a quadrotor with deep neural network processing, where the quadrotor dynamics is considered as a perceptive supplement of the inertial kinematics. To improve the precision of multi-sensor fusion, we train cascaded networks on real-world quadrotor flight data to learn IMU kinematic properties, quadrotor dynamic characteristics, and motion states of the quadrotor along with their uncertainty information, respectively. This encoded information empowers us to address the issues of IMU bias stability, dynamic constraints, and multi-sensor calibration during sensor fusion. The above multi-source information is fused into a two-stage Extended Kalman Filter (EKF) framework for better estimation. Experiments have demonstrated the advantages of our proposed work over several conventional and learning-based methods.
# Folding Knots Using a Team of Aerial Robots
## Keywords:
- Aerial Systems: Applications
- Path Planning for Multiple Mobile Robots or Agents
- Flexible Robotics
## Abstract:
From ancient times, humans have been using cables and ropes to tie, carry, and manipulate objects by folding knots. However, automating knot folding is challenging because it requires dexterity to move a cable over and under itself. In this paper, we propose a method to fold knots in midair using a team of aerial vehicles. We take advantage of the fact that vehicles are able to fly in between cable segments without any re-grasping. So the team grasps the cable from the floor, and releases it once the knot is folded. Based on a composition of catenary curves, we simplify the complexity of dealing with an infinite-dimensional configuration space of the cable, and formally propose a new knot representation. Such representation allows us to design a trajectory that can be used to fold knots using a leader-follower approach. We show that our method works for different types of knots in simulations. Additionally, we show that our solution is also computationally efficient and can be executed in real-time.
# Hand-Crafted Features for Floating Plastic Detection
## Keywords:
- Aerial Systems: Applications
- Environment Monitoring and Management
- Object Detection, Segmentation and Categorization
## Abstract:
Plastic waste is a global concern that has a negative impact on the oceans and wildlife health. This paper focuses on detection of floating plastics in aerial images taken from unmanned aerial vehicles (UAVs). It proposes a new method for plastic detection in marine environments, based on SIFT descriptor and color histograms for feature extraction, as an alternative to state-of-the-art object detectors based on convolutional neural networks (CNNs). Our approach is named SURFACE: “SIFT featURes For plAstiC dEtection”. We investigate how different color-spaces and image resolutions impact the extraction of SIFT features and compare SURFACE to ResNet CNN. Also, we provide a detailed comparison with YOLO and Faster-RCNN object detection models and show that SURFACE achieves approximately the same accuracy while being faster and less memory consuming. The dataset acquired during this research will be publicly available.
# Reactive Motion Planning for Rope Manipulation and Collision Avoidance Using Aerial Robots
## Keywords:
- Aerial Systems: Applications
- Motion and Path Planning
- Manipulation Planning
## Abstract:
In this work we address the challenging problem of manipulating a flexible link, like a rope, with an aerial robot. Inspired by spraying tasks in construction and maintenance scenarios, we consider the case in which an autonomous end-effector (e.g., a spray nozzle moved by a robot or a human operator) is connected to a fixed point by a rope (e.g., a hose). To avoid collisions between the rope and the environment while the end-effector moves, we propose the use of an aerial robot as a flying companion to properly manipulate the rope away from collisions. The aerial robot is attached to the rope between the end-effector and the fixed point. Assuming no direct control of the end-effector (e.g., when operated by a human), we design a reactive and fast motion planner for the aerial robot. Grounding on the theory of Forced Geometric Fabrics, we design a motion planner that generates trajectories to drive the aerial robot to follow the end-effector, while manipulating the rope to avoid collisions in cluttered environments. To include the complex behavior of the flexible link, we propose a rope model that estimates its real-time state under forces and position-based interactions, as well as collisions with obstacle surfaces. Finally, we evaluate the system behavior and the motion planner performance in simulations, as well as in real-world experiments on an original spray painting application.
# Autonomous Emergency Landing for Multicopters Using Deep Reinforcement Learning
## Keywords:
- Aerial Systems: Perception and Autonomy
- Reinforcement Learning
## Abstract:
This work presents a pipeline for autonomous emergency landing for multicopters, such as rotary wing Unmanned Aerial Vehicles (UAVs), using deep Reinforcement Learning (RL). Mechanical malfunctions, strong winds, sudden battery life drops (e.g. due to cold weather), failure in localization or GPS jamming are not uncommon and all constitute emergency situations that require a UAV to abort its mission early and land as quickly as possible in the immediate vicinity. To this end, it is crucial for a UAV that is deployed in real missions to be able to detect a safe landing spot efficiently and proceed to land autonomously, avoiding damage to both its integrity and the surroundings. Driven by the advances in semantic segmentation and depth completion using machine learning, the proposed architecture uses deep RL to infer actions from semantic and depth information, flying the robot towards secure areas, while respecting safety constraints. Thanks to our robust training strategy and the choice of these mid-level representations as input to the RL agent, we show that our policy can directly transfer to the real world, without the need for any additional fine-tuning. In a series of challenging experiments both in simulation and with a real platform, we demonstrate that our planner guides a rotorcraft UAV to a safe landing spot up to 1.5 times faster and with double success rate than the state of the art (including a commercially available solution), paving the way towards realistically deployable UAVs.
# GNGraph: Self-Organizing Maps for Autonomous Aerial Vehicle Planning
## Keywords:
- Aerial Systems: Perception and Autonomy
- Aerial Systems: Applications
- Autonomous Vehicle Navigation
## Abstract:
The present paper tackles the problem of planning a collision-free path in a known environment from a general point of view. We address the problem by using an unsupervised learning algorithm to generate a sparse graph representing the topological structure of the environment and use it for planning paths in 3D spaces. We propose GNGraph, an integrated solution combining the Growing Neural Gas algorithm to generate the sparse graph, a stop criterion to guarantee the graph’s connectivity and a collision check to assess the edges and nodes validity. The proposed solution has been tested on simulated and real environment maps, and compared against a state-of-the-art graph planning algorithm among other global planning methods.
# Medical Robots and Systems 3
# Biocompatible Ferrofluid Robot with Photothermal Property for Targeted Tumor Therapy
## Keywords:
- Soft Robot Materials and Design
- Soft Robot Applications
- Medical Robots and Systems
## Abstract:
Magnetic-controlled micro-robots have promising applications in disease therapy due to their high targetability and drug utilization. Due to their unique deformable and divisible properties, ferrofluid robots have gained much attention in microchemical reaction chips and micromanipulation. This study proposes a biocompatible ferrofluid robot and validates its potential to achieve targeted drug delivery and tumor cell killing. This biocompatible ferrofluidic robot contains 10 nm oleic acid-coated ferric tetroxide particles and vegetable oil and has good magnetic responsiveness, deformability, and photothermal properties, and can move in liquid environments such as blood. It can achieve motion with an error of less than 0.4 mm under closed-loop control and obstacle overturning and passage through narrow channels less than twice its diameter. In addition, the biocompatible ferrofluid robot can kill tumor cells in the target area due to the photothermal properties of the magnetic particles, and experimental results show that the tumor cell death rate can reach 95%. These capabilities give the biocompatible ferrofluid robot a significant advantage in getting the target location for cancer treatment through the vascular environment.
# Lumen Shape Reconstruction Using a Soft Robotic Balloon Catheter and Electrical Impedance Tomography
## Keywords:
- Soft Robot Applications
- Modeling, Control, and Learning for Soft Robots
- Medical Robots and Systems
## Abstract:
Incorrectly sized balloon catheters can lead to increased post-surgical complications, yet even with preoperative imaging, correct selection remains a challenge. With limited feedback during surgery, it is difficult to verify correct deployment. We propose the use of integrated impedance measurements and Electrical Impedance Tomography (EIT) imaging to assess the deformation of the balloon and determine the size and shape of the surrounding lumen. Previous work using single impedance measurements, or pressure data and analytical models, whilst demonstrating high sizing accuracy, have assumed a circular cross section. Here we extend these methods by adding a multitude of electrodes to detect elliptical and occluded lumen and obtain EIT images to localise deformations. Using a 14 Fr (5.3 mm) catheter as an example, numerical simulations were performed to find the optimal electrode configuration of two rings of 8 electrodes spaced 10 mm apart. The simulations predicted that the maximum detectable aspect ratio decreased from 0.9 for a 14mm balloon to 0.5 at 30mm. The sizing and ellipticity detection results were verified experimentally. A prototype robotic balloon catheter was constructed to automatically inflate a compliant balloon while simultaneously recording EIT and pressure data. Data were collected in experiments replicating stenotic vessels with an elliptical and asymmetrical profile, and the widening of a lumen during angioplasty. After calibration, the system was able to correctly localise the occlusion and detect aspect ratios of 0.75. EIT images further localised the occlusion and visualised the dilation of the lumen during balloon inflation.
# Ultrasound Tracking and Closed-Loop Control of a Magnetically-Actuated Biomimetic Soft Robot
## Keywords:
- Soft Robot Applications
- Vision-Based Navigation
- Medical Robots and Systems
## Abstract:
Small untethered soft robots have potential for diverse applications, particularly in constrained spaces where the use of a tethered device would be infeasible. Examples include biomedical applications such as brachytherapy, fine# needle biospy and micro-needle drug delivery. To advance soft robots towards these applications, there is a need to establish methods for tracking and control using clinically# relevant methods. This study demonstrates motion planning and magnetic control of a soft untethered robot, using ultrasound images as feedback. The closed-loop control of the Millipede soft robot is first validated using a camera-based tracker, where the deviation between the planned path and the trajectory of the robot is 1.71 mm. Afterwards, two methods for ultrasound-based tracking capable of estimating the pose of the robot are proposed, a geometric approach and a convolutional neural network (CNN), and their performance is compared using a video camera as ground truth. Following this, the CNN method replaces the camera tracker to estimate the position and ori# entation of the robot. The closed-loop system using ultrasound images guides the robot through the workspace while avoiding virtual obstacles, and achieves an average tracking error of 1.59 mm and an angle error of 2.24 degrees.
# Robust Sim2Real Transfer with the Da Vinci Research Kit: A Study on Camera, Lighting, and Physics Domain Randomization
## Keywords:
- Surgical Robotics: Planning
- Simulation and Animation
- Reinforcement Learning
## Abstract:
Autonomous surgical robotics is a growing area of research, with advances being made in the areas of vision and control. Central to this research is the need for simulations to facilitate data collection and simulate learning environments for Reinforcement Learning (RL) agents. Recent simulators have facilitated RL policy generation, but lack a robust sim2real pipeline and a proven vision-based policy that can use any type of camera including the da Vinci Surgical System (dVSS) Endoscope. To solve this, we build a ROS-based sim2real pipeline that incorporates a Unity3D da Vinci Research Kit (dVRK) simulation, modular kinematics, and shared interfaces. We examine the vision-based task of cube pushing, and train RL policies to execute in real life through Domain Randomization. Our experiments evaluate model success in simulation and two camera systems: OAK-1 and the dVSS Endoscope. Our results indicate that Domain Randomization is effective at bridging the sim2real gap, and even extends to the difficult endoscope scenario. We achieve 100% transfer success rate on both OAK-1 and the dVSS Endoscope, with gains of over 60% compared to a base model with no Domain Randomization. We examine the various randomization parameters, including lighting, camera, and physics variables, and determine that all parameters play a significant role in bridging the sim2real gap. Testing across extreme lighting and camera configurations not seen in simulation, our models continue to perform well, with 85% accuracy on the OAK-1 camera. Our future work will extend to other tasks and more complex policies to take advantage of stereo-camera imaging.
# Simulation-Based Reinforcement Learning for Real-World Autonomous US Probe Navigation
## Keywords:
- Medical Robots and Systems
- Reinforcement Learning
- Sensor-based Control
## Abstract:
Ultrasound (US) is one of the most commonly used medical imaging tools since it is radiation-free, low-cost, and real-time. In freehand US examinations, sonographers often navigate a US probe to visualize standard examination planes with rich diagnostic information. However, reproducibility and stability of the resulting images often suffer from intra# and inter-operator variation. Reinforcement learning (RL), as an interaction-based learning method, has demonstrated its effectiveness in visual navigating tasks; however, RL has been limited in terms of generalization. To overcome this challenge, we propose a simulation-based RL framework for real-world navigation of US probes towards the standard longitudinal views of vessels. A UNet is used to provide binary masks from US images; thereby, the RL agent trained on simulated binary vessel images can be applied in real scenarios without further training. To accurately characterize actual states, a multi-modality state representation structure is introduced to facilitate the understanding of environments. Moreover, considering the characteristics of vessels, a novel standard view recognition approach based on the minimum bounding rectangle is proposed to terminate the searching process. To evaluate the effectiveness of the proposed method, the trained policy is validated virtually on 3D volumes of a volunteer's in-vivo carotid artery, and physically on custom-designed gel phantoms using robotic US. The results demonstrate that the proposed method can effectively and accurately navigate the probe towards the longitudinal view of vessels.
# PH Sensor-Embedded Magnetically Driven Capsule for H. Pylori Infection Diagnosis
## Keywords:
- Medical Robots and Systems
- Micro/Nano Robots
## Abstract:
The Campylobacter-like organism (CLO) test is the most commonly employed test for diagnosing Helicobacter pylori (H. pylori) infection in the stomach. Since the CLO test is an invasive method, non-invasive methods have been proposed. However, the proposed methods exhibit relatively low specificity and sensitivity. In this letter, a novel H. pylori infection diagnosis method that uses a pH sensor-embedded magnetically driven capsule is proposed. The proposed method adopts the principle of the CLO test to diagnose H. pylori infection non-invasively. The capsule comprises two chambers to sample gastric juice, and a pH sensor is embedded inside each chamber. Therefore, H. pylori infection can be diagnosed using the urea hydrolysis property of H. pylori and a pH sensor embedded in the chambers of the capsule. In addition, the capsule can be magnetically actuated using an external magnetic field owing to its neodymium-magnet. The performance of the proposed capsule was evaluated in several aspects. First, the sensing ability of the fabricated pH sensor was verified using a pH buffer solution. Second, the magnetic actuation capacity of the capsule was evaluated using a 6-coil electromagnetic actuation (EMA) system. Third, the gastric juice sampling and pH-sensing capabilities of the assembled capsule were evaluated using a phantom test. Finally, the ability to diagnose H. pylori infection was validated using an ex vivo test. Consequently, this letter highlights the potential feasibility of establishing an H. pylori infection diagnosis method using a pH sensor-embedded magnetically driven capsule.
# Development of a Robotic Capsule for in Vivo Sampling of Gut Microbiota
## Keywords:
- Medical Robots and Systems
- Micro/Nano Robots
- Biologically-Inspired Robots
## Abstract:
Human gut microbiota can provide comprehensive information about the health of a host but the tools to collect microbiome samples are not currently available. A standalone wireless robotic capsule that has been developed in this study, collects the microbiota both from lumen (capsule surrounding) and intestinal wall (mucosa layer) for the first time. First, a two-way shape memory alloy (SMA) spring actuation system was developed by tackling the high-drain current requirement of SMAs. The actuator can produce a 800 mN force that was sufficient to collect samples. Second, successful encapsulation of the collected sample to avoid contamination was realised by testing 3 main sealing materials. Third, the robotic capsule was tested in a gut simulator that mimics in-vivo environment to ensure successful and safe travel of the capsule along the gastrointestinal tract. Finally, an in vitro experimental setup that keeps an intestine alive for 6 hours was used to optimise the sample collection. The capsule collected 128 µL and 107 µL samples (which are sufficient quantities for microbiome analysis) from duodenal and ileal tissue of a sheep. The proposed robotic capsule has a potential to become a vital apparatus for clinicians to sample human and animal gut in the future.
# Local One-Dimensional Motion Estimation Using FBG-Based Shape Sensing for Cardiac Applications
## Keywords:
- Medical Robots and Systems
- Surgical Robotics: Steerable Catheters/Needles
- Calibration and Identification
## Abstract:
The human heart is a fragile and dynamic organ that requires careful approach during catheter intervention. It is essential for physicians to have a high degree of awareness of the anatomy and the relative pose of the catheter when operating inside the heart. One of the key aspects that can aid physicians during such interventions is knowledge of the heart’s motion profile. Accordingly, this work addresses the objective of estimating local predominantly one-dimensional heart motions by making use of FBG-inscribed multi-core fibers and shape sensing. An FBG-fiber embedded in a cardiac catheter is propagated towards a designated region in the heart, where a force sensor at the tip of the catheter is used to identify contact with the heart tissue. The catheter’s tip position is continuously monitored during contact with the moving tissue. The proposed method is able to determine the direction of the local surface motion and estimates the evolution of the motion profile through time. An Unscented Kalman Filter (UKF) is thus employed to provide continuous quasi-periodic estimation of this motion. Experiments on a bench-top laboratory heart mock-up were carried out to validate the proposed approach. Results show that the proposed method can provide accurate estimations of the heart motion profile with an absolute mean error of 1.1 ± 0.4 mm (9.2%) for motions with average peak-to-peak amplitudes of 12 mm.
# Sim-To-Real Transfer of Image-Based Autonomous Guidewire Navigation Trained by Deep Deterministic Policy Gradient with Behavior Cloning for Fast Learning
## Keywords:
- Surgical Robotics: Steerable Catheters/Needles
- Reinforcement Learning
- Computer Vision for Medical Robotics
## Abstract:
Percutaneous coronary intervention (PCI) is a frequently used surgical treatment for cardiovascular disease, one of the leading cause of death in the world. In traditional PCI, a doctor navigates a thin guidewire in a patient's vessel toward a target location by looking into live X-ray angiogram images of the patient. Recently, researchers are using reinforcement learning to automate this guidewire navigation process without attaching any sensor to the guidewire tip. These researchers use a real vessel phantom to train their behavior policy using reinforcement learning. Training a reinforcement learning algorithm on a real setup can give a good guidewire control on that setup, but it is under question whether the trained algorithm can be applied to other vessel structures. We can make various vessel phantoms and train the algorithm on the setups, but it can be really time and money consuming. In this paper, we devise a method for sim-to-real transfer of a guidewire navigation trained by reinforcement learning using only images. We pretrain our behavior policy using data collected by running an expert algorithm in the virtual environment. Then, we train the behavior policy by deep deterministic policy gradient (DDPG) in a virtual environment. With behavior cloning, our method learns to successfully navigate a guidewire in much shorter time than training DDPG from scratch without behavior cloning. After done with the training, we transfer the behavior policy trained in the virtual environment to the guidewire navigation in a real vessel phantom. Our trained behavior policy navigates the guidewire to destinations successfully in all test episodes and navigates faster than the expert algorithm. Experiment video is available at: https://youtu.be/HCEbIhZsXqw
# Mechanism Design 3
# Modular and Hybrid Numerical-Analytical Approach # a Case Study on Improving Computational Efficiency for Series-Parallel Hybrid Robots
## Keywords:
- Dynamics
- Parallel Robots
- Performance Evaluation and Benchmarking
## Abstract:
Modeling closed loop mechanisms is a necessity for the control and simulation of various systems and poses a great challenge to rigid body dynamics algorithms. Solving the forward and inverse dynamics for such systems require resolution of loop closure constraints which are often solved via numerical procedures. This brings an additional burden to these algorithms as they have to stabilize and control the loop closure errors. In order to avoid this issue, analytical solutions are preferred for commonly studied parallel mechanisms. This paper has two contributions. Firstly, it reports a case study on a modular and hybrid numerical-analytical approach to model and control series-parallel hybrid robots which are subjected to large number of holonomic constraints. The approach exploits the modularity in the robot design to combine analytical loop closure for the known submechanisms and numerical loop closure for submechanisms where analytical solutions are not available. This offers an edge over purely numerical approach in terms of computational efficiency. Secondly, an adaption of the constraint embedding approach in Articulated Body Algorithm (ABA) is presented which yields a recursive algorithm in minimal coordinates for computing the forward dynamics of series-parallel hybrid systems. The proposed modification exploits the Lie group formulations and allows easy implementation of recursive forward dynamics of constrained systems in state of the art multi-body solvers.
# Multi-Axis Reorientation of a Free-Falling Omnidirectional Wheeled Robot
## Keywords:
- Underactuated Robots
- Wheeled Robots
- Mechanism Design
## Abstract:
This paper presents reorientation manoeuvres applied to an omnidirectional wheeled robot for impact mitigation during short falls. The proposed robot architecture aims to build upon recent innovations in reorientation robots to attain fast, multi-axis reorientation. Indeed, the use of omnidirectional wheels allows for simplifications to be made with respect to previous mobile robot architectures that make the proposed architecture more efficient for free fall reorientation, while still maintaining free roaming capabilities. To test these improvements, a prototype is built and a free roam and two free fall demonstrations are completed. On the one hand, the free roam demonstration validates that translation along both horizontal axes and rotation about the yaw axis are achieved with the presented prototype. On the other hand, the first free fall demonstration shows that a worst case scenario of a 180-degree reorientation about one axis can be completed in just under 0.45 seconds (one-metre fall) and the second free fall demonstration validates that the prototype is capable of simultaneous reorientation about both the roll and pitch axes. Therefore, the fast, multi-axis reorientation capabilities of the developed prototype are verified.
# Steady-State Manifold of Riderless Motorcycles
## Keywords:
- Underactuated Robots
- Wheeled Robots
- Dynamics
## Abstract:
Keeping balance is one of the most important tasks of a motorcycle. The steady-state manifold is proposed in this paper to explore the inherent dynamics and the balance properties of a riderless motorcycle. The dynamic and kinematic characteristics are analyzed based on the manifold and are validated by simulation. Comparing to traditional control method, the usefulness of the manifold in control is shown through the design of a novel control strategy. Furthermore, based on the analysis and the simulation, the potential applications of the manifold for control and planning are summarized.
# Foot-Operated Tele-Impedance Interface for Robot Manipulation Tasks in Interaction with Unpredictable Environments
## Keywords:
- Design and Human Factors
- Telerobotics and Teleoperation
- Compliance and Impedance Control
## Abstract:
Tele-impedance increases interaction performance between a robotic tool and unstructured/unpredictable environments during teleoperation. However, the existing tele-impedance interfaces have several ongoing issues, such as long calibration times and various obstructions for the human operator. In addition, they are all designed to be controlled by the operator's arms, which can cause difficulties when both arms are used, as in bi-manual teleoperation. To resolve these issues, we designed a novel foot-based tele-impedance control method inspired by the human limb stiffness ellipse modulation. The proposed mechanical interface design includes a disc and a foot pressure sensor that controls the orientation and size/shape of the stiffness ellipse, respectively. We evaluated the disc interface control method in an experimental study with 12 participants, who performed a complex drilling task in a virtual environment. The results show the ability of the operator to use the proposed interface in order to dynamically adapt to different phases of the task and changes in the environment. In addition, a comparison with low and high uniform impedance modes demonstrates a superior interaction performance of the proposed method.
# Toward FBG-Sensorized Needle Shape Prediction in Tissue Insertions
## Keywords:
- Nonholonomic Mechanisms and Systems
- Surgical Robotics: Planning
- Surgical Robotics: Steerable Catheters/Needles
## Abstract:
Complex needle shape prediction remains an issue for planning of surgical interventions of flexible needles. In this paper, we validate a theoretical method for flexible needle shape prediction allowing for non-uniform curvatures, extending upon a previous sensor-based model which combines curvature measurements from fiber Bragg grating (FBG) sensors and the mechanics of an inextensible elastic rod to determine and predict the 3D needle shape during insertion. We evaluate the model’s effectiveness in single-layer isotropic tissue for shape sensing and shape prediction capabilities. Experiments on a four-active area, FBG-sensorized needle were performed in varying single-layer isotropic tissues under stereo vision to provide 3D ground truth of the needle shape. The results validate a viable 3D needle shape prediction model accounting for non-uniform curvatures in flexible needles with mean needle shape sensing and prediction root-mean-square errors of 0.479 mm and 0.892 mm, respectively.
# Robust Cartesian Kinematics Estimation for Task-Space Control Systems
## Keywords:
- Kinematics
- Sensor Fusion
- Sensor-based Control
## Abstract:
We discuss a novel method for estimating task Cartesian position and velocity in robot manipulators. This is done by model-based fusion of inertial measurement units with motor encoders. The model is developed to robustly handle the uncertainties in the trajectory. Thus, not only the approach benefits from high fidelity and bandwidth thanks to multiple-sensory fusion, but it also enforces stability despite poorly formulated motions. This empowers the method to be utilized in complex closed-loop applications, where both task position and velocity information is required.
# Unsupervised 3D Link Segmentation of Articulated Objects with a Mixture of Coherent Point Drift
## Keywords:
- Kinematics
- Data Sets for Robotic Vision
- Manipulation Planning
## Abstract:
In this paper, we address the 3D link segmentation problem of articulated objects using multiple point sets with different configurations. We are motivated by the fact that a point set of an object can be aligned to point sets with different configurations by applying rigid transformations to links. Since existing 3D part segmentation datasets do not provide motion-based annotations, we propose a novel dataset of articulated objects, which are annotated based on its kinematic models. We define the point set alignment process as a probability density estimation problem and find the optimal decomposition of the point set and deformations using the EM algorithm. In addition, to improve the segmentation performance, we propose a regularization loss designed with a physical prior of decomposition. We evaluate the proposed method on our dataset, demonstrating that the proposed method achieves the state-of-the-art performance compared to baseline methods. Finally, we also propose an effective target manipulating point proposer, which can be applied to collect multiple point sets from an unknown object with different configurations to better solve the 3D link segmentation problem.
# A Robot Factors Approach to Designing Modular Hardware
## Keywords:
- Design and Human Factors
- Cellular and Modular Robots
- Space Robotics and Automation
## Abstract:
Robots are increasingly being called on to operate in settings and on tasks originally designed for humans, or where humans are also expected to work. Accordingly, the hardware and tools to be packaged, operated, or maintained are typically designed for use by humans, not robots. Robot autonomy in such cases can be expedited by a “robot factors” approach to the design of hardware, analogous to ergonomics for humans, taking typical current robot capabilities into account during the design process. In this paper, we present two case studies of redesigning mission-critical hardware in space habitats to facilitate autonomous robot operation. In both cases, hardware that previously required dexterous bi-manual manipulation is redesigned such that the entire maintenance task can be completed by a single robotic arm with a standard parallel jaw gripper. We demonstrate successful autonomous replacement of modules in the two hardware systems, and characterize how orientation and compliance of a grasp helps compensate for positioning errors. Based on our findings, we identify several key design strategies that underpin the robot factors approach to designing robot-friendly hardware, including consolidating compound actions into simpler mechanisms, constraining required motions to a single axis, and introducing mechanical compliance to decrease the effects of pose uncertainties.
# BSA # Bi-Stiffness Actuation for Optimally Exploiting Intrinsic Compliance and Inertial Coupling Effects in Elastic Joint Robots
## Keywords:
- Compliant Joints and Mechanisms
- Actuation and Joint Mechanisms
## Abstract:
Compliance in actuation has been exploited to generate highly dynamic maneuvers such as throwing that take advantage of the potential energy stored in joint springs. However, the energy storage and release could not be well-timed yet. On the contrary, for multi-link systems, the natural system dynamics might even work against the actual goal. With the introduction of variable stiffness actuators, this problem has been partially addressed. With a suitable optimal control strategy, the approximate decoupling of the motor from the link can be achieved to maximize the energy transfer into the distal link prior to launch. However, such continuous stiffness variation is complex and typically leads to oscillatory swing-up motions instead of clear launch sequences. To circumvent this issue, we investigate decoupling for speed maximization with a dedicated novel actuator concept denoted Bi-Stiffness Actuation. With this, it is possible to fully decouple the link from the joint mechanism by a switch-and-hold clutch and simultaneously keep the elastic energy stored. We show that with this novel paradigm, it is not only possible to reach the same optimal performance as with power-equivalent variable stiffness actuation, but even directly control the energy transfer timing. This is a major step forward compared to previous optimal control approaches, which rely on optimizing the full time-series control input.
# Object Detection, Segmentation and Categorization 3
# Time-To-Label: Temporal Consistency for Self-Supervised Monocular 3D Object Detection
## Keywords:
- Object Detection, Segmentation and Categorization
- Computer Vision for Transportation
## Abstract:
Monocular 3D object detection continues to attract attention due to the cost benefits and wider availability of RGB cameras. Despite the recent advances and the ability to acquire data at scale, annotation cost and complexity still limit the size of 3D object detection datasets in the supervised settings. Self-supervised methods, on the other hand, aim at training deep networks relying on pretext tasks or various consistency constraints. Moreover, other 3D perception tasks (such as depth estimation) have shown the benefits of temporal priors as a self-supervision signal. In this work, we argue that the temporal consistency on the level of object poses, provides an important supervision signal given the strong prior on physical motion. Specifically, we propose a self-supervised loss which uses this consistency, in addition to render-and-compare losses, to refine noisy pose predictions and derive high-quality pseudo labels. To assess the effectiveness of the proposed method, we finetune a synthetically trained monocular 3D object detection model using the pseudo-labels that we generated on real data. Evaluation on the standard KITTI3D benchmark demonstrates that our method reaches competitive performance compared to other monocular self-supervised and supervised methods.
# 3D Multi-Object Tracking Using Graph Neural Networks with Cross-Edge Modality Attention
## Keywords:
- Object Detection, Segmentation and Categorization
- Deep Learning for Visual Perception
- Semantic Scene Understanding
## Abstract:
Online 3D multi-object tracking (MOT) has witnessed significant research interest in recent years, largely driven by demand from the autonomous systems community. However, 3D offline MOT is relatively less explored. Labeling 3D trajectory scene data at a large scale while not relying on high-cost human experts is still an open research question. In this work, we propose Batch3DMOT which follows the tracking-by-detection paradigm and represents real-world scenes as directed, acyclic, and category-disjoint tracking graphs that are attributed using various modalities such as camera, LiDAR, and radar. We present a multi-modal graph neural network that uses a cross-edge attention mechanism mitigating modality intermittence, which translates into sparsity in the graph domain. Additionally, we present attention-weighted convolutions over frame-wise k-NN neighborhoods as suitable means to allow information exchange across disconnected graph components. We evaluate our approach using various sensor modalities and model configurations on the challenging nuScenes and KITTI datasets. Extensive experiments demonstrate that our proposed approach yields an overall improvement of 3.3% in the AMOTA score on nuScenes thereby setting the new state-of-the-art for 3D tracking and further enhancing false positive filtering.
# See Eye to Eye: A Lidar-Agnostic 3D Detection Framework for Unsupervised Multi-Target Domain Adaptation
## Keywords:
- Object Detection, Segmentation and Categorization
- Deep Learning for Visual Perception
- Sensor Fusion
## Abstract:
Sampling discrepancies between different manufacturers and models of lidar sensors result in inconsistent representations of objects. This leads to performance degradation when 3D detectors trained for one lidar are tested on other types of lidars. Remarkable progress in lidar manufacturing has brought about advances in mechanical, solid-state, and recently, adjustable scan pattern lidars. For the latter, existing works often require fine-tuning the model each time scan patterns are adjusted, which is infeasible. We explicitly deal with the sampling discrepancy by proposing a novel unsupervised multi-target domain adaptation framework, SEE, for transferring the performance of state-of-the-art 3D detectors across both fixed and flexible scan pattern lidars without requiring fine-tuning of models by end-users. Our approach interpolates the underlying geometry and normalises the scan pattern of objects from different lidars before passing them to the detection network. We demonstrate the effectiveness of SEE on public datasets, achieving state-of-the-art results, and additionally provide quantitative results on a novel high-resolution lidar to prove the industry applications of our framework. Our code and data are available at https://github.com/darrenjkt/SEE-MTDA.
# MV6D: Multi-View 6D Pose Estimation on RGB-D Frames Using a Deep Point-Wise Voting Network
## Keywords:
- Object Detection, Segmentation and Categorization
- RGB-D Perception
- Deep Learning for Visual Perception
## Abstract:
Estimating 6D poses of objects is an essential computer vision task. However, most conventional approaches rely on camera data from a single perspective and therefore suffer from occlusions. We overcome this issue with our novel multi-view 6D pose estimation method called MV6D which accurately predicts the 6D poses of all objects in a cluttered scene based on RGB-D images from multiple perspectives. We base our approach on the PVN3D network that uses a single RGB-D image to predict keypoints of the target objects. We extend this approach by using a combined point cloud from multiple views and fusing the images from each view with a DenseFusion layer. In contrast to current multi-view pose detection networks such as CosyPose, our MV6D can learn the fusion of multiple perspectives in an end-to-end manner and does not require multiple prediction stages or subsequent fine tuning of the prediction. Furthermore, we present three novel photorealistic datasets of cluttered scenes with heavy occlusions. All of them contain RGB-D images from multiple perspectives and the ground truth for instance semantic segmentation and 6D pose estimation. MV6D significantly outperforms the state-of-the-art in multi-view 6D pose estimation even in cases where the camera poses are known inaccurately. Furthermore, we show that our approach is robust towards dynamic camera setups and that its accuracy increases incrementally with an increasing number of perspectives.
# Deep Tri-Training for Semi-Supervised Image Segmentation
## Keywords:
- Object Detection, Segmentation and Categorization
- Semantic Scene Understanding
## Abstract:
Semantic segmentation is of great value to autonomous driving and many robotic applications, while it highly depends on costly and time-consuming pixel-level annotation. To make full use of unlabeled data, this work proposes a deep tri-training framework (dubbed DTT) to utilize labeled along with unlabeled data for training in a semi-supervised manner. Concretely, in the DTT framework, three networks are initialized with the same structure but different parameters. The networks are optimized circularly, where one network is trained in each optimization step with the guidance of the other two networks. A simple yet effective voting mechanism is adopted to construct reliable training sets from unlabeled data for the training stage and fusing multi-experts prediction in the testing stage. Exhaustive experiments on Cityscapes and PASCAL VOC 2012 demonstrate that the proposed DTT realizes state-of-the-art performance in the semi-supervised segmentation task. The source code is made publicly available.
# Child Engagement Estimation in Heterogeneous Child-Robot Interactions Using Spatiotemporal Visual Cues
## Keywords:
- Social HRI
- Visual Learning
## Abstract:
Robots are increasingly introduced in various Child-Robot Interactions with educational, entertainment or even therapeutic goals. In order to achieve qualitative interactions, robots need to adjust their behavior according to children's response. A robot's ability to successfully estimate partner's engagement is of great importance towards this direction. In this research we propose a method to estimate the engagement level of children during heterogeneous and challenging child-robot interactions. Our method uses the spatiotemporal residual R(2+1)D blocks to simultaneously leverage the rich RGB and temporal information, which is crucial for the engagement estimation. We present results on three different groups of data, including the PInSoRo open dataset, proving our method's robustness and improvement over previous works.
# TRAVEL: Traversable Ground and Above-Ground Object Segmentation Using Graph Representation of 3D LiDAR Scans
## Keywords:
- Object Detection, Segmentation and Categorization
- Range Sensing
- Autonomous Vehicle Navigation
## Abstract:
Perception of traversable regions and objects of interest from a 3D point cloud is one of the critical tasks in autonomous navigation. A ground vehicle needs to look for traversable terrains that are explorable by wheels. Then, to make safe navigation decisions, the segmentation of objects positioned on those terrains has to be followed up. However, over-segmentation and under-segmentation can negatively influence such navigation decisions. To that end, we propose TRAVEL, which performs traversable ground detection and object clustering simultaneously using the graph representation of a 3D point cloud. To segment the traversable ground, a point cloud is encoded into a graph structure, tri-grid field, which treats each tri-grid as a node. Then, the traversable regions are searched and redefined by examining local convexity and concavity of edges that connect nodes. On the other hand, our above-ground object segmentation employs a graph structure by representing a group of horizontally neighboring 3D points in a spherical-projection space as a node and vertical/horizontal relationship between nodes as an edge. Fully leveraging the node-edge structure, the above-ground segmentation ensures real-time operation and mitigates over-segmentation. Through experiments using simulations, urban scenes, and our own datasets, we have demonstrated that our proposed traversable ground segmentation algorithm outperforms other state-of-the-art methods in terms of the conventional metrics and that our newly proposed evaluation metrics are meaningful for assessing the above-ground segmentation. We will make the code and our own dataset available to public at https://github.com/url-kaist/TRAVEL
# One Object at a Time: Accurate and Robust Structure from Motion for Robots
## Keywords:
- Perception-Action Coupling
- RGB-D Perception
- Visual Servoing
## Abstract:
A gaze-fixating robot perceives distance to the fixated object and relative positions of surrounding objects immediately, accurately, and robustly. We show how fixation, which is the act of looking at one object while moving, exploits regularities in the geometry of 3D space to obtain this information. These regularities introduce rotation-translation couplings that are not commonly used in structure from motion. To validate, we use a Franka Emika Robot with an RGB camera. We a) find that error in distance estimate is less than 5 mm at a distance of 15 cm, and b) show how relative position can be used to find obstacles under challenging scenarios. We combine accurate distance estimates and obstacle information into a reactive robot behavior that is able to pick up objects of unknown size, while impeded by unforeseen obstacles.
# 2D vs. 3D LiDAR-Based Person Detection on Mobile Robots
## Keywords:
- Human Detection and Tracking
- Service Robotics
- Performance Evaluation and Benchmarking
## Abstract:
Person detection is a crucial task for mobile robots navigating in human-populated environments. LiDAR sensors are promising for this task, thanks to their accurate depth measurements and large field of view. Two types of LiDAR sensors exist: the 2D LiDAR sensors, which scan a single plane, and the 3D LiDAR sensors, which scan multiple planes, thus forming a volume. How do they compare for the task of person detection? To answer this, we conduct a series of experiments, using the public, large-scale JackRabbot dataset and the state-of-the-art 2D and 3D LiDAR-based person detectors (DR-SPAAM and CenterPoint respectively). Our experiments include multiple aspects, ranging from the basic performance and speed comparison, to more detailed analysis on localization accuracy and robustness against distance and scene clutter. The insights from these experiments highlight the strengths and weaknesses of 2D and 3D LiDAR sensors as sources for person detection, and are especially valuable for designing mobile robots that will operate in close proximity to surrounding humans (e.g. service or social robot).
# Contact Modeling and Force/Tactile Sensing
# Validating Robotics Simulators on Real-World Impacts
## Keywords:
- Contact Modeling
- Simulation and Animation
- Dynamics
## Abstract:
A realistic simulation environment is an essential tool in every roboticist's toolkit, with uses ranging from planning and control to training policies with reinforcement learning. Despite the centrality of simulation in modern robotics, little work has been done comparing robotics simulators against real-world data, especially for scenarios involving dynamic motions with high speed impact events. Handling dynamic contact is the computational bottleneck for most simulations, and thus the modeling and algorithmic choices surrounding impacts and friction form the largest distinctions between popular tools. Here, we evaluate the ability of several simulators to reproduce real-world trajectories involving impacts. Using experimental data, we identify system-specific contact parameters of popular simulators Drake, MuJoCo, and Bullet, analyzing the effects of modeling choices around these parameters. For the simple example of a cube tossed onto a table, simulators capture inelastic impacts surprisingly well, though generally fail to reproduce elasticity. For the higher-dimensional case of a Cassie biped landing from a jump, the simulators capture the bulk motion well but the accuracy is limited by model differences between the real robot and the simulators.
# Velocity Level Approximation of Pressure Field Contact Patches
## Keywords:
- Contact Modeling
- Simulation and Animation
- Dynamics
## Abstract:
Pressure Field Contact (PFC) was recently introduced as a method for detailed modeling of contact interface regions at rates much faster than elasticity-theory models, while at the same time predicting essential trends and capturing rich contact behavior. The PFC model was designed to work in conjunction with error-controlled integration at the acceleration level. Therefore a vast majority of existent multibody codes using solvers at the velocity level cannot incorporate PFC in its original form. In this work we introduce a discrete in time approximation of PFC making it suitable for use with existent velocity-level time steppers and enabling execution at real-time rates. We evaluate the accuracy and performance gains of our approach and demonstrate its effectiveness in simulating relevant manipulation tasks. The method is available in open source as part of Drake’s Hydroelastic Contact model.
# Visual Pressure Estimation and Control for Soft Robotic Grippers
## Keywords:
- Contact Modeling
- Modeling, Control, and Learning for Soft Robots
- Perception for Grasping and Manipulation
## Abstract:
Soft robotic grippers facilitate contact-rich manipulation, including robust grasping of varied objects. Yet the beneficial compliance of a soft gripper also results in significant deformation that can make precision manipulation challenging. We present visual pressure estimation & control (VPEC), a method that infers pressure applied by a soft gripper using an RGB image from an external camera. We provide results for visual pressure inference when a pneumatic gripper and a tendon-actuated gripper make contact with a flat surface. We also show that VPEC enables precision manipulation via closed-loop control of inferred pressure images. In our evaluation, a mobile manipulator (Stretch RE1 from Hello Robot) uses visual servoing to make contact at a desired pressure; follow a spatial pressure trajectory; and grasp small low-profile objects, including a microSD card, a penny, and a pill. Overall, our results show that visual estimates of applied pressure can enable a soft gripper to perform precision manipulation.
# Environmental Interaction with Continuum Robots Exploiting Impact
## Keywords:
- Contact Modeling
- Force and Tactile Sensing
- Tendon/Wire Mechanism
## Abstract:
Continuum robots offer unique potential benefits for environmental exploration, notably in using their maneuverability to navigate congested environments. However, significant challenges remain in environmental sensing using continuum structures, within which space for local sensing is often extremely limited. In this paper, we discuss the use of novel impulsive interaction, i.e. active tapping, using continuum robots to sense and identify features within their environment. We introduce an impact model-based tapping approach for environmental feature detection with continuum robots which does not require the addition of specialized sensors, and demonstrate its utility in hardware. We contrast the method to two alternative approaches to contact detection. The methods are compared empirically on two different types of continuum robot hardware, the pneumatically actuated "OctArm" and a tendon actuated "Tendril". The results identify relative strengths of the approaches. The impact model based approach is shown to include information not accessible to the other approaches.
# Tactile Pattern Super Resolution with Taxel-Based Sensors
## Keywords:
- Force and Tactile Sensing
- Perception for Grasping and Manipulation
- Calibration and Identification
## Abstract:
In contrast to sophisticated means of visual super resolution (SR), not much work has been done in the tactile SR field. Existing tactile SR algorithms for taxel-based sensors mainly focus on enhancing the localization accuracy, and generally associate with a specific type of hardware, sometimes not applicable to generic taxel-based tactile sensors. Inspired by image SR, we investigate the tactile pattern SR in this paper, and present how to transform successful image SR schemes, e.g. Convolutional Neural Network (CNN) and Generative Adversarial Network (GAN) to serve the tactile SR. We propose two tactile SR models, i.e. TactileSRCNN and TactileSRGAN, and establish a new tactile pattern SR dataset for model learning. The ground truth of high resolution (HR) tactile patterns in the dataset is obtained via multi-sampling (i.e. overlapping reception) and registration of low resolution (LR) sensor. One key contribution of this research lies in achieving x100 (from 3x4x4 to 40x40) times tactile pattern SR with a one-time tapping of 3-axis taxel-based sensor.Different from existing tactile SR algorithms which improves the localization accuracy of a single contact point, the proposed scheme can provide multipoint contact detection to robotic applications.
# Learning-Based Six-Axis Force/Torque Estimation Using GelStereo Fingertip Visuotactile Sensing
## Keywords:
- Force and Tactile Sensing
- Grasping
- Perception for Grasping and Manipulation
## Abstract:
Visuotactile sensors have recently attracted much attention in robot communities due to the benefit of high spatial resolution sensing. However, force/torque estimation by visuotactile sensors remains a challenging problem. In this paper, we propose a learning-based six-axis force/torque estimation network using GelStereo visuotactile sensor, which can provide two-dimensional (2D) and three-dimensional (3D) displacements of markers embedded in the sensor surface. The convolutional neural networks are employed to extract multi-modal tactile deformation features; and a novel contact positional encoding method is proposed to eliminate the influence of translation invariance in convolutional operators. The well-trained model achieves the best RMSE of 0.290 N in force and 0.0084 Nm in torque. Furthermore, the proposed force/torque estimation network is integrated with a force-feedback policy for adaptive grasping tasks. The experimental results demonstrate the effectiveness of the proposed method and its potential application in robotic grasping and manipulation tasks.
# Deep Learning Classification of Touch Gestures Using Distributed Normal and Shear Force
## Keywords:
- Haptics and Haptic Interfaces
- Force and Tactile Sensing
- Touch in HRI
## Abstract:
When humans socially interact with another agent (e.g., human, pet, or robot) through touch, they do so by applying varying amounts of force with different directions, locations, contact areas, and durations. While previous work on touch gesture recognition has focused on the spatio-temporal distribution of normal forces, we hypothesize that the addition of shear forces will permit more reliable classification. We present a soft, flexible skin with an array of tri-axial tactile sensors for the arm of a person or robot. We use it to collect data on 13 touch gesture classes through user studies and train a Convolutional Neural Network (CNN) to learn spatio-temporal features from the recorded data. The network achieved a recognition accuracy of 74% with normal and shear data, compared to 66% using only normal force data. Adding distributed shear data improved classification accuracy for 11 out of 13 touch gesture classes.
# Modulo Cellulo: Modular Versatile Tangible Educational Robots
## Keywords:
- Education Robotics
- Cellular and Modular Robots
## Abstract:
This article presents the novel modular version of the robotic platform Cellulo, a versatile handheld robot initially designed as an educational robot. The use of Cellulo in different contexts and applications over the years has highlighted the need for modularity. Modularity adds versatility by increasing the spectrum of functionalities of the robot, as well as more robustness. Modulo Cellulo consists of three modules: a main module, a battery module, and an interaction module. We describe the new Modulo Cellulo platform, the different modules design, the mechanical and electrical inter-connectivity between them, the new adaptive controller, and the application development framework. As a show case, we present the addition of the reconfigurable robot Mori as a module for Cellulo, in an activity envisioning the collaboration between reconfigurable swarm robots.
# Design and Evaluation of a Miniaturized Force Sensor Based on Wave Backscattering
## Keywords:
- Force and Tactile Sensing
- Surgical Robotics: Steerable Catheters/Needles
- Medical Robots and Systems
## Abstract:
The ability to sense forces is a critical component for ensuring that robots can safely interact with their environment. Yet there are numerous situations, in particular for medical applications, where environmental and sensor density requirements can pose challenges to sensor design. In our previous work, we presented a novel wireless force sensing paradigm, based on wave backscattering. In this paper, we present an improved and miniaturized design, suitable for wireless communications. We present an end-to-end simulation of the proposed sensor, its fabrication, modeling, and experimental validations in a wired setting. Our sensor can sense forces in the range of 0 N to 6 N, with a Root Mean Square (RMS) error of 0.17 N, on average, for our two sensor prototypes, and provides wireless compatibility in a range of frequencies adapted for use inside the human body. We present a demonstration of contact force sensing with our sensors mounted on the body of a continuum robot, and show its potential to enable applications in fields such as medical robotics.
# Physical Human-Robot Interaction
# A Framework of Rehabilitation-Assisted Robot Skill Representation, Learning, and Modulation Via Manifold-Mappings and Gaussian Processes
## Keywords:
- Physical Human-Robot Interaction
- Rehabilitation Robotics
- Learning from Demonstration
## Abstract:
Stroke survivors usually have dyskinesia, who have an urgent need for rehabilitation-assist training. To reduce the labor of therapists, this paper attempts to investigate an effective rehabilitation-assisted robot skill acquisition framework, which is inspired by the scheme of robot learning from demonstration (LfD). Since most of the current LfD methods were implemented with rigorous assumptions that the considering motion features are only represented on an individual manifold. Meanwhile, despite many advancements that have been achieved on time-position and position-velocity trajectories, those methods are restricted to Euclidean space and cannot be applied to learn those dexterous and compliant rehabilitation-assisted robot skills such as position-orientation and force-stiffness trajectories, etc. In this paper, we propose a novel rehabilitation robot skill learning scheme using manifold-mappings and Gaussian processes, named as MF^2RoSL, which allows the robot to 1) simultaneously considering the robot position, orientation, force as well as stiffness by manifold-mappings among Euclidean space, special orthogonal group, and Riemannian space, respectively, which resulting in accurate motion and compliant behavior; 2) retrieving skill representation by encapsulating the variability of multiple high-dimensional demonstrations that with input-dependent noises; 3) implementing the via-points-based trajectory modulation by considering task constraints or environmental changes. To effectively evaluate the effectiveness, an upper limb rehabilitation training system with a Kinova robot is developed. The training exercises of our system are determined according to the Brunnstrom therapeutic approach to the management of hemiplegic patients, including the 3-DoFs movement of the shoulder joint and a 7-DoF movement of an insertion/extraction task for assessing the activities of daily living (ADL). Results indicate that our proposed MF^2RoSL method allows the robot to learn rehabilitation skills from the therapist and can be rapidly adapted to new patients.
# Position-Based Treadmill Drive with Wire Traction for Experience of Level Ground Walking from Gait Acceleration State to Steady State
## Keywords:
- Physical Human-Robot Interaction
- Human-Centered Automation
- Human Factors and Human-in-the-Loop
## Abstract:
A treadmill system has a large potential to provide humans with an augmented walking experience in real-life without a spatial limitation. However, a treadmill gait is different from walking on level ground. In previous studies, the adaptive belt speed control of a treadmill was developed to achieve a self-paced walking for making the users’ treadmill gait similar to their level ground gait. Such studies have focused on steady-state walking and regulating the user’s position on the treadmill. A normal gait can be divided into an acceleration state after gait initiation, a steady state, and a deceleration state for stopping. The objective of this study is to develop a treadmill system with a wire tension application enabling a human to experience a similar gait to a level ground gait during the transition phase from an acceleration state to a steady state. We developed a treadmill 4 m long × 1 m wide. To allow a user to move on the treadmill during the gait acceleration phase, an insensitive zone where a user can move without the treadmill belt drive was set. In addition, the treadmill was equipped with a wire traction system to apply a traction force canceling the effect of the belt floor acceleration of the treadmill when the belt speed of the treadmill changes. Through an experiment with six participants, the proposed treadmill system allowed the users to move in an acceleration state with the same head acceleration pattern as with level ground walking and cancel the inertial effect with the wire traction, which enabled the users to transition to a steady state from an acceleration state.
# A Null-Space Based Approach for a Safe and Effective Human-Robot Collaboration
## Keywords:
- Physical Human-Robot Interaction
- Human-Robot Collaboration
- Force Control
## Abstract:
During physical human robot collaboration, it is important to be able to implement a time-varying interactive behaviour while ensuring robust stability. Admittance control and passivity theory can be exploited for achieving these objectives. Nevertheless, when the admittance dynamics is time-varying, it can happen that, for ensuring a passive and stable behaviour, some spurious dissipative effects have to be introduced in the admittance dynamics. These effects are perceived by the user and degrade the collaborative performance. In this paper we exploit the task redundancy of the manipulator in order to harvest energy in the null space and to avoid spurious dynamics on the admittance. The proposed architecture is validated by simulations and by experiments onto a collaborative robot.
# Fast and Comfortable Interactive Robot-To-Human Object Handover
## Keywords:
- Physical Human-Robot Interaction
## Abstract:
Transferring tools and objects to human hands is an important ability of collaborative robots. Most of the existing approaches focus on handover affordance, however, the comfort of receiving objects with human hands is often neglected. In this paper, we use advanced deep learning models to pre-generate handover target configurations that are convenient for human grasping based on the characteristics of the objects and tools, and then the robot grasps and passes the objects to the human. Experimental results on a mobile collaborative robot show that our proposed framework is able to robustly and efficiently deliver different shapes and types of objects to a human hand of any pose within the robot's field of view in a target pose that is convenient for grasping and can quickly deliver objects to a new target location even after the human hand moves to a new position.
# MOCA-S: A Sensitive Mobile Collaborative Robotic Assistant Exploiting Low-Cost Capacitive Tactile Cover and Whole-Body Control
## Keywords:
- Physical Human-Robot Interaction
- Safety in HRI
- Human-Centered Robotics
## Abstract:
Safety is one of the most fundamental aspects of robotics, especially when it comes to collaborative robots (cobots) that are expected to physically interact with humans. Although a large body of literature has focused on safety-related aspects for fixed-based cobots, a low effort has been put into developing collaborative mobile manipulators. In response to this need, this work presents MOCA-S, i.e., Sensitive Mobile Collaborative Robotic Assistant, that integrates a low-cost, capacitive tactile cover to measure interaction forces applied to the robot base. The tactile cover comprises a set of 11 capacitive large-area tactile sensors distributed as a 1-D tactile array around the base. Characterization of the tactile sensors with different materials is included. Moreover, two expanded whole-body controllers that exploit the platform's tactile cover and the loco-manipulation features are proposed. These controllers are tested in two experiments, demonstrating the potential of MOCA-S for safe physical Human-Robot Interaction (pHRI). Finally, an experiment is carried out in which an undesired collision occurs between MOCA-S and a human during a loco-manipulation task. The results demonstrate the intrinsic safety of MOCA-S and the proposed controllers, suggesting a new step towards creating safe mobile manipulators.
# In-Hand Admittance Controller for a Robotic Assistive Walker Based on Tactile Grasping Feedback
## Keywords:
- Physical Human-Robot Interaction
- Physically Assistive Devices
- Force and Tactile Sensing
## Abstract:
An intelligent assistive robotic walker can be a tremendous help to patients with mobility disorders, e.g., hemiplegia patients. However, at the same time, a full-size assistive walker could be difficult to steer due to the reduced balancing ability of the patient. An intuitive interface can provide a promising solution to the low operability of such robotized assistive devices. Commonly developed gait assistance methodologies perform real-time adjustment of admittance model parameters in a forward direction. However, such a variable admittance model often accidentally affects the rotation behavior as well, which can lead to reducing the operability of the robotic device. To resolve such operational issues, we propose an in-Hand Admittance Controller (i-HAC) as a novel physical human-robot interaction interface for a robotic assistive walker. i-HAC is composed of multiple admittance models based on grasping feedback from sensitive robotic skin placed on both handlebars of a robotic assistive walker. This controller is formulated as a multiple-point-mass-damper system and can generate intuitive movement in both single and dual grasping situations. We conduct two experiments to demonstrate the benefits of i-HAC on a full-sized robotic walker in going forward with single grasping and rotating with dual grasping in comparison to the conventional admittance controller. Our experimental studies show that i-HAC potentially reduces the operation effort by 85% in the single grasping case and improves rotation consistency by 93% in the dual grasping case.
# Robot-Assisted Drilling on Curved Surfaces with Haptic Guidance under Adaptive Admittance Control
## Keywords:
- Physical Human-Robot Interaction
- Compliance and Impedance Control
## Abstract:
Drilling a hole on a curved surface with a desired angle is prone to failure when done manually, due to the difficulties in drill alignment and also inherent instabilities of the task, potentially causing injury and fatigue to the workers. On the other hand, it can be impractical to fully automate such a task in real manufacturing environments because the parts arriving at an assembly line can have various complex shapes where drill point locations are not easily accessible, making automated path planning difficult. In this work, an adaptive admittance controller with 6 degrees of freedom is developed and deployed on a KUKA LBR iiwa 7 cobot such that the operator is able to manipulate a drill mounted on the robot with one hand comfortably and open holes on a curved surface with haptic guidance of the cobot and visual guidance provided through an AR interface. Real-time adaptation of the admittance damping provides more transparency when driving the robot in free space while ensuring stability during drilling. After the user brings the drill sufficiently close to the drill target and roughly aligns to the desired drilling angle, the haptic guidance module fine tunes the alignment first and then constrains the user movement to the drilling axis only, after which the operator simply pushes the drill into the workpiece with minimal effort. Two sets of experiments were conducted to investigate the potential benefits of the haptic guidance module quantitatively (Experiment I) and also the practical value of the proposed pHRI system for real manufacturing settings based on the subjective opinion of the participants (Experiment II). The results of Experiment I, conducted with 3 naive participants, show that the haptic guidance improves task completion time by 26% while decreasing human effort by 16% and muscle activation levels by 27% compared to no haptic guidance condition. The results of Experiment II, conducted with 3 experienced industrial workers, show that the proposed system is perceived to be easy to use, safe, and helpful in carrying out the drilling task.
# Towards Safe Physical Human-Robot Interaction by Exploring the Rapid Stiffness Switching Feature of Discrete Variable Stiffness Actuation
## Keywords:
- Physical Human-Robot Interaction
- Safety in HRI
- Compliant Joints and Mechanisms
## Abstract:
Safety holds the prime importance in direct physical human-robot interaction (pHRI) tasks. Robots should have the ability to handle unexpected collisions in unstructured environments. Collision avoidance based on exteroceptive sensors can work in these scenarios. However, it may not be sufficient, especially considering that the relative motion between robots and humans can be fast and hardly predictable. This highlights the importance of fast and reliable detection and reaction techniques for the collisions. Rapid switching to intrinsic complaint mode upon collisions is a promising solution for this requirement. Recently, we have proposed a new design of the discrete variable stiffness actuator (DVSA), which has the capability of instantaneously switching its stiffness between different predefined levels. We believe that this rapid stiffness switching feature can significantly improve safety during collisions. In this letter, we combined a software-based collision detection method with a hardware-based rapid stiffness switching technique. The proposed strategy has been implemented on a DVSA-based manipulator to evaluate its safety performance in the sudden dynamic collision and static near-singular clamping collision scenarios. The results clearly indicate that the proposed strategy can significantly mitigate the impact of unexpected collisions and improve safety during pHRI.
# Robustness of Interaction Parameters Identification Technique for Collaborative Robots
## Keywords:
- Physical Human-Robot Interaction
- Force and Tactile Sensing
- Human-Robot Collaboration
## Abstract:
The work focuses on accuracy of the identification procedure allowing to estimate the force and its application point in human-robot physical interaction. It is assumed that the desired parameters are estimated using data obtained from internal torque sensors embedded in the robot joints as well as 3D geometric models describing the robot link surfaces. In practice, the measurement data are corrupted by the noise, which causes identification errors. To evaluate these errors, the relevant covariance matrix is obtained assuming that the measurement noise is presented as unbiased and independent but not identically distributed random values. Based on the relevant analysis, enhancement of the existing method was proposed, which improves the identification accuracy and its robustness with respect to the measurement noise. Particular attention is paid to singular cases arising when the estimated force action line intersects one or several joint sensor axes or does not intersect the robot body at all. The efficiency of the developed techniques was confirmed via simulation and experimental studies with the KUKA iiwa robot.
# Visual Tracking
# Learning Moving-Object Tracking with FMCW LiDAR
## Keywords:
- Visual Tracking
- Deep Learning for Visual Perception
- Object Detection, Segmentation and Categorization
## Abstract:
In this paper, we propose a learning-based moving-object tracking method utilizing the newly developed LiDAR sensor, Frequency Modulated Continuous Wave (FMCW) LiDAR. Compared with most existing commercial LiDAR sensors, FMCW LiDAR can provide additional Doppler velocity information to each 3D point of the point clouds. Benefiting from this, we can generate instance labels as ground truth in a semi-automatic manner. Given the labels, we propose a contrastive learning framework, which pulls together the features from the same instance in embedding space and pushes apart the features from different instances, to improve the tracking quality. Extensive experiments are conducted on the recorded driving data, and the results show that our method outperforms the baseline methods by a large margin.
# Self-Supervised Learning for Multiple Object Tracking in 3D Point Clouds
## Keywords:
- Visual Tracking
- Human Detection and Tracking
- Autonomous Vehicle Navigation
## Abstract:
Multiple object tracking in 3D point clouds has applications in mobile robots and autonomous driving. This is a challenging problem due to the sparse nature of the point clouds and the added difficulty of annotation in 3D for supervised learning. To overcome these challenges, we propose a neural network architecture that learns effective object features and their affinities in a self-supervised fashion for multiple object tracking in 3D point clouds captured with LiDAR sensors. For self supervision, we use two approaches. First, we generate two augmented LiDAR frames from a single real frame by applying translation, rotation and cutout to the objects. Second, we synthesize a LiDAR frame using CAD models or primitive geometric shapes and then apply the above three augmentations to them. Hence, the ground truth object locations and associations are known in both frames for self supervision. This removes the need to annotate object associations in real data, and additionally the need for training data collection and annotation for object detection in synthetic data. To the best of our knowledge, this is the first self supervised multiple object tracking in 3D method.	Our model achieves state of the art results.
# An Efficient and Accurate Solution to Camera Pose Estimation Problem from Point and Line Correspondences Based on Null Space Analysis
## Keywords:
- Visual Tracking
- Calibration and Identification
- Computer Vision for Automation
## Abstract:
In this paper, we propose an accurate and simultaneously efficient solution to perspective-n-point-and-line (PnPL) problem by null space analysis. Although many PnPL-like methods have been proposed, it is hard to obtain the optimal solution considering both calculation efficiency and accuracy at the same time. Based on the remarkable EOPnP method, the proposed algorithm integrates linear-expressed line constraints with original point constraints, leading to a new solution named EOPnPL. For line error measurement, instead of using the algebraic error built with reprojected endpoints and image lines, we adopt line error function containing the distance from the reprojected midpoint of the model line segment to the image line and giving it a weight 4 times as that of the endpoints. A system of linear homogeneous equations only involving the rotation are derived, containing point and line constraints. Minima are obtained by a null space analysis according to rotation constraints and then the solution is selected by reprojection errors before iterative refinement. Experimental results show that the proposed method showcases great performances in both simulations and real-data experiment on VGG dataset. Great advantages are presented by EOPnPL compared to PnL methods when using only lines. Among the state-of-the-arts methods, the proposed method stands out with high accuracy under ordinary condition and comparable results in planar condition with the speed close to the fastest.
# Improving 3D Markerless Pose Estimation of Animals in the Wild Using Low-Cost Cameras
## Keywords:
- Visual Tracking
- Optimization and Optimal Control
- Simulation and Animation
## Abstract:
Tracking the 3D motion of agile animals in the wild will enable new insight into the design of robotic controllers. However, in-field 3D pose estimation of high-speed wildlife such as cheetahs is still a challenge. In this work, we aim to solve two of these challenges: unnatural pose estimates during highly occluded sequences and synchronization error between multi-view data. We expand on our previous Full Trajectory Estimation (FTE) method with two significant additions: Pairwise FTE (PW-FTE) and Shutter-delay FTE (SD-FTE). The PW-FTE expands on image-dependent pairwise terms, produced by a convolutional neural network (CNN), to infer occluded 2D keypoints, while SD-FTE uses shutter delay estimation to correct the synchronization error. Lastly, we combine both methods into PW-SD-FTE and perform a quantitative and qualitative analysis on a subset of AcinoSet, the video dataset of rapid and agile motions of cheetahs. We found that SD-FTE has significant benefits in tracking the position of the cheetah in the world frame, while PW-FTE provided a more robust 3D pose estimate during events of high occlusion. The PW-SD-FTE was found to retain both advantages, resulting in an improved baseline for AcinoSet. Code and data can be found at https://github.com/African-Robotics-Unit/ AcinoSet/tree/pw_sd_fte.
# DirectTracker: 3D Multi-Object Tracking Using Direct Image Alignment and Photometric Bundle Adjustment
## Keywords:
- Visual Tracking
- Object Detection, Segmentation and Categorization
## Abstract:
Direct methods have shown excellent performance in the applications of visual odometry and SLAM. In this work we propose to leverage their effectiveness for the task of 3D multi-object tracking. To this end, we propose DirectTracker, a framework that effectively combines direct image alignment for the short-term tracking and sliding-window photometric bundle adjustment for 3D object detection. Object proposals are estimated based on the sparse sliding-window pointcloud and further refined using an optimization-based cost function that carefully combines 3D and 2D cues to ensure consistency in image and world space. We propose to evaluate 3D tracking using the recently introduced higher-order tracking accuracy (HOTA) metric and the generalized intersection over union similarity measure to mitigate the limitations of the conventional use of intersection over union for the evaluation of vision-based trackers. We perform evaluation on the KITTI Tracking benchmark for the Car class and show competitive performance in tracking objects both in 2D and 3D.
# Scene-Level Tracking and Reconstruction without Object Priors
## Keywords:
- Visual Tracking
- RGB-D Perception
- Sensor Fusion
## Abstract:
We present the first real-time system capable of tracking and reconstructing, individually, every visible object in a given scene, without any form of prior on the rigidness of the objects, texture existence, or object category. In contrast with previous methods such as Co-Fusion and MaskFusion that first segment the scene into individual objects and then process each object independently, the proposed method dynamically segments the non-rigid scene as part of the tracking and reconstruction process. When new measurements indicate topology change, reconstructed models are updated in real-time to reflect that change. Our proposed system can provide the live geometry and deformation of all visible objects in a novel scene in real-time, which makes it possible to be integrated seamlessly into numerous existing robotics applications that rely on object models for grasping and manipulation. The capabilities of the proposed system are demonstrated in challenging scenes that contain multiple rigid and non-rigid objects.
# Smart Visual Beacons with Asynchronous Optical Communications Using Event Cameras
## Keywords:
- Visual Tracking
- Networked Robots
- Cooperating Robots
## Abstract:
Event cameras are bio-inspired dynamic vision sensors that respond to changes in image intensity with a high temporal resolution, high dynamic range and low latency. These sensor characteristics are ideally suited to enable visual target tracking in concert with a broadcast visual communication channel for smart visual beacons with applications in distributed robotics. Visual beacons can be constructed by high-frequency modulation of Light Emitting Diodes (LEDs) such as vehicle headlights, Internet of Things (IoT) LEDs, smart building lights, etc., that are already present in many real-world scenarios. The high temporal resolution characteristic of the event cameras allows them to capture visual signals at far higher data rates compared to classical frame-based cameras. In this paper, we propose a novel smart visual beacon architecture with both LED modulation and event camera demodulation algorithms. We quantitatively evaluate the relationship between LED transmission rate, communication distance and the message transmission accuracy for the smart visual beacon communication system that we prototyped. The proposed method achieves up to 4 kbps in an indoor environment and lossless transmission over a distance of 100 meters, at a transmission rate of 500 bps, in full sunlight, demonstrating the potential of the technology in an outdoor environment.
# Category-Independent Articulated Object Tracking with Factor Graphs
## Keywords:
- Visual Tracking
- Probabilistic Inference
- Perception for Grasping and Manipulation
## Abstract:
Robots deployed in human-centric environments may need to manipulate a diverse range of articulated objects, such as doors, dishwashers, and cabinets. Articulated objects often come with unexpected articulation mechanisms that are inconsistent with categorical priors: for example, a drawer might rotate about a hinge joint instead of sliding open. We propose a category-independent framework for predicting the articulation models of unknown objects from sequences of RGB-D images. The prediction is performed by a two-step process: first, a visual perception module tracks object part poses from raw images, and second, a factor graph takes these poses and infers the articulation model including the current configuration between the parts as a 6D twist. We also propose a manipulation-oriented metric to evaluate predicted joint twists in terms of how well a compliant robot controller would be able to manipulate the articulated object given the predicted twist. We demonstrate that our visual perception and factor graph modules outperform baselines on simulated data and show the applicability of our factor graph on real world data.
# ECDT: Event Clustering for Simultaneous Feature Detection and Tracking
## Keywords:
- Visual Tracking
## Abstract:
Contrary to other standard cameras, event cameras interpret the world in an entirely different manner; as a collection of asynchronous events. Despite event camera's unique data output, many event feature detection and tracking algorithms have shown significant progress by making detours to frame-based data representations. This paper questions the need to do so and proposes a novel event data-friendly method that achieve simultaneous feature detection and tracking, called event Clustering-based Detection and Tracking (eCDT). Our method employs a novel clustering method, named as k-NN Classifier-based Spatial Clustering and Applications with noise (KCSCAN), to cluster adjacent polarity events to retrieve event trajectories. With the aid of a Head and Tail Descriptor Matching process, event clusters that reappear in a different polarity are continually tracked, elongating the feature tracks. Thanks to our clustering approach in spatio-temporal space, our method automatically solves feature detection and feature tracking simultaneously. Also, eCDT can extract feature tracks at any frequency with an adjustable time window, which does not corrupt the high temporal resolution of the original event data. Our method achieves 30% better feature tracking ages compared with the state-of-the-art approach while also having a low error approximately equal to it.
# Mapping 3
# Hierarchical Road Topology Learning for Urban Mapless Driving
## Keywords:
- Mapping
- Semantic Scene Understanding
- Sensor Fusion
## Abstract:
The majority of current approaches in autonomous driving rely on High-Definition (HD) maps which detail the road geometry and surrounding area. Yet, this reliance is one of the obstacles to mass deployment of autonomous vehicles due to poor scalability of such prior maps. In this paper, we tackle the problem of online road map extraction via leveraging the sensory system aboard the vehicle itself. To this end, we design a structured model where a graph representation of the road network is generated in a hierarchical fashion within a fully convolutional network. The method is able to handle complex road topology and does not require a user in the loop.
# S-MKI: Incremental Dense Semantic Occupancy Reconstruction through Multi-Entropy Kernel Inference
## Keywords:
- Mapping
- Semantic Scene Understanding
- Sensor Fusion
## Abstract:
Autonomous robots are often required to acquire high-level prior knowledge by continuously reconstructing the semantics and geometry of the surrounding scene, which is the basis of exploration and planning. Most existing continuous semantic mapping algorithms cannot distinguish potential differences in voxels, resulting in an over-inflated map. Furthermore, fixed-size query ranges introduce high computational complex ity. Based on the limitation of over-inflation and inefficiency, this paper proposes a novel incremental continuous semantic occupancy mapping algorithm (S-MKI). The key innovation of this work comes from the two models in the preprocessing stage. On the one hand, Redundant Voxel Filter Model utilizes context entropy to filter out redundant voxels to improve the confidence of the final map, where objects have accurate boundaries with sharp edges. On the other hand, Adaptive Kernel Length Model adaptively adjusts the kernel length with class entropy, which reduces the inherent amount of training data. The final multi-entropy kernel inference function is formulated to integrate these two models to infer sparse noisy sensor data into dense accurate 3D maps. Experimental results conducted in both indoors and outdoors datasets validate that S-MKI outperforms existing methods.
# BEV-SLAM: Building a Globally-Consistent World Map Using Monocular Vision
## Keywords:
- Mapping
- Vision-Based Navigation
- SLAM
## Abstract:
The ability to produce large-scale maps for navigation, path planning and other tasks is a crucial step for autonomous agents, but has always been challenging. In this work, we introduce BEV-SLAM, a novel type of graph-based SLAM that aligns semantically-segmented Bird's Eye View (BEV) predictions from monocular cameras. We introduce a novel form of occlusion reasoning into BEV estimation and demonstrate its importance to aid spatial aggregation of BEV predictions. The result is a versatile SLAM system that can operate across arbitrary multi-camera configurations and can be seamlessly integrated with other sensors. We show that the use of multiple cameras significantly increases performance, and achieves lower relative error than high-performance GPS. The resulting system is able to create large, dense, globally-consistent world maps from monocular cameras mounted around an ego vehicle. The maps are metric and correctly-scaled, making them suitable for downstream navigation tasks.
# Multi-Modal Lidar Dataset for Benchmarking General-Purpose Localization and Mapping Algorithms
## Keywords:
- Data Sets for SLAM
- Localization
- Sensor Fusion
## Abstract:
Lidar technology has evolved significantly over the last decade, with higher resolution, better accuracy, and lower cost devices available today. In addition, new scanning modalities and novel sensor technologies have emerged in recent years. Public datasets have enabled benchmarking of algorithms and have set standards for the cutting edge technology. However, existing datasets are not representative of the technological landscape, with only a reduced number of lidars available. This inherently limits the development and comparison of general-purpose algorithms in the evolving landscape. This paper presents a novel multi-modal lidar dataset with sensors showcasing different scanning modalities (spinning and solid-state), sensing technologies, and lidar cameras. The focus of the dataset is on low-drift odometry, with ground truth data available in both indoors and outdoors environment with sub-millimeter accuracy from a motion capture (MOCAP) system. For comparison in longer distances, we also include data recorded in larger spaces indoors and outdoors. The dataset contains point cloud data from spinning lidars and solid-state lidars. Also, it provides range images from high resolution spinning lidars, RGB and depth images from a lidar camera, and inertial data from built-in IMUs. This is, to the best of our knowledge, the lidar dataset with the most variety of sensors and environments where ground truth data is available. This dataset can be widely used in multiple research areas, such as 3D LiDAR simultaneous localization and mapping (SLAM), performance comparison between multi-modal lidars, appearance recognition and loop closure detection. The datasets are available at: https://github.com/TIERS/tiers-lidars-dataset.
# OdomBeyondVision: An Indoor Multi-Modal Multi-Platform Odometry Dataset Beyond the Visible Spectrum
## Keywords:
- Data Sets for SLAM
- Data Sets for Robotic Vision
- Data Sets for Robot Learning
## Abstract:
This paper presents a multimodal indoor odometry dataset, OdomBeyondVision, featuring multiple sensors across the different spectrum and collected with different mobile platforms. Not only does OdomBeyondVision contain the traditional navigation sensors, sensors such as IMUs, mechanical LiDAR, RGBD camera, it also includes several emerging sensors such as the single-chip mmWave radar, LWIR thermal camera and solid-state LiDAR. With the above sensors on UAV, UGV and handheld platforms, we respectively recorded the multimodal odometry data and their movement trajectories in various indoor scenes and different illumination conditions. We release the exemplar radar, radar-inertial and thermal-inertial odometry implementations to demonstrate their results for future works to compare against and improve upon. The full dataset including toolkit and documentation is publicly available at: https://github.com/MAPS-Lab/OdomBeyondVision
# FusionPortable: A Multi-Sensor Campus-Scene Dataset for Evaluation of Localization and Mapping Accuracy on Diverse Platforms
## Keywords:
- Data Sets for SLAM
- Sensor Fusion
- Autonomous Vehicle Navigation
## Abstract:
Combining multiple sensors enables a robot to maximize its perceptual awareness of environments and enhance its robustness to external disturbance, crucial to robotic navigation. This paper proposes the FusionPortable benchmark, a complete multi-sensor dataset with a diverse set of sequences for mobile robots. This paper presents three contributions. We first advance a portable and versatile multi-sensor suite that offers rich sensory measurements: 10Hz LiDAR point clouds, 20Hz stereo frame images, high-rate and asynchronous events from stereo event cameras, 200Hz inertial readings from an IMU, and 10Hz GPS signal. Sensors are already temporally synchronized in hardware. This device is lightweight, self-contained, and has plug-and-play support for mobile robots. Second, we construct a dataset by collecting 17 sequences that cover a variety of environments on the campus by exploiting multiple robot platforms for data collection. Some sequences are challenging to existing SLAM algorithms. Third, we provide ground truth for the decouple localization and mapping performance evaluation. We additionally evaluate state-of-the-art SLAM approaches and identify their limitations. The dataset, consisting of raw sensor measurements, ground truth, calibration data, and evaluated algorithms, will be released.
# STheReO: Stereo Thermal Dataset for Research in Odometry and Mapping
## Keywords:
- Data Sets for SLAM
- SLAM
- Vision-Based Navigation
## Abstract:
This paper introduces a stereo thermal camera dataset (STheReO) with multiple navigation sensors to encour# age thermal SLAM researches. A thermal camera measures infrared rays beyond the visible spectrum therefore it could provide a simple yet robust solution to visually degraded envi# ronments where existing visual sensor-based SLAM would fail. Existing thermal camera datasets mostly focused on monocular configuration using the thermal camera with RGB cameras in a visually challenging environment. A few stereo thermal rig were examined but in computer vision perspective without supporting sequential images for state estimation algorithms. To encourage the academia for the evolving stereo thermal SLAM, we obtain nine sequences in total across three spatial locations and three different times per location (e.g., morning, day, and night) to capture the variety of thermal characteristics. By using the STheReO dataset, we hope diverse types of researches will be made, including but not limited to odom# etry, mapping, and SLAM (e.g., thermal-LiDAR mapping or long-term thermal localization). Our datasets are available at https://sites.google.com/view/rpmsthereo/.
# VECtor: A Versatile Event-Centric Benchmark for Multi-Sensor SLAM
## Keywords:
- Data Sets for SLAM
- Data Sets for Robotic Vision
## Abstract:
Event cameras have recently gained in popularity as they hold strong potential to complement regular cameras in situations of high dynamics or challenging illumination. An important problem that may benefit from the addition of an event camera is given by Simultaneous Localization And Mapping (SLAM). However, in order to ensure progress on event-inclusive multi-sensor SLAM, novel benchmark sequences are needed. Our contribution is the first complete set of benchmark datasets captured with a multi-sensor setup containing an event-based stereo camera, a regular stereo camera, multiple depth sensors, and an inertial measurement unit. The setup is fully hardware-synchronized and underwent accurate extrinsic calibration. All sequences come with ground truth data captured by highly accurate external reference devices such as a motion capture system. Individual sequences include both small and large-scale environments, and cover the specific challenges targeted by dynamic vision sensors.
# Challenges of SLAM in Extremely Unstructured Environments: The DLR Planetary Stereo, Solid-State LiDAR, Inertial Dataset
## Keywords:
- Data Sets for SLAM
- Space Robotics and Automation
- Field Robots
## Abstract:
We present the DLR Planetary Stereo, Solid-State LiDAR, Inertial (S3LI) dataset, recorded on Mt. Etna, Sicily, an environment analogous to the Moon and Mars, using a hand-held sensor suite with attributes suitable for implementation on a space-like mobile rover. The environment is characterized by challenging conditions regarding both the visual and structural appearance: severe visual aliasing poses significant limitations to the ability of visual SLAM systems to perform place recognition, while the absence of outstanding structural details, joined with the limited Field-of-View of the utilized Solid-State LiDAR sensor, challenges traditional LiDAR SLAM for the task of pose estimation using point clouds alone. With this data, that covers more than 4 kilometers of travel on soft volcanic slopes, we aim to: 1) provide a tool to expose limitations of state-of-the-art SLAM systems with respect to environments, which are not present in widely available datasets and 2) motivate the development of novel localization and mapping approaches, that rely efficiently on the complementary capabilities of the two sensors. The dataset is accessible at the following url: https://rmc.dlr.de/s3li_dataset
# Human-Centered Robotics 3
# Affective Behavior Learning for Social Robot Haru with Implicit Evaluative Feedback
## Keywords:
- Human-Centered Automation
- Emotional Robotics
- Human-Robot Collaboration
## Abstract:
We propose a human-in-the-loop reinforcement learning mechanism to help robots learn emotional behavior. Unlike the previous methods of providing explicit feedback via pressing keyboard buttons or mouse clicks, we provide a more natural way for ordinary people to train social robots how to perform social tasks according to their preferences -# facial expressions. The whole experiment is carried out on the desktop robot Haru, which is mainly used for the research of emotion and empathy participation. Our experimental results show that through learning from implicit feedback of facial features, Haru can quickly understand and dynamically adapt to individual preferences, and obtain a similar performance to learning from explicit feedback. In addition, we observe that the recognition error of human feedback will cause a "temporary regress" of the robot's learning performance, which is more obvious at the beginning of the training process. This phenomenon is shown to be correlated with the accuracy of recognizing negative implicit feedback.
# Efficient Hand Gesture Recognition for Human-Robot Interaction
## Keywords:
- Gesture, Posture and Facial Expressions
## Abstract:
In this paper, we present an efficient and reliable deep-learning approach that allows users to communicate with robots via hand gesture recognition.
Contrary to other works which use external devices such as gloves or joysticks to tele-operate robots, the proposed approach uses only visual information to recognize user's instructions that are encoded in a set of pre-defined hand gestures.
Particularly, the method consists of two modules which work sequentially to extract 2D landmarks of hands --ie. joints positions-# and to predict the hand gesture based on a temporal representation of them.
The approach has been validated in a recent state-of-the-art dataset where it outperformed other methods that use multiple pre-processing steps such as optical flow and semantic segmentation. 
Our method achieves an accuracy of 87,5% and runs at 10 frames per second. Finally, we conducted real-life experiments with our IVO robot to validate the framework during the interaction process.
# Augmented Reality-Assisted Reconfiguration and Workspace Visualisation of Malleable Robots (I)
## Keywords:
- Physical Human-Robot Interaction
- Virtual Reality and Interfaces
- Soft Robot Applications
## Abstract:
Malleable robots are a type of reconfigurable serial robot capable of adapting their topology, through the use of variable stiffness malleable links, to desired tasks and workspaces by varying the relative positioning between their revolute joints. However, their reconfiguration is non-trivial, lacking intuitive communication between the human and the robot, and a method of efficiently aligning the end-effector to a desired position. In this paper, we present the design of an interactive augmented reality alignment interface, which helps a malleable robot understand the users task requirements, visualises to the user the requested robot configuration and its workspace, and guides the user in reconfiguring the robot to achieve that configuration. Through motion tracking of a physical two-degree-of-freedom malleable robot, which can achieve an infinite number of workspaces, we compute the accuracy of the system in terms of initial calibration and overall accuracy, and demonstrate its viability. Results demonstrated a good performance with an average repositioning accuracy of 9.64±2.06 mm, and an average base alignment accuracy of 10.54±4.32 mm, in an environment of size 2000mm x 2000mm x 1200mm.
# A Tool for Organizing Key Characteristics of Virtual, Augmented, and Mixed Reality for Human-Robot Interaction Systems: Synthesizing VAM-HRI Trends and Takeaways (I)
## Keywords:
- Virtual Reality and Interfaces
## Abstract:
Frameworks have begun to emerge to categorize Virtual, Augmented, and Mixed Reality (VAM) technologies that provide immersive, intuitive interfaces to facilitate Human-Robot Interaction. These frameworks, however, fail to capture key characteristics of the growing subfield of VAM-HRI and can be difficult to consistently apply due to continuous scales. This work builds upon these prior frameworks through the creation of a Tool for Organizing Key Characteristics of VAM-HRI Systems (TOKCS). TOKCS discretizes the continuous scales used within prior works for more consistent classification and adds additional characteristics related to a robot's internal model, anchor locations, manipulability, and the system's software and hardware. To showcase the tool's capability, TOKCS is applied to the ten papers from the fourth VAM-HRI workshop and examined for key trends and takeaways. These trends highlight the expressive capability of TOKCS while also helping frame newer trends and future work recommendations for VAM-HRI research.
# Feasibility Study on Disentangling Muscle Movements in TMR Patients through a Myokinetic Control Interface for the Control of Artificial Hands
## Keywords:
- Prosthetics and Exoskeletons
- Visual Tracking
- Localization
## Abstract:
Targeted muscle reinnervation (TMR) is a surgical procedure which allows to restore myoelectric control sources in people with proximal upper-limb amputations. However, the large physical displacement generally provoked by the reinnervated muscles following contraction can represent a drawback for the use of surface electrodes, which are affected by movement artifacts. In this regard, the viability of directly exploiting the physical displacement of muscles as control source would be beneficial. We recently introduced the so called myokinetic interface, aimed at transducing muscle movements into decipherable signals for artificial hands by tracking magnetic markers implanted inside the muscles. This work features the combination of the TMR procedure with such interface, in a noninvasive way. Two participants who underwent TMR surgery following above-the-elbow amputation were enrolled in this study. During two experimental sessions, we assessed the feasibility of: (i) disentangling muscle displacements associated with different degrees of freedom (DoFs) of the missing limb through video analysis, and (ii) discriminating different DoFs by tracking the displacement of five magnetic markers placed on the skin, over the reinnervated sites. A simple logistic regressor proved able to discriminate three different DoFs (six movements), with an average F1-score among classes and testing conditions of 0.84 (0.65) and 0.69 (0.60) for the video and the myokinetic data, for the first (second) participant, respectively. The presented outcomes encourage further investigations, and pave the way towards novel control strategies for artificial hands in TMR patients.
# A-RIFT: Visual Substitution of Force Feedback for a Zero-Cost Interface in Telemanipulation
## Keywords:
- Telerobotics and Teleoperation
- Human Factors and Human-in-the-Loop
## Abstract:
We present an accessible robot interface for telemanipulation (A-RIFT), which preserves the haptic channel partially in a zero-additional-cost interface by visual substitution of force feedback (VSFF). This work explores a gap in the literature, resulting from the focus on performance improvements in telerobotics at increasing interface costs. Unlike most telemanipulation interfaces for high-degree-of-freedom robotic systems, this one requires minimal training and can be run in a web browser under high latency conditions, using an Internet connected computer with the user's own mouse and keyboard. To evaluate the performance of the system, we ran a controlled user study (N=12) to test how different distances (local vs. remote) and VSFF (on vs. off) affect the system's usability. As expected, participants in remote conditions performed worse than those in closer proximity. Despite several participants claiming that the visual display of force feedback did not help them, our analysis of their task performance showed that operators in remote condition actually performed statistically significantly better with the visual force feedback display than without it. These results indicate a promising new interface design direction for low-cost telemanipulation.
# Metabolic Efficiency Improvement of Human Walking by Shoulder Stress Reduction through Load Transfer Backpack
## Keywords:
- Human Performance Augmentation
- Human-Centered Robotics
- Physical Human-Robot Interaction
## Abstract:
The dynamic load attached to the load gravity imposes an excessive burden to human shoulders during load carriage, resulting in possible muscle injuries and additional physical exertion. This paper proposes an active suspension backpack, capable of transferring partial load from human shoulders to pelvis and alleviating the dynamic load through separated panels and motor actuation, to reduce pressure on human shoulders and improve walking metabolic efficiency. Based on the human body motion in the vertical direction, the dynamical model of the human-backpack system with shoulder interaction force measured by a soft ballonet with an embedded air pressure sensor is introduced, and an impedance controller has been implemented to maintain a relatively small and constant pressure on the shoulder. In an experimental case study, we presents preliminary results of three healthy subjects performing a treadmill walking with a 20kg load in ACTIVE configuration where the shoulder pressure shows a decrease by 30% along with a reduction of the metabolic energy consumption by 16.4%, compared with the load LOCKED case.
# Learning an Interpretable Model for Driver Behavior Prediction with Inductive Biases
## Keywords:
- Motion and Path Planning
- Physical Human-Robot Interaction
- Modeling and Simulating Humans
## Abstract:
To plan safe maneuvers and act with foresight, autonomous vehicles must be capable of accurately predicting the uncertain future. In the context of autonomous driving, deep neural networks have been successfully applied to learning predictive models of human driving behavior from data. However, the predictions suffer from cascading errors, resulting in large inaccuracies over long time horizons. Furthermore, the learned models are black boxes, and thus it is often unclear how they arrive at their predictions. In contrast, rule-based models---which are informed by human experts---maintain long-term coherence in their predictions and are human-interpretable. However, such models often lack the sufficient expressiveness needed to capture complex real-world dynamics. In this work, we begin to close this gap by embedding the Intelligent Driver Model, a popular hand-crafted driver model, into deep neural networks. Our model's transparency can offer considerable advantages, e.g., in debugging the model and more easily interpreting its predictions. We evaluate our approach on a simulated merging scenario, showing that it yields a robust model that is end-to-end trainable and provides greater transparency at no cost to the model's predictive accuracy.
# Sensor Fusion 2
# Robust Real-Time LiDAR-Inertial Initialization
## Keywords:
- Sensor Fusion
- Calibration and Identification
- SLAM
## Abstract:
For most LiDAR-inertial odometry, accurate initial states, including temporal offset and extrinsic transformation between LiDAR and 6-axis IMUs, play a significant role and are often considered as prerequisites. However, such information may not be always available in customized LiDAR-inertial systems. In this paper, we propose LI-Init: a full and real-time LiDAR-inertial system initialization process that calibrates the temporal offset and extrinsic parameter between LiDARs and IMUs, and also the gravity vector and IMU bias by aligning the state estimated from LiDAR measurements with that measured by IMU. We implement the proposed method as an initialization module, which can automatically detects the degree of excitation of the collected data and calibrate, on-the-fly, the temporal offset, extrinsic, gravity vector, and IMU bias, which are then used as high-quality initial state values for real-time LiDAR-inertial odometry systems. Experiments conducted with different types of LiDARs and LiDAR-inertial combinations show the robustness, adaptability and efficiency of our initialization method. The implementation of our LiDAR-inertial initialization procedure LI-Init and test data are open-sourced on Github and also integrated into a state-of-the-art LiDAR-inertial odometry system FAST-LIO2.
# VAST: Visual and Spectral Terrain Classification in Unstructured Multi-Class Environments
## Keywords:
- Sensor Fusion
- Data Sets for Robotic Vision
- Field Robots
## Abstract:
Terrain classification is a challenging task for robots operating in unstructured environments. Existing classification methods make simplifying assumptions, such as a reduced number of classes, clearly segmentable roads, or good lighting conditions, and focus primarily on one sensor type. These assumptions do not translate well to off-road vehicles, which operate in varying terrain conditions. To provide mobile robots with the capability to identify the terrain being traversed and avoid undesirable surface types, we propose a multimodal sensor suite capable of classifying different terrains. We capture high resolution macro images of surface texture, spectral reflectance curves, and localization data from a 9 degrees of freedom (DOF) inertial measurement unit (IMU) on 11 different terrains at different times of day. Using this dataset, we train individual neural networks on each of the modalities, and then combine their outputs in a fusion network. The fused network achieved an accuracy of 99.98% percent on the test set, exceeding the results of the best individual network component by 0.98%. We conclude that a combination of visual, spectral, and IMU data provides meaningful improvement over state of the art in terrain classification approaches. The data created for this research is available at (https://github.com/RIVeR-Lab/vast_data).
# EFGHNet: A Versatile Image-To-Point Cloud Registration Network for Extreme Outdoor Environment
## Keywords:
- Sensor Fusion
- Deep Learning for Visual Perception
- Deep Learning Methods
## Abstract:
We present an accurate and robust image-to-point cloud registration method that is viable in urban and off-road environments. Existing image-to-point cloud registration methods have focused on vehicle platforms along paved roads. Therefore, image-to-point cloud registration on UGV platforms for off-road driving remains an open question. Our objective is to find a versatile solution for image-to-point cloud registration. We present a method that stably estimates a precise transformation between an image and a point cloud using a two-phase method that aligns the two input data in the virtual reference coordinate system (virtual-alignment) and then compares and matches the data to complete the registration (compare-and-match). Our main contribution is the introduction of divide-and-conquer strategies to image-to-point cloud registration. The virtual-alignment phase effectively reduces relative pose differences without cross-modality comparison. The compare-and-match phase divides the process of matching the image and point cloud into the rotation and translation steps. By breaking down the registration problem, it is possible to develop algorithms that can robustly operate in various environments. We performed extensive experiments on four datasets (Rellis-3D, KITTI odometry, nuScenes, and KITTI raw). Experiments cover a variety of situations in which image-to-point cloud registration is applied, from image-based localization in off-road environments to camera-LiDAR extrinsic calibration in urban environments. The experiments demonstrate that the proposed method outperforms the existing methods in accuracy and robustness.
# Shape Estimation of Concentric Tube Robots Using Single Point Position Measurement
## Keywords:
- Sensor Fusion
- Flexible Robotics
## Abstract:
Accurate shape estimation of concentric tube robots (CTRs) using mathematical models remains a challenge, reinforcing the need to develop techniques for accurate and real-time shape sensing of CTRs. In this paper, we develop a fusion algorithm that predicts the robot's shape by combining a mathematical model of the CTR with a measurement of the Cartesian coordinates of the robot's tip using an electromagnetic sensor. We experimentally validated our method in static and dynamic scenarios with and without external loading. Results demonstrated that the sensor fusion algorithm improves the error of model-based shape prediction by an average of 44.3%, corresponding to 2.43% of the robot's arc length. Furthermore, we demonstrate that our method can be used in real-time to simultaneously track the robot's tip position and predict its shape.
# Estimating Odometry Scale and UWB Anchor Location Based on Semidefinite Programming Optimization
## Keywords:
- Sensor Fusion
- Localization
- SLAM
## Abstract:
In this paper, we study the problem of estimating the unknown metric scale of an odometry system of a mobile robot and the 3D location of an Ultra-wideband (UWB) anchor in the environment. Firstly, we present a theoretical analysis of the problem which includes the derivation of Fisher Information Matrix (FIM) and its determinant. Secondly, based on the FIM we provide an evaluation and geometric interpretation of singular configurations. Thirdly, we present an estimation-trajectory optimization framework, which consists of a semidefinite programming (SDP) relaxation approach that solves the problem more effectively by exploiting the relationship between the parameters, and an FIM-based trajectory optimization approach that aims to minimize the uncertainty volume while remains easily adaptable to various scenarios. Simulation results show that our estimation method is more accurate and robust than previous approaches, while our trajectory optimization method can improve the estimator's performance even under challenging constraints.
# Visual-Tactile Multimodality for Following Deformable Linear Objects Using Reinforcement Learning
## Keywords:
- Sensor Fusion
- Perception for Grasping and Manipulation
- Reinforcement Learning
## Abstract:
Manipulation of deformable objects is a challenging task for a robot. It would be problematic to use a single sensory input to track the behaviour of such objects: vision can be subjected to occlusions, whereas tactile inputs cannot capture the global information that is useful for the task. In this paper, we study the problem of using vision and tactile inputs together to complete the task of following deformable linear objects, for the first time. We create a Reinforcement Learning agent using different sensing modalities and investigate how its behaviour can be boosted using visual-tactile fusion, compared to using a single sensing modality. To this end, we developed a benchmark in simulation for manipulating the deformable linear objects using multimodal sensing inputs. The policy of the agent uses distilled information, e.g., the pose of the object in both visual and tactile perspectives, instead of the raw sensing signals, so that it can be directly transferred to real environments. In this way, we disentangle the perception system and the learned control policy. Our extensive experiments show that the use of both vision and tactile inputs, together with proprioception, allows the agent to complete the task in up to 92% of cases, compared to 77% when only one of the signals is given. Our results can provide valuable insights for the future design of tactile sensors and for deformable objects manipulation.
# Exploring mmWave Radar and Camera Fusion for High-Resolution and Long-Range Depth Imaging
## Keywords:
- Sensor Fusion
- Range Sensing
- RGB-D Perception
## Abstract:
Robotic geo-fencing and surveillance systems require accurate monitoring of objects if/when they violate perimeter restrictions. In this paper, we seek a solution for depth imaging of such objects of interest at high accuracy (few tens of cm) over extended ranges (up to 300 meters) from a single vantage point, such as a pole mounted platform. Unfortunately, the rich literature in depth imaging using camera, lidar and radar in isolation struggles to meet these tight requirements in real-world conditions. This paper proposes Metamoran, a solution that explores long-range depth imaging of objects of interest by fusing the strengths of two complementary technologies: mmWave radar and camera. Unlike cameras, mmWave radars offer excellent cm-scale depth resolution even at very long ranges. However, their angular resolution is at least 10x worse than camera systems. Fusing these two modalities is natural, but in scenes with high clutter and at long ranges, radar reflections are weak and experience spurious artifacts. Metamoran's core contribution is to leverage image segmentation and monocular depth estimation on camera images to help declutter radar and discover true object reflections. We perform a detailed evaluation of Metamoran's depth imaging capabilities in 400 diverse scenarios. Our evaluation shows that Metamoran estimates the depth of static objects up to 90m away and moving objects up to 305m away and with a median error of 28cm, an improvement of 13x over a naive radar+camera baseline and 23x compared to monocular depth estimation.
# FAST-LIVO: Fast and Tightly-Coupled Sparse-Direct LiDAR-Inertial-Visual Odometry
## Keywords:
- Sensor Fusion
- SLAM
- Mapping
## Abstract:
To achieve accurate and robust pose estimation in Simultaneous Localization and Mapping (SLAM) task, multi-sensor fusion is proven to be an effective solution and thus provides great potential in robotic applications. This paper proposes FAST-LIVO, a fast LiDAR-Inertial-Visual Odometry system, which builds on two tightly-coupled and direct odometry subsystems: a VIO subsystem and a LIO subsystem. The LIO subsystem registers raw points (instead of feature points on e.g., edges or planes) of a new scan to an incrementally-built point cloud map. The map points are additionally attached with image patches, which are then used in the VIO subsystem to align a new image by minimizing the direct photometric errors without extracting any visual features (e.g., ORB or FAST corner features). To further improve the VIO robustness and accuracy, a novel outlier rejection method is proposed to reject unstable map points that lie on edges or are occluded in the image view. Experiments on both open data sequences and our customized device data are conducted. The results show our proposed system outperforms other counterparts and can handle challenging environments at reduced computation cost. The system supports both multi-line spinning LiDARs and emerging solid-state LiDARs with completely different scanning patterns, and can run in real-time on both Intel and ARM processors. We open source our code and dataset of this work on Github to benefit the robotics community.
# Adaptive Gradient-Descent Extended Kalman Filter for Pose Estimation of Mobile Robots with Sparse Reference Signals
## Keywords:
- Sensor Fusion
- Localization
- Wheeled Robots
## Abstract:
This paper proposes a novel extended Kalman filter (EKF) along with its adaptive variant for effective magnetic, angular rate and gravity (MARG) sensor-only pose estimation of mobile robots operated longer periods in reference-denied environments. First, a gradient-descent orientation-based EKF framework is derived, which formulates the MARG-based pose propagation with both bandpass-filtered and bias compensated external acceleration signals. The proposed approach uses two correction signals beside the orientation update, namely, virtual observations and sparse reference signals are incorporated in the state correction. Next, the instantaneous dynamics is characterized by accelerometer/gyroscope signals-based measures and an adaptive strategy is derived for real-time tuning of EKF parameters. The algorithm is fine tuned in an optimization framework on an appropriate database. This database of ground truth and raw MARG measurements contains 16 robot motion scenarios, where both slow motions and agile maneuvers are performed on different terrains.	The conducted analysis highlights that the proposed algorithms outperform the standard approaches, moreover, the adaptive strategy further improves the performance by 13%. The comprehensive performance evaluation demonstrates the efficacy of the new algorithms, thereby these robust approaches are proposed in environments characterized by sparse reference measurements.
# Reinforcement Learning 2
# Automated Flexible Needle Trajectory Planning for Keyhole Neurosurgery Using Reinforcement Learning
## Keywords:
- Reinforcement Learning
- Surgical Robotics: Steerable Catheters/Needles
- Surgical Robotics: Planning
## Abstract:
Planning a safe trajectory for minimally invasive (keyhole) neurosurgery procedures require avoiding critical anatomical structures such as blood vessels and ventricles while optimizing the needle trajectory parameters such as length and curvature to comply with the needle kinematics. In this paper, we propose a reinforcement learning-based method for obtaining kinematically feasible trajectories for flexible needle insertions. Proposed approach utilizes Bezier curve control points that are generated by a reward-based reinforcement learning framework, called Flexible Needle Path Generation (FNPG). FNPG framework is trained using an environment that consists of (1) critical structures (e.g. ventricles) obtained through atlas based segmentation of MRI-T1 images, (2) blood vessels segmented from MR angiography (MRA) data and, (3) simulated brain tumor with varying size and location. The curvilinear paths obtained through the FNPG framwork are compared with the traditional sampling based algorithm RRT*. The results show that the FNPG approach can produce smoother and shorter trajectories compared to RRT* while avoiding the critical anatomical structures.
# Learning Time-Optimized Path Tracking in Joint Space with or without Sensory Feedback
## Keywords:
- Reinforcement Learning
- Reactive and Sensor-Based Planning
- Body Balancing
## Abstract:
In this paper, we present a learning-based approach that allows a robot to quickly follow a reference path defined in joint space without exceeding limits on the position, velocity, acceleration and jerk of each robot joint. Contrary to offline methods for time-optimal path parameterization, the reference path can be changed during motion execution. In addition, our approach can utilize sensory feedback, for instance, to follow a reference path with a bipedal robot without losing balance. With our method, the robot is controlled by a neural network that is trained via reinforcement learning using data generated by a physics simulator. From a mathematical perspective, the problem of tracking a reference path in a time-optimized manner is formalized as a Markov decision process. Each state includes a fixed number of waypoints specifying the next part of the reference path. The action space is designed in such a way that all resulting motions comply with the specified kinematic joint limits. The reward function finally reflects the trade-off between the execution time, the deviation from the desired reference path and optional additional objectives like balancing. We evaluate our approach with and without additional objectives and show that time-optimized path tracking can be successfully learned for both industrial and humanoid robots. In addition, we demonstrate that networks trained in simulation can be successfully transferred to a real robot.
# L2C2: Locally Lipschitz Continuous Constraint towards Stable and Smooth Reinforcement Learning
## Keywords:
- Reinforcement Learning
- Machine Learning for Robot Control
- Deep Learning Methods
## Abstract:
This paper proposes a new regularization technique for reinforcement learning (RL) towards making policy and value functions smooth and stable. RL is known for the instability of the learning process and the sensitivity of the acquired policy to noise. Several methods have been proposed to resolve these problems, and in summary, the smoothness of policy and value functions learned mainly in RL contributes to these problems. However, if these functions are extremely smooth, their expressiveness would be lost, resulting in not obtaining the global optimal solution. This paper therefore considers RL under local Lipschitz continuity constraint, so-called L2C2. By designing the spatio-temporal locally compact space for L2C2 from the state transition at each time step, the moderate smoothness can be achieved without loss of expressiveness. Numerical noisy simulations verified that the proposed L2C2 outperforms the task performance while smoothing out the robot action generated from the learned policy.
# Learning Visual Robotic Control Efficiently with Contrastive Pre-Training and Data Augmentation
## Keywords:
- Reinforcement Learning
- Imitation Learning
- Learning from Demonstration
## Abstract:
Recent advances in unsupervised representation learning significantly improved the sample efficiency of training Reinforcement Learning policies in simulated environments. However, similar gains have not yet been seen for real-robot reinforcement learning. In this work, we focus on enabling data-efficient real-robot learning from pixels. We present Contrastive Pre-training and Data Augmentation for Efficient Robotic Learning (CoDER), a method that utilizes data augmentation and unsupervised learning to achieve sample-efficient training of real-robot arm policies from sparse rewards. While contrastive pre-training, data augmentation, demonstrations, and reinforcement learning are alone insufficient for efficient learning, our main contribution is showing that the combination of these disparate techniques results in a simple yet data-efficient method. We show that, given only 10 demonstrations, a single robotic arm can learn sparse-reward manipulation policies from pixels, such as reaching, picking, moving, pulling a large object, flipping a switch, and opening a drawer in just 30 minutes of mean real-world training time.
# Analyzing and Overcoming Degradation in Warm-Start Reinforcement Learning
## Keywords:
- Reinforcement Learning
- Robot Safety
- Learning from Demonstration
## Abstract:
Reinforcement Learning (RL) for robotic applications can benefit from a warm-start where the agent is initialized with a pretrained behavioral policy. However, when transitioning to RL updates, degradation in performance can occur, which may compromise the robot's safety. This degradation, which constitutes an inability to properly utilize the pretrained policy, is attributed to extrapolation error in the value function, a result of high values being assigned to Out-Of-Distribution actions not present in the behavioral policy's data. We investigate why the magnitude of degradation varies across policies and why the policy fails to quickly return to behavioral performance. We present visual confirmation of our analysis and draw comparisons to the Offline RL setting which suffers from similar difficulties. We propose a novel method, Confidence Constrained Learning (CCL) for Warm-Start RL, that reduces degradation by balancing between the policy gradient and constrained learning according to a confidence measure of the Q-values. For the constrained learning component we propose a novel objective, Positive Q-value Distance (CCL-PQD). We investigate a variety of constraint-based methods that aim to overcome the degradation, and find they constitute solutions for a multi-objective optimization problem between maximimal performance and miniminal degradation. Our results demonstrate that hyperparameter tuning for CCL-PQD produces solutions on the Pareto Front of this multi-objective problem, allowing the user to balance between performance and tolerable compromises to the robot's safety.
# Online Model Learning for Shape Control of Deformable Linear Objects
## Keywords:
- Reinforcement Learning
- Machine Learning for Robot Control
## Abstract:
Traditional approaches to manipulating the state of deformable linear objects (DLOs) --# i.e., cables, ropes --# rely on model-based planning. However, constructing an accurate dynamic model of a DLO is challenging due to the complexity of interactions and a high number of degrees of freedom. This renders the task of achieving a desired DLO shape particularly difficult and motivates the use of model-free alternatives, which while maintaining generality suffer from a high sample complexity. In this paper, we bridge the gap between these fundamentally different approaches and propose a framework that learns dynamic models of DLOs through trial-and-error interaction. Akin to model-based reinforcement learning (RL), we interleave learning and exploration to solve a 3D shape control task for a DLO. Our approach requires only a fraction of the interaction samples of the current state-of-the-art model-free RL alternatives to achieve superior shape control performance. Unlike offline model learning, our approach does not require expert knowledge for data collection, retains the ability to explore, and automatically selects relevant experience.
# PM-FSM: Policies Modulating Finite State Machine for Robust Quadrupedal Locomotion
## Keywords:
- Reinforcement Learning
- Deep Learning Methods
- Legged Robots
## Abstract:
Deep reinforcement learning (deep RL) has emerged as an effective tool for developing controllers for legged robots. However, vanilla deep RL often requires a tremendous amount of training samples and is not feasible for achieving robust behaviors. Instead, researchers have investigated a novel policy architecture by incorporating human experts' knowledge, such as Policies Modulating Trajectory Generators (PMTG). This architecture builds a recurrent control loop by combining a parametric trajectory generator (TG) and a feedback policy network to achieve more robust behaviors. In this work, we propose Policies Modulating Finite State Machine (PM-FSM) by replacing TGs with contact-aware finite state machines (FSM), which offers more flexible control of each leg. This invention offers an explicit notion of contact events to the policy to negotiate unexpected perturbations. We demonstrated that the proposed architecture could achieve more robust behaviors in various scenarios, such as challenging terrains or external perturbations, on both simulated and real robots.
# SafeTAC: Safe Tsallis Actor-Critic Reinforcement Learning for Safer Exploration
## Keywords:
- Reinforcement Learning
- Robot Safety
## Abstract:
Satisfying safety constraints is the top priority in safe reinforcement learning (RL). However, without proper exploration, an overly conservative policy such as freezing at the same position can be generated. To this end, we utilize maximum entropy RL methods for exploration. In particular, an RL method with Tsallis entropy maximization, called Tsallis actor-critic (TAC), is used to synthesize policies which can explore with more promising actions. In this paper, we propose a Tsallis entropy-regularized safe RL method for safer exploration, called SafeTAC. For more expressiveness, we extend the TAC to use a Gaussian mixture model policy, which improves the safety performance. To stabilize the training process, the retrace estimators for safety critics are formulated, and a safe policy update rule using a trust region method is proposed.
# Planning to Practice: Efficient Online Fine-Tuning by Composing Goals in Latent Space
## Keywords:
- Reinforcement Learning
- Deep Learning Methods
- Deep Learning in Grasping and Manipulation
## Abstract:
General-purpose robots in real-world settings require diverse repertoires of behaviors to complete challenging tasks in unstructured environments. To address this problem, goal-conditioned reinforcement learning aims to train policies that can reach configurable goals for a wide range of tasks on command. However, such goal-conditioned policies are notoriously difficult and time-consuming to train from scratch.In this paper, we propose Planning to Practice (PTP), a method that makes it practical to train goal-conditioned policies for long-horizon tasks that require multiple distinct types of interactions to solve.Our approach is based on two key ideas.First, we decompose the goal-reaching problem hierarchically, with a high-level planner that sets intermediate subgoals using conditional subgoal generators in the latent space for a low-level model-free policy.Second, we propose a hybrid offline reinforcement learning approach with online fine-tuning, which uses previously collected data to pretrain both the conditional subgoal generator and the policy, and then fine-tune the policy via online exploration.This fine-tuning process is itself facilitated by the planned subgoals, which break down the original target task into short-horizon goal-reaching tasks that are significantly easier to learn. We conduct experiments in both the simulation and real world, in which the policy is pre-trained on demonstrations of short primitive behaviors and fine-tuned for temporally extended tasks that are unseen in the offline data. Our experimental results show that PTP can generate feasible sequences of subgoals that enable the policy to efficiently solve the target tasks.
# Space Robotics and Automation
# Trajectory Optimization and Following for a Three Degrees of Freedom Overactuated Floating Platform
## Keywords:
- Space Robotics and Automation
- Control Architectures and Programming
- Optimization and Optimal Control
## Abstract:
Space robotics applications, such as Active Space Debris Removal (ASDR), require representative testing before launch. A commonly used approach to emulate the microgravity environment in space is air-bearing based platforms on flat# floors, such as the European Space Agency’s Orbital Robotics and GNC Lab (ORGL). This work proposes a control architecture for a floating platform at the ORGL, equipped with eight solenoid-valve-based thrusters and one reaction wheel. The control architecture consists of two main components: a trajectory planner that finds optimal trajectories connecting two states and a trajectory follower that follows any physically feasible trajectory. The controller is first evaluated within an introduced simulation, achieving a 100% success rate at finding and following trajectories to the origin within a Monte-Carlo test. Individual trajectories are also successfully followed by the physical system. In this work, we showcase the ability of the controller to reject disturbances and follow a straight-line trajectory within tens of centimeters.
# Optimal and Risk-Aware Path Planning Considering Localization Uncertainty for Space Exploration Rovers
## Keywords:
- Space Robotics and Automation
## Abstract:
The reliability of autonomous traverses of rovers is critical. It may be jeopardized by the accumulation of errors and the uncertainty propagation of their localization systems. Moreover, space environments are usually harsh, challenging and unpredictable. Teleoperation is complex due to the significant and unavoidable delay. For these reasons, a path planner that provides some level of autonomy with guarantees could increase the success rate of planetary exploration missions. This paper proposes a path planning solution that tackles increasing localization uncertainty and makes a trade-off between the collision risk and the path length. The planner uses the the Fast Marching Method (FMM) to produce a costmap aware of this uncertainty and calculate the optimal path for a level of confidence. This paper additionally presents several simulation and experimental using a wheeled robotic vehicle within a lunar analogue facility.
# 3D Human Pose Estimation in Weightless Environments Using a Fisheye Camera
## Keywords:
- Space Robotics and Automation
- Human Detection and Tracking
- Omnidirectional Vision
## Abstract:
Three-dimensional (3D) human pose estimation is one of the most basic tasks for human-interacting robots. Especially in weightless environments such as the International Space Station (ISS), wherein objects may move with a higher degree of freedom compared to on the ground, a camera with a wider field of view (FOV) is crucial in improving the probability of capturing surrounding humans. To this end, we propose a learning-based 3D human pose estimation (3D-HPE) using a fisheye camera targeted at weightless environments. One impediment is that 3D-HPE trained on existing datasets are incapable of addressing the adverse effects of strong fisheye distortion and weightlessness as existing human detection and pose estimation datasets are recorded on the ground using typical rectilinear cameras. To overcome this difficulty, we integrate virtual camera projection to perform a detected human-centered undistortion from fisheye to rectilinear images. We also include upside-down augmentation during training to improve the performance toward weightlessness. Our results show that these two techniques successfully mitigate the adverse effects of weightlessness and fisheye distortion.
# A Sampling Based Approach to Robust Planning for a Planetary Lander
## Keywords:
- Space Robotics and Automation
- Planning, Scheduling and Coordination
- Autonomous Agents
## Abstract:
Planning for autonomous operation in unknown environments poses a number of technical challenges. The agent must ensure robustness to unknown phenomena, unpredictable variation in execution, and uncertain resources, all while maximizing its objective. These challenges are exacerbated in the context of space missions where uncertainty is often higher, long communication delays necessitate robust autonomous execution, and severely constrained computational resources limit the scope of planning techniques that can be used. We examine this problem in the context of a Europa Lander concept mission where an autonomous lander must collect valuable data and communicate that data back to Earth. We model the problem as a hierarchical task network, framing it as a utility maximization problem constrained by a strictly monotonically decreasing energy resource. We propose a novel deterministic planning framework that uses periodic replanning and sampling-based optimization to better handle model uncertainty and execution variation, while remaining computationally tractable. We demonstrate the efficacy of our framework through simulations of a Europa Lander concept mission in which our approach outperforms several baselines in utility maximization and robustness.
# Learning to Grasp on the Moon from 3D Octree Observations with Deep Reinforcement Learning
## Keywords:
- Space Robotics and Automation
- Reinforcement Learning
- Deep Learning in Grasping and Manipulation
## Abstract:
Extraterrestrial rovers with a general-purpose robotic arm have many potential applications in lunar and planetary exploration. Introducing autonomy into such systems is desirable for increasing the time that rovers can spend gathering scientific data and collecting samples. This work investigates the applicability of deep reinforcement learning for vision-based robotic grasping of objects on the Moon. A novel simulation environment with procedurally-generated datasets is created to train agents under challenging conditions in unstructured scenes with uneven terrain and harsh illumination. A model-free off-policy actor-critic algorithm is then employed for end-to-end learning of a policy that directly maps compact octree observations to continuous actions in Cartesian space. Experimental evaluation indicates that 3D data representations enable more effective learning of manipulation skills when compared to traditionally used image-based observations. Domain randomization improves the generalization of learned policies to novel scenes with previously unseen objects and different illumination conditions. To this end, we demonstrate zero-shot sim-to-real transfer by evaluating trained agents on a real robot in a Moon-analogue facility.
# Adaptive Sampling Site Selection for Robotic Exploration in Unknown Environments
## Keywords:
- Space Robotics and Automation
## Abstract:
Autonomously selecting the right sequence of locations to sample is critical during exploration missions in unknown environments, with constraints on the number of samples that can be collected, and a possibility of system failure. A key idea for decision-making in unknown environments is to exploit side information available to the agent, combined with the information gained from samples collected so far, to estimate the sampling values. In this paper, we pose the problem of sampling site selection as a problem of finding the optimal policy in a Markov decision process modeling the unknown sampling values and the outcomes associated with sampling attempts at different locations. Our solution exploits the fact that the partially unknown rewards of this Markov decision process are correlated to each other to devise a strategy that attempts to maximize the total sample value while also ensuring that the agent achieves its minimum mission requirement. We validate the utility of the proposed approach by evaluating the method against a baseline strategy that pursues collecting the samples that are estimated to be of the highest value. Our evaluations use a simulated sampling problem on Martian terrain and using OceanWATERS, a high-fidelity simulator of a future Europa lander mission.
# An Approach to Science and Risk-Aware Planetary Rover Exploration
## Keywords:
- Space Robotics and Automation
- Probability and Statistical Methods
- Motion and Path Planning
## Abstract:
This work grapples with the challenge of directing autonomous decision making by planetary rovers conducting science investigations. Most of the related work addresses obstacle avoidance and traversabilty, while less work seeks to directly improve science yield. This research develops a comprehensive approach for planetary rovers that accounts for both science investigation and mobility risk. We present a probabilistic framework that quantifies these two attributes of rover exploration and generates paths that constrain risk while increasing science return. Specifically, science productivity is measured and improved using formal principles from information theory and statistical learning for decision making. Risk is estimated using a probabilistic model that predicts rover wheel slippage based on geometric and semantic information. Our method is evaluated in a simulation study using real Mars surface data that is relevant for both science and terrain investigations. Experimental analysis verifies the effectiveness of our approach.
# Attracting Conductive Nonmagnetic Objects with Rotating Magnetic Dipole Fields
## Keywords:
- Space Robotics and Automation
- Manipulation Planning
## Abstract:
 Recent research has shown that eddy currents induced by rotating magnetic dipole fields can produce forces and torques useful for dexterous manipulation of conductive nonmagnetic objects. This control paradigm shows promise for application in the remediation of space debris. However, the resulting force from each field source always includes a repulsive component, suggesting that the object should be surrounded by field sources to some degree to ensure the object does not leave the dexterous workspace during manipulation. In this letter, we describe the ability of multiple field sources working together in a coordinated fashion to attract conductive nonmagnetic objects that are not surrounded, reminiscent of a tractor beam. This enables an object to be pulled into a dexterous manipulation workspace. We explicitly describe the nominal attractive force on spherical objects, serving as an approximation for other object geometries, as a function of the properties of the object and the field-generation system. We perform experimental verification using a water-based microgravity simulator.
# Active Traversability Learning Via Risk-Aware Information Gathering for Planetary Exploration Rovers
## Keywords:
- Space Robotics and Automation
- Motion and Path Planning
- Field Robots
## Abstract:
Traversability prediction enables safe and efficient autonomous rover operation on deformable planetary surfaces. Revealing spatial distribution from terrain geometry to rover slip behavior is key to assessing prospective traversability, but is hindered by insufficient in situ measurements on hazardous states due to conservative rover traverses. To achieve a more accurate prediction, this paper proposes a framework that actively learns latent traversability by exploring informative terrain under the constraints of stochastic rover slip. With a Gaussian process (GP) modeling the spatial distribution, we devise an iterative two-stage framework that gradually refines the model estimation, combining risk-aware informative path planning and GP updates by taking in situ measurements. The path planning stage employs our designed sampling-based algorithm to generate informative trajectories with fault-tolerant risk inference, while the GP is cautiously updated with traverse data to avoid rover immobilization. Chance constraint formulation is exploited in the framework to infer the stochastic reachability of informative regions. Through GP estimates reducing uncertainty, the algorithm incrementally reaches informative yet hazardous states along feasible trajectories. Simulation studies in rough terrain environments demonstrate that the proposed framework gathers informative traverse data while averting rover stuck situations to estimate the latent traversability model.
# Model Learning for Control
# Randomized-To-Canonical Model Predictive Control for Real-World Visual Robotic Manipulation
## Keywords:
- Machine Learning for Robot Control
- Deep Learning for Visual Perception
- Model Learning for Control
## Abstract:
Many works have recently explored Sim-to-real transferable visual model predictive control (MPC). However, such works are limited to one-shot transfer, where real-world data must be collected once to perform the sim-to-real transfer, which remains a significant human effort in transferring the models learned in simulations to new domains in the real world. To alleviate this problem, we first propose a novel model-learning framework called Kalman Randomized-to-Canonical Model (KRC-model). This framework is capable of extracting task-relevant intrinsic features and their dynamics from randomized images. We then propose Kalman Randomized-to-Canonical Model Predictive Control (KRC-MPC) as a zero-shot sim-to-real transferable visual MPC using KRC-model. The effectiveness of our method is evaluated through a valve rotation task by a robot hand in both simulation and the real world, and a block mating task in simulation. The experimental results show that KRC-MPC can be applied to various real domains and tasks in a zero-shot manner.
# Nonlinear Model Learning for Compensation and Feed-Forward Control of Real-World Hydraulic Actuators Using Gaussian Processes
## Keywords:
- Machine Learning for Robot Control
- Model Learning for Control
- Hydraulic/Pneumatic Actuators
## Abstract:
This paper presents a robust machine learning framework for modeling and control of hydraulic actuators. We identify several important challenges concerning learning accurate models of the dynamics for real machines, including noise and uncertainty in state measurements, nonlinear effects, input delays, and data-efficiency. In particular, we propose a dual-Gaussian process (GP) model architecture to learn a surrogate dynamics model of the actuator, and showcase the accuracy of predictions against the piecewise and neural network models that have been widely used in the literature. In addition, we provide robust techniques for learning neural network inverse models and controllers by batch GP inference in an automated, seamless and computationally fast manner. Finally, we demonstrate the performance of the trained controllers in real-world feedforward and tracking control applications.
# Learning Neuro-Symbolic Relational Transition Models for Bilevel Planning
## Keywords:
- Model Learning for Control
- Task and Motion Planning
- Planning, Scheduling and Coordination
## Abstract:
In robotic domains, learning and planning are complicated by continuous state spaces, continuous action spaces, and long task horizons. In this work, we address these challenges with Neuro-Symbolic Relational Transition Models (NSRTs), a novel class of models that are data-efficient to learn, compatible with powerful robotic planning methods, and generalizable over objects. NSRTs have both symbolic and neural components, enabling a bilevel planning scheme where symbolic AI planning in an outer loop guides continuous planning with neural models in an inner loop. Experiments in four robotic planning domains show that NSRTs can be learned very data-efficiently, and then used for fast planning in new tasks that require up to 60 actions and involve many more objects than were seen during training.
# T3VIP: Transformation-Based 3D Video Prediction
## Keywords:
- Model Learning for Control
- RGB-D Perception
## Abstract:
For autonomous skill acquisition, robots have to learn about the physical rules governing the 3D world dynamics from their own past experience to predict and reason about plausible future outcomes. To this end, we propose a transformation-based 3D video prediction (T3VIP) approach that explicitly models the 3D motion by decomposing a scene into its object parts and predicting their corresponding rigid transformations. Our model is fully unsupervised, captures the stochastic nature of the real world, and the observational cues in image and point cloud domains constitute its learning signals. To fully leverage all the 2D and 3D observational signals, we equip our model with automatic hyperparameter optimization (HPO) to interpret the best way of learning from them. To the best of our knowledge, our model is the first generative model that provides an RGB-D video prediction of the future for a static camera. Our extensive evaluation with simulated and real-world datasets demonstrates that our formulation leads to interpretable 3D models that predict future depth videos while achieving on-par performance with 2D models on RGB video prediction. Moreover, we demonstrate that our model outperforms 2D baselines on visuomotor control. Videos, code, dataset, and pre-trained models are available at http://t3vip.cs.uni-freiburg.de.
# Physics Embedded Neural Network Vehicle Model and Applications in Risk-Aware Autonomous Driving Using Latent Features
## Keywords:
- Model Learning for Control
- AI-Enabled Robotics
- Autonomous Vehicle Navigation
## Abstract:
Non-holonomic vehicle motion has been studied extensively using physics-based models. Common approaches when using these models interpret the wheel/ground interactions using a linear tire model and thus may not fully capture the nonlinear and complex dynamics under various environments. On the other hand, neural network models have been widely employed in this domain, demonstrating powerful function approximation capabilities. However, these black-box learning strategies completely abandon the existing knowledge of well-known physics. In this paper, we seamlessly combine deep learning with a fully differentiable physics model to endow the neural network with available prior knowledge. The proposed model shows better generalization performance than the vanilla neural network model by a large margin. We also show that the latent features of our model can accurately represent lateral tire forces without the need for any additional training. Lastly, We develop a risk-aware model predictive controller using proprioceptive information derived from the latent features. We validate our idea in two autonomous driving tasks under unknown friction, outperforming the baseline control framework.
# TOAST: Trajectory Optimization and Simultaneous Tracking Using Shared Neural Network Dynamics
## Keywords:
- Model Learning for Control
- Robust/Adaptive Control
- Autonomous Vehicle Navigation
## Abstract:
Neural networks have been increasingly employed in Model Predictive Controller (MPC) to control nonlinear dynamic systems. However, MPC still poses a problem that an achievable update rate is insufficient to cope with model uncertainty and external disturbances. In this paper, we present a novel control scheme that can design an optimal tracking controller using the neural network dynamics of the MPC, making it possible to be applied as a plug-and-play extension for any existing model-based feedforward controller. We also describe how our method handles a neural network containing history information, which does not follow a general form of dynamics. The proposed method is evaluated by its performance in classical control benchmarks with external disturbances. We also extend our control framework to be applied in an aggressive autonomous driving task with unknown friction. In all experiments, our method outperformed the compared methods by a large margin. Our controller also showed low control chattering levels, demonstrating that our feedback controller does not interfere with the optimal command of MPC.
# Augmented Neural Network for Full Robot Kinematic Modelling in SE(3)
## Keywords:
- Model Learning for Control
- Machine Learning for Robot Control
- Redundant Robots
## Abstract:
Due to the increasing complexity of robotic structures, modelling robots is becoming more and more challenging, and analytical models are very difficult to build. Machine learning approaches have shown great capabilities in learning complex mapping and have widely been used in robot model learning and control. Generally, the inverse kinematics is directly learned, yet, learning the forward kinematics is simpler and allows computing exploiting the optimality of the controllers. Nevertheless, the learning method has no knowledge about the differential relationship between the position and velocity mappings. Currently, few works have targeted learning full robot poses considering both position and orientation. In this work, we present a novel feedforward Artificial Neural network (ANN) architecture to learn full robot pose in SE(3) incorporating differential relationships in the learning process. Simulation and real world experiments show the capabilities of the proposed network to properly model the robot pose and its advantages over standard ANN.
# Physics-Inspired Temporal Learning of Quadrotor Dynamics for Accurate Model Predictive Trajectory Tracking
## Keywords:
- Model Learning for Control
- Aerial Systems: Perception and Autonomy
- Machine Learning for Robot Control
## Abstract:
Accurately modeling quadrotor's system dynamics is critical for guaranteeing agile, safe, and stable navigation. The model needs to capture the system behavior in multiple flight regimes and operating conditions, including those producing highly nonlinear effects such as aerodynamic forces and torques, rotor interactions, or possible system configuration modifications. Classical approaches rely on handcrafted models and struggle to generalize and scale to capture these effects. In this paper, we present a novel Physics-Inspired Temporal Convolutional Network (PI-TCN) approach to learning quadrotor's system dynamics purely from robot experience. Our approach combines the expressive power of sparse temporal convolutions and dense feed-forward connections to make accurate system predictions. In addition, physics constraints are embedded in the training process to facilitate the network's generalization capabilities to data outside the training distribution. Finally, we design a model predictive control approach that incorporates the learned dynamics for accurate closed-loop trajectory tracking fully exploiting the learned model predictions in a receding horizon fashion. Experimental results demonstrate that our approach accurately extracts the structure of the quadrotor's dynamics from data, capturing effects that would remain hidden to classical approaches. To the best of our knowledge, this is the first time physics-inspired deep learning is successfully applied to temporal convolutional networks and to the system identification task, while concurrently enabling predictive control.
# Learning Non-Parametric Models in Real Time Via Online Generalized Product of Experts
## Keywords:
- Model Learning for Control
- Modeling, Control, and Learning for Soft Robots
- Machine Learning for Robot Control
## Abstract:
In this work, we address the problem of online learning, where models must be continually updated from an incoming stream of data, while retaining past information. We develop an approach that is nonparametric, models uncertainty, and requires minimal hand-tuning. Our proposed algorithm, which we term online generalized product of experts (OGPoE), extends the powerful generalized product of experts (GPoE) framework to the online setting by leveraging methods for sparse, variational Gaussian process approximations, as well as nonparametric clustering. We devise a 1-D example learning problem to illustrate how our method works, and we verify that we achieve competitive results with other popular modeling approaches on a benchmark learning problem. Finally, we demonstrate how our algorithm can produce high accuracy predictions on a physical system, by learning the kinematics for a concentric tube robot, even when the robot is subject to changing, unknown loads.
# Biologically-Inspired Robots 3
# A Flexible Calibration Algorithm for High-Speed Bionic Vision System Based on Galvanometer
## Keywords:
- Biologically-Inspired Robots
- Computer Vision for Automation
## Abstract:
Traditional gimbal-based bionic eye systems usually use a multi-degree-of-freedom mechanical platform to move the camera freely, which makes the structure complex and bulky. The galvanometer-based reflective bionic eye system uses a galvanometer to replace the traditional mechanical rotation structure, which separates the camera from the gimbal system, greatly simplifying the structure. However, there are currently few methods for calibrating such systems, mostly for object detection and tracking. In this paper, a flexible method for high-precision calibration of a galvanometer-based reflective bionic eye system is proposed. In this method, a planar target is used for the calibration of the bionic eye system. The effectiveness and accuracy of the method are evaluated by the reprojection error of the control voltage and the spatial localization of the binocular system. Experiments show that the error of the control voltage after calibration is less than 0.2 %. At an indoor distance of about 7 m, the RMSE of spatial visual localization is less than 0.3 cm.
# Design and Control of a Multi-Modal Soft Gripper Inspired by Elephant Fingers
## Keywords:
- Grippers and Other End-Effectors
- Manipulation Planning
- Soft Robot Applications
## Abstract:
Soft grippers have the potential to solve many existing manipulation challenges, particularly in agile industry applications. However, existing soft grippers are often limited in the range of objects they can pick, or by cluttered environments. We present a design inspired by the nose and fingers at the end of an elephant's trunk, which can pick both by suction and pinching, allowing increased grasping diversity. In addition, we observe an emergent grasping mode, a hybrid of pinching and suction where the cup aperture is morphed online, using embedded soft fingers, to form a seal over challenging objects. An algorithmic grasping strategy, based-on analytical grasping models and primitive objects, is presented. With this, we predict grasping performance and show increased grasping range compared to other soft gripper designs. Finally, the gripper and grasping strategy are successfully applied to grasping more varied everyday objects, demonstrating exploitation of this multi-modal gripping for adaptive grasping.
# Design Optimization of an Ultrafast-Striking Mantis Shrimp Microrobot
## Keywords:
- Micro/Nano Robots
- Mechanism Design
- Optimization and Optimal Control
## Abstract:
Mantis shrimp produce one of the fastest strikes in the animal kingdom, their striking appendages reaching tip velocities of tens of meters per second underwater. Their ultrafast movement is capable of crushing the shells of prey and generating cavitation bubbles, and has long raised interest from the scientific community. To study the underlying mechanisms and operating principles behind these behaviors, prior research has developed physical models that mimic the motions and speeds of mantis shrimp. That microrobot demonstrated speeds of approximately 5 m/s in water and 26 m/s in air. Here we utilize an accurate dynamical model of the four-bar mechanism and geometric latch observed in biological shrimp in a numerical trajectory optimization approach to find the design changes that can maximize the microrobot’s striking velocities. Through a suboptimization problem maximizing the energy loaded in the mechanism’s spring, we manage to improve the performance of the microrobot by over 58%, reaching tip velocities of 41.2 ± 0.6 m/s.
# Imitation Behavior of the Outer Edge of the Foot by Humanoids Using a Simplified Contact State Representation
## Keywords:
- Biomimetics
- Human and Humanoid Motion Analysis and Synthesis
- Imitation Learning
## Abstract:
There is a way to utilize humanoid robots to mimic human behavior by taking advantage of their human-like proportions. In general, motion capture is used, and in this case, the posture of the body links can be taken. However, this method does not provide detailed information on the contact state, which is important for actions that involve contact with objects. In this study, we focused on the foot, which has not been paid much attention among the parts where contact and manipulation with objects are important and developed a device to measure the contact pressure distribution at the outer edge of the sole. We proposed an index, SS-COP, which simply reflects the contact on the curved surface of the sole of the foot for this device and a robot foot with lateral force sensation and realized a behavior that imitates the foot condition by a humanoid robot by using this index.
# Visual Confined-Space Navigation Using an Efficient Learned Bilinear Optic Flow Approximation for Insect-Scale Robots
## Keywords:
- Biologically-Inspired Robots
- Vision-Based Navigation
- Visual Servoing
## Abstract:
Visual navigation for insect-scale robots is very challenging because in such a small scale, the size, weight, and power (SWaP) constraints do not appear to permit visual navigation techniques such as SLAM (Simultaneous Localization and Mapping) because they are likely to be too power-hungry.	We propose to use a biology-inspired approach, which we term the bilinear optic flow approximation, that is more computationally efficient. We build on previous work that has shown that the bilinear approximation can be used for visual servoing. Here, we show that a bilinear approximator can be learned that is able to stabilize the heading of a robot while performing continuous forward motion in a corridor-shaped environment. This is a necessary capability for confined-space navigation that insect-sized robots are likely to perform. In this work, we describe the underlining methodology of the method and built a 2D visual simulation environment and omnidirectional camera model to validate our results.
# Tactile Perception for Growing Robots Via Discrete Curvature Measurements
## Keywords:
- Biologically-Inspired Robots
- Soft Robot Applications
- Force and Tactile Sensing
## Abstract:
Soft, growing robots have the ability to conform to their environment and traverse highly curved paths that would typically prove challenging for other robot designs. As they navigate through these constrained and cluttered environments, there is often significant interaction between the robot and its surroundings. In this work, we propose a method to enable tactile perception for growing robots, which utilizes commercially available, flexible sensors that measure the curvature of the robot shape at multiple locations. Our method consists of both a pouch design to enable seamless integration of the sensors with the material of the growing robot, as well as an algorithm for determining the location of point contacts along the robot body. We validate our proposed approach experimentally using a 3.5 cm robot that can grow to be 53 cm long. We show that we can localize a force applied to various locations along its length with an average error of 3.44±1.38 cm when the robot is unactuated and 4.62±0.95 cm when the robot is actuated. Additionally, we characterize the minimum distance required for our tactile sensing approach to discriminate between two separate contact points along the robot body to be 23.5 cm. Finally, we apply our method to a growing robot exploring an unknown environment and show that we are able to effectively determine when and where the growing robot collides with an unknown obstacle.
# Bioinspired Antagonist–agonist Artificial Muscles for Humanoid Eyeball Motions
## Keywords:
- Soft Sensors and Actuators
- Soft Robot Applications
- Soft Robot Materials and Design
## Abstract:
Natural eyeball motions in humanoid robots can contribute to friendly communication, thus improving the human-robot interaction. In this paper, we develop antagonist–agonist artificial muscles for humanoid eyeball motions, by using dielectric elastomer actuators (DEAs). Inspired by human eyeballs, the artificial muscles consist of two pairs of DEA: one pair for the horizontal motion, and the other for the vertical motion. The fabrication time of actuators can be significantly decreased due to their simple structure. The antagonist–agonist actuator outperforms the dielectric elastomer minimum energy structure in terms of actuation displacement and response time. We conduct experiments in a lifesize human face model. The experiments demonstrate the capability of antagonist–agonist artificial muscles to mimic eyeball motions in the horizontal, vertical, and diagonal directions. Future work includes modeling and control of artificial muscles for optimal performance of various humanoid eyeball motions.
# The Relationship between Incremental Changes in Orientation and Slip Speed Estimation Using the Fingerprint Effect
## Keywords:
- Biomimetics
- Soft Sensors and Actuators
- Force and Tactile Sensing
## Abstract:
The fingerprint effect, wherein vibrations are produced with frequencies related to the speed of a surface sliding across fingerprint ridges and the period of those ridges, has been studied for use in both slip detection and texture recognition. Here, we use a simple bioinspired sensor with parallel, straight, fingerprint-like ridges and a single ferroelectric ceramic transducer to show that the fingerprint effect is orientation dependent and that, if the orientation is known, it can be used to estimate slip speed. Our results, obtained at sliding speeds of 15 mm/s, 20 mm/s, and 25 mm/s and orientations from 0º # 90º, clearly demonstrate this dependence. Additionally, we use our results to run a simulation, using MATLAB software, of real-time slip speed estimation. The simulation shows that the fingerprint effect can be used for real-time slip-speed estimation.
# Diaphragm Ankle Actuation for Efficient Series Elastic Legged Robot Hopping
## Keywords:
- Biologically-Inspired Robots
- Legged Robots
- Actuation and Joint Mechanisms
## Abstract:
The observation of the anatomy of agile animals and their locomotion capabilities emphasizes the importance of fast and lightweight legs and confirms the intrinsic compliance integrated into muscle-tendon units as a major ingredient for energy efficient and robust locomotion. This quality is especially relevant for distal leg segments which are subject to aggressive dynamics. Legged robots are accordingly designed to improve dynamic performance by lightweight mechanisms combined with series elastic actuation systems. However, so far no designs are available that feature all characteristics of a perfect distal legged locomotion actuator such as a lightweight and low-inertia structure, with high mechanical efficiency, no stick and sliding friction, and low mechanical complexity. With this goal in mind, we propose a novel robotic leg which integrates all above features. Specifically, we develop, implement, and characterize a bioinspired robot leg that features a lightweight Series ELastic Diaphragm distal Actuator (SELDA) for active control of foot motion. We conducted experiments to compare two leg configurations, with and without foot actuation, to demonstrate the effectiveness of the proposed solution in agile forward hopping controlled by a central pattern generator. We studied how tuning SELDA’s activation timing can adjust the robot’s hopping height by 11% and its forward velocity by 14%, even with comparatively low power injection to the distal joint.
# Failure Detection and Recovery
# Model-Free Unsupervised Anomaly Detection of a General Robotic System Using a Stacked LSTM and Its Application to a Fixed-Wing Unmanned Aerial Vehicle
## Keywords:
- Failure Detection and Recovery
- Robot Safety
- AI-Based Methods
## Abstract:
With the growing application of various robots in real life, the need for an automatic anomaly detection system for robots is necessary for safety. In this paper, we develop an anomaly detection method using a stacked LSTM that can be applied to any robot controlled by a feedback control. Our method does not need installation of additional sensors. Our method is model-free and unsupervised because it does not require the analytical model of the system and the training data does not require faulty operation conditions. We validate our method on real fixed-wing unmanned aerial vehicle flight data containing control surface failure scenarios. We demonstrate the superiority of the proposed algorithm over existing anomaly detection methods in the literature. Our code is available at https://github.com/superhumangod/Model-free-unsupervised-anomaly-detection}{https://github.com/superhumangod/Model-free-unsupervised-anomaly-detection.
# Meta-Active Learning in Probabilistically Safe Optimization
## Keywords:
- Failure Detection and Recovery
- Robot Safety
- AI-Enabled Robotics
## Abstract:
When a robotic system is faced with uncertainty, the system must take calculated risks to gain information as efficiently as possible while ensuring system safety. The need to safely and efficiently gain information in the face of uncertainty spans domains from healthcare to
search and rescue. To efficiently learn when data is scarce or difficult to label, active learning acquisition functions intelligently
select a data point that, if the label were known, would most improve the estimate of the unknown model. Unfortunately, prior work in active learning suffers from an inability to accurately quantify information-gain, generalize to new domains, and ensure safe operation. To overcome these limitations, we develop Safe MetAL, a probabilistically-safe, active learning algorithm which meta-learns an acquisition function for selecting sample efficient data points in safety critical domains. The key to our approach is a novel integration of meta-active learning and chance-constrained optimization. We (1) meta-learn an acquisition function based on sample history, (2) encode this acquisition function in a chance-constrained optimization framework, and (3) solve for an information-rich set of data points while enforcing probabilistic safety guarantees. We present state-of-the-art results in active learning of the model of a damaged UAV and in learning the optimal parameters for deep brain stimulation. Our approach achieves a 41% improvement in learning the optimal model and a 20% speedup in computation time compared to active and meta-learning approaches while ensuring safety of the system.
# Learning Symbolic Failure Detection for Grasping and Mobile Manipulation Tasks
## Keywords:
- Failure Detection and Recovery
- Reactive and Sensor-Based Planning
- AI-Enabled Robotics
## Abstract:
The ability to detect failure during task execution and to recover from failure is vital for autonomous robots performing tasks in previously unknown environments. In this paper, we present an approach for failure detection during the execution of grasping and mobile manipulation tasks by a humanoid robot. The approach combines multi-modal sensory information consisting of proprioceptive, force and visual information to learn task models from multiple successful task executions, in order to detect failures and to externalize them for humans in an interpretable way. To this end, we define symbolic action predicates based on multi-modal sensory information to allow high-level state estimation based on action-specific decision trees. To allow symbolic failure detection, we then learn task models that are represented as Markov chains. We evaluated the approach in several pick-and-place and mobile manipulation tasks performed by a humanoid robot in a decommissioning and a household scenario. The evaluation shows that the learned task models are capable of detecting failure with an F1-score of 93%.
# Design, Modeling and Control for a Tilt-Rotor VTOL UAV in the Presence of Actuator Failure
## Keywords:
- Failure Detection and Recovery
- Motion Control
- Dynamics
## Abstract:
Enabling vertical take-off and landing while providing the ability to fly long ranges opens the door to a wide range of new real-world aircraft applications while improving many existing tasks. Tiltrotor vertical take-off and landing (VTOL) unmanned aerial vehicles (UAVs) are a better choice than fixed-wing and multirotor aircraft for such applications. Prior works on these aircraft have addressed the aerodynamic performance, design, modeling, and control. However, a less explored area is the study of their potential fault tolerance due to their inherent redundancy, which allows them to tolerate some degree of actuation failure. This paper introduces tolerance to several types of actuator failures in a tiltrotor VTOL aircraft. We discuss the design and modeling of a custom tiltrotor VTOL UAV, which is a combination of a fixed-wing aircraft and a quadrotor with tilting rotors, where the four propellers can be rotated individually. Then, we analyze the feasible wrench space the vehicle can generate and design the dynamic control allocation so that the system can adapt to actuator failures, benefiting from the configuration redundancy. The proposed approach is lightweight and is implemented as an extension to an already-existing flight control stack. Extensive experiments validate that the system can maintain the controlled flight under different actuator failures. To the best of our knowledge, this work is the first study of the tiltrotor VTOL's fault-tolerance that exploits the configuration redundancy. The source code and simulation can be accessed from https://theairlab.org/vtol.
# Transmissibility-Based DAgger for Fault Classification in Connected Autonomous Vehicles
## Keywords:
- Failure Detection and Recovery
- Learning from Experience
- Imitation Learning
## Abstract:
Fault mitigation in Connected Autonomous Vehicle (CAV) platoons is faster and more reliable if the fault structure is known. In this paper we propose using transmissibility operators, which are relationships that relate a set of velocities with another in the platoon, to classify the faults. Transmissibility operators were shown to be exceptional in signals estimation; however, its also shown to be noncausal and thus can only be used offline. To this end, we propose using Data Aggregation (DAgger), which is an extension in imitation learning to transfer the classification experience from transmissibility operators to a novice machine learning agent to be used online. A heterogeneous CAV platoon was modeled with three different faults separately. These faults are actuator disturbances, false data injection attacks, and communication time delay. The classification scheme depends on estimating the faulty signal in the case of each fault class. Next, the measured faulty signal is compared with the three estimations and the closer fault estimation to the measured one is considered as the actual fault on the platoon. The proposed algorithm is then tested on the platoon model and then applied to an experimental setup that consists of three autonomous robots. The overall classification accuracy achieved was 95.8% for the experiment.
# Robot Vitals and Robot Health: Towards Systematically Quantifying Runtime Performance Degradation in Robots under Adverse Conditions
## Keywords:
- Failure Detection and Recovery
- Human-Robot Teaming
- Robotics in Hazardous Fields
## Abstract:
This paper addresses the problem of automatically detecting and quantifying performance degradation in remote mobile robots, in real-time, during task execution. A robot may encounter a variety of uncertainties and adversities during task execution, which can impair its ability to carry out tasks effectively and cause its performance to degrade. Such situations can be mitigated or averted by timely detection and intervention, e.g., by a remote human supervisor taking over control in teleoperation mode. Inspired by patient triaging systems in hospitals, we introduce the framework of "robot vitals" for estimating overall "robot health". A robot's vitals are a set of lower-level metrics that estimate a variety of indicators of performance degradation faced by a robot at any given point in time. Robot health is a higher-level metric that combines robot vitals into a single scalar value estimate of performance degradation. Experiments, both in simulation and on a real mobile robot, demonstrate that the proposed robot vitals and robot health can be used effectively for online estimation of robot performance degradation during run-time.
# RoBiGAN: A Bidirectional Wasserstein GAN Approach for Online Robot Fault Diagnosis Via Internal Anomaly Detection
## Keywords:
- Failure Detection and Recovery
- Deep Learning Methods
- Legged Robots
## Abstract:
Complex robots in challenging scenarios require constant monitoring of their state and adaptation of their behavior to ensure robustness, reliability and longevity. While known possible errors can be specifically surveilled, other problems can be fully unforeseen, requiring detection systems able to identify novel faults. We detect possible faults as anomalies on various internal sensor data, utilizing unsupervised learning techniques. A bidirectional Wasserstein GAN approach for anomaly detection on multivariate, highly dependent timeseries data is implemented and trained on a small amount of non-anomalous robot sensor data. This model is then used for inference on the on-board hardware of a robot without parallel processing units. We evaluate multiple variants of the architecture using manually introduced anomalies in the form of different weights attached to the robot’s legs. Overall we are able to show that RoBiGAN is able to consistently detect and localize small anomalies in an online scenario, with little to no robot specific modeling needed.
# PrePARE: Predictive Proprioception for Agile Failure Event Detection in Robotic Exploration of Extreme Terrains
## Keywords:
- Failure Detection and Recovery
## Abstract:
Legged robots can traverse a wide variety of terrains, some of which may be challenging for wheeled robots, such as stairs or highly uneven surfaces. However, quadruped robots face stability challenges on slippery surfaces. This can be resolved by adjusting the robot's locomotion by switching to more conservative and stable locomotion modes, such as crawl mode (where three feet are in contact with the ground always) or amble mode (where one foot touches down at a time) to prevent potential falls. To tackle these challenges, we propose an approach to learn a model from past robot experience for predictive detection of potential failures. Accordingly, we trigger gait switching merely based on proprioceptive sensory information. To learn this predictive model, we propose a semi-supervised process for detecting and annotating ground truth slip events in two stages: We first detect abnormal occurrences in the time series sequences of the gait data using an unsupervised anomaly detector, and then, the anomalies are verified with expert human knowledge in a replay simulation to assert the event of a slip. These annotated slip events are then used as ground truth examples to train an ensemble decision learner for predicting slip probabilities across terrains for traversability. We analyze our model on data recorded by a legged robot on multiple sites with slippery terrain. We demonstrate that a potential slip event can be predicted up to 720 ms ahead of a potential fall with an average precision greater than 0.95 and an average F-score of 0.82. Finally, we validate our approach in real-time by deploying it on a legged robot and switching its gait mode based on slip event detection.
# Why Did I Fail? a Causal-Based Method to Find Explanations for Robot Failures
## Keywords:
- Acceptability and Trust
- Probabilistic Inference
- Learning from Experience
## Abstract:
Robot failures in human-centered environments are inevitable. Therefore, the ability of robots to explain such failures is paramount for interacting with humans to increase trust and transparency. To achieve this skill, the main challenges addressed in this letter are I) acquiring enough data to learn a cause-effect model of the environment and II) generating causal explanations based on the obtained model. We address I) by learning a causal Bayesian network from simulation data. Concerning II), we propose a novel method that enables robots to generate contrastive explanations upon task failures. The explanation is based on setting the failure state in contrast with the closest state that would have allowed for successful execution. This state is found through breadth-first search and is based on success predictions from the learned causal model. We assessed our method in two different scenarios I) stacking cubes and II) dropping spheres into a container. The obtained causal models reach a sim2real accuracy of 70% and 72%, respectively. We finally show that our novel method scales over multiple tasks and allows real robots to give failure explanations like “the upper cube was stacked too high and too far to the right of the lower cube.”
# SLAM 3
# Closing the Loop: Graph Networks to Unify Semantic Objects and Visual Features for Multi-Object Scenes
## Keywords:
- Visual-Inertial SLAM
- Object Detection, Segmentation and Categorization
- Semantic Scene Understanding
## Abstract:
In Simultaneous Localization and Mapping (SLAM), Loop Closure Detection (LCD) is essential to minimize drift when recognizing previously visited places. Visual Bag-of-Words (vBoW) has been an LCD algorithm of choice for many state-of-the-art SLAM systems. It uses a set of visual features to provide robust place recognition but fails to perceive the semantics or spatial relationship between feature points. Previous work has mainly focused on addressing these issues by combining vBoW with semantic and spatial information from objects in the scene. However, they are unable to exploit spatial information of local visual features and lack a structure that unifies semantic objects and visual features, therefore limiting the symbiosis between the two components. This paper proposes SymbioLCD2, which creates a unified graph structure to integrate semantic objects and visual features symbiotically. Our novel graph-based LCD system utilizes the unified graph structure by applying a Weisfeiler-Lehman graph kernel with temporal constraints to robustly predict loop closure candidates. Evaluation of the proposed system shows that having a unified graph structure incorporating semantic objects and visual features improves LCD prediction accuracy, illustrating that the proposed graph structure provides a strong symbiosis between these two complementary components. It also outperforms other Machine Learning algorithms # such as SVM, Decision Tree, Random Forest, Neural Network and GNN based Graph Matching Networks. Furthermore, it has shown good performance in detecting loop closure candidates earlier than state-of-the-art SLAM systems, demonstrating that extended semantic and spatial awareness from the unified graph structure significantly impacts LCD performance.
# Probabilistic Data Association for Semantic SLAM at Scale
## Keywords:
- Visual-Inertial SLAM
- SLAM
- Probability and Statistical Methods
## Abstract:
With advances in image processing and machine learning, it is now feasible to incorporate semantic information into the problem of simultaneous localisation and mapping (SLAM). Previously, SLAM was carried out using lower level geometric features (points, lines, and planes) which are often view-point dependent and error prone in visually repetitive environments. Semantic information can improve the ability to recognise previously visited locations, as well as maintain sparser maps for long term SLAM applications. However, SLAM in repetitive environments has the critical problem of assigning measurements to the landmarks which generated them. In this paper, we use k-best assignment enumeration to compute marginal assignment probabilities for each measurement landmark pair, in real time. We present numerical studies on the KITTI dataset to demonstrate the effectiveness and speed of the proposed framework.
# Observability Analysis and Keyframe-Based Filtering for Visual Inertial Odometry with Full Self-Calibration (I)
## Keywords:
- Visual-Inertial SLAM
- Sensor Fusion
- Vision-Based Navigation
## Abstract:
Camera-IMU (Inertial Measurement Unit) sensor fusion has been extensively studied in recent decades. Numerous observability analysis and fusion schemes for motion estimation with self-calibration have been presented. However, it has been uncertain whether both camera and IMU intrinsic parameters are observable under general motion. To answer this question, by using the Lie derivatives, we first prove that for a rolling shutter (RS) camera-IMU system, all intrinsic and extrinsic parameters, camera time offset, and readout time of the RS camera, are observable with an unknown landmark. To our knowledge, we are the first to present such a proof. Next, to validate this analysis and to solve the drift issue of a structureless filter during standstills, we develop a Keyframe-based Sliding Window Filter (KSWF) for odometry and self-calibration, which works with a monocular RS camera or stereo RS cameras. Though the keyframe concept is widely used in vision-based sensor fusion, to our knowledge, KSWF is the first of its kind to support self-calibration. Our simulation and real data tests have validated that it is possible to fully calibrate the camera-IMU system using observations of opportunistic landmarks under diverse motion. Real data tests confirmed previous allusions that keeping landmarks in the state vector can remedy the drift in standstill, and showed that the keyframe-based scheme is an alternative solution.
# OverlapTransformer: An Efficient and Yaw-Angle-Invariant Transformer Network for LiDAR-Based Place Recognition
## Keywords:
- SLAM
- Deep Learning Methods
- Data Sets for Robot Learning
## Abstract:
Place recognition is an important capability for autonomously navigating vehicles operating in complex environments and under changing conditions. It is a key component for tasks such as loop closing in SLAM or global localization. In this paper, we address the problem of place recognition based on 3D LiDAR scans recorded by an autonomous vehicle. We propose a novel lightweight neural network exploiting the range image representation of LiDAR sensors to achieve fast execution with less than 2 ms per frame. We design a yaw# angle-invariant architecture exploiting a transformer network, which boosts the place recognition performance of our method. We evaluate our approach on the KITTI and Ford Campus datasets. The experimental results show that our method can effectively detect loop closures compared to the state-of-the-art methods and generalizes well across different environments. To evaluate long-term place recognition performance, we provide a novel dataset containing LiDAR sequences recorded by a mobile robot in repetitive places at different times. The implementation of our method and dataset are released here: https://github.com/haomo-ai/OverlapTransformer.
# Distributed Riemannian Optimization with Lazy Communication for Collaborative Geometric Estimation
## Keywords:
- Multi-Robot SLAM
- Optimization and Optimal Control
- Multi-Robot Systems
## Abstract:
We present the first distributed optimization algorithm with lazy communication for collaborative geometric estimation, the backbone of modern collaborative simultaneous localization and mapping (SLAM) and structure-from-motion (SfM) applications. Our method allows agents to cooperatively reconstruct a shared geometric model on a central server by fusing individual observations, but without the need to transmit potentially sensitive information about the agents themselves (such as their locations). Furthermore, to alleviate the burden of communication during iterative optimization, we design a set of communication triggering conditions that enable agents to selectively upload a targeted subset of local information that is useful to global optimization. Our approach thus achieves significant communication reduction with minimal impact on optimization performance. As our main theoretical contribution, we prove that our method converges to first-order critical points with a global sublinear convergence rate. Numerical evaluations on bundle adjustment problems from collaborative SLAM and SfM datasets show that our method performs competitively against existing distributed techniques, while achieving up to 78% total communication reduction.
# CFP-SLAM: A Real-Time Visual SLAM Based on Coarse-To-Fine Probability in Dynamic Environments
## Keywords:
- SLAM
- Localization
## Abstract:
The dynamic factors in the environment will lead to the decline of camera localization accuracy due to the violation of the static environment assumption of SLAM algorithm. Recently, some related works generally use the combination of semantic constraints and geometric constraints to deal with dynamic objects, but problems can still be raised, such as poor real-time performance, easy to treat people as rigid bodies, and poor performance in low dynamic scenes. In this paper, a dynamic scene-oriented visual SLAM algorithm based on object detection and coarse-to-fine static probability named CFP-SLAM is proposed. The algorithm combines semantic constraints and geometric constraints to calculate the static probability of objects, keypoints and map points, and takes them as weights to participate in camera pose estimation. Extensive evaluations show that our approach can achieve almost the best results in high dynamic and low dynamic scenarios compared to the state-of-the-art dynamic SLAM methods, and shows quite high real-time ability.
# Object-Plane Co-Represented and Graph Propagation-Based Semantic Descriptor for Relocalization
## Keywords:
- SLAM
- Localization
- Multi-Robot SLAM
## Abstract:
Relocalization is a critical component of robotics applications, it poses challenges due to changes in lighting conditions, weather, and viewing point. Image feature-based approaches are appearance-sensitive, high-level semantic landmark-based methods are ambiguous, and topological map matching-based methods are not robust enough among available solutions. We propose a highly robust and highly expressive semantic descriptor for graph matching. Specifically, we begin by introducing an object-plane co-represented topological graph and a graph propagation algorithm to formulate descriptors for high-level landmarks; we then solve graph matching using the sKM algorithm. Finally, we develop a relocalization system that combines semantic objects and geometric planes for pose optimization and conducts experimental validation on various datasets. Experimental results demonstrate that the suggested method remains effective even when the viewpoint changes by more than 80° on the 2D-3D-S dataset, and the mean orientation error is less than 5° on the sceneNN dataset.
# Certifiably Optimal Mutual Localization with Anonymous Bearing Measurements
## Keywords:
- Multi-Robot SLAM
- Localization
- Multi-Robot Systems
## Abstract:
Mutual localization is essential for coordination and cooperation in multi-robot systems. Previous works have tackled this problem by assuming available correspondences between measurements and received odometry estimations, which are difficult to acquire, especially for unified robot teams. Furthermore, most local optimization methods ask for initial guesses and are sensitive to their quality. In this paper, we present a certifiably optimal algorithm that uses only anonymous bearing measurements to formulate a novel mixed-integer quadratically constrained quadratic problem (MIQCQP). Then, we relax the original nonconvex problem into a semidefinite programming (SDP) problem and obtain a certifiably global optimum using with off-the-shelf solvers. As a result, our method can determine bearing-pose correspondences and furthermore recover the initial relative poses between robots under a certain condition. We compare the performance with local optimization methods on extensive simulations under different noise levels to show our advantage in global optimality and robustness. Real-world experiments are conducted to show the practicality and robustness.
# LF-VIO: A Visual-Inertial-Odometry Framework for Large Field-Of-View Cameras with Negative Plane
## Keywords:
- Visual-Inertial SLAM
- SLAM
- Data Sets for SLAM
## Abstract:
Visual-inertial-odometry has attracted extensive attention in the field of autonomous driving and robotics. The size of Field of View (FoV) plays an important role in Visual-Odometry (VO) and Visual-Inertial-Odometry (VIO), as a large FoV enables to perceive a wide range of surrounding scene elements and features. However, when the field of the camera reaches the negative half plane, one cannot simply use [u,v,1]^T to represent the image feature points anymore. To tackle this issue, we propose LF-VIO, a real-time VIO framework for cameras with extremely large FoV. We leverage a three-dimensional vector with unit length to represent feature points, and design a series of algorithms to overcome this challenge. To address the scarcity of panoramic visual odometry datasets with ground-truth location and pose, we present the PALVIO dataset, collected with a Panoramic Annular Lens (PAL) system with an entire FoV of 360-degree*(40-degree~120-degree) and an IMU sensor. With a comprehensive variety of experiments, the proposed LF-VIO is verified on both the established PALVIO benchmark and a public fisheye camera dataset with a FoV of 360-degree*(0-degree~93.5-degree). LF-VIO outperforms state-of-the-art visual-inertial-odometry methods. Our dataset and code are made publicly available at https://github.com/flysoaryun/LF-VIO
# Localization 3
# SO-PFH: Semantic Object-Based Point Feature Histogram for Global Localization in Parking Lot
## Keywords:
- Localization
- Service Robotics
- Autonomous Vehicle Navigation
## Abstract:
Global localization is essential for autonomous mobile systems, especially indoor applications where the GPS signal is denied. Although the appearance-based methods have been successfully applied in various localization tasks, they face various challenges such as light variation, viewpoint changing and dynamic interference. Additionally, the appearance-based methods usually require a visual feature point map, which increases the storage burden. This paper proposes a novel global localization solution that leverages sparse and repetitive semantic object information. The proposal can conduct global localization based on object-level maps that are self-built or externally provided. In this solution, the semantic objects are firstly modelled with the point cloud. Then, the object's semantic information is embedded into the geometry of the corresponding point, and the Semantic Object-based Point Feature Histogram (SO-PFH) descriptors of the modelled point clouds are estimated. Finally, the global localization is executed by applying a Geometric Consistent Filter based RANdom SAmple Consensus (GCF-RANSAC) method on the point clouds matching. Experiments and simulations are conducted in indoor parking lots. The result demonstrates the effectiveness of the proposed method.
# Tether-Based Localization for Cooperative Ground and Aerial Vehicles
## Keywords:
- Localization
- Multi-Robot Systems
- Aerial Systems: Applications
## Abstract:
Considering a multi-robot system composed of a ground vehicle and a multi-copter connected each other with a tether, it is crucial for them to know their relative positions in order to carry out any operating task. Localization is usually accomplished by using GPS in outdoor environments. However, such a system does not work in indoor and more generally in so-called GPS denied environments. We investigated a solution which exploits the catenary configuration assumed by tether and does not require any computationally demanding resource or complex cable tension sensors. Different approaches have been experimentally tested, compared and validated with classical localization systems in both indoor and outdoor environments.
# Tightly-Coupled Visual-Inertial-Pressure Fusion Using Forward and Backward IMU Preintegration
## Keywords:
- Localization
- Visual-Inertial SLAM
- Sensor Fusion
## Abstract:
In this work, we present a visual-inertial-pressure (VIP) fusion method for underwater robot localization. Specifically, this letter focuses on the tightly-coupled fusion of pressure measurements into a visual inertial odometry (VIO) based on sliding window optimization. Previous works used to associate partial pressure measurements with the nearest keyframes, which not only fail to utilize all the pressure measurement information but also introduce measurement errors that only lead to sub-optimal solutions. Inspired by the current tightlycoupled visual-inertial-GPS and visual-inertial-UWB fusion methods, this letter uses IMU preintegration algorithm to derive the pressure factors. Furthermore, we propose a backward IMU preintegration method and the pressure factors are derived using forward or backward IMU preintegration based on the time-offset between the pressure measurements and the adjacent keyframes. Quantitative and qualitative analyses through simulation and real-world datasets experiments demonstrate the effectiveness of the method with negligible time cost.
# A 2D Georeferenced Map Aided Visual-Inertial System for Precise UAV Localization
## Keywords:
- Localization
- Vision-Based Navigation
- Aerial Systems: Perception and Autonomy
## Abstract:
Precise geolocalization is crucial for unmanned aerial vehicles (UAVs).However, most current deployed UAVs rely on the global navigation satellite systems (GNSS) for geolocalization. In this paper, we propose to use a lightweight visual-inertial system with a 2D georeference map to obtain accurate geodetic positions for UAVs. The proposed system firstly integrates a micro inertial measurement unit (MIMU) and a monocular camera to build a visual-inertial odometry (VIO) to consecutively estimate the UAV’s motion states and reconstruct the 3D position of the observed visual features in the local world frame. To obtain the geolocation, the visual features tracked by the odometry are further registered to the 2D georeferenced map. While most conventional methods perform image-level aerial image registration, we propose to align the reconstructed 3D points with the map, and then use the registered 3D points to relocalize the vehicle in the geodetic frame,which helps to improve the geolocalization accuracy. Finally, a pose graph is deployed to fuse the geolocation from the point registration and the local navigation result from the visual-inertial odometry (VIO) to obtain smooth and drift-free geolocalization results. We have validated the proposed method by installing the sensors to a UAV body rigidly and have conducted two real-world flights in different environments with unknown initials. The results show that the proposed method can achieve less than 4m position error in flight at about 100m high and less than 9m position error in flight at about 300m high.
# Global Data Association for SLAM with 3D Grassmannian Manifold Objects
## Keywords:
- Localization
- Recognition
- Autonomous Vehicle Navigation
## Abstract:
Using pole and plane objects in lidar SLAM can increase accuracy and decrease map storage requirements compared to commonly-used point cloud maps. However, place recognition and geometric verification using these landmarks is challenging due to the requirement for global matching without an initial guess. Existing works typically only leverage either pole or plane landmarks, limiting application to a restricted set of environments. We present a global data association method for loop closure in lidar scans using 3D line and plane objects simultaneously and in a unified manner. The main novelty of this paper is in the representation of line and plane objects extracted from lidar scans on the manifold of affine subspaces, known as the affine Grassmannian. Line and plane correspondences are matched using our graph-based data association framework and subsequently registered in the least-squares sense. Compared to pole-only approaches and plane-only approaches, our 3D affine Grassmannian method yields a 71% and 325% increase respectively to loop closure recall at 100% precision on the KITTI dataset and can provide frame alignment with less than 10 cm and 1 deg of error.
# Confidence-Rich Localization and Mapping Based on Particle Filter for Robotic Exploration
## Keywords:
- Localization
- Range Sensing
- View Planning for SLAM
## Abstract:
This paper mainly studies the localization and mapping of range sensing robots in the confidence-rich map (CRM) and then extends it to provide a full state estimate for information-theoretic exploration. Most previous works about active simultaneous localization and mapping and exploration always assumed the known robot poses or utilized inaccurate information metrics to approximate pose uncertainty, resulting in imbalanced exploration performance and efficiency in the unknown environment. This inspires us to extend the confidence-rich mutual information (CRMI) with measurable pose uncertainty. Specifically, we propose a Rao-Blackwellized particle filter-based localization and mapping scheme (RBPF-CLAM) for CRM, then we develop a new closed-form weighting method to improve the localization accuracy without scan matching. We further derive the uncertain CRMI (UCRMI) with the weighted particles by a more accurate approximation. Simulations and experimental evaluations show the localization accuracy and exploration performance of the proposed methods.
# Motion and Path Planning 3
# Homology-Class Guided Rapidly-Exploring Random Tree for Belief Space Planning
## Keywords:
- Motion and Path Planning
## Abstract:
In this work, an efficient homology guided belief space planning method for obstacle-cluttered environments is presented. The proposed planner follows a two-step approach. First, a h-signature guided rapidly-exploring random tree (HRRT) algorithm is proposed to provide nominal trajectories in different homology classes by constructing homology aware sub-trees in a parallel manner. The HRRT planner is extended to a h-signature guided RRT* algorithm, where an inter-homology-class rewire procedure is proposed, increasing the probability of discovering homology classes in narrow space/passages. The iLQG-based belief space planning algorithm is then employed to find locally optimal trajectories minimizing uncertainties in each homology class.
# Improving the Efficiency of Sampling-Based Motion Planners Via Runtime Predictions for Motion-Planning Problems with Dynamics
## Keywords:
- Motion and Path Planning
## Abstract:
While sampling-based approaches have made significant progress, motion planning with dynamics still poses significant challenges as the planner has to generate not only collision-free but also dynamically-feasible trajectories that enable the robot to reach its goal. To improve the efficiency of sampling-based motion planners, this paper develops a framework, termed Motion-Planning Runtime Prediction (MPRP), that relies on machine learning to train models to predict the expected runtime of a planner. When solving a new motion-planning problem, the trained model is then incorporated into the motion planner to more effectively guide the search toward parts of the state space that are associated with low expected runtime predictions. This paper applies the MPRP framework to state-of-the-art sampling-based motion planners to obtain new planners, which are shown to be significantly faster.
# BITKOMO: Combining Sampling and Optimization for Fast Convergence in Optimal Motion Planning
## Keywords:
- Motion and Path Planning
## Abstract:
Optimal sampling based motion planning and trajectory optimization are two competing frameworks to generate optimal motion plans. Both frameworks have complementary properties: Sampling based planners are typically slow to converge, but provide optimality guarantees. Trajectory optimizers, however, are typically fast to converge, but do not provide global optimality guarantees in nonconvex problems, e.g. scenarios with obstacles. To achieve the best of both worlds, we introduce a new planner, BITKOMO, which integrates the asymptotically optimal Batch Informed Trees (BIT*) planner with the K-Order Markov Optimization (KOMO) trajectory optimization framework. Our planner is anytime and maintains the same asymptotic optimality guarantees provided by BIT*, while also exploiting the fast convergence of the KOMO trajectory optimizer. We experimentally evaluate our planner on manipulation scenarios that involve high dimensional configuration spaces, with up to two 7-DoF manipulators, obstacles and narrow passages. BITKOMO performs better than KOMO by succeeding even when KOMO fails, and it outperforms BIT* in terms of convergence to the optimal solution.
# Making Robotics Swarm Flow More Smoothly: A Regular Virtual Tube Model
## Keywords:
- Motion and Path Planning
- Swarm Robotics
- Path Planning for Multiple Mobile Robots or Agents
## Abstract:
This paper proposes a model of a class of regular virtual tubes that can generate safe, feasible, and smooth space for robotics swarm in an obstacle-dense environment, especially for a drone swarm based on the flocking model. The regular principles are first proposed and the regular conditions are then formulated based on the principles. Based on trajectory planning and the regular conditions, a method to obtain a regular virtual tube is also presented. The proposed method's effectiveness and robustness are comprehensively demonstrated in a simulation environment with random obstacles.
# Image-Goal Navigation in Complex Environments Via Modular Learning
## Keywords:
- Motion and Path Planning
- Reactive and Sensor-Based Planning
- Vision-Based Navigation
## Abstract:
We present a novel approach for image-goal navigation, where an agent navigates with a goal image rather than accurate target information, which is more challenging. Our goal is to decouple the learning of navigation goal planning, collision avoidance, and navigation ending prediction, which enables more concentrated learning of each part. This is realized by four different modules. The first module maintains an obstacle map during robot navigation. The second predicts a long-term goal on the real-time map periodically, which can thus convert an image-goal navigation task to several point-goal navigation tasks. To achieve these point-goal navigation tasks, the third module plans collision-free command sets for navigating to these long-term goals. The final module stops the robot properly near the goal image. The four modules are designed or maintained separately, which helps cut down the search time during navigation and improves the generalization to previously unseen real scenes. We evaluate the method in both a simulator and in the real world with a mobile robot. The results in real complex environments show that our method attains at least a 17% increase in navigation success rate and a 23% decrease in navigation collision rate over some state-of-the-art models.
# Reachability Based Trajectory Generation Combining Global Graph Search in Task Space and Local Optimization in Configuration Space
## Keywords:
- Motion and Path Planning
- Optimization and Optimal Control
- Kinematics
## Abstract:
In this paper, we propose a trajectory planning framework for a robot that exploits a pre-computed database of end-effector trajectories as the guidance of optimization-based inverse kinematics. We constructed a reachable graph of a robot offline, which represents feasible end-effector paths with corresponding configurations. When performing the online trajectory planning, we applied A* search to the reachable graph to find a feasible path between input start and goal globally in the task space. Its cost function has the separated term dependent on the robot, which comes from the manipulability of configurations preserved in the reachable graph, and that is dependent on the environment. Then, we solve optimization-based inverse kinematics to generate an optimal joint trajectory while utilizing the end-effector trajectory and its corresponding configurations as the guidance to avoid local optimum. We evaluated our framework quantitatively by comparing it with existing methods to confirm that it achieved a high success rate and quality of results while suppressing its computational time. We also qualitatively proved its practicality by applying it to the material handling task in the real-world. This result shows that it improved the performance of the optimization-based inverse kinematics avoiding local optimum and applicability to the different environments of the pre-computed motion database.
# Multi-Objective Safe-Interval Path Planning with Dynamic Obstacles
## Keywords:
- Motion and Path Planning
## Abstract:
Path planning among dynamic obstacles is a fundamental problem in Robotics with numerous applications. In this work, we investigate a problem called Multi-Objective Path Planning with Dynamic Obstacles (MOPPwDO), which requires finding collision-free Pareto-optimal paths amid obstacles moving along known trajectories while simultaneously optimizing multiple conflicting objectives, such as arrival time, communication robustness and obstacle clearance. Most of the existing multi-objective A*-like planners consider no dynamic obstacles, and naively applying them to address MOPPwDO can lead to large computation times. On the other hand, efficient algorithms such as Safe-Interval Path Planing (SIPP) can handle dynamic obstacles but for a single objective. In this work, we develop an algorithm called MO-SIPP by leveraging both the notion of safe intervals from SIPP to efficiently represent the search space in the presence of dynamic obstacles, and search techniques from multi-objective A* algorithms. We show that MO-SIPP is guaranteed to find the entire Pareto-optimal front, and verify MO-SIPP with extensive numerical tests with two and three objectives. The results show that the MO-SIPP runs up to an order of magnitude faster than the conventional alternates.
# Optimal Partitioning of Non-Convex Environments for Minimum Turn Coverage Planning
## Keywords:
- Motion and Path Planning
- Optimization and Optimal Control
- Service Robotics
## Abstract:
In this paper, we tackle the problem of planning an optimal coverage path for a robot operating indoors. Many existing approaches attempt to discourage turns in the path by covering the environment along the least number of coverage lines, i.e., straight-line paths. This is because turning not only slows down the robot but also negatively affects the quality of coverage, e.g., tools like cameras and cleaning attachments commonly have poor performance around turns. The problem of minimizing coverage lines however is typically solved using heuristics that do not guarantee optimality. In this work, we propose a turn-minimizing coverage planning method that computes the optimal number of axis-parallel (horizontal/vertical) coverage lines for the environment in polynomial time. We do this by formulating a linear program (LP) that optimally partitions the environment into axis-parallel ranks (non-intersecting rectangles of width equal to the tool width). We then generate coverage paths for a set of real-world indoor environments and compare the results with state-of-the-art coverage approaches.
# Optimal Time Trajectory Generation and Tracking Control for Over-Actuated Multirotors with Large-Angle Maneuvering Capability
## Keywords:
- Motion and Path Planning
- Sensor-based Control
- Aerial Systems: Applications
## Abstract:
This paper presents an optimal time trajectory generation method for over-actuated multirotors. Different from underactuated multi-rotors that can only track a 4-D trajectory, over-actuated multi-rotors have the ability to track a 6-D trajectory. The proposed method can generate a 3-degree of freedom(DoF) position trajectory and a 3-DoF attitude trajectory. The method is composed of two steps: first, on the basis of polynomials, position and attitude trajectories satisfying geometric constraints are generated by solving unconstrainted problem in the spatial domain. Second, attitude and position dynamics constraints are added in the temporal domain, in order to achieve large-angle maneuvers. Afterwards, optimal time allocation is achieved by solving a mapping function in the temporal domain. The mapping function describes the mapping relationship between spatial variables and temporal variables. A comparative experiment is presented to verify that time allocated to trajectory by the proposed algorithm is shorter compared to other algorithms, while a tracking controller is constructed for overactuated multirotors. The tracking controller is verified to be feasible for the experimental platform through flight experiment.
# Award Session V
# Robot-Assisted Nuclear Disaster Response: Report and Insights from a Field Exercise
(Finalist for IROS Best Paper Award on Safety, Security, and Rescue Robotics in Memory of Motohiro Kisoi Sponsored by IRSI)
## Keywords:
- Robotics in Hazardous Fields
- Search and Rescue Robots
- Human Factors and Human-in-the-Loop
## Abstract:
This paper reports on insights by robotics researchers that participated in a 5-day robot-assisted nuclear disaster response field exercise conducted by Kerntechnische Hilfdienst GmbH (KHG) in Karlsruhe, Germany. The German nuclear industry established KHG to provide a robot-assisted emergency response capability for nuclear accidents. We present a systematic description of the equipment used; the robot operators' training program; the field exercise and robot tasks; and the protocols followed during the exercise. Additionally, we provide insights and suggestions for advancing disaster response robotics based on these observations. Specifically, the main degradation in performance comes from the cognitive and attentional demands on the operator. Furthermore, robotic platforms and modules should aim to be robust and reliable in addition to their ease of use. Last, as emergency response stakeholders are often skeptical about using autonomous systems, we suggest adopting a variable autonomy paradigm to integrate autonomous robotic capabilities with the human-in-the-loop gradually. This middle ground between teleoperation and autonomy can increase end-user acceptance while directly alleviating some of the operator's robot control burden and maintaining the resilience of the human-in-the-loop.
# Power-Based Safety Layer for Aerial Vehicles in Physical Interaction Using Lyapunov Exponents
(Finalist for IROS Best Paper Award on Safety, Security, and Rescue Robotics in Memory of Motohiro Kisoi Sponsored by IRSI)
## Keywords:
- Aerial Systems: Mechanics and Control
- Robot Safety
- Force Control
## Abstract:
As the performance of autonomous systems increases, safety concerns arise, especially when operating in non-structured environments. To deal with these concerns, this work presents a safety layer for mechanical systems that detects and responds to unstable dynamics caused by external disturbances. The safety layer is implemented independently and on top of already present nominal controllers, like pose or wrench tracking, and limits power flow when the system's response would lead to instability. This approach is based on the computation of the Largest Lyapunov Exponent (LLE) of the system’s error dynamics, which represent a measure of the dynamics’ divergence or convergence rate. By actively computing this metric, divergent and possibly dangerous system behaviors can be promptly detected. The LLE is then used in combination with Control Barrier Functions (CBFs) to impose power limit constraints on a jerk controlled system. The proposed architecture is experimentally validated on an Omnidirectional Micro Aerial Vehicle (OMAV) both in free flight and interaction tasks.
# Risk-Aware Motion Planning for Collision-Tolerant Aerial Robots Subject to Localization Uncertainty
(Finalist for IROS Best Paper Award on Safety, Security, and Rescue Robotics in Memory of Motohiro Kisoi Sponsored by IRSI)
## Keywords:
- Aerial Systems: Perception and Autonomy
- Motion and Path Planning
## Abstract:
This paper contributes a novel strategy towards risk-aware motion planning for collision-tolerant aerial robots subject to localization uncertainty. Attuned to the fact that micro aerial vehicles are often tasked to navigate within GPS-denied, possibly unknown, confined and obstacle-filled environments the proposed method exploits collision-tolerance at the robot design level to mitigate the risks of collisions especially as their likelihood increases with growing uncertainty. Accounting for the maximum kinetic energy with which an impact is considered safe, alongside the robot dynamics, the planner builds a set of admissible uncertainty-aware and collision-inclusive paths over a horizon involving multiple motion steps. The first step of the best path is executed by the robot, while the procedure is then repeated in a receding horizon manner. Evaluated in extensive simulation studies and experimental results with a collision-tolerant flying robot, the planner successfully considers the interplay between uncertainty and the likelihood of a collision, balances the risks of possible impacts and enables to navigate safely within highly cluttered environments.
# A Planning-And-Control Framework for Aerial Manipulation of Articulated Objects
(Finalist for IROS Best Paper Award on Mobile Manipulation Sponsored by OMRON Sinic X Corp.)
## Keywords:
- Aerial Systems: Applications
- Aerial Systems: Perception and Autonomy
- Manipulation Planning
## Abstract:
While the variety of applications for Aerial Manipulators (AMs) has increased over the last years, they are mostly limited to push-and-slide tasks. More complex manipulations of dynamic environments are poorly addressed and still require handcrafted designs of hardware, control, and trajectory planning. In this paper we focus on the active manipulation of articulated objects with AMs. We present a novel planning and control approach that allows the AM to execute complex interaction maneuvers with as little as possible priors given by the operator. Our framework combines sampling-based predictive control to generate pose trajectories with an impedance controller for compliant behaviours, applied to a fully-actuated flying platform. The framework leverages a physics engine to simulate the dynamics of the platform and the environment in order to find optimal motions to execute manipulation tasks. Experiments on two selected examples of pulling open a door and of turning a valve show the feasibility of the proposed approach.
# Safe Drone Flight with Time-Varying Backup Controllers
(Finalist for IROS Best Paper Award on Safety, Security, and Rescue Robotics in Memory of Motohiro Kisoi Sponsored by IRSI)
## Keywords:
- Robot Safety
- Aerial Systems: Mechanics and Control
- Multi-Robot Systems
## Abstract:
The weight, space, and power limitations of small aerial vehicles often prevent the application of modern control techniques without significant model simplifications. Moreover, high-speed agile behavior, such as that exhibited in drone racing, make these simplified models too unreliable for safety-critical control. In this work, we introduce the concept of time-varying backup controllers (TBCs): user-specified maneuvers combined with backup controllers that generate reference trajectories which guarantee the safety of nonlinear systems. TBCs reduce conservatism when compared to traditional backup controllers and can be directly applied to multi-agent coordination to guarantee safety. Theoretically, we provide conditions under which TBCs strictly reduce conservatism, describe how to switch between several TBC's and show how to embed TBCs in a multi-agent setting. Experimentally, we verify that TBCs safely increase operational freedom when filtering a pilot's actions and demonstrate robustness and computational efficiency when applied to decentralized safety filtering of two quadrotors.
# Mobile Manipulation Leveraging Multiple Views
(Finalist for IROS Best Paper Award on Mobile Manipulation Sponsored by OMRON Sinic X Corp.)
## Keywords:
- Mobile Manipulation
- Vision-Based Navigation
- Machine Learning for Robot Control
## Abstract:
While both navigation and manipulation are challenging topics in isolation, many tasks require the ability to both navigate and manipulate in concert. To this end, we propose a mobile manipulation system that leverages novel navigation and shape completion methods to manipulate an object with a mobile robot. Our system utilizes uncertainty in the initial estimation of a manipulation target to calculate a predicted next-best-view. Without the need of localization, the robot then uses the predicted panoramic view at the next-best-view location to navigate to the desired location, capture a second view of the object, create a new model that predicts the shape of object more accurately than a single image alone, and uses this model for grasp planning. We show that the system is highly effective for mobile manipulation tasks through simulation experiments using real world data, as well as ablations on each component of our system.
# Award Session VI
# Safety-Critical Manipulation for Collision-Free Food Preparation
(Finalist for IROS Best Paper Award for Industrial Robotics Research with Real-World Applications Sponsored by Mujin Inc.)
## Keywords:
- Robot Safety
- Manipulation Planning
- Integrated Planning and Control
## Abstract:
Recent advances allow for the automation of food preparation in high-throughput environments, yet the successful deployment of these robots requires the planning and execution of quick, robust, and ultimately collision-free behaviors. In this work, we showcase a novel framework for modifying previously generated trajectories of robotic manipulators in highly detailed and dynamic collision environments using Control Barrier Functions (CBFs). This method dynamically re-plans previously validated behaviors in the presence of changing environments---and does so in a computationally efficient manner. Moreover, the approach provides rigorous safety guarantees of the resulting trajectories, factoring in the true underlying dynamics of the manipulator. This methodology is extensively validated on a full-scale robotic manipulator in a real-world cooking environment, and has resulted in substantial improvements in computation time and robustness over re-planning.
# Impedance Control on Arbitrary Surfaces for Ultrasound Scanning Using Discrete Differential Geometry
(Finalist for IROS Best Paper Award for Industrial Robotics Research with Real-World Applications Sponsored by Mujin Inc.)
## Keywords:
- Compliance and Impedance Control
- Computational Geometry
- Medical Robots and Systems
## Abstract:
We propose an approach to robotic ultrasound scanning systems using a passivity-based impedance control scheme on arbitrary surfaces. First, we introduce task coordinates depending on the geometry of the surface, which enables hands-on guidance of the robot along the surface, as well as teleoperated and autonomous ultrasound image acquisition. Our coordinates allow controlling the signed distance of the robot to the surface and alignment of the tool to the surface normal using classical impedance control. This corresponds to implicitly obtaining a foliation of parallel surfaces. By setting the desired signed distance negative, i.e. into the surface, we obtain passive contact forces. We extend the approach to also incorporate coordinates that allow controlling the specific point on the surface and, likewise, on all parallel surfaces. Finally, we demonstrate the performance of the controller on the seven degrees of freedom lightweight robot DLR MIRO. In the experiments the robot can track complex trajectories while keeping the distance error below 1mm and applying an almost constant contact force.
# Soft Tissue Characterisation Using a Novel Robotic Medical Percussion Device with Acoustic Analysis and Neural Networks
(Finalist for IROS Best Application Paper Award Sponsored by ICROS)
## Keywords:
- Medical Robots and Systems
- AI-Based Methods
- Mechanism Design
## Abstract:
Medical percussion is a common manual examination procedure used by physicians to determine the state of underlying tissues from their acoustic responses. Although it has been used for centuries, there is a limited quantitative understanding of its dynamics, leading to subjectivity and a lack of detailed standardisation. This paper presents a novel compliant two-degree-of-freedom robotic device inspired by the human percussion action, and validates its performance in two tissue characterisation experiments. In Experiment 1, spectrotemporal analysis using 1-D Continuous Wavelet Transform (CWT) proved the potential of the device to identify hard nodules, mimicking lipomas, embedded in silicone phantoms representing a patient’s abdominal region. In Experiment 2, Gaussian Mixture Modelling (GMM) and Neural Network (NN) predictive models were implemented to classify composite phantom tissues of varying density and thickness. The proposed device and methods showed up to 97.5% accuracy in the classification of phantoms, proving the potential of robotic solutions to standardise and improve the accuracy of percussion diagnostic procedures.
# Multi-Directional Bicycle Robot for Bridge Inspection with Steel Defect Detection System
(Finalist for IROS Best Application Paper Award Sponsored by ICROS)
## Keywords:
- Climbing Robots
- Field Robots
- Robotics and Automation in Construction
## Abstract:
This paper presents a novel design of a multi-directional bicycle robot, which is developed for the inspection of steel structures, in particular, steel-reinforced bridges. The locomotion concept is based on arranging two magnetic wheels in a bicycle-like configuration with two independent steering actuators. This configuration allows the robot to possess multi-directional mobility. An additional free joint helps the robot adapt naturally to non-flat and complex steel structures. The robot’s design provides the advantage of being mechanically simple and providing high-level mobility across diverse steel structures. In addition, a visual sensor is equipped that allows the data collection for steel defect detection with offline training and validation. The paper also provides a novel pipeline for Steel Defect Detection, which utilizes multiple datasets (one for training and one for validation) from real bridges. The quantitative results have been reported for three Deep Encoder-Decoder Networks (i.e., LinkNet, UNet, DeepLab) with their corresponding Encoder modules (i.e., ResNet-18, ResNet-34, RegNet-X2, EfficientNet-B0, and EfficientNet-B2). Due to space concerns, the qualitative results have been outlined in Appendix, with a link in Fig. 11 caption to access the result provided.
# Tactile-Sensitive NewtonianVAE for High-Accuracy Industrial Connector Insertion
(Finalist for IROS Best Application Paper Award Sponsored by ICROS)
## Keywords:
- Computer Vision for Automation
- Force and Tactile Sensing
- Machine Learning for Robot Control
## Abstract:
An industrial connector insertion task requires submillimeter positioning and grasp pose compensation for a plug. Thus, highly accurate estimation of the relative pose between a plug and socket is fundamental for achieving the task. World models are promising technologies for visuomotor control because they obtain appropriate state representation to jointly optimize feature extraction and latent dynamics model. Recent studies show that the NewtonianVAE, a type of the world model, acquires latent space equivalent to mapping from images to physical coordinates. Proportional control can be achieved in the latent space of NewtonianVAE. However, applying NewtonianVAE to high-accuracy industrial tasks in physical environments is an open problem. Moreover, the existing framework does not consider the grasp pose compensation in the obtained latent space. In this work, we proposed tactile-sensitive NewtonianVAE and applied it to a USB connector insertion with grasp pose variation in the physical environments. We adopted a GelSight-type tactile sensor and estimated the insertion position compensated by the grasp pose of the plug. Our method trains the latent space in an end-to-end manner, and no additional engineering and annotation are required. Simple proportional control is available in the obtained latent space. Moreover, we showed that the original NewtonianVAE fails in some situations, and demonstrated that domain knowledge induction improves model accuracy. This domain knowledge can be easily obtained using robot specification and grasp pose error measurement. We demonstrated that our proposed method achieved a 100% success rate and 0.3 mm positioning accuracy in the USB connector insertion task in the physical environment. It outperformed SOTA CNN-based two-stage goal pose regression with grasp pose compensation using coordinate transformation.
# Grasping 4
# Enabling Massage Actions: An Interactive Parallel Robot with Compliant Joints
## Keywords:
- Grippers and Other End-Effectors
- Compliant Joints and Mechanisms
- Compliance and Impedance Control
## Abstract:
We propose a parallel massage robot with compliant joints based on the series elastic actuator (SEA), offering a unified force-position control approach. First, the kinematic and static force models are established for obtaining the corresponding control variables. Then, a novel force-position control strategy is proposed to separately control the force-position along the normal direction of the surface and another two-direction displacement, without the requirement of a robotic dynamics model. To evaluate its performance, we implement a series of robotic massage experiments. The results demonstrate that the proposed massage manipulator can successfully achieve desired forces and motion patterns of massage tasks, arriving at a high-score user experience.
# Designing Underactuated Graspers with Dynamically Variable Geometry Using Potential Energy Map Based Analysis
## Keywords:
- Grippers and Other End-Effectors
- Underactuated Robots
- Methods and Tools for Robot System Design
## Abstract:
In this paper we present a potential energy map based approach that provides a framework for the design and control of a robotic grasper. Unlike other potential energy map approaches, our framework considers friction for a more realistic perspective on grasper performance. Our analysis establishes the importance of considering dynamically variable geometry in grasper design, namely palm width, link lengths, and transmission ratios, which are assumed to be able to change in real-time. Our analysis assumes a two-phalanx tendon-pulley underactuated grasper, but it can be extended to other underactuated mechanisms. We demonstrate the utility of these novel potential energy maps and the method used to generate them in order by showing how various design parameters impact the grasping and in-hand manipulation performance of a particular design across a range of object sizes and friction coefficients. Optimal grasping designs have palms that scale with object size and transmission ratios that scale with the coefficient of friction. Using a custom in-hand manipulation metric, we compared the in-hand manipulation capabilities of a grasper that only dynamically varied its palm size, link lengths, and transmission ratios to a grasper with a variable palm and controllable actuation efforts. The analysis revealed the advantage of dynamically variable geometry; by varying only its palm size, link lengths, and transmission ratios in real-time, safe, caged in-hand manipulation of a wide range of objects could be performed.
# A Novel Human-Safe Robotic Gripper: An Application of a Programmable Permanent Magnet Actuator
## Keywords:
- Grippers and Other End-Effectors
- Human-Robot Collaboration
- Safety in HRI
## Abstract:
While collaborative robotic arms offer significant safety benefits, safety of the overall manipulator system cannot be guaranteed unless equally strict safety requirements are satisfied by the accompanying end-effector. Current robot grippers are not made in a way that fulfills such a requirement, resulting in collaborative robots needing to operate in a protected environment. This paper presents a novel permanent magnet actuator inside of a conventional industrial electric gripper which results in an end-effector that has an unmatched force range of 1-2N to 43N and exhibits interesting characteristics suited to the requirements of a safe gripper such as torque holding without power, variable stiffness and force sensing.
# The Good Grasp, the Bad Grasp, and the Plateau in Tactile Based Grasp Stability Prediction
## Keywords:
- Deep Learning in Grasping and Manipulation
- Perception for Grasping and Manipulation
- Force and Tactile Sensing
## Abstract:
Research around tactile sensing for grasp stability prediction in robotic manipulators continues to be popular, however few works are able to achieve a high classification accuracy. Due to simulation complexity, data-driven methods are often forced to rely on experimental data, yielding small, often unbalanced, data sets. In this work, the authors use a 3972 sample data set to explore the effects of the data set composition on the performance of a classifier. While maintaining a similar overall accuracy, the ability to recognize a grasp failure was significantly impacted by the composition of the data set. The authors propose an autonomous pipeline designed to generate more diverse failure grasps. On failure-rich data, a tactile-based classifier with a balanced training set achieved a classification accuracy of 84.68% while maintaining a recall of the grasp failure class of 76%. This represents a 71.79% improvement in recall over a model trained on a larger but unbalanced data set.
# Extrinsic Dexterous Manipulation with a Direct-Drive Hand: A Case Study
## Keywords:
- Grippers and Other End-Effectors
- Dexterous Manipulation
- Industrial Robots
## Abstract:
This paper explores a novel approach to dexterous manipulation, aimed at levels of speed, precision, robustness, and simplicity suitable for practical deployment. The enabling technology is a Direct-drive Hand (DDHand) comprising two fingers, two DOFs each, that exhibit high speed and a light touch. The test application is the dexterous manipulation of three small and irregular parts, moving them to a grasp suitable for a subsequent assembly operation, regardless of initial presentation. We employed four primitive behaviors that use ground contact as a “third finger”, prior to or during the grasp process: pushing, pivoting, toppling, and squeeze# grasping. In our experiments, each part was presented from 30 to 90 times randomly positioned in each stable pose. Success rates varied from 83% to 100%. The time to manipulate and grasp was 6.32 seconds on average, varying from 2.07 to 16 seconds. In some cases, performance was robust, precise, and fast enough for practical applications, but in other cases, pose uncertainty required time-consuming vision and arm motions. The paper concludes with a discussion of further improvements required to make the primitives robust, eliminate uncertainty, and reduce this dependence on vision and arm motion.
# GTac-Gripper: A Reconfigurable Under-Actuated Four-Fingered Robotic Gripper with Tactile Sensing
## Keywords:
- Grippers and Other End-Effectors
- Multifingered Hands
- Force and Tactile Sensing
## Abstract:
Humans can use different grasping poses and forces for everyday objects of different shapes and sizes. Grasping and manipulating everyday objects have been longstanding challenges in robotics. Performing multiple grasping configurations is difficult for robotic end-effectors with limited degrees of freedom (DOF). Integrating tactile sensing into robotic grippers will facilitate grasping and manipulating a wider range of objects. In this letter, we present a robotic gripper with a reconfigurable mechanism and tactile sensors (GTac) integrated into the fingers and palm. Each finger consists of two phalanges with a 2 DOF underactuated design and a metacarpophalangeal (MCP) joint. Our gripper with four adaptive fingers can perform 5 grasping configurations and obtain 228 tactile feedback signals (normal and shear forces) at 150 Hz. Our results show that the gripper can grasp various everyday objects and achieve in-hand manipulation including translation and rotation with closed-loop control. In the YCB benchmark assessment, the gripper achieved a score of 93% (round objects), 0% (flat objects), 78% (tools), 90% (articulated objects), and 65% in total This research provides a new hardware design and could be beneficial to various robotic applications in the domestic and industrial fields.
# Single-Fingered Reconfigurable Robotic Gripper with a Folding Mechanism for Narrow Working Spaces
## Keywords:
- Grippers and Other End-Effectors
- Mechanism Design
- Grasping
## Abstract:
This paper proposes a novel single-fingered reconfigurable robotic gripper for grasping objects in narrow working spaces. The finger of the developed gripper realizes two configurations, namely, the insertion and grasping modes, using only a single motor. In the insertion mode, the finger assumes a thin shape such that it can insert its tip into a narrow space. The grasping mode of the finger is activated through a folding mechanism. Mode switching can be achieved in two ways: switching the mode actively by a motor, or combining passive rotation of the fingertip through contact with the support surface and active motorized construction of the claw. The latter approach is effective when it is unclear how much finger insertion is required for a specific task. The structure provides a simple control scheme. The performance of the proposed robotic gripper design and control methodology was experimentally evaluated. The minimum width of the insertion space required to grasp an object is 4 mm (1 mm, when using a strategy).
# SEED: Series Elastic End Effectors in 6D for Visuotactile Tool Use
## Keywords:
- Grippers and Other End-Effectors
- Soft Robot Applications
- Force Control
## Abstract:
We propose the framework of Series Elastic End Effectors in 6D (SEED), which combines a spatially compliant element with visuotactile sensing to grasp and manipulate tools in the wild. Our framework generalizes the benefits of series elasticity to 6-dof, while providing an abstraction of control using visuotactile sensing. We propose an algorithm for relative pose estimation from visuotactile sensing, and a spatial hybrid force-position controller capable of achieving stable force interaction with the environment. We demonstrate the effectiveness of our framework on tools that require regulation of spatial forces. Video link: https://youtu.be/2-YuIfspDrk
# Elongatable Gripper Fingers with Integrated Stretchable Tactile Sensors for Underactuated Grasping and Dexterous Manipulation (I)
## Keywords:
- Multifingered Hands
- Underactuated Robots
- Soft Sensors and Actuators
## Abstract:
The ability to grasp a wider range of objects in size and shape directly relates to the performance of robotic grippers. Adapting to complex geometries of objects requires large degrees of freedom to allow complex configurations. However, complexity in controlling many individual joints leads to introduction of underactuated mechanisms, in which traditional finger designs composed of revolute joints allow only flexion/extension motions. In this article, we propose a length-adjustable linkage mechanism in the underactuated finger controlled by an antagonistic tendon pair. The resulting gripper can elongate the fingers for an increased task space or shorten them for a finer spatial resolution. For tactile sensing, hyperelastic soft sensors are used to stretch with finger elongation. Contact pressures measured by the soft sensors are used in force-feedback control for which either the joint angles or the link lengths are adjusted. Lastly, a multimodal control scheme that combines elongation and flexion modes is demonstrated with tasks of dexterous manipulation.
# Manipulation Systems 4
# Challenges and Outlook in Robotic Manipulation of Deformable Objects (I)
## Keywords:
- Sensor-based Control
- Dexterous Manipulation
- Perception for Grasping and Manipulation
## Abstract:
Deformable object manipulation (DOM) is an emerging research problem in robotics. The ability to manipulate deformable objects endows robots with higher autonomy and promises new applications in the industrial, services, and healthcare sectors. However, compared to rigid object manipulation, the manipulation of deformable objects is considerably more complex, and is still an open research problem. Addressing DOM challenges demand breakthroughs in almost all aspects of robotics, namely, hardware design, sensing, (deformation) modeling, planning, and control. In this article, we review recent advances and highlight the main challenges when considering deformation in each sub-field. A particular focus of our paper lies in the discussions of these challenges and proposing future directions of research.
# Robust Robotic 3-D Drawing Using Closed-Loop Planning and Online Picked Pens (I)
## Keywords:
- Manipulation Planning
- Task and Motion Planning
- Task Planning
## Abstract:
This paper develops a flexible and robust robotic system for autonomously drawing on 3D surfaces. The system takes 2D drawing strokes and a 3D target surface (mesh or point clouds) as input. It maps the 2D strokes onto the 3D surface and generates a robot motion to draw the mapped strokes using visual recognition, grasp pose reasoning, and motion planning. The system is flexible compared to conventional robotic drawing systems as we do not fix drawing tools to the end of a robot arm. Instead, a robot recognizes and picks up pens online and holds the pens to draw 3D strokes. Meanwhile, the system has high robustness thanks to the following crafts: First, a high-quality mapping method is developed to minimize deformation in the strokes. Second, visual detection is used to re-estimate the drawing tool's pose before executing each drawing motion. Third, force control is employed to compensate for noisy visual detection and calibration and ensure a firm touch between the pen tip and the surface. Fourth, error detection and recovery are implemented to deal with slippage and other anomalies. The planning and executions are performed in a closed-loop manner until the strokes are successfully drawn. We evaluate the system and analyze the necessity of the various crafts using different real-world tasks. The results show that the proposed system is flexible and robust to generate robotic motion that picks up the pens and successfully draws 3D strokes on given surfaces.
# 6D Robotic Assembly Based on RGB-Only Object Pose Estimation
## Keywords:
- Deep Learning in Grasping and Manipulation
- Assembly
- Deep Learning for Visual Perception
## Abstract:
Vision-based robotic assembly is a crucial yet challenging task as the interaction with multiple objects requires high levels of precision. In this paper, we propose an integrated 6D robotic system to perceive, grasp, manipulate and assemble blocks with tight tolerances. Aiming to provide an off-the-shelf RGB-only solution, our system is built upon a monocular 6D object pose estimation network trained solely with synthetic images leveraging physically-based rendering. Subsequently, pose-guided 6D transformation along with collision-free assembly is proposed to construct any designed structure with arbitrary initial poses. Our novel 3-axis calibration operation further enhances the precision and robustness by disentangling 6D pose estimation and robotic assembly. Both quantitative and qualitative results demonstrate the effectiveness of our proposed 6D robotic assembly system.
# Context and Intention Aware 3D Human Body Motion Prediction Using an Attention Deep Learning Model in Handover Tasks
## Keywords:
- Deep Learning in Grasping and Manipulation
- Human-Robot Collaboration
- Human-Aware Motion Planning
## Abstract:
 This work explores how contextual information and human intention affect the motion prediction of humans during a handover operation with a social robot. By classifying human intention in four different classes, we developed a model able to generate a different motion for each intention class. Furthermore, the model uses a multi-headed attention architecture to add contextual information to the pipeline, such as the position of the robot end effector (REE) or the position of obstacles in the interaction scene. We generate predictions up to two and half seconds in the future given an input sequence of one second containing the previous motion of the human. The results show an improvement of the prediction accuracy, both for the full skeleton prediction and the human hand used for the delivery. The model also allows to generate different sequences with the desired human intention.
# Learning a State Estimator for Tactile In-Hand Manipulation
## Keywords:
- Deep Learning in Grasping and Manipulation
- Probability and Statistical Methods
- In-Hand Manipulation
## Abstract:
We study the problem of estimating the pose of an object which is being manipulated by a multi-fingered robotic hand by only using proprioceptive feedback. To address this challenging problem, we propose a novel variant of differentiable particle filters, which combines two key extensions. First, our learned proposal distribution incorporates recent measurements in a way that mitigates weight degeneracy. Second, the particle update works on non-euclidean manifolds like Lie-groups, enabling learning-based pose estimation in 3D on SE(3). We show that the method can represent the rich and often multi-modal distributions over poses that arise in tactile state estimation. The models are trained in simulation, but by using domain randomization, we obtain state estimators that can be employed for pose estimation on a real robotic hand (equipped with joint torque sensors). Moreover, the estimator runs fast, allowing for online usage with update rates of more than 100Hz on a single CPU core. We quantitatively evaluate our method and benchmark it against other approaches in simulation. We also show qualitative experiments on the real torque-controlled DLR-Hand II.
# A Two-Stage Learning Architecture That Generates High-Quality Grasps for a Multi-Fingered Hand
## Keywords:
- Deep Learning in Grasping and Manipulation
- Multifingered Hands
- Grasping
## Abstract:
In this work, we investigate the problem of planning stable grasps for object manipulations using an 18-DOF robotic hand with four fingers. The main challenge here is the high-dimensional search space, and we address this problem using a novel two-stage learning process. In the first stage, we train an autoregressive network called the hand-pose-generator, which learns to generate a distribution of valid 6D poses of the palm for a given volumetric object representation. In the second stage, we employ a network that regresses 12D finger positions and scalar grasp qualities from given object representations and palm poses. To train our networks, we use synthetic training data generated by a novel grasp planning algorithm, which also proceeds stage-wise: first the palm pose, then the finger positions. Here, we devise a Bayesian Optimization scheme for the palm pose and a physics-based grasp pose metric to rate stable grasps. In experiments on the YCB benchmark data set, we show a grasp success rate of over 83%, as well as qualitative results on real scenarios of grasping unknown objects.	
# Graph-Structured Policy Learning for Multi-Goal Manipulation Tasks
## Keywords:
- Deep Learning in Grasping and Manipulation
- Reinforcement Learning
- Transfer Learning
## Abstract:
Multi-goal policy learning for robotic manipulation is challenging. Prior successes have used state-based representations of the objects or provided demonstration data to facilitate learning. In this paper, by hand-coding a high-level discrete representation of the domain, we show that policies to reach dozens of goals can be learned with a single network using Q-learning from pixels.	The agent focuses learning on simpler, local policies which are sequenced together by planning in the abstract space. We compare our method against standard multi-goal RL baselines, as well as other methods that leverage the discrete representation, on a challenging block construction domain. We find that our method can build more than a hundred different block structures, and demonstrate forward transfer to structures with novel objects. Lastly, we deploy the policy learned in simulation on a real robot.
# Scene Editing As Teleoperation: A Case Study in 6DoF Kit Assembly
## Keywords:
- Deep Learning in Grasping and Manipulation
- Deep Learning for Visual Perception
- Telerobotics and Teleoperation
## Abstract:
Studies in robot teleoperation have been centered around action specifications -# from continuous joint control to discrete end-effector pose control. However, these "robot-centric" interfaces often require skilled operators with extensive robotics expertise. To make teleoperation accessible to non-expert users, we propose the framework "Scene Editing as Teleoperation" (SEaT), where the key idea is to transform the traditional "robot-centric" interface into a "scene-centric" interface -# instead of controlling the robot, users focus on specifying the task's goal by manipulating digital twins of the real-world objects. As a result, a user can perform teleoperation without any expert knowledge of the robot hardware. To achieve this goal, we utilize a category-agnostic scene-completion algorithm that translates the real-world workspace (with unknown objects) into a manipulable virtual scene representation and an action-snapping algorithm that refines the user input before generating the robot's action plan. To train the algorithms, we procedurely generated a large-scale, diverse kit-assembly dataset that contains object-kit pairs that mimic real-world object-kitting tasks. Our experiments in simulation and on a real-world system demonstrate that our framework improves both the efficiency and success rate for 6DoF kit-assembly tasks. A user study demonstrates that SEaT framework participants achieve a higher task success rate and report a lower subjective workload compared to an alternative robot-centric interface.
# On the Importance of Label Encoding and Uncertainty Estimation for Robotic Grasp Detection
## Keywords:
- Deep Learning in Grasping and Manipulation
- Grasping
## Abstract:
Automated grasping of arbitrary objects is an essential skill for many applications such as smart manufacturing and human robot interaction. This makes grasp detection a vital skill for automated robotic systems. Recent work in model-free grasp detection uses point cloud data as input and typically outperforms the earlier work on RGB(D)-based methods. We show that RGB(D)-based methods are being underestimated due to suboptimal label encodings used for training. Using the evaluation pipeline of the GraspNet-1Billion dataset, we investigate different encodings and propose a novel encoding that significantly improves grasp detection on depth images. Additionally, we show shortcomings of the 2D rectangle grasps supplied by the GraspNet-1Billion dataset and propose a filtering scheme by which the ground truth labels can be improved significantly. Furthermore, we apply established methods for uncertainty estimation on our trained models since knowing when we can trust the model's decisions provides an advantage for real-world application. By doing so, we are the first to directly estimate uncertainties of detected grasps. We also investigate the applicability of the estimated aleatoric and epistemic uncertainties based on their theoretical properties. Additionally, we demonstrate the correlation between estimated uncertainties and grasp quality, thus improving selection of high quality grasp detections. By all these modifications, our approach using only depth images can compete with point-cloud-based approaches for grasp detection despite the lower degree of freedom for grasp poses in 2D image space.
# Navigation Systems 3
# A Unified MPC Design Approach for AGV Path Following
## Keywords:
- Autonomous Vehicle Navigation
- Motion and Path Planning
- Service Robotics
## Abstract:
This paper presents a unified approach to the design of Model Predictive Controllers (MPC), custom-tailored for path following by Automated Guided Vehicles (AGVs). The approach can be applied in a unified manner to several relevant AGV kinematic configurations, including tricycle, differential, and double steer-drive. By leveraging Linear Parameter Varying (LPV) MPC, it provides maximum maneuverability and industrial-grade positioning accuracy. We incorporate state-of-the-art optimized velocity planning, to maximize vehicle utilization. Experimental validation is performed on three different kinematic configurations, including a real forklift with tricycle configuration, using industrially-relevant positioning maneuvers.
# GPU-Parallelized Iterative LQR with Input Constraints for Fast Collision Avoidance of Autonomous Vehicles
## Keywords:
- Autonomous Vehicle Navigation
- Motion and Path Planning
- Control Architectures and Programming
## Abstract:
Collision avoidance in emergency situations is a crucial and challenging task in motion planning for autonomous vehicles. Especially in the field of optimization-based planning using nonlinear model predictive control, many efforts to achieve real-time performance are still ongoing. Among various approaches, the iterative linear quadratic regulator (iLQR) is known as an efficient means of nonlinear optimization. Additionally, parallel computing architectures, such as GPUs, are more widely applied in autonomous vehicles. In this paper, we propose 1) a parallel computing framework for iLQR with input constraints considering the characteristics of the problem and 2) a proper environmental formulation that is suitable for lower-precision GPU computations. The GPU-accelerated framework was tested on a real-time simulation-in-the-loop system using CarMaker and ROS at a 20 Hz sampling rate on a low-performance mobile computer and was compared against the same framework realized with a CPU.
# RIANet: Road Graph and Image Attention Network for Urban Autonomous Driving
## Keywords:
- Autonomous Vehicle Navigation
- Imitation Learning
- Sensor Fusion
## Abstract:
In this paper, we present a novel autonomous driving framework, called a road graph and image attention network (RIANet), which computes the attention scores of objects in the image using the road graph feature. The process of the proposed method is as follows: First, the feature encoder module encodes the road graph, image, and additional features of the scene. The attention network module then incorporates the encoded features and computes the scene context feature via the attention mechanism. Finally, the low-level controller module drives the ego-vehicle based on the scene context feature. In the experiments, we use an urban scene driving simulator named CARLA to train and test the proposed method. The results show that the proposed method outperforms existing autonomous driving methods.
# Sem-Aug: Improving Camera-LiDAR Feature Fusion with Semantic Augmentation for 3D Vehicle Detection
## Keywords:
- Computer Vision for Transportation
- Intelligent Transportation Systems
- Object Detection, Segmentation and Categorization
## Abstract:
Camera-LiDAR fusion provides precise distance measurements and fine-grained textures, making it a promising option for 3D vehicle detection in autonomous driving scenarios. Previous camera-LiDAR based 3D vehicle detection approaches mainly focused on employing image-based pre-trained models to fetch semantic features. However, these methods may perform inferior to the LiDAR-based ones when lacking semantic segmentation labels in autonomous driving tasks. Motivated by this observation, we propose a novel semantic augmentation method, namely Sem-Aug, to guide high-confidence camera-LiDAR fusion feature generation and boost the performance of multimodal 3D vehicle detection. The key novelty of semantic augmentation lies in the 2D segmentation mask auto-labeling, which provides supervision for semantic segmentation sub-network to mitigate the poor generalization performance of camera-LiDAR fusion. Using semantic-augmentation-guided camera-LiDAR fusion features, Sem-Aug achieves remarkable performance on the representative autonomous driving KITTI dataset compared to both the LiDAR-based baseline and previous multimodal 3D vehicle detectors. Qualitative and quantitative experiments demonstrate that Sem-Aug provides significant improvements in challenging Hard detection scenarios caused by occlusion and truncation.
# P2EG: Prediction and Planning Integrated Robust Decision-Making for Automated Vehicle Negotiating in Narrow Lane with Explorative Game
## Keywords:
- Autonomous Vehicle Navigation
- Planning under Uncertainty
- Motion and Path Planning
## Abstract:
In the narrow lane scene of autonomous driving, it is critical for the ego car to recognize the intentions of social vehicles and cooperate with them. However, cooperating with social vehicles is challenging due to insufficient information. This paper proposes an Explorative Game that adopts Participant Game and Perfect Bayesian Equilibrium to exploratively perform some aggressive actions to obtain additional information, thus the autonomous vehicle can cooperate robustly and efficiently. Explorative Game assumes each vehicle maintains a unique belief about the current situation and attributes insecurity and instability to the conflict of various Perfect Bayesian Equilibriums formed by various beliefs. Aggressive actions enable the ego car to proactively guide social vehicles to cooperate as it expects and encourage them to express their intentions as quickly and clearly as possible so that the equilibriums can converge and the conflict can be eliminated. Additional information reduces the error between the actual intentions of social vehicles and the estimated intentions from the ego car, helping rationally prune potential interactions and update parameters of the reward function. We demonstrate our algorithm on recorded data as well as virtual environments with manually controlled social vehicles to prove the efficiency of cooperation and the robustness of decision-making. And it has been running for more than 20 kilometers in the real world.
# Visual Mapping and Localization System Based on Compact Instance-Level Road Markings with Spatial Uncertainty
## Keywords:
- Autonomous Vehicle Navigation
- Mapping
- Localization
## Abstract:
High-definition (HD) map is crucial for intelligent vehicles to perform high-level localization and navigation. To improve the availability and usability of HD map, it is meaningful to investigate crowd-sourced mapping solutions and low-cost map-aided localization schemes which don't rely on high-end sensors. In this paper, we propose a novel vision-based mapping and localization system, which could generate compact instance-level road maps automatically and provide high-availability map-aided localization. The spatial uncertainties of the map elements are taken into consideration by analyzing the inverse perspective mapping (IPM) model, which enables more flexible map usages in both mapping and localization phases of the system. Besides, a pose graph optimization framework is developed for accurate pose estimation by fusing global positioning (GNSS), local navigation (odometry) and map matching information together. Real-world experiments in urban environment were conducted to validate different phases of the system, including on-vehicle mapping, multi-source map merging and map-aided localization.
# Motion Planning for HyTAQs: A Topology-Guided Unified NMPC Approach
## Keywords:
- Autonomous Vehicle Navigation
- Motion and Path Planning
- Optimization and Optimal Control
## Abstract:
In this study, a topology-guided unified nonlinear model predictive control (NMPC) approach is proposed for autonomous navigation of a class of Hybrid Terrestrial and Aerial Quadrotors (HyTAQs) in unknown environments. The approach can fully exploit the hybrid terrestrial-aerial locomotion of the vehicle and as such ensure a high navigation efficiency. A unified terrestrial-aerial NMPC is first formulated with a type of complementarity constraints involving the hybrid dynamics, together with the collision avoidance constraints for safety. Further, a topological roadmap with both terrestrial and aerial paths is leveraged to guide the kinodynamic path searching and thus the unified NMPC. Then, a complete and distinctive navigation framework is established and validated on our self-developed HyTAQ. Compared with the existing unified terrestrial-aerial planning methods, ours takes the vehicle dynamics into account for the first attempt and achieves a more reasonable decision of modes switching. Experimental results are presented to demonstrate the effectiveness and superiority of the proposed approach.
# SEAN 2.0: Formalizing and Generating Social Situations for Robot Navigation
## Keywords:
- Software Tools for Benchmarking and Reproducibility
- Social HRI
- Modeling and Simulating Humans
## Abstract:
We present SEAN 2.0, an open-source system designed to advance social navigation via the training and benchmarking of navigation policies in varied social contexts. A key limitation of current social navigation research is that policies are often trained and evaluated considering only a few social contexts, which are fragmented across prior work. Inspired by work in psychology, we describe navigation context based on social situations, which encompass the robot task and environmental factors, and propose logic-based classifiers for five common examples. SEAN 2.0 allows a robot to experience these social situations via different methods for specifying and generating pedestrian motion, including a novel Behavior Graph method. Our experiments show that when data collected using the Behavior Graph method is used to learn a robot navigation policy, that policy outperforms others trained using alternative methods for pedestrian control. Also, social situations were found to be useful for understanding performance across social contexts. Other components of SEAN 2.0 include vision and depth sensors, several physical environments, different means of specifying robot tasks, and a range of evaluation metrics for social robot navigation. User feedback for SEAN 2.0 indicated that the system was "easier to navigate and more user friendly" than our prior work, SEAN 1.0.
# SLAM 4
# Group-K Consistent Measurement Set Maximization for Robust Outlier Detection
## Keywords:
- SLAM
- Range Sensing
## Abstract:
 This paper presents a method for the robust selection of measurements in a simultaneous localization and mapping (SLAM) framework. Existing methods check consistency or compatibility on a pairwise basis, however many measurement types are not sufficiently constrained in a pairwise scenario to determine if either measurement is inconsistent with the other. This paper presents group-k consistency maximization (GkCM) that estimates the largest set of measurements that is internally group-k consistent. Solving for the largest set of group-k consistent measurements can be formulated as an instance of the maximum clique problem on generalized graphs and can be solved by adapting current methods. This paper evaluates the performance of GkCM using simulated data and compares it to pairwise consistency maximization (PCM) presented in previous work.
# Floorplan-Aware Camera Poses Refinement
## Keywords:
- SLAM
- Mapping
- Semantic Scene Understanding
## Abstract:
Processing large indoor scenes is a challenging task, as scan registration and camera trajectory estimation methods accumulate errors across time. As a result, the quality of reconstructed scans is insufficient for some applications, such as visual-based localization and navigation, where the correct position of walls is crucial.
For many indoor scenes, there exists an image of a technical floorplan that contains information about the geometry and main structural elements of the scene, such as walls, partitions, and doors. We argue that such a floorplan is a useful source of spatial information, which can guide a 3D model optimization.
The standard RGB-D 3D reconstruction pipeline consists of a tracking module applied to an RGB-D sequence and a bundle adjustment (BA) module that takes the posed RGB-D sequence and corrects the camera poses to improve consistency. We propose a novel optimization algorithm expanding conventional BA that leverages the prior knowledge about the scene structure in the form of a floorplan. Our experiments on the Redwood dataset and our self-captured data demonstrate that utilizing floorplan improves accuracy of 3D reconstructions.
# MOTSLAM: MOT-Assisted Monocular Dynamic SLAM Using Single-View Depth Estimation
## Keywords:
- SLAM
- Visual Tracking
- Deep Learning Methods
## Abstract:
Visual SLAM systems targeting static scenes have been developed with satisfactory accuracy and robustness. Dynamic 3D object tracking has then become a significant capability in visual SLAM with the requirement of understanding dynamic surroundings in various scenarios including autonomous driving, augmented and virtual reality. However, performing dynamic SLAM solely with monocular images remains a challenging problem due to the difficulty of associating dynamic features and estimating their positions. In this paper, we present MOTSLAM, a dynamic visual SLAM system with the monocular configuration that tracks both poses and bounding boxes of dynamic objects. MOTSLAM first performs multiple object tracking (MOT) with associated both 2D and 3D bounding box detection to create initial 3D objects. Then, neural-network-based monocular depth estimation is applied to fetch the depth of dynamic features. Finally, camera poses, object poses, and both static, as well as dynamic map points, are jointly optimized using a novel bundle adjustment. Our experiments on the KITTI dataset demonstrate that our system has reached best performance on both camera ego-motion and object tracking on monocular dynamic SLAM.
# Gravity-Constrained Point Cloud Registration
## Keywords:
- SLAM
- Sensor Fusion
- Range Sensing
## Abstract:
Visual and lidar Simultaneous Localization and Mapping (SLAM) algorithms benefit from the Inertial Measurement Unit (IMU) modality. The high-rate inertial data complement the other lower-rate modalities. Moreover, in the absence of constant acceleration, the gravity vector makes two attitude angles out of three observable in the global coordinate frame. In visual odometry, this is already being used to reduce the 6-Degrees Of Freedom (DOF) pose estimation problem to 4-DOF. In lidar SLAM, the gravity measurements are often used as a penalty in the back-end global map optimization to prevent map deformations. In this work, we propose an Iterative Closest Point (ICP)-based front-end which exploits the observable DOF and provides pose estimates aligned with the gravity vector. We believe that this front-end has the potential to support the loop closure identification, thus speeding up convergences of global map optimizations. The presented approach has been extensively tested against accurate ground-truth localization in large-scale outdoor environments as well as in the Subterranean Challenge organized by Defense Advanced Research Projects Agency (DARPA). We show that it can reduce the localization drift by 30% when compared to the standard 6-DOF ICP. Moreover, the code is readily available to the community as a part of the libpointmatcher library.
# When Geometry Is Not Enough: Using Reflector Markers in Lidar SLAM
## Keywords:
- SLAM
- Mapping
- Localization
## Abstract:
Lidar-based SLAM systems perform well in a wide range of circumstances by relying on the geometry of the environment. However, even mature and reliable approaches struggle when the environment contains structureless areas such as long hallways. To allow the use of lidar-based SLAM in such environments, we propose to add reflector markers in specific locations that would otherwise be difficult. We present an algorithm to reliably detect these markers and two approaches to fuse the detected markers with geometry-based scan matching. The performance of the proposed methods is demonstrated on real-world datasets from several industrial environments.
# LOCUS 2.0: Robust and Computationally Efficient LiDAR Odometry for Real-Time 3D Mapping
## Keywords:
- SLAM
- Sensor Fusion
- Data Sets for SLAM
## Abstract:
LiDAR odometry has attracted considerable attention as a robust localization method for autonomous robots operating in complex GNSS-denied environments. However, achieving reliable and efficient performance on heterogeneous platforms in large-scale environments remains an open challenge due to the limitations of onboard computation and memory resources needed for autonomous operation. In this work, we present LOCUS 2.0, a robust and computationally-efficient LiDAR odometry system for real-time underground 3D mapping. LOCUS 2.0 includes a novel normals-based GICP formulation that reduces the computation time of point cloud alignment, an adaptive voxelization strategy that maintains the desired computation load regardless of the environment’s geometry, and a sliding-window map approach that bounds the memory consumption and management. The proposed approach is shown to be suitable to be deployed on heterogeneous robotic platforms involved in large-scale explorations under severe computation and memory constraints. We demonstrate LOCUS 2.0, a key element of the CoSTAR team’s entry in the DARPA Subterranean Challenge, across various underground scenarios. 
We release LOCUS 2.0 as an open-source library and also release a LiDAR-based odometry dataset in challenging and largescale underground environments. The dataset features a legged and wheeled platform in multiple environments including fog, dust, darkness, and geometrically degenerate surroundings with a total of 11 h of operations and 16 km of distance traveled.
# The Hilti SLAM Challenge Dataset
## Keywords:
- SLAM
- Sensor Fusion
## Abstract:
Research in Simultaneous Localization and Mapping (SLAM) has made outstanding progress over the past years. SLAM systems are nowadays transitioning from academic to real world applications. However, this transition has posed new demanding challenges in terms of accuracy and robustness. To develop new SLAM systems that can address these challenges, new datasets containing cutting-edge hardware and realistic scenarios are required. We propose the Hilti SLAM Challenge Dataset. Our dataset contains indoor sequences of offices, labs, and construction environments and outdoor sequences of construction sites and parking areas. All these sequences are characterized by featureless areas and varying illumination conditions that are typical in real-world scenarios and pose great challenges to SLAM algorithms that have been developed in confined lab environments. Accurate sparse ground truth, at millimeter level, is provided for each sequence. The sensor platform used to record the data includes a number of visual, lidar, and inertial sensors, which are spatially and temporally calibrated. The purpose of this dataset is to foster the research in sensor fusion to develop SLAM algorithms that can be deployed in tasks where high accuracy and robustness are required, e.g., in construction environments. Many academic and industrial groups tested their SLAM systems on the proposed dataset in the Hilti SLAM Challenge. The results of the challenge, which are summarized in this paper, show that the proposed dataset is an important asset in the development of new SLAM algorithms that are ready to be deployed in the real-world.
# Photometric Single-View Dense 3D Reconstruction in Endoscopy
## Keywords:
- SLAM
- Computer Vision for Medical Robotics
## Abstract:
Visual SLAM inside the human body will open the way to computer-assisted navigation in endoscopy. However, due to space limitations, medical endoscopes only provide monocular images, leading to systems lacking true scale. In this paper we exploit the controlled lighting in colonoscopy to achieve the first in-vivo 3D reconstruction of the human colon using photometric stereo on a calibrated monocular endoscope. Our method works in a real medical environment, providing both a suitable in-place calibration procedure and a depth estimation technique adapted to the colon's tubular geometry. We validate our method on simulated colonoscopies, obtaining a mean error of 7% in depth estimation, which is below 3 mm on average. Our qualitative results on the EndoMapper dataset show that the method is able to correctly estimate the colon shape in real human colonoscopies, paving the ground for true-scale monocular SLAM in endoscopy.
# Continuous-Time Stereo-Inertial Odometry
## Keywords:
- SLAM
- Sensor Fusion
## Abstract:
The emerging paradigm of Continuous-Time Simultaneous Localization And Mapping (CTSLAM) has become a competitive alternative to conventional discrete-time approaches in recent times and holds the additional promise of fusing multi-modal sensor setups in a truly generic manner, rendering its importance to robotic navigation and manipulation seminal. In this spirit, this work expands upon continuous-time concepts, evaluates their suitability in common stereo and stereo-inertial online configurations, and provides an extensible, generic, robust, and modular open-source implementation to the community. The presented experimental analysis records the performance of our approach in these setups against the state-of-the-art in discrete-time Simultaneous Localization And Mapping (SLAM) on established datasets, achieving competitive results, and provides a direct comparison between online discrete# and continuous-time approaches for the first time. Targeting the absence of open-sourced, continuous-time pipelines and their associated, oftentimes prohibitive, initial developmental overhead, our implementation is made public.
# Virtual Reality and Interfaces
# Immersive View and Interface Design for Teleoperated Aerial Manipulation
## Keywords:
- Virtual Reality and Interfaces
- Telerobotics and Teleoperation
- Human-Centered Robotics
## Abstract:
The recent momentum in aerial manipulation has led to an interest in developing virtual reality interfaces for aerial physical interaction tasks with simple, intuitive, and reliable control and perception. However, this requires the use of expensive subsystems and there is still a research gap between interface design, user evaluations and the effect on aerial manipulation tasks. Here, we present a methodology for low-cost available drone systems with a Unity-based interface for immersive FPV teleoperation. We applied our approach in a flight track where a cluttered environment is used to simulate a demanding aerial manipulation task inspired by forestry drones and canopy sampling. Through objective measures of teleoperation performance and subjective questionnaires, we found that operators performed worse using the FPV interface and had higher perceived levels of cognitive load when compared to traditional interface design. Additional analysis of physiological measures highlighted that objective stress levels and cognitive load were also influenced by task duration and perceived performance, providing an insight into what interfaces could target to support teleoperator requirements during aerial manipulation tasks.
# WFH-VR: Teleoperating a Robot Arm to Set a Dining Table across the Globe Via Virtual Reality
## Keywords:
- Virtual Reality and Interfaces
- Telerobotics and Teleoperation
- Physical Human-Robot Interaction
## Abstract:
This paper presents an easy-to-deploy, virtual reality-based teleoperation system for controlling a robot arm. The proposed system is based on a consumer-grade virtual reality device (Oculus Quest 2) with a low-cost robot arm (a LoCoBot) to allow easy replication and set up. The proposed Work-from-Home Virtual Reality (WFH-VR) system allows the user to feel an intimate connection with the real remote robot arm. Virtual representations of the robot and objects to be manipulated in the real-world are presented in VR by streaming data pertaining to orientation and poses. The user studies suggest that 1) the proposed telerobotic system is effective under conditions both with and without network latency, whereas a method that simply streams video does not. This design enables the system implemented at an arbitrary distance from the actual work site. 2) The proposed system allows novices to perform manipulation tasks requiring higher dexterity than traditional keyboard controls can support, such as setting tableware. All results, hardware settings, and questionnaire feedback can be obtained at https://arg-nctu.github.io/projects/vr-robot-arm.html.
# A Deep Learning Technique As a Sensor Fusion for Enhancing the Position in a Virtual Reality Micro-Environment
## Keywords:
- Virtual Reality and Interfaces
- Sensor Fusion
- AI-Based Methods
## Abstract:
Most virtual reality (VR) applications use a commercial controller for interaction. However, a typical virtual reality controller (VRC) lacks positional precision and accuracy in millimeter-scale scenarios. This lack of precision and accuracy is caused by built-in sensors’ drift. Therefore, the tracking performance of a VRC needs to be enhanced for millimeter-scale scenarios. Herein, we introduce a novel way of enhancing the tracking performance of a commercial VRC in a millimeter-scale environment using a deep learning (DL) algorithm. Specifically, we use a long short-term memory (LSTM) model trained with data collected from a linear motor, an IMU sensor, and a VRC. We integrate the virtual environment developed in Unity software with the LSTM model running in Python. We designed three experimental conditions: the VRC, Kalman filter (KF), and LSTM modes. Furthermore, we evaluate tracking performances in the three conditions and two other experimental scenarios, namely stationary and dynamic. In the stationary experimental scenario, the system is left motionless for 10 s. By contrast, in the dynamic experimental scenarios, the linear stage moves the system by 12 mm along the X, Y, and Z axes. The experimental results indicate that the deep learning model outperforms the standard controller’s positional performance by 85.69 % and 92.14 % in static and dynamic situations, respectively.
# A Wearable Multi-Joint Wrist Contour Measuring Device for Hand Shape Recognition
## Keywords:
- Virtual Reality and Interfaces
- Sensor Fusion
## Abstract:
Recently, various types of hand shape recognition systems have been developed for human-machine interfaces. However, most wearable recognition systems cannot robustly handle the variations in attachment positions of the devices. Thus, we propose a hand shape recognition system using a wearable multi-joint wrist contour measuring device to realize robust and effective recognition of hand shape, regardless of attachment position variations. In particular, this device can measure the wrist contour and band flexion data to recognize hand shape. The wrist contour data are measured using photo-reflectors mounted inside the device, and the band flexion data are measured using photo-interrupters installed at the device joints. Additionally, the attachment position information is extracted from the wrist contour or band flexion data using dimensional compression or attachment position recognition to achieve robustness against the position variations. Subsequently, the extracted information is incorporated into the hand shape recognizer. The results of the recognition experiment demonstrate that the attachment position information extracted from the band flexion data using dimensional compression could effectively realize robust hand shape recognition, considering variations in the device attachment position.
# A Torque Controlled Approach for Virtual Remote Centre of Motion Implementation
## Keywords:
- Motion Control
- Medical Robots and Systems
## Abstract:
In this paper, we propose a novel torque controller for the implementation virtual remote center of motion. The controller allows the system to implement the required behavior and guarantees the satisfaction of the remote center of motion constraint. Exploiting the Udwadia-Kalaba equation for constrained dynamic systems, the controller is synthesized considering the dynamic effect the constraint produces on the manipulator, achieving more effective control with respect to kinematic strategies, and allowing the implementation of compliance behaviors. Simulations and experimental validation with a KUKA LWR 4+ with 7 degrees of freedom has been performed to check the performances of the proposed controller. Results show the effectiveness of the proposed controller with different control action, and the capability to interact with the environment by implementing compliant motion control.
# Semi-Automatic Infrared Calibration for Augmented Reality Systems in Surgery
## Keywords:
- Virtual Reality and Interfaces
- Human Performance Augmentation
- Computer Vision for Medical Robotics
## Abstract:
Augmented reality (AR) has the potential to improve the immersion and efficiency of computer-assisted orthopaedic surgery (CAOS) by allowing surgeons to maintain focus on the operating site rather than external displays in the operating theatre. Successful deployment of AR to CAOS requires a calibration that can accurately calculate the spatial relationship between real and holographic objects. Several studies attempt this calibration through manual alignment or with additional fiducial markers in the surgical scene. We propose a calibration system that offers a direct method for the calibration of AR head-mounted displays (HMDs) with CAOS systems, by using infrared-reflective marker-arrays widely used in CAOS. In our fast, user-agnostic setup, a HoloLens 2 detected the pose of marker arrays using infrared response and time-of-flight depth obtained through sensors onboard the HMD. Registration with a commercially available CAOS system was achieved when an IR marker-array was visible to both devices. Study tests found relative-tracking mean errors of 2.03 mm and 1.12 degrees when calculating the relative pose between two static marker-arrays at short ranges. When using the calibration result to provide in-situ holographic guidance for a simulated wire-insertion task, a pre-clinical test reported mean errors of 2.07 mm and 1.54 degrees when compared to a pre-planned trajectory.
# Detecting Touch and Grasp Gestures Using a Wrist-Worn Optical and Inertial Sensing Network
## Keywords:
- Virtual Reality and Interfaces
- Human Detection and Tracking
- Touch in HRI
## Abstract:
Freehand gesture based interaction promises to enable rich interaction in applications such as augmented reality (AR), virtual reality (VR), Human-Robot Interaction (HRI), and Robotic Prosthetic devices. However, current sensing approaches are limited; camera-based solutions are constrained by optical occlusion, and devices that interpret muscle activity are unreliable. This work presents a novel wrist-worn sensing device that combines near-infrared (NIR) sensing through 20 active LED-photodiode pairs and 6 DOF inertial measurement unit (IMU) sensing to enable high-accuracy detection of surface touch and grasp interactions for applications in AR and robotic prosthetic devices. Two convolutional neural networks are used to map device inputs to detect touch events, and subsequently classify them by gesture type and direction. We evaluate the accuracy and temporal precision of our system for event detection and classification. Results from an in-lab user study of 12 participants show an average of 97% touch detection accuracy and 98% grasp detection accuracy.
# Towards Reproducible Evaluations for Flying Drone Controllers in Virtual Environments
## Keywords:
- Virtual Reality and Interfaces
- Force and Tactile Sensing
- Design and Human Factors
## Abstract:
Research attention on natural user interfaces (NUIs) for drone flights are rising. Nevertheless, NUIs are highly diversified, and primarily evaluated by different physical environments leading to hard-to-compare performance between such solutions. We propose a virtual environment, namely VRFlightSim, enabling comparative evaluations with enriched drone flight details to address this issue. We first replicated a state-of-the-art (SOTA) interface and designed two tasks (crossing and pointing) in our virtual environment. Then, two user studies with 13 participants demonstrate the necessity of VRFlightSim and further highlight the potential of open-data interface designs.
# Learning with Yourself: A Tangible Twin Robot System to Promote STEM Education
## Keywords:
- Education Robotics
- Physical Human-Robot Interaction
- Design and Human Factors
## Abstract:
This paper presents a customized programmable robotic system, TanTwin (Tangible Twin), designed to promote STEM education for K-12 children. Firstly, TanTwin is implemented based on a wheel-robot with standard LEGO bricks. With several deep neural networks, a child can convert a captured portrait of himself/herself into standard LEGO bricks, therefore he/she can build a tangible twin robot of himself/herself automatically. Besides, to adapt to the customized appearance, the corresponding visual element and content of the robotic system were also changed by a rule-based adaption algorithm. To demonstrate the effectiveness of TanTwin and to investigate whether tangible twin robots could contribute to children’s learning, we conducted a controlled experimental study to compare learning with a TanTwin and with a standard robot system through measuring students’ cognitive learning outcomes. The pre-/post# knowledge test results indicated that learning with a tangible twin robot leads to significantly better learning outcomes. Given the results, we validate our system and customization technology can promote STEM education.
# Tendon Driven Mechanisms
# Kinematics-Inertial Fusion for Localization of a 4-Cable Underactuated Suspended Robot Considering Cable Sag
## Keywords:
- Tendon/Wire Mechanism
- Sensor Fusion
- Parallel Robots
## Abstract:
Suspended Cable-Driven Parallel Robots (SCDPR) have intriguing capabilities on large scales but still have open challenges in precisely estimating the end-effector pose. The cables exhibit a downward curved shape, also known as cable sag which needs to be accounted for in the pose estimation. The catenary equations can accurately describe this phenomenon but are only accurate in equilibrium conditions. Thus, pose estimation for large-scale SCDPR in dynamic motion is an open challenge. This work proposes a real-time pose estimation algorithm for dynamic trajectories of SCDPRs, which is accurate over large areas. We present a novel approach that considers cable sag to reduce the estimation error for large scales while also employing an Inertial Measurement Unit (IMU) to improve estimation accuracy for dynamic motion. Our approach reduces the RMSE to less than a third compared to standard methods not considering cable sag. Similarly, the inclusion of the IMU reduces the RMSE in dynamic situations by 40% compared to non-IMU aided approaches considering cable sag. Furthermore, we evaluate our Extended Kalman Filter (EKF) based algorithm on a real system with ground truth pose information.
# End-Point Stiffness and Joint Viscosity Control of Musculoskeletal Robotic Arm Using Muscle Redundancy
## Keywords:
- Tendon/Wire Mechanism
- Redundant Robots
- Compliance and Impedance Control
## Abstract:
This study focuses on replicating the musculoskeletal system of human arms for mimicking its movement. Muscle redundancy is critical for regulating the mechanical impedance of arms and legs. However, when implementing muscle redundancy on robots, making an ill-posed problem that cannot determine the muscle forces uniquely. In this paper, first, a method for controlling end-point stiffness in the muscle space for the joint and muscle redundant system is described. Next, the muscle model imitating the nonlinear viscosity characteristic of human muscles is introduced. Then, a method to control the joint viscosity by adjusting the internal forces of muscles adequately without affecting the stiffness control directly is proposed. Finally, numerical simulations are performed to investigate the effectiveness of the proposed method.
# Data-Driven Kinematic Control Scheme for Cable-Driven Parallel Robots Allowing Collisions
## Keywords:
- Tendon/Wire Mechanism
- Parallel Robots
## Abstract:
Cable-Driven Parallel Robots (CDPRs) have been proposed for a variety of applications such as material handling, rehabilitation, and instrumentation. However, the collision-free constraint of CDPRs limits the workspace of CDPRs and the feasible position of anchor points. To address the collision-free constraint of CDPRs, a data-driven kinematic control scheme is developed for CDPRs, enabling a CDPR to control its pose even if suffering collisions between a cable and the base or the end-effector. To deal with the collisions, the data-driven kinematic control scheme utilizes a motion model obtained based on data samples of the motion of the CDPR, rather than the Jacobian matrix of the CDPR, to map a control law in the task space to the time derivative of the length of cables in the joint space. To evaluate the effectiveness of the developed data-driven kinematic control scheme, experiments of controlling a suspended CDPR with two cables allowing collisions are conducted.
# Miniature, Lightweight, High-Force, Capstan Winch for Mobile Robots
## Keywords:
- Tendon/Wire Mechanism
- Mechanism Design
- Actuation and Joint Mechanisms
## Abstract:
Actuators that apply tension forces are widely applicable in robotics. In many applications of tensile actuators, a large stroke length, high force, and small, light device are important. For these requirements, the best current solution is a winch, which uses a rotating shaft to pull lightweight cable. However, most winches accumulate cable in a spool on their shaft which limits maximum stroke length and force at a miniature scale. An alternative is a capstan winch, in which the cable wraps around the shaft in a single-layered spiral before passing off the shaft. Although high-force and high# stroke versions exist, miniaturization has not been successfully demonstrated. We present the design, modeling, and characterization of a miniaturized capstan winch. The 16 g winch is capable of lifting 4.5 kg (280x body weight) a distance of 4.3 m (67x body length). We also demonstrate it actuating a jumping robot and pulling a remote-controlled car out of a ditch. Through its miniature design and high-force, high-stroke performance, our winch expands the potential capabilities of small-scale robots.
# RAMIEL: A Parallel-Wire Driven Monopedal Robot for High and Continuous Jumping
## Keywords:
- Tendon/Wire Mechanism
- Legged Robots
- Mechanism Design
## Abstract:
Legged robots with high locomotive performance have been extensively studied, and various leg structures have been proposed. Especially, a leg structure that can achieve both continuous and high jumps is advantageous for moving around in a three-dimensional environment. In this study, we propose a parallel wire-driven leg structure, which has one DoF of linear motion and two DoFs of rotation and is controlled by six wires, as a structure that can achieve both continuous jumping and high jumping. The proposed structure can simultaneously achieve high controllability on each DoF, long acceleration distance and high power required for jumping. In order to verify the jumping performance of the parallel wire-driven leg structure, we have developed a parallel wire-driven monopedal robot, RAMIEL. RAMIEL is equipped with quasi-direct drive, high power wire winding mechanisms and a lightweight leg, and can achieve a maximum jumping height of 1.6 m and a maximum of seven continuous jumps.
# Workspace-Based Model Predictive Control for Cable-Driven Robots (I)
## Keywords:
- Optimization and Optimal Control
- Motion Control
- Tendon/Wire Mechanism
## Abstract:
The control of cable-driven robots is challenging due to the system’s non-linearity, actuation redundancy and the unilaterally bounded actuation constraints. To solve this problem, a workspace-based model predictive control (W-MPC) scheme is proposed which combines the online model predictive control with offline workspace analysis. Using the workspace, a set of convex constraints can be generated for a given reference trajectory. This can then be used to formulate a convex optimization problem for the online W-MPC. Meanwhile strict recursive feasibility and stability are obtained by taking advantage of the predictive feature of MPC. To demonstrate the effectiveness of the proposed W-MPC, simulation was performed on a 2-link planar cabled-riven robot and a spatial cable-driven parallel robot for both nominal and non-nominal scenarios. Hardware experiment was also carried out using a 3 degree-of-freedom planar cable robot. The results show that the controller is efficient and effective to motion tracking with the cable force constraints satisfied despite the existence of various model uncertainties.
# Dexterity Analysis and Motion Optimization of In-Situ Torsionally-Steerable Flexible Surgical Robots
## Keywords:
- Tendon/Wire Mechanism
- Flexible Robotics
- Medical Robots and Systems
## Abstract:
Flexible robots with in-situ torsion can be used in laryngeal endoscopic surgery which can maintain the position and approach vector of the end-effector during the operation. However, the inherent errors would be produced by in-situ torsional motion which are different due to the various configuration of serpentine module in robot. In this paper, the kinematics model is established according to the structure of serpentine module. The dexterity analysis shows that the singular position is reduced and the angular velocity of dexterity is improved comparing with the robot without in-situ torsion function. The theoretical position errors caused by in-situ torsion is quantitatively analyzed by simulation. It is found that the maximum error is 5.19mm at the bending angle of 120°.In addition, the existence of joints in the robot arm also leads to the occurrence of rotation errors. The configuration and number of the joints are optimized to improve the accuracy. Finally, the experiments are carried out to verify the effectiveness of the proposed design and model. The results indicate that the flexible surgical robot have higher motion dexterity. And the inherent error during the in-situ torsion motion can be eliminated by structural optimization.
# Planning under Uncertainty
# Meta-Learning-Based Proactive Online Planning for UAVs under Degraded Conditions
## Keywords:
- Planning under Uncertainty
- Failure Detection and Recovery
- Aerial Systems: Applications
## Abstract:
Changes in model dynamics due to factors like actuator faults, platform aging, and unexpected disturbances can challenge an autonomous robot during real-world operations affecting its intended behavior and safety. Under such circumstances, it becomes critical to improve tracking performance, predict future states of the system, and replan to maintain safety and liveness conditions. In this letter, we propose a meta-learning-based framework to learn a model to predict the future system's states and their uncertainties under unforeseen and untrained conditions. Meta-learning is considered for this problem thanks to its ability to easily adapt to new tasks with a few data points gathered at runtime. We use the predictions from the meta-learned model to detect unsafe situations and proactively replan the system's trajectory when an unsafe situation is detected (e.g., a collision with an object). The proposed framework is applied and validated with both simulations and experiments on a faulty UAV performing an infrastructure inspection mission, demonstrating safety improvements.
# Path-Tree Optimization in Discrete Partially Observable Environments Using Rapidly-Exploring Belief-Space Graphs
## Keywords:
- Planning under Uncertainty
- Motion and Path Planning
- Mobile Manipulation
## Abstract:
Robots often need to solve path planning problems where essential and discrete aspects of the environment are partially observable. This introduces a multi-modality, where the robot must be able to observe and infer the state of its environment. To tackle this problem, we introduce the Path# Tree Optimization (PTO) algorithm which plans a path-tree in belief-space. A path-tree is a tree-like motion with branching points where the robot receives an observation leading to a belief-state update. The robot takes different branches depend# ing on the observation received. The algorithm has three main steps. First, a rapidly-exploring random graph (RRG) on the state space is grown. Second, the RRG is expanded to a belief# space graph by querying the observation model. In a third step, dynamic programming is performed on the belief-space graph to extract a path-tree. The resulting path-tree combines exploration with exploitation i.e. it balances the need for gaining knowledge about the environment with the need for reaching the goal. We demonstrate the algorithm capabilities on navigation and mobile manipulation tasks, and show its advantage over a baseline using a task and motion planning approach (TAMP) both in terms of optimality and runtime.
# Object-Aware SLAM Based on Efficient Quadric Initialization and Joint Data Association
## Keywords:
- SLAM
- Localization
- Mapping
## Abstract:
Semantic simultaneous localization and mapping (SLAM) is a popular technology enabling indoor mobile robots to sufficiently perceive and interact with the environment. In this paper, we propose an object-aware semantic SLAM system, which consists of a quadric initialization method, an object-level data association method, and a multi-constraint optimization factor graph. To overcome the limitation of multi-view observations and the requirement of dense point clouds for objects, an efficient quadric initialization method based on object detection and surfel construction is proposed, which can efficiently initialize quadrics within fewer frames and with small viewing angles. The robust object-level joint data association method and the tightly coupled multi-constraint factor graph for quadrics optimization and joint bundle adjustment enable the accurate estimation of constructed quadrics and camera poses. Extensive experiments using public datasets show that the proposed system achieves competitive performance with respect to accuracy and robustness of object quadric estimation and camera localization compared with stateof-the-art methods.
# Accelerated Reinforcement Learning for Temporal Logic Control Objectives
## Keywords:
- Planning under Uncertainty
- Reinforcement Learning
- Integrated Planning and Learning
## Abstract:
This paper addresses the problem of learning control policies for mobile robots, modeled as unknown Markov Decision Processes (MDPs), that are tasked with temporal logic missions, such as sequencing, coverage, or surveillance. The MDP captures uncertainty in the workspace structure and the outcomes of control decisions. The control objective is to synthesize a control policy that maximizes the probability of accomplishing a high-level task, specified as a Linear Temporal Logic (LTL) formula. To address this problem, we propose a novel accelerated model-based reinforcement learning (RL) algorithm for LTL control objectives that is capable of learning control policies significantly faster than related approaches. Its sample-efficiency relies on biasing exploration towards directions that may contribute to task satisfaction. This is accomplished by leveraging an automaton representation of the LTL task as well as a continuously learned MDP model. Finally, we provide comparative experiments that demonstrate the sample efficiency of the proposed method against recent RL methods for LTL objectives.
# Smooth Model Predictive Path Integral Control without Smoothing
## Keywords:
- Planning under Uncertainty
- Optimization and Optimal Control
- Model Learning for Control
## Abstract:
We present a sampling-based control approach that can generate smooth actions for general nonlinear systems without external smoothing algorithms. Model Predictive Path Integral (MPPI) control has been utilized in numerous robotic applications due to its appealing characteristics to solve non-convex optimization problems. However, the stochastic nature of sampling-based methods can cause significant chattering in the resulting commands. Chattering becomes more prominent in cases where the environment changes rapidly, possibly even causing the MPPI to diverge. To address this issue, we propose a method that seamlessly combines MPPI with an input-lifting strategy. In addition, we introduce a new action cost to smooth control sequence during trajectory rollouts while preserving the information theoretic interpretation of MPPI, which was derived from non-affine dynamics. We validate our method in two nonlinear control tasks with neural network dynamics: a pendulum swing-up task and a challenging autonomous driving task. The experimental results demonstrate that our method outperforms the MPPI baselines with additionally applied smoothing algorithms.
# Monte-Carlo Robot Path Planning
## Keywords:
- Planning under Uncertainty
- Motion and Path Planning
- Planning, Scheduling and Coordination
## Abstract:
Path planning is a crucial algorithmic approach for designing robot behaviors. Sampling-based approaches, like rapidly exploring random trees (RRTs) or probabilistic roadmaps, are prominent algorithmic solutions for path planning problems. Despite its exponential convergence rate, RRT can only find suboptimal paths. On the other hand, RRT*, a widely-used extension to RRT, guarantees probabilistic completeness for finding optimal paths but suffers in practice from slow convergence in complex environments. Furthermore, real-world robotic environments are often partially observable or with poorly described dynamics, casting the application of RRT* in complex tasks suboptimal. This paper studies a novel algorithmic formulation of the popular Monte-Carlo tree search (MCTS) algorithm for robot path planning. Notably, we study Monte-Carlo Path Planning (MCPP) by analyzing and proving, on the one part, its exponential convergence rate to the optimal path in fully observable Markov decision processes (MDPs), and on the other part, its probabilistic completeness for finding feasible paths in partially observable MDPs (POMDP) assuming limited distance observability (proof sketch). Our algorithmic contribution allows us to employ recently proposed variants of MCTS with different exploration strategies for robot path planning. Experimental evaluation in simulated 2D and 3D environments with a 7 degrees of freedom (DOF) manipulator, as well as in a real-world robot path planning task, demonstrate the superiority of MCPP in POMDP tasks.
# Qualitative Belief Space Planning Via Compositions
## Keywords:
- Planning under Uncertainty
## Abstract:
Planning under uncertainty is a fundamental problem in robotics. Classical approaches rely on a metrical representation of the world and robot's states to infer the next course of action. While these approaches are considered accurate, they are often susceptible to metric errors and tend to be costly regarding memory and time consumption. However, in some cases, relying on qualitative geometric information alone is sufficient. Hence, the issues described above become an unnecessary burden. This work presents a novel qualitative Belief Space Planning (BSP) approach, highly suitable for platforms with low-cost sensors and particularly appealing in sparse environment scenarios. Our algorithm generalizes its predecessors by avoiding any deterministic assumptions. Moreover, it smoothly incorporates spatial information propagation techniques, known as compositions. We demonstrate our algorithm in simulations and the advantage of using compositions in particular.
# Task and Motion Informed Trees (TMIT*): Almost-Surely Asymptotically Optimal Integrated Task and Motion Planning
## Keywords:
- Task and Motion Planning
- Motion and Path Planning
- Manipulation Planning
## Abstract:
High-level autonomy requires discrete and continuous reasoning to decide both what actions to take and how to execute them. Integrated Task and Motion Planning (TMP) algorithms solve these hybrid problems jointly to consider constraints between the discrete symbolic actions (i.e., the task plan) and their continuous geometric realization (i.e., motion plans). This joint approach solves more difficult problems than approaches that address the task and motion subproblems independently.
TMP algorithms combine and extend results from both task and motion planning. TMP has mainly focused on computational performance and completeness and less on solution optimality. Optimal TMP is difficult because the independent optima of the subproblems may not be the optimal integrated solution, which can only be found by jointly optimizing both plans.
This paper presents Task and Motion Informed Trees (TMIT*), an optimal TMP algorithm that combines results from makespan-optimal task planning and almost-surely asymptotically optimal motion planning. TMIT* interleaves asymmetric forward and reverse searches to delay computationally expensive operations until necessary and perform an efficient informed search directly in the problem’s hybrid state space. This allows it to solve problems quickly and then converge towards the optimal solution with additional computational time, as demonstrated on the evaluated robotic-manipulation benchmark problems.
# Generalizable Task Planning through Representation Pretraining
## Keywords:
- Integrated Planning and Learning
- Task and Motion Planning
- Representation Learning
## Abstract:
The ability to plan for multi-step manipulation tasks in unseen situations is crucial for future home robots. But collecting sufficient experience data for end-to-end learning is often infeasible in the real world, as deploying robots in many environments can be prohibitively expensive. On the other hand, large-scale scene understanding datasets contain diverse and rich semantic and geometric information. But how to leverage such information for manipulation remains an open problem. In this paper, we propose a learning-to-plan method that can generalize to new object instances by leveraging object-level representations extracted from a synthetic scene understanding dataset. We evaluate our method with a suite of challenging multi-step manipulation tasks inspired by household activities and show that our model achieves measurably better success rate than state-of-the-art end-to-end approaches.
# Robot Safety
# An Analytical Study of Motion of Autonomous Vehicles under Imperfect Sensing
## Keywords:
- Robot Safety
- Autonomous Vehicle Navigation
- Sensor-based Control
## Abstract:
A fully tested autonomous system works predictably under ideal or assumed environment. However, its behavior is not fully defined when some components malfunction or fail. In this paper, we consider automated guided vehicle (AGV), equipped with multiple sensors, executing a traversal task in a static unknown environment. We have analytically studied the system, computed a set of performance and safety metrics, and validated it with simulation results in Webots. We have also analyzed the effect on system performance under independent and correlated sensing errors. We have also performed sensitivity analysis to identify the most critical components in any given system; and this can be utilized to increase the reliability of the system and its conformance to safety objectives.
# Adhesion Risk Assessment of an Aircraft Inspection Robot for Improving Operator Awareness
## Keywords:
- Robot Safety
- Human-Robot Collaboration
- Service Robotics
## Abstract:
Vacuum-adhesion-based climbing robots have been developed to cater to the demands in the cleaning and inspection work of airplanes. A robot intended to clean and inspect an airplane faces a Risk of Adhesion (RoA) based on the robot and the surface conditions, such as worn-out suction cups. These sorts of underlying conditions are not easily noticeable for an operator of a robot and might lead to catastrophic events. Therefore, the ability of a robot to self-assess the RoA in a scenario and notify the operator is crucial for ensuring safety. Particularly, an aircraft inspection robot should have adhesion awareness. This paper proposes a novel method to self-assess the RoA of a vacuum-adhesion-based robot intended to clean and inspect airplanes. The RoA is assessed by a fuzzy inference system that analyzes the present pressure difference and the current duty setting of the vacuum pump of a robot. The robot operator can collaborate with the robot to take precautions based on the assessed RoA to ensure safety. The outcomes of the experiment conducted on an airplane skin validate the ability of the proposed method to assess the RoA associated with heterogeneous operating conditions effectively. Thus, the utilization of the proposed method would improve the safety of a vacuum-adhesion-based robot intended to clean and inspect airplanes.
# How Do We Fail? Stress Testing Perception in Autonomous Vehicles
## Keywords:
- Robot Safety
- Intelligent Transportation Systems
## Abstract:
Autonomous vehicles (AVs) rely on environment perception and behavior prediction to reason about agents in their surroundings. These perception systems must be robust to adverse weather such as rain, fog, and snow. However, validation of these systems is challenging due to their complexity and dependence on observation histories. This paper presents a method for characterizing failures of LiDAR-based perception systems for AVs in adverse weather conditions. We develop a methodology based in reinforcement learning to find likely failures in object tracking and trajectory prediction due to sequences of disturbances. We apply disturbances using a physics-based data augmentation technique for simulating LiDAR point clouds in adverse weather conditions. Experiments performed across a wide range of driving scenarios from a real-world driving dataset show that our proposed approach finds high likelihood failures with smaller input disturbances compared to baselines while remaining computationally tractable. Identified failures can inform future development of robust perception systems for AVs.
# HiddenGems: Efficient Safety Boundary Detection with Active Learning
## Keywords:
- Robot Safety
- Methods and Tools for Robot System Design
- Intelligent Transportation Systems
## Abstract:
Evaluating safety performance in a resource-efficient way is crucial for the development of autonomous systems. Simulation of parameterized scenarios is a popular testing strategy but parameter sweeps can be prohibitively expensive. To address this, we propose HiddenGems: a sample-efficient method for discovering the boundary between compliant and non-compliant behavior via active learning. Given a parameterized scenario, one or more compliance metrics, and a simulation oracle, HiddenGems maps the compliant and non-compliant domains of the scenario. The methodology enables critical test case identification, comparative analysis of different versions of the system under test, as well as verification of design objectives. We evaluate HiddenGems on a scenario with a jaywalker crossing in front of an autonomous vehicle and obtain compliance boundary estimates for collision, lane keep, and acceleration metrics individually and in combination, with 6 times fewer simulations than a parameter sweep. We also show how HiddenGems can be used to detect and rectify a failure mode for an unprotected turn with 86% fewer simulations.
# Enpheeph: A Fault Injection Framework for Spiking and Compressed Deep Neural Networks
## Keywords:
- Robot Safety
- Object Detection, Segmentation and Categorization
- Deep Learning Methods
## Abstract:
Research on Deep Neural Networks (DNNs) has focused on improving performance and accuracy for real-world deployments, leading to new models, such as Spiking Neural Networks (SNNs), and optimization techniques, e.g., quantization and pruning for compressed networks. However, the deployment of these innovative models and optimization techniques introduces possible reliability issues, which is a pillar for DNNs to be widely used in safety-critical applications, e.g., autonomous driving. Moreover, scaling technology nodes have the associated risk of multiple faults happening at the same time, a possibility not addressed in state-of-the-art resiliency analyses.
Towards better reliability analysis for DNNs, we present enpheeph, a Fault Injection Framework for Spiking and Compressed DNNs. The enpheeph framework enables optimized execution on specialized hardware devices, e.g., GPUs, while providing complete customizability to investigate different fault models, emulating various reliability constraints and use-cases. Hence, the faults can be executed on SNNs as well as compressed networks with minimal-to-none modifications to the underlying code, a feat that is not achievable by other state-of-the-art tools.
To evaluate our enpheeph framework, we analyze the resiliency of different DNN and SNN models, with different compression techniques. By injecting a random and increasing number of faults, we show that DNNs can show a reduction in accuracy with a fault rate as low as 7 x 10 ^ (-7) faults per parameter, with an accuracy drop higher than 40%. Run-time overhead when executing enpheeph is less than 20% of the baseline execution time when executing 100 000 faults concurrently, at least 10x lower than state-of-the-art frameworks, making enpheeph future-proof for complex fault injection scenarios.
We release the source code of our enpheeph framework under an open-source license at https://github.com/Alexei95/enpheeph.
# Continuous Safety Control of a Mobile Robot in Cluttered Environments
## Keywords:
- Robot Safety
- Optimization and Optimal Control
## Abstract:
This paper studies the safety control problem for mobile robots working in cluttered environments. A compact set is employed to represent the obstacles, and a direction-distance function is used to describe the obstacle-measurement model. The major contribution is a nontrivial modification of the quadratic programming (QP) approach for continuous safety control of integrator-modeled mobile robots. In particular, a refinement of the Moreau-Yosida method is proposed to regularize the measurement model while retaining feasibility and safety. The second contribution is the development of a new feasible set shaping technique with a positive basis for a QP-based continuous safety controller. Physical experiments are employed to verify the proposed method.
# Dependability Analysis of Deep Reinforcement Learning Based Robotics and Autonomous Systems through Probabilistic Model Checking
## Keywords:
- Robot Safety
- Probability and Statistical Methods
- Reinforcement Learning
## Abstract:
While Deep Reinforcement Learning (DRL) provides transformational capabilities to the control of Robotics and Autonomous Systems (RAS), the black-box nature of DRL and uncertain deployment environments of RAS pose new challenges on its dependability. Although existing works impose constraints on the DRL policy to ensure successful completion of the mission, it is far from adequate to assess the DRL-driven RAS in a holistic way considering all dependability properties. In this paper, we formally define a set of dependability properties in temporal logic and construct a Discrete-Time Markov Chain (DTMC) to model the dynamics of risk/failures of a DRL-driven RAS interacting with the stochastic environment. We then conduct Probabilistic Model Checking (PMC) on the designed DTMC to verify those properties. Our experimental results show that the proposed method is effective as a holistic assessment framework while uncovering conflicts between the properties that may need trade-offs in training. Moreover, we find that the standard DRL training cannot improve dependability properties, thus requiring bespoke optimisation objectives. Finally, our method offers sensitivity analysis of dependability properties to disturbance levels from environments, providing insights for the assurance of real RAS.
# On Safety Testing, Validation, and Characterization with Scenario-Sampling: A Case Study of Legged Robots
## Keywords:
- Robot Safety
- Performance Evaluation and Benchmarking
- Legged Robots
## Abstract:
The dynamic response of the legged robot locomotion is non-Lipschitz and can be stochastic due to environmental uncertainties. To test, validate, and characterize the safety performance of legged robots, existing solutions on observed and inferred risk can be incomplete and sampling inefficient. Some formal verification methods suffer from the model precision and other surrogate assumptions. In this paper, we propose a scenario sampling based testing framework that characterizes the overall safety performance of a legged robot by specifying (i) where (in terms of a set of states) the robot is potentially safe, and (ii) how safe the robot is within the specified set. The framework can also help certify the commercial deployment of the legged robot in real-world environment along with human and compare safety performance among legged robots with different mechanical structures and dynamic properties. The proposed framework is further deployed to evaluate a group of state-of-the-art legged robot locomotion controllers from various model-based, deep neural network involved, and reinforcement learning based methods in the literature. Among a series of intended work domains of the studied legged robots (e.g. tracking speed on sloped surface, with abrupt changes on demanded velocity, and against adversarial push-over disturbances), we show that the method can adequately capture the overall safety characterization and the subtle performance insights. Many of the observed safety outcomes, to the best of our knowledge, have never been reported by the existing work in the legged robot literature.
# Semi-Perspective Decoupled Heatmaps for 3D Robot Pose Estimation from Depth Maps
## Keywords:
- Gesture, Posture and Facial Expressions
- Computer Vision for Automation
- RGB-D Perception
## Abstract:
Knowing the exact 3D location of workers and robots in a collaborative environment enables several real applications, such as the detection of unsafe situations or the study of mutual interactions for statistical and social purposes. In this paper, we propose a non-invasive and light-invariant framework based on depth devices and deep neural networks to estimate the 3D pose of robots from an external camera. The method can be applied to any robot without requiring hardware access to the internal states. We introduce a novel representation of the predicted pose, namely Semi-Perspective Decoupled Heatmaps (SPDH), to accurately compute 3D joint locations in world coordinates adapting efficient deep networks designed for the 2D Human Pose Estimation. The proposed approach, which takes as input a depth representation based on XYZ coordinates, can be trained on synthetic depth data and applied to real-world settings without the need for domain adaptation techniques. To this end, we present the SimBa dataset, based on both synthetic and real depth images, and use it for the experimental evaluation. Results show that the proposed approach, made of a specific depth map representation and the SPDH, overcomes the current state of the art.
# Human and Humanoid Motion Analysis and Synthesis
# Understanding Spatio-Temporal Relations in Human-Object Interaction Using Pyramid Graph Convolutional Network
## Keywords:
- Human and Humanoid Motion Analysis and Synthesis
- Human Detection and Tracking
- Learning from Demonstration
## Abstract:
Human activities recognition is an important task for an intelligent robot, especially in the field of human-robot collaboration, it requires not only the label of sub-activities but also the temporal structure of the activity. In order to automatically recognize both the label and the temporal structure in sequence of human-object interaction, we propose a novel Pyramid Graph Convolutional Network (PGCN), which employs a pyramidal encoder-decoder architecture consisting of an attention based graph convolution network and a temporal pyramid pooling module for downsampling and upsampling interaction sequence on the temporal axis, respectively. The system represents the 2D or 3D spatial relation of human and objects from the detection results in video data as a graph. To learn the human-object relations, a new attention graph convolutional network is trained to extract condensed information from the graph representation. To segment action into sub-actions, a novel temporal pyramid pooling module is proposed, which upsamples compressed features back to the original time scale and classifies actions per frame. 		 We explore various attention layers, namely spatial attention, temporal attention and channel attention, and combine different upsampling decoders to test the performance on action recognition and segmentation. We evaluate our model on two challenging datasets in the field of human-object interaction recognition, i.e. Bimanual Actions and IKEA Assembly datasets. We demonstrate that our classifier significantly improves both framewise action recognition and segmentation, e.g., F1 micro and F1@50 scores on Bimanual Actions dataset are improved by 4.3% and 8.5% respectively.
# Gastrocnemius and Power Amplifier Soleus Spring-Tendons Achieve Fast Human-Like Walking in a Bipedal Robot
## Keywords:
- Humanoid and Bipedal Locomotion
- Humanoid Robot Systems
- Legged Robots
## Abstract:
Legged locomotion in humans is governed by natural dynamics of the human body and neural control. One mechanism that is assumed to contribute to the high efficiency of human walking is the impulsive ankle push-off, which potentially powers the swing leg catapult. However, the mechanics of the human lower leg with its complex muscle-tendon units spanning over single and multiple joints is not yet understood. Legged robots allow testing the interaction between complex leg mechanics, control, and environment in real-world walking gait. We developed a 0.49 m tall, 2.2 kg anthropomorphic bipedal robot with Soleus and Gastrocnemius muscle-tendon units represented by linear springs, acting as mono# and biarticular elastic structures around the robot's ankle and knee joints. We tested the influence of three Soleus and Gastrocnemius spring-tendon configurations on the ankle power curves, the coordination of the ankle and knee joint movements, the total cost of transport, and walking speed. We controlled the robot with a feed-forward central pattern generator, leading to walking speeds between 0.35 m/s and 0.57 m/s at 1.0 Hz locomotion frequency, at 0.35 m leg length. We found differences between all three configurations; the Soleus spring-tendon modulates the robot's speed and energy efficiency likely by ankle power amplification, while the Gastrocnemius spring-tendon changes the movement coordination between ankle and knee joints during push-off.
# A Riemannian Take on Human Motion Analysis and Retargeting
## Keywords:
- Human and Humanoid Motion Analysis and Synthesis
- Dynamics
## Abstract:
Dynamic motions of humans and robots are widely driven by posture-dependent nonlinear interactions between their degrees of freedom. However, these dynamical effects remain mostly overlooked when studying the mechanisms of human movement generation. Inspired by recent works, we hypothesize that human motions are planned as sequences of geodesic synergies, and thus correspond to coordinated joint movements achieved with piecewise minimum energy. The underlying computational model is built on Riemannian geometry to account for the inertial characteristics of the body. Through the analysis of various human arm motions, we find that our model segments motions into geodesic synergies, and successfully predicts observed arm postures, hand trajectories, as well as their respective velocity profiles. Moreover, we show that our analysis can further be exploited to transfer arm motions to robots by reproducing individual human synergies as geodesic paths in the robot configuration space.
# Human-To-Robot Manipulability Domain Adaptation with Parallel Transport and Manifold-Aware ICP
## Keywords:
- Human and Humanoid Motion Analysis and Synthesis
- Learning from Demonstration
- Human-Robot Collaboration
## Abstract:
Manipulability ellipsoids efficiently capture the human pose and reveal information about the task at hand. Their use in task-dependent robot teaching – particularly their transfer from a teacher to a learner – can advance emulation of human-like motion. Although in recent literature focus is shifted towards manipulability transfer between two robots, the adaptation to the capabilities of the other kinematic system is to date not addressed and research in transfer from human to robot is still in its infancy. This work presents a novel manipulability domain adaptation method for the transfer of manipulability information to the domain of another kinematic system. As manipulability matrices/ellipsoids are symmetric positive-definite (SPD) they can be viewed as points on the Riemannian manifold of SPD matrices. We are the first to address the problem of manipulability transfer from the perspective of point cloud registration. We propose a manifold-aware Iterative Closest Point algorithm (ICP) with parallel transport initialization. Furthermore, we introduce a correspondence matching heuristic for manipulability ellipsoids based on inherent geometric features. We confirm our method in simulation experiments with 2-DoF manipulators as well as 7-DoF models representing the human-arm kinematics.
# From Human Walking to Bipedal Robot Locomotion: Reflex Inspired Compensation on Planned and Unplanned Downsteps
## Keywords:
- Humanoid and Bipedal Locomotion
- Biomimetics
- Legged Robots
## Abstract:
Humans are able to negotiate downstep behaviors---both planned and unplanned---with remarkable agility and ease. The goal of this paper is to systematically study the translation of this human behavior to bipedal walking robots, even if the morphology is inherently different. Concretely, we begin with human data wherein planned and unplanned downsteps are taken. We analyze this data from the perspective of reduced-order modelling of the human, encoding the center of mass (CoM) kinematics and contact forces, which allows for the translation of these behaviors into the corresponding reduced-order model of a bipedal robot. We embed the resulting behaviors into the full-order dynamics of a bipedal robot via nonlinear optimization-based controllers. The end result is the demonstration of planned and unplanned downsteps in simulation on an underactuated walking robot.
# End-To-End from Human Hand Synergies to Robot Hand Tendon Routing
## Keywords:
- Grasping
- Multifingered Hands
- Deep Learning in Grasping and Manipulation
## Abstract:
The human hand capabilities are paramount for highly dexterous manipulation interactions. Unfortunately, the limitations of current technologies make replicating such capabilities unfeasible. Although several works have focused on directly attempting to create robot hands able to mimic human ones closely, few of them have attempted to create generalizable platforms, where robotic hand mechanisms can be iteratively selected and customized to different tasks. In order to build highly dexterous robotic hands in the future, it is crucial to understand not only human manipulation, but also develop methods to leverage robotic mechanisms limitations to mimic human hand interactions accurately. In this letter, we propose an end-to-end framework capable of generating underactuated tendon routings that allow a generic robot hand model to reproduce desired observed human grasp motion synergies accurately. Our contributions are threefold: (1) an end to end framework to generate task-oriented robot hand tendon routings, with the potential to implement desired synergies, (2) a novel grammar based representation of robot hand tendon routings, and (3) a schematic visualization of robot hand tendon routings. The latter two contributions have the potential to embed and compare properties among robot hands. Our results in simulation show that the proposed method produces tendon routing mechanisms that are able to closely mimic the joint trajectories of human subjects performing the same experimental tasks, while achieving dynamically stable grasping postures.
# A Centaur System for Assisting Human Walking with Load Carriage
## Keywords:
- Human Performance Augmentation
- Physically Assistive Devices
- Human-Robot Collaboration
## Abstract:
Walking with load is a common task in daily life and disaster rescue. Long-term load carriage may cause irreversible damage to the human body. Although remarkable progress has been made in the field of wearable robots, it is still far from avoiding interference to human legs, which will lead to energy consumption. In this paper, a novel wearable robot, Centaur, for assisting load carriage has been proposed. The Centaur system consists of two rigid robotic legs of two degrees-of-freedom (DOFs) to transfer load weight to the ground. Different from exoskeletons, the robotic legs of the Centaur are placed behind the human rather than attached to human limbs, which can provide a larger support polygon and avoid additional interference to the wearer. Additionally, the Centaur can attain the locomotion stability of the quadruped while maintaining the motion agility of the biped itself. This paper also presents an interactive motion control strategy based on the human-robot interaction force. This control strategy incorporates legged robotics walking controller and real-time walking trajectory planning to realize the cooperative walking with human beings. Finally, experiments of human walking with load carriage have been conducted on flat terrain to verify the concept of the Centaur system. The result demonstrates that the Centaur system can effectively reduce 70.03% of load weight during the single stance phase, which indicates that the Centaur system provides a new solution for assisting human walking with load-carriage.
# Construction of a Simulator to Reproduce the Changes of Running by Motion Strategy with Spring-Loaded Inverted Pendulum Model
## Keywords:
- Human Performance Augmentation
- Modeling and Simulating Humans
- Optimization and Optimal Control
## Abstract:
This study aims to construct a running simulator based on a motion generation and control system that enables the description of motion strategies using the spring-loaded inverted pendulum (SLIP) model. The problems of stability and robustness encountered in the running simulation with the SLIP model are elucidated, and stable running is achieved by controlling the stiffness and the attitude angle dynamically at touchdown, as well as human energy adjustment that is introduced to consider the active motion strategy. As a result, passive and active control by humans can be expressed, and a framework that can express the changes in running due to motion strategies is constructed. Finally, we discuss the possibility of describing and elucidating the motion strategies.
# Koopman Pose Predictions for Temporally Consistent Human Walking Estimations
## Keywords:
- Human Detection and Tracking
- Sensor Fusion
- RGB-D Perception
## Abstract:
We tackle the problem of tracking the human lower body as an initial step toward an automatic motion assessment system for clinical mobility evaluation, using a multimodal system that combines Inertial Measurement Unit (IMU) data, RGB images, and point cloud depth measurements. This system applies the factor graph representation to an optimization problem that provides 3-D skeleton joint estimations. In this paper, we focus on improving the temporal consistency of the estimated human trajectories to greatly extend the range of operability of the depth sensor. More specifically, we introduce a new factor graph factor based on Koopman theory that embeds the nonlinear dynamics of several lower-limb movement activities. This factor performs a two-step process: first, a custom activity recognition module based on spatial temporal graph convolutional networks recognizes the walking activity; then, a Koopman pose prediction of the subsequent skeleton is used as an a priori estimation to drive the optimization problem toward more consistent results. We tested the performance of this module on datasets composed of multiple clinical lower-limb mobility tests, and we show that our approach reduces outliers on the skeleton form by almost 1 m, while preserving natural walking trajectories at depths up to more than 10 m.
# Vision
# LapSeg3D: Weakly Supervised Semantic Segmentation of Point Clouds Representing Laparoscopic Scenes
## Keywords:
- Computer Vision for Medical Robotics
- Surgical Robotics: Laparoscopy
- RGB-D Perception
## Abstract:
The semantic segmentation of surgical scenes is a prerequisite for task automation in robot assisted interventions. We propose LapSeg3D, a novel DNN-based approach for the voxel-wise annotation of point clouds representing surgical scenes. As the manual annotation of training data is highly time consuming, we introduce a semi-autonomous clustering-based pipeline for the annotation of the gallbladder, which is used to generate segmented labels for the DNN. When evaluated against manually annotated data, LapSeg3D achieves an F1 score of 0.94 for gallbladder segmentation on various datasets of ex-vivo porcine livers. We show LapSeg3D to generalize accurately across different gallbladders and datasets recorded with different RGB-D camera systems.
# Ego+X: An Egocentric Vision System for Global 3D Human Pose Estimation and Social Interaction Characterization
## Keywords:
- Computer Vision for Medical Robotics
- Social HRI
- Human-Centered Robotics
## Abstract:
Egocentric vision is an emerging topic, which has demonstrated great potential in assistive healthcare scenarios, ranging from human-centric behavior analysis to personal social assistance. Within this field, due to the heterogeneity of visual perception from first-person views, egocentric pose estimation is one of the most significant prerequisites for enabling various downstream applications. However, existing methods for egocentric pose estimation mainly focus on predicting the pose represented in the camera coordinates from a single image, which ignores the latent cues in the temporal domain and results in less accuracy. In this paper, we propose Ego+X, an egocentric vision based system for 3D canonical pose estimation and human-centric social interaction characterization. Our system is composed of two head-mounted egocentric cameras, where one is faced downwards and the other looks outwards. By leveraging the global context provided by visual SLAM, we first propose Ego-Glo for spatial-accurate and temporal-consistent egocentric 3D pose estimation in the canonical coordinate system. With the help of an egocentric camera looking outwards, we then propose Ego-Soc by extending Ego-Glo to various social interaction tasks, e.g., object detection and human-human interaction. Quantitative and qualitative experiments have been conducted to demonstrate the effectiveness of our proposed Ego+X.
# Tracking Monocular Camera Pose and Deformation for SLAM Inside the Human Body
## Keywords:
- Computer Vision for Medical Robotics
- Localization
## Abstract:
Monocular SLAM in deformable scenes will open the way to multiple medical applications like computer# assisted navigation in endoscopy, automatic drug delivery or autonomous robotic surgery. In this paper we propose a novel method to simultaneously track the camera pose and the 3D scene deformation, without any assumption about environment topology or shape. The method uses an illumination-invariant photometric method to track image features and estimates camera motion and deformation combining reprojection error with spatial and temporal regularization of deformations. Our results in simulated colonoscopies show the method’s accuracy and robustness in complex scenes under increasing levels of deformation. Our qualitative results in human colonoscopies from Endomapper dataset show that the method is able to successfully cope with the challenges of real endoscopies: deformations, low texture and strong illumination changes. We also compare with previous tracking methods in simpler scenarios from Hamlyn dataset where we obtain competitive performance, without needing any topological assumption.
# Markerless Suture Needle 6D Pose Tracking with Robust Uncertainty Estimation for Autonomous Minimally Invasive Robotic Surgery
## Keywords:
- Computer Vision for Medical Robotics
- Visual Tracking
- Medical Robots and Systems
## Abstract:
Suture needle localization is necessary for autonomous suturing. Previous approaches in autonomous suturing often relied on fiducial markers rather than markerless detection schemes for localizing a suture needle due to the inconsistency of markerless detections. However, fiducial markers are not practical for real-world applications and can often be occluded from environmental factors in surgery (e.g., blood). Therefore in this work, we present a robust tracking approach for estimating the 6D pose of a suture needle when using inconsistent detections. We define observation models based on suture needles' geometry that captures the uncertainty of the detections and fuse them temporally in a probabilistic fashion. In our experiments, we compare different permutations of the observation models in the suture needle localization task to show their effectiveness. Our proposed method outperforms previous approaches in localizing a suture needle. We also demonstrate the proposed tracking method in an autonomous suture needle regrasping task and ex vivo environments.
# Monocular Depth Estimation for Equirectangular Videos
## Keywords:
- Omnidirectional Vision
- RGB-D Perception
## Abstract:
Depth estimation from panoramic imagery has received minimal attention in contrast to standard perspective imagery, which constitutes the majority of the literature on the key research topic. The vast # and frequently complete # field of view provided by such panoramic photographs makes them appealing for a variety of applications, including robots, autonomous vehicles, and virtual reality. Consumer-level camera systems capable of capturing such images are likewise growing more affordable, and may be desirable complements to autonomous systems' sensor packages. They do, however, introduce significant distortions and violate some assumptions regarding perspective view images. Additionally, many state-of-the-art algorithms are not designed for its projection model, and their depth estimation performance tends to degrade when being applied to panoramic imagery.
This paper presents a novel technique for adapting view synthesis-based depth estimation models to omnidirectional vision. Specifically, we: 1) integrate a ``virtual'' spherical camera model into the training pipeline, facilitating the model training, 2) exploit spherical convolutional layers to perform convolution operations on equirectangular images, handling the severe distortion, and 3) propose an optical flow-based masking scheme to mitigate the effect of unwanted pixels during training. Our qualitative and quantitative results demonstrate that these simple yet efficient designs result in significantly improved depth estimations when compared to previous approaches.
# Visual Servoing with Geometrically Interpretable Neural Perception
## Keywords:
- Visual Servoing
- Deep Learning for Visual Perception
## Abstract:
An increasing number of nonspecialist robotic users demand easy-to-use machines. In the context of visual servoing, the removal of explicit image processing is becoming a trend, allowing an easy application of this technique. This work presents a deep learning approach for solving the perception problem within the visual servoing scheme. An artificial neural network is trained using the supervision coming from the knowledge of the controller and the visual features motion model. In this way, it is possible to give a geometrical interpretation to the estimated visual features, which can be used in the analytical law of the visual servoing. The approach keeps perception and control decoupled, conferring flexibility and interpretability on the whole framework. Simulated and real experiments with a robotic manipulator validate our approach.
# Online Adaptation for Implicit Object Tracking and Shape Reconstruction in the Wild
## Keywords:
- Visual Tracking
- Deep Learning for Visual Perception
## Abstract:
Tracking and reconstructing 3D objects from cluttered scenes are the key components for computer vision, robotics and autonomous driving systems. While recent progress in implicit function has shown encouraging results on high-quality 3D shape reconstruction, it is still very challenging to generalize to cluttered and partially observable LiDAR data. In this paper, we propose to leverage the continuity in video data. We introduce a novel and unified framework which utilizes a neural implicit function to simultaneously track and reconstruct 3D objects in the wild. Our approach adapts the DeepSDF model (i.e., an instantiation of the implicit function) in the video online, iteratively improving the shape reconstruction while in return improving the tracking, and vice versa. We experiment with both Waymo and KITTI datasets, and show significant improvements over state-of-the-art methods for both tracking and shape reconstruction tasks.
# DeepFusionMOT: A 3D Multi-Object Tracking Framework Based on Camera-LiDAR Fusion with Deep Association
## Keywords:
- Visual Tracking
- Computer Vision for Transportation
- Computer Vision for Automation
## Abstract:
In the recent literature, on the one hand, many 3D multi-object tracking (MOT) works have focused on tracking accuracy and neglected computation speed, commonly by designing rather complex cost functions and feature extractors. On the other hand, some methods have focused too much on computation speed at the expense of tracking accuracy. In view of these issues, this paper proposes a robust and fast camera-LiDAR fusion-based MOT method that achieves a good trade-off between accuracy and speed. Relying on the characteristics of camera and LiDAR sensors, an effective deep association mechanism is designed and embedded in the proposed MOT method. This association mechanism realizes tracking of an object in a 2D domain when the object is far away and only detected by the camera, and updating of the 2D trajectory with 3D information obtained when the object appears in the LiDAR field of view to achieve a smooth fusion of 2D and 3D trajectories. Extensive experiments based on the KITTI dataset indicate that our proposed method presents obvious advantages over the state-of-the-art MOT methods in terms of both tracking accuracy and processing speed. Our code is made publicly available for the benefit of the community.
# EV-Catcher: High Speed Object Catching Using Low-Latency Event-Based Neural Networks
## Keywords:
- Visual Tracking
- Sensor-based Control
## Abstract:
Event-based sensors have recently drawn increasing interest in robotic perception due to their lower latency, higher dynamic range, and lower bandwidth requirements compared to standard CMOS-based imagers. These properties make them ideal tools for real-time perception tasks in highly dynamic environments. In this work, we demonstrate an application where event cameras excel: accurately estimating the impact location of fast-moving objects. We introduce a lightweight event representation called Binary Event History Image (BEHI) to encode event data at low latency, as well as a learning-based approach that allows real-time inference of a confidence-enabled control signal to the robot. To validate our approach, we present an experimental catching system in which we catch fast-flying ping-pong balls. We show that the system is capable of achieving a success rate of 81% in catching balls targeted at different locations, with a velocity of up to 13 m/s even on compute-constrained embedded platforms such as the Nvidia Jetson NX.
# Mapping 4
# Voxfield: Non-Projective Signed Distance Fields for Online Planning and 3D Reconstruction
## Keywords:
- Mapping
- RGB-D Perception
- Motion and Path Planning
## Abstract:
Creating accurate maps of complex, unknown environments is of utmost importance for truly autonomous navigation robot. However, building these maps online is far from trivial, especially when dealing with large amounts of raw sensor readings on a computation and energy constrained mobile system, such as a small drone. While numerous approaches tackling this problem have emerged in recent years, the mapping accuracy is often sacrificed as systematic approximation errors are tolerated for efficiency's sake. Motivated by these challenges, we propose Voxfield, a mapping framework that can generate maps online with higher accuracy and lower computational burden than the state of the art. Built upon the novel formulation of non-projective truncated signed distance fields (TSDFs), our approach produces more accurate and complete maps, suitable for surface reconstruction. Additionally, it enables efficient generation of euclidean signed distance fields (ESDFs), useful e.g. for path planning, that does not suffer from typical approximation errors. Through a series of experiments with public datasets, both real-world and synthetic, we demonstrate that our method beats the state of the art in map coverage, accuracy and computational time. Moreover, we show that Voxfield can be utilized as a back-end in recent multi-resolution mapping frameworks, producing high quality maps even in large-scale experiments. Finally, we validate our method by running it onboard a quadrotor, showing it can generate accurate ESDF maps usable for real-time path planning and obstacle avoidance.
# 3D Lidar Reconstruction with Probabilistic Depth Completion for Robotic Navigation
## Keywords:
- Mapping
- SLAM
## Abstract:
Safe motion planning in robotics requires planning into space which has been verified to be free of obstacles. However, obtaining such environment representations using lidars is challenging by virtue of the sparsity of their depth mea# surements. We present a learning-aided 3D lidar reconstruction framework that upsamples sparse lidar depth measurements with the aid of overlapping camera images so as to generate denser reconstructions with more definitively free space than can be achieved with the raw lidar measurements alone. We use a neural network with an encoder-decoder structure to predict dense depth images along with depth uncertainty estimates which are fused using a volumetric mapping system. We conduct experiments on real-world outdoor datasets captured using a handheld sensing device and a legged robot. Using input data from a 16-beam lidar mapping a building network, our experiments showed that the amount of estimated free space was increased by more than 40% with our approach. We also show that our approach trained on a synthetic dataset generalises well to real-world outdoor scenes without additional fine-tuning. Finally, we demonstrate how motion planning tasks can benefit from these denser reconstructions.
# Scalable Fiducial Tag Localization on a 3D Prior Map Via Graph-Theoretic Global Tag-Map Registration
## Keywords:
- Mapping
- Vision-Based Navigation
- Localization
## Abstract:
This paper presents an accurate and scalable method for fiducial tag localization on a 3D prior environmental map. The proposed method comprises three steps: 1) visual odometry-based landmark SLAM for estimating the relative poses between fiducial tags, 2) geometrical matching-based global tag-map registration via maximum clique finding, and 3) tag pose refinement based on direct camera-map alignment with normalized information distance. Through simulation-based evaluations, the proposed method achieved a 98 % global tag-map registration success rate and an average tag pose estimation accuracy of a few centimeters. Experimental results in a real environment demonstrated that it enables to localize over 110 fiducial tags placed in an environment in 25 minutes for data recording and post-processing.
# These Maps Are Made for Walking: Real-Time Terrain Property Estimation for Mobile Robots
## Keywords:
- Mapping
- Semantic Scene Understanding
- RGB-D Perception
## Abstract:
The equations of motion governing mobile robots are dependent on terrain properties such as the coefficient of friction, and contact model parameters. Estimating these properties is thus essential for robotic navigation. Ideally any map estimating terrain properties should run in real time, mitigate sensor noise, and provide probability distributions of the aforementioned properties, thus enabling risk-mitigating navigation and planning. This paper addresses these needs and proposes a Bayesian inference framework for semantic mapping which recursively estimates both the terrain surface profile and a probability distribution for terrain properties using data from a single RGB-D camera. The proposed framework is evaluated in simulation against other semantic mapping methods and is shown to outperform these state-of-the-art methods in terms of correctly estimating simulated ground-truth terrain properties when evaluated using a precision-recall curve and the Kullback-Leibler divergence test. Additionally, the proposed method is deployed on a physical legged robotic platform in both indoor and outdoor environments, and we show our method correctly predicts terrain properties in both cases. The proposed framework runs in real-time and includes a ROS interface for easy integration.
# MapLite 2.0: Online HD Map Inference Using a Prior SD Map
## Keywords:
- Mapping
- Autonomous Vehicle Navigation
- Localization
## Abstract:
Deploying fully autonomous vehicles has been a subject of intense research in both industry and academia. However, the majority of these efforts have relied heavily on High Definition (HD) prior maps. These are necessary to provide the planning and control modules a rich model of the operating environment. While this approach has shown success, it drastically limits both the scale and scope of these deployments as creating and maintaining HD maps for very large areas can be prohibitive. In this work, we present a new method for building the HD map online by starting with a Standard Definition (SD) prior map such as a navigational road map, and incorporating onboard sensors to infer the local HD map. We evaluate our method extensively on 100 sequences of real-world vehicle data and demonstrate that it can infer a highly structured HD map-like model of the world accurately using only SD prior maps and onboard sensors.
# Towards High-Definition Maps: A Framework Leveraging Semantic Segmentation to Improve NDT Map Compression and Descriptivity
## Keywords:
- Mapping
- Localization
## Abstract:
High-Definition (HD) maps are needed for robust navigation of autonomous vehicles, limited by the on-board storage capacity. To solve this, we propose a novel framework, Environment-Aware Normal Distributions Transform (EA-NDT), that significantly improves compression of standard NDT map representation. The compressed representation of EA-NDT is based on semantic-aided clustering of point clouds resulting in more optimal cells compared to grid cells of standard NDT. To evaluate EA-NDT, we present an open-source implementation that extracts planar and cylindrical primitive features from a point cloud and further divides them into smaller cells to represent the data as an EA-NDT HD map. We collected an open suburban environment dataset and evaluated EA-NDT HD map representation against the standard NDT representation. Compared to the standard NDT, EA-NDT achieved consistently at least 1.5× higher map compression while maintaining the same descriptive capability. Moreover, we showed that EA-NDT is capable of producing maps with significantly higher descriptivity score when using the same number of cells than the standard NDT.
# Robust Structure Identification and Room Segmentation of Cluttered Indoor Environments from Occupancy Grid Maps
## Keywords:
- Mapping
## Abstract:
Identifying the environment's structure, i.e., to detect core components as rooms and walls, can facilitate several tasks fundamental for the successful operation of indoor autonomous mobile robots, including semantic environment understanding. These robots often rely on 2D occupancy maps for core tasks such as localisation, motion and task planning. However, reliable identification of structure and room segmentation from 2D occupancy maps is still an open problem due to clutter (e.g., furniture and movable object), occlusions, and partial coverage. We propose a method for the RObust StructurE identification and ROom SEgmentation (ROSE^2) of 2D occupancy maps, which may be cluttered and incomplete. ROSE^2 identifies the main directions of walls and is resilient to clutter and partial observations, allowing to extract a clean, abstract geometrical floor-plan-like description of the environment, which is used to segment, i.e., to identify rooms in, the original occupancy grid map. ROSE^2 is tested in several real-world publicly-available cluttered maps obtained in different conditions. The results show how it can robustly identify the environment structure in 2D occupancy maps suffering from clutter and partial observations, while significantly improving room segmentation accuracy. Thanks to the combination of clutter removal and robust room segmentation ROSE^2 consistently achieves higher performance than the state-of-the-art methods, against which it is compared.
# Struct-MDC: Mesh-Refined Unsupervised Depth Completion Leveraging Structural Regularities from Visual SLAM
## Keywords:
- Mapping
- SLAM
- Deep Learning for Visual Perception
## Abstract:
Feature-based visual simultaneous localization and mapping (SLAM) methods only estimate the depth of extracted features, generating a sparse depth map. To solve this sparsity problem, depth completion tasks that estimate a dense depth from a sparse depth have gained significant importance in recent years. Existing methodologies that use sparse depth from visual SLAM mainly employ point features. However, point features have limitations in preserving structural regularities owing to textureless environments and sparsity problems. To deal with these issues, we perform depth completion with visual SLAM using line features, which can better contain structural regularities than point features. The proposed methodology creates a convex hull region by performing constrained Delaunay triangulation with depth interpolation using line features. However, the generated depth includes low-frequency information and is discontinuous at the convex hull boundary. Therefore, we propose a mesh depth refinement (MDR) module to address this problem. The MDR module effectively transfers the high-frequency details of an input image to the interpolated depth and plays a vital role in bridging the conventional and deep learning-based approaches. The Struct-MDC outperforms other state-of-the-art algorithms on public and our custom datasets, and even outperforms supervised methodologies for some metrics. In addition, the effectiveness of the proposed MDR module is verified by a rigorous ablation study.
# MotionSC: Data Set and Network for Real-Time Semantic Mapping in Dynamic Environments
## Keywords:
- Data Sets for Robotic Vision
- Deep Learning for Visual Perception
- Mapping
## Abstract:
This work addresses a gap in semantic scene completion (SSC) data by creating a novel outdoor data set with accurate and complete dynamic scenes. Our data set is formed from randomly sampled views of the world at each time step, which supervises generalizability to complete scenes without occlusions or traces. We create SSC baselines from state-of-the-art open source networks and construct a benchmark real-time dense local semantic mapping algorithm, MotionSC, by leveraging recent 3D deep learning architectures to enhance SSC with temporal information. Our network shows that the proposed data set can quantify and supervise accurate scene completion in the presence of dynamic objects, which can lead to the development of improved dynamic mapping algorithms. All software is available at https://github.com/UMich-CURLY/3DMapping.
# Soft Robot Materials and Design 1
# Rigid Skeleton Enhanced Dexterous Soft Finger Possessing Proprioception
## Keywords:
- Soft Robot Materials and Design
- Biologically-Inspired Robots
- Soft Sensors and Actuators
## Abstract:
This work presents a humanoid soft robotics finger design with rigid skeletons and proprioceptive sensors. This 4-DOFs dexterous finger has soft joints and rigid phalanxes, which is about the size of human hand. To enhance the overall stiffness and for human-like behavior and configuration, rigid-soft actuators which we called quasi-joint is introduced. Although their lengths are shortened in this design, the soft actuators can still bend over 90°, exhibiting joint-like flexion and abduction/adduction. Thus IP joints and MCP joint are realized. EGaIn soft sensors are embedded into the structure for bending detection. In addition, multi-step molding fabrication method is introduced for this complex multi-material structure. This rigid-soft finger is a preliminary work and modular part of a highly dexterous humanoid soft robotic hand.
# Self-Propelled Soft Everting Toroidal Robot for Navigation and Climbing in Confined Spaces
## Keywords:
- Soft Robot Materials and Design
- Mechanism Design
- Climbing Robots
## Abstract:
There are many spaces inaccessible to humans where robots could help deliver sensors and equipment. Many of these spaces contain three-dimensional passageways and uneven terrain that pose challenges for robot design and control. Everting toroidal robots, which move via simultaneous eversion and inversion of their body material, are promising for navigation in these types of spaces. We present a novel soft everting toroidal robot that propels itself using a motorized device inside an air-filled membrane. Our robot requires only a single control signal to move, can conform to its environment, and can climb vertically with a motor torque that is independent of the force used to brace the robot against its environment. We derive and validate models of the forces involved in its motion, and we demonstrate the robot's ability to navigate a maze and climb a pipe.
# A Geometric Design Approach for Continuum Robots by Piecewise Approximation of Free-Form Shapes
## Keywords:
- Soft Robot Materials and Design
- Kinematics
## Abstract:
As soft, continuum robots see increasing areas of application, many scenarios have arisen where it is necessary to consider the geometric shape of the robot. The current approaches to robot kinematics, such as the piecewise constant-curvature (PCC) model, are effective in representing simple overall robot geometry and estimating the end-effector state, but they are less intuitive for planing robots that involve complex geometries. In this work, we propose a solution to the geometric design problem by a two-part approach: a free-form spline defines a "shape curve" that describes the overall geometry of the robot, and then a "kinematic curve" composed of shapes that are feasible to replicate with continuum robots is fitted to the shape curve. As an implementation of this approach, we specifically explore the application of piecewise cubic Bezier curves in designing the shape curve of the robot, and pairs of arcs to construct the kinematic curves. Finally, the approach is applied to a tip-extension "vine" robot that is designed and fabricated to "grow" along a designed path and access the top surface of an obstacle.
# A Multi-Segmented Soft Finger Using Snap-Through Instability of a Soft Valve with a Slit
## Keywords:
- Soft Robot Materials and Design
- Grippers and Other End-Effectors
- Soft Sensors and Actuators
## Abstract:
Soft fingers with multiple segments can perform various grasping modes when each segment is individually controlled, although this requires a number of inputs and leads to a complicated structure. In this paper, we propose a multi-segment soft finger capable of generating dual modes only using a single input channel. We use the snap-through behavior of a soft spherical shell with a slit as a flow valve between two finger segments. Experimental results showed that geometrical designs and material properties of the valve determine its critical pressure (i.e., the pressure causing buckling of the shell) and affect the proposed soft fingers' shape deformation and mode transition. We finally characterized an antipodal gripper with two proposed fingers in terms of the acquisition region and grasp robustness. The gripper could achieve not only a broad range of precision grasp by fingers with a passive distal segment but also robust stability of power grasp by fingers with an active distal segment, without adding extra input channels.
# Deformation-Driven Closed-Chain Soft Mobile Robot Aimed for Rolling and Climbing Locomotion
## Keywords:
- Soft Robot Materials and Design
- Hydraulic/Pneumatic Actuators
- Soft Robot Applications
## Abstract:
The inherent compliance of soft mobile robots makes them a safe option for interaction with humans and fragile environments. To expand their possibilities around our daily life, it is desirable for them to have enhanced traversal ability with safe structure and movement. To meet this requirement, we propose a new type of soft mobile robot that moves while selecting rotational, wave, and climbing locomotion. The proposed robot, named DECSO, forms a closed chain of modular segment actuators that individually generate contraction and bidirectional bending motion by applying negative pressure. In this paper, after presenting methods for generating the above three kinds of locomotion, the characteristics and modeling of the segment actuator are illustrated. Furthermore, the experimental results show that a 4-segment prototype achieved smooth rotational movement in the horizontal plane at a velocity of 75 mm/s, while a 6-segment prototype was able not only to move forward by travelling waves, but also to cross over the human body and obstacles of 62% of its own height by rotational movement. These findings suggest a new possibility for soft mobile robots that can safely touch and move around the human body.
# Soft, Multi-Layer, Disposable, Kirigami Based Robotic Grippers: On Handling of Delicate, Contaminated, and Everyday Objects
## Keywords:
- Soft Robot Materials and Design
- Soft Robot Applications
## Abstract:
Grasping and manipulation are complex and demanding tasks, especially when executed in dynamic and unstructured environments. Typically, such tasks are executed by rigid articulated end-effectors, with a plethora of actuators that need sophisticated sensing and complex control laws to execute them efficiently. Soft robotics offers an alternative that allows for simplified execution of these demanding tasks, enabling the creation of robust, efficient, lightweight, and affordable solutions that are easy to control and operate. In this work, we introduce a new class of soft, kirigami-based robotic grippers, study their post-contact behavior and investigate different cut patterns for their development. We follow an experimental approach in which several designs are proposed and employed in a series of grasping and force exertion tests to compare their capabilities and post-contact behavior. The results of such experiments indicate a clear relationship between degree of reconfiguration and grasping force, and provide key insights into the effect of the cut patterns in the performance of the designs. These findings are then used in the design process of an improved version of multi-layer, disposable kirigami grippers that are fabricated employing simple 3D printed layers or laser cut PET films and silicone rubber using the concept of Hybrid Deposition Manufacturing (HDM). A series of experimental results demonstrate that the proposed design and manufacturing methods can enable the creation of soft, kirigami-based grippers with superior grasping capabilities that can handle delicate, contaminated, and everyday life objects and can even be disposed off in an automated way (e.g., after handling hazardous materials, such as medical waste).
# Topology Optimized Multi-Material Self-Healing Actuator with Reduced Out of Plane Deformation
## Keywords:
- Soft Robot Materials and Design
- Soft Robot Applications
- Modeling, Control, and Learning for Soft Robots
## Abstract:
Recent advances in soft robotics in academia have led to the adoption of soft grippers in industrial settings. Due to their soft bending actuators, these grippers can handle delicate objects with great care. However, due to their flexibility, the actuators are prone to out-of-plane deformations upon asymmetric loading. These undesired deformations lead to reduced grasp performance and may cause instability or failure of the grip. While the state-of-the-art contributions describe complex designs to limit those deformations, this work focuses on a complementary path investigating the material distribution. In this paper, a novel bending actuator is developed with improved out-of-plane deformation resistance by optimizing the material distribution in multi-material designs composed of two polymers with different mechanical properties. This is made possible by the strong interfacial strength of Diels-Alder chemical bonds in the used polymers, which have a self-healing capability. A Solid Isotropic Material with Penalization (SIMP) topology optimization is performed to increase the out-of-plane resistance. The actuator is simulated using FEA COMSOL in which the (hyper) elastic materials are simulated by Mooney-Rivlin models, fitted on experimental uniaxial tensile test data. This multi-material actuator and a reference single material actuator were manufactured and modeled. Via experimental characterization and validation in FEA simulations, it is shown that the actuator performance, characterized by the in-plane performance and out-plane resistance, can be increased by an optimized multi-material composition, without changing the geometrical shape of the actuator.
# Performance Evaluation for Braided McKibben Pneumatic Actuators in Telescopic Nested Structure
## Keywords:
- Soft Robot Materials and Design
- Hydraulic/Pneumatic Actuators
- Soft Sensors and Actuators
## Abstract:
This study presents the usage of Braided Actuators with Nested Structures to improve the stroke characteristics of the McKibben actuators. Thin McKibben actuators can contract 23 % of their original length when pressurized. Usage of braiding and nested structures to improve contraction ratio has proven successful. In this study, we use a combined telescopic Nested Structure and Braided Actuators to increase the contraction ratio of the actuators. The Nested Braided Actuator (NBA) performance was compared to Single Actuator (SA), Braided Actuator (BA), and Nested Actuator (NA). The results at 350 kPa indicate that, NBA had the highest contraction ratio of 45.5 %, followed by NA (39.38 %), BA (29.57 %), and SA (23.41 %). At 350 kPa, the contraction force per actuator NBA was 36.29 N, NA exerted 41.33 N, BA exerted 30.41 N and SA exerted 43.8 N. The actuator's performance showed that it was capable of high stroke with only a 20 – 30 % loss in contraction force compared to the SA.
# Energy-Efficient Tunable-Stiffness Soft Robots Using Second Moment of Area Actuation
## Keywords:
- Soft Robot Materials and Design
- Hydraulic/Pneumatic Actuators
- Marine Robotics
## Abstract:
The optimal stiffness for soft swimming robots depends on swimming speed, which means no single stiffness can maximise efficiency in all swimming conditions. Tunable-stiffness would produce an increased range of high-efficiency swimming speeds for robots with flexible propulsors and enable soft control surfaces for steering underwater vehicles. We propose and demonstrate a method for tunable soft robotic stiffness using inflatable rubber tubes to stiffen a silicone foil through pressure and second moment of area change. We achieved double the effective stiffness of the system for an input pressure change from 0 to 0.8 bar and 2 J energy input. We achieved a resonant amplitude gain of 5 to 7 times the input amplitude and tripled the high-gain frequency range compared to a foil with fixed stiffness. These results show that changing second moment of area is an energy effective approach to tunable-stiffness robots.
# Localization 4
# Acoustic Localization and Communication Using a MEMS Microphone for Low-Cost and Low-Power Bio-Inspired Underwater Robots
## Keywords:
- Localization
- Marine Robotics
- Biologically-Inspired Robots
## Abstract:
Having accurate localization capabilities is one of the fundamental requirements of autonomous robots. For underwater vehicles, the choices for effective localization are limited due to limitations of GPS use in water and poor environmental visibility that makes camera-based methods ineffective. Popular inertial navigation methods for underwater localization using Doppler-velocity log sensors, sonar, high-end inertial navigation systems, or acoustic positioning systems require bulky expensive hardware which are incompatible with low-cost, bio-inspired underwater robots. In this paper, we introduce an approach for underwater robot localization inspired by GPS methods known as acoustic pseudoranging. Our method allows us to localize multiple bio-inspired robots equipped with commonly available micro electro-mechanical systems microphones. This is achieved by estimating the time difference of arrival of acoustic signals sent simultaneously through four speakers with a known constellation geometry. We also leverage the same acoustic framework to perform one-way communication with multiple robots to execute some primitive motions. To our knowledge, this is the first application of the approach for the on-board localization of small bio-inspired robots in water. Hardware schematics and the accompanying code are released to aid further development in the field.
# Using Magnetic Fields to Navigate and Simultaneously Localize Catheters in Endoluminal Environments
## Keywords:
- Localization
- Surgical Robotics: Steerable Catheters/Needles
- Surgical Robotics: Planning
## Abstract:
Remote magnetic navigation offers an ideal platform for automated catheter navigation. Magnetically guided catheters show great dexterity and can reach locations that are otherwise challenging to access. By automating aspects of catheterization procedures, we can simplify and expedite the procedure to allow surgeons to focus on other critical tasks during the surgery. In this article, we describe an automation strategy that is based on the center line of extracted and registered vascular geometries. Position feedback is accomplished with a Hall-effect sensor embedded near the distal end of the catheter. Sensor measurements are compared to the magnetic field predicted by a linear model of the electromagnetic navigation system. By defining specific magnetic field gradients and applying the known vascular geometry, the magnetic fields can be utilized for the simultaneous navigation and localization of the catheter. This eliminates the need for other external, dedicated mapping systems, and the use of fluoroscopy imaging is minimized. The concept is tested in 2d vascular models and the accuracy of the localization is assessed with overhead camera tracking.
# Robust Slip-Aware Fusion for Mobile Robots State Estimation
## Keywords:
- Localization
- Wheeled Robots
- Sensor Fusion
## Abstract:
A novel robust and slip-aware speed estimation framework is developed and experimentally verified for mobile robot navigation by designing proprioceptive robust observers at each wheel. The observer for each corner is proved to be consistent, in the sense that it can provide an upper bound of the mean square estimation error (MSE) timely. Under proper conditions, the MSE is proved to be uniformly bounded. A covariance intersection fusion method is used to fuse the wheel-level estimates, such that the updated estimate remains consistent. The estimated slips at each wheel are then used for a robust consensus to improve the reliability of speed estimation in harsh and combined-slip scenarios. As confirmed by indoor and outdoor experiments under different surface conditions, the developed framework addresses state estimation challenges for mobile robots that experience uneven torque distribution or large slip. The novel proprioceptive observer can also be integrated with existing tightly-coupled visual-inertial navigation systems.
# Highly-Efficient Binary Neural Networks for Visual Place Recognition
## Keywords:
- Localization
- Autonomous Vehicle Navigation
## Abstract:
VPR is a fundamental task for autonomous navigation as it enables a robot to localize itself in the workspace when a known location is detected. Although accuracy is an essential requirement for a VPR technique, computational and energy efficiency are not less important for real-world applications. CNN-based techniques archive state-of-the-art VPR performance but are computationally intensive and energy demanding. Binary neural networks (BNN) have been recently proposed to address VPR efficiently. Although a typical BNN is an order of magnitude more efficient than a CNN, its processing time and energy usage can be further improved. In a typical BNN, the first convolution is not completely binarized for the sake of accuracy. Consequently, the first layer is the slowest network stage, requiring a large share of the entire computational effort. This paper presents a class of BNNs for VPR that combines depthwise separable factorization and binarization to replace the first convolutional layer to improve computational and energy efficiency. Our best model achieves higher VPR performance while spending considerably less time and energy to process an image than a BNN using a non-binary convolution as a first stage.
# GNSS Odometry: Precise Trajectory Estimation Based on Carrier Phase Cycle Slip Estimation
## Keywords:
- Localization
- SLAM
## Abstract:
This paper proposes a highly accurate trajectory estimation method for outdoor mobile robots using global navigation satellite system (GNSS) time differences of carrier phase (TDCP) measurements. By using GNSS TDCP, the relative 3D position can be estimated with millimeter precision. However, when a phenomenon called cycle slip occurs, wherein the carrier phase measurement jumps and becomes discontinuous, it is impossible to accurately estimate the relative position using TDCP. Although previous studies have eliminated the effect of cycle slip using a robust optimization technique, it was difficult to completely eliminate the effect of outliers. In this paper, we propose a method to detect GNSS carrier phase cycle slip, estimate the amount of cycle slip, and modify the observed TDCP to calculate the relative position using the factor graph optimization framework. The estimated relative position acts as a loop closure in graph optimization and contributes to the reduction in the integration error of the relative position. Experiments with an unmanned aerial vehicle showed that by modifying the cycle slip using the proposed method, the vehicle trajectory could be estimated with an accuracy of 5–30 cm using only a single GNSS receiver, without using any other external data or sensors.
# Square-Root Robocentric Visual-Inertial Odometry with Online Spatiotemporal Calibration
## Keywords:
- Localization
- Vision-Based Navigation
## Abstract:
Robocentric visual-inertial odometry (R-VIO) in our recent work [1] models the probabilistic state estimation problem with respect to a moving local (body) frame, which is contrary to a fixed global (world) frame as in the world-centric formulation, thus avoiding the observability mismatch issue and achieving better estimation consistency. To further improve efficiency and robustness in order to be amenable for the resource-constrained applications, in this paper, we propose a novel information-based estimator, termed R-VIO2. In particular, the numerical stability and computational efficiency are significantly boosted by using the i) square-root expression and ii) incremental QR-based update combined with back substitution. Moreover, the spatial transformation and time offset between visual and inertial sensors are jointly calibrated online to robustify the estimator performance in the presence of unknown parameter errors. The proposed R-VIO2 has been extensively tested on public benchmark dataset as well as in a large-scale real-world experiment, and shown to achieve very competitive accuracy and superior time efficiency against the state-of-the-art visual-inertial navigation methods.
# Are We Ready for Radar to Replace Lidar in All-Weather Mapping and Localization?
## Keywords:
- Localization
- Range Sensing
- Intelligent Transportation Systems
## Abstract:
We present an extensive comparison between three topometric localization systems: radar-only, lidar-only, and a cross-modal radar-to-lidar system across varying seasonal and weather conditions using the Boreas dataset. Contrary to our expectations, our experiments showed that our lidar-only pipeline achieved the best localization accuracy even during a snowstorm. Our results seem to suggest that the sensitivity of lidar localization to moderate precipitation has been exaggerated in prior works. However, our radar-only pipeline was able to achieve competitive accuracy with a much smaller map. Furthermore, radar localization and radar sensors still have room to improve and may yet prove valuable in extreme weather or as a redundant backup system. Code for this project can be found at: https://github.com/utiasASRL/vtr3
# Continuous-Time Factor Graph Optimization for Trajectory Smoothness of GNSS/INS Navigation in Temporarily GNSS-Denied Environments
## Keywords:
- Localization
- Sensor Fusion
- Marine Robotics
## Abstract:
For autonomous systems, the smoothness of estimated trajectories is essential to ensure robust and performant vehicle control. Unfortunately, approaches for state estimation using Kalman filters are sensitive to measurement outliers that can diverge dramatically. We propose a state-estimation algorithm using factor graph optimization (FGO) in continuous-time for GNSS/INS navigation systems to track this problem. The focus is on the smoothness of the estimated trajectory in environments where the GNSS observations become temporarily unreliable. Therefore, an inland shipping scenario with bridge crossings is selected as an application example. To estimate the trajectory in continuous-time, we integrate a White-Noise-On-Acceleration (WNOA) motion prior factor based on Gaussian process regression between successive states. Our results show a 30% improvement in accuracy and increased smoothness of the estimated trajectory with FGO compared to Kalman filtering.
# Maintaining Robot Localizability with Bayesian Cramer-Rao Lower Bounds
## Keywords:
- Localization
- Range Sensing
- Multi-Robot Systems
## Abstract:
Accurate and real-time position estimates are crucial for mobile robots. This work focuses on ranging-based positioning systems, which rely on distance measurements between known points, called anchors, and a tag to localize. 
The topology of the network formed by the anchors strongly influences the tag's localizability, i.e., its ability to be accurately localized.
Here, the tag and some anchors are supposed to be carried by robots, which allows enhancing the positioning accuracy by planing the anchors' motions. 
We leverage Bayesian Cram'er-Rao Lower Bounds (CRLBs) on the estimates' covariance in order to quantify the tag's localizability. This class of CRLBs can capture prior information on the tag's position and take it into account when deploying the anchors. 
We propose a method to decrease a potential function based on the Bayesian CRLB in order to maintain the localizability of the tag while having some prior knowledge about its position distribution. Then, we present a new experiment highlighting the link between the localizability potential and the precision expected in practice. Finally, two real-time anchor motion planners are demonstrated with ranging measurements in the presence or absence of prior information about the tag's position.
# Reinforcement Learning 3
# Safe Reinforcement Learning Using Black-Box Reachability Analysis
## Keywords:
- Reinforcement Learning
- Robot Safety
- Motion and Path Planning
## Abstract:
Reinforcement learning (RL) is capable of sophisticated motion planning and control for robots in uncertain environments. However, state-of-the-art deep RL approaches typically lack safety guarantees, especially when the robot and environment models are unknown. To justify widespread deployment, robots must respect safety constraints without sacrificing performance. Thus, we propose a Black-box Reachability-based Safety Layer (BRSL) with three main components: (1) data-driven reachability analysis for a black-box robot model, (2) a trajectory rollout planner that predicts future actions and observations using an ensemble of neural networks trained online, and (3) a differentiable polytope collision check between the reachable set and obstacles that enables correcting unsafe actions. In simulation, BRSL outperforms other state-of-the-art safe RL methods on a Turtlebot 3, a quadrotor, a trajectory-tracking point mass, and a hexarotor in wind with an unsafe set adjacent to the area of highest reward.
# Hierarchical Primitive Composition: Simultaneous Activation of Skills with Inconsistent Action Dimensions in Multiple Hierarchies
## Keywords:
- Reinforcement Learning
- Incremental Learning
- Deep Learning in Grasping and Manipulation
## Abstract:
Deep reinforcement learning has shown its effectiveness in various applications, providing a promising direction for solving tasks with high complexity. However, naively applying classical RL for learning a complex long-horizon task with a single control policy is prohibitively inefficient. Thus, policy modularization tackles this problem by learning a set of modules that are mapped to primitive and properly orchestrating them. In this study, we further expand the discussion by incorporating simultaneous activation of the skills and structuring them into multiple hierarchies in a recursive fashion. Moreover, we sought to devise an algorithm that can properly orchestrate the skills with different action spaces via multiplicative Gaussian distributions, which highly increase the reusability. By exploiting the modularity, interpretability can also be achieved by observing the modules that are used in the new task if each of the skills is known. We demonstrate how the proposed scheme can be employed in practice by solving a pick and place task with a 6 DoF manipulator, and examine the effects of each property from ablation studies.
# Vision-Guided Quadrupedal Locomotion in the Wild with Multi-Modal Delay Randomization
## Keywords:
- Reinforcement Learning
- Legged Robots
## Abstract:
Developing robust vision-guided controllers for quadrupedal robots in complex environments, with various obstacles, dynamical surroundings and uneven terrains, is very challenging. While Reinforcement Learning (RL) provides a promising paradigm for agile locomotion skills with vision inputs in simulation, it is still very challenging to deploy the RL policy in the real world. Our key insight is that aside from the discrepancy in the domain gap, in visual appearance between the simulation and the real world, the latency from the control pipeline is also a major cause of difficulty. In this paper, we propose Multi-Modal Delay Randomization (MMDR) to address this issue when training RL agents. Specifically, we simulate the latency of real hardware by using past observations, sampled with randomized periods, for both proprioception and vision. We train the RL policy for end-to-end control in a physical simulator without any predefined controller or reference motion, and directly deploy it on the real A1 quadruped robot running in the wild. We evaluate our method in different outdoor environments with complex terrains and obstacles. We demonstrate the robot can smoothly maneuver at a high speed, avoid the obstacles, and show significant improvement over the baselines.
# Temporal Logic Guided Meta Q-Learning of Multiple Tasks
## Keywords:
- Reinforcement Learning
- Motion and Path Planning
- Formal Methods in Robotics and Automation
## Abstract:
Reinforcement learning (RL) based approaches have enabled robots to perform various tasks. However, most existing RL algorithms focus on learning a particular task, without considering generalization to new tasks. To address this issue, by combining meta learning and reinforcement learning, we develop a meta Q-learning of multi-task (MQMT) framework where the robot effectively learns a meta model from a diverse set of training tasks and then generalizes the learned model to a new set of tasks that have never been encountered during training using only a small amount of additional data. Particularly, the multiple tasks are specified by co-safe linear temporal logic specification. As a semantics-preserving rewriting operation, LTL progression is exploited to decompose training tasks into learnable sub-goals, which not only enables simultaneous learning of multiple tasks, but also facilitates reward design by converting non-Markovian reward process to Markovian ones. Reward shaping is further incorporated into the reward design to relax the sparse reward issue to improve reinforcement learning. The simulation and experiment results demonstrate the effectiveness of the MQMT framework.
# Model-Free Neural Lyapunov Control for Safe Robot Navigation
## Keywords:
- Machine Learning for Robot Control
- Reinforcement Learning
- Motion and Path Planning
## Abstract:
Model-free Deep Reinforcement Learning (DRL) controllers have demonstrated promising results on various challenging non-linear control tasks. While a model-free DRL algorithm can solve unknown dynamics and high-dimensional problems, it lacks safety assurance. Although safety constraints can be encoded as part of a reward function, there still exists a large gap between an RL controller trained with this modified reward and a safe controller. In contrast, instead of implicitly encoding safety constraints with rewards, we explicitly co-learn a Twin Neural Lyapunov Function (TNLF) with the control policy in the DRL training loop and use the learned TNLF to build a runtime monitor. Combined with the path generated from a planner, the monitor chooses appropriate waypoints that guide the learned controller to provide collision-free control trajectories. Our approach inherits the scalability advantages from DRL while enhancing safety guarantees. Our experimental evaluation demonstrates the effectiveness of our approach compared to DRL with augmented rewards and constrained DRL methods over a range of high-dimensional safety-sensitive navigation tasks.
# Efficient Off-Policy Safe Reinforcement Learning Using Trust Region Conditional Value at Risk
## Keywords:
- Reinforcement Learning
- Robot Safety
- Collision Avoidance
## Abstract:
This paper aims to solve a safe reinforcement learning (RL) problem with risk measure-based constraints. As risk measures, such as conditional value at risk (CVaR), focus on the tail distribution of cost signals, constraining risk measures can effectively prevent a failure in the worst case. An on-policy safe RL method, called TRC, deals with a CVaR-constrained RL problem using a trust region method and can generate policies with almost zero constraint violations with high returns. However, to achieve outstanding performance in complex environments and satisfy safety constraints quickly, RL methods are required to be sample efficient. To this end, we propose an off-policy safe RL method with CVaR constraints, called off-policy TRC. If off-policy data from replay buffers is directly used to train TRC, the estimation error caused by the distributional shift results in performance degradation. To resolve this issue, we propose novel surrogate functions, in which the effect of the distributional shift can be reduced, and introduce an adaptive trust-region constraint to ensure a policy not to deviate far from replay buffers. buffer. The proposed method has been evaluated in simulation and real-world environments and satisfied safety constraints within a few steps while achieving high returns even in complex robotic tasks.
# Variable Impedance Skill Learning for Contact-Rich Manipulation
## Keywords:
- Reinforcement Learning
- Compliance and Impedance Control
- Machine Learning for Robot Control
## Abstract:
Reinforcement Learning (RL) has the potential of solving complex continuous control tasks, with direct applications to robotics. Nevertheless, current state-of-the-art methods require a vast amount of interaction experience and are generally not safe or feasible to learn directly on a physical robot. We address this challenge by a framework for learning latent action spaces for RL agents from demonstrated trajectories. We extend this framework by connecting it to a variable impedance Cartesian space controller, allowing us to learn contact-rich tasks safely and efficiently. Our method learns from trajectories that incorporate both positional, but also crucially impedance-space information. We evaluate our method on a number of peg-in-hole task variants with a Franka Panda arm and demonstrate that learning variable impedance actions for RL in Cartesian space can be deployed directly on the real robot, without resorting to learning in simulation.
# Source Term Estimation Using Deep Reinforcement Learning with Gaussian Mixture Model Feature Extraction for Mobile Sensors
## Keywords:
- Reinforcement Learning
- Planning under Uncertainty
- Aerial Systems: Perception and Autonomy
## Abstract:
This paper proposes a deep reinforcement learning method for mobile sensors to estimate the properties of the source of the hazardous gas release. The problem of estimating the properties of the released gas is generally termed as the source term estimation (STE) problem. Since the sensor measurements from atmospheric gas dispersion are sparse, intermittent, and time-varying due to the turbulence and the sensor noise, STE is considered to be a challenging problem. The particle filter is adopted to estimate the source term under such stochastic noise conditions. The deep deterministic policy gradient (DDPG) is also employed to find the best source search policy in terms of successful estimation and traveled distance. Through ablation studies, we demonstrate that the use of the Gaussian mixture model, which clusters the potential source positions from the particle filter, as an input to the DDPG and the gated recurrent unit functioning as a memory in DDPG help to improve the STE performance. Besides, simulation results in randomized source term conditions and previously-unseen environments show the superior STE performance of the proposed algorithm compared with the existing information-theoretic STE algorithm.
# Autonomous Learning of Page Flipping Movements Via Tactile Feedback (I)
## Keywords:
- Reinforcement Learning
- Perception for Grasping and Manipulation
- Force and Tactile Sensing
## Abstract:
Robotic manipulation is challenging when both the objects being manipulated and the tactile sensors are deformable. In this work, we addressed the interplay between the manipulation of deformable objects, tactile sensing, and model-free reinforcement learning on a real robot. We showed how a real robot can learn to manipulate a deformable, thin-shell object via feedback from deformable, multimodal tactile sensors. We addressed the learning of a page flipping task using a two-stage approach. For the first stage, we learned nominal page flipping trajectories for two page sizes by constructing a reward function that quantifies functional task performance from the perspective of tactile sensing. For the second stage, we learned adapted trajectories using tactile-driven perceptual coupling, with an intuitive assumption that, while the page flipping trajectories for different task contexts (page sizes) might differ, similar tactile feedback should be expected from functional trajectories for each context. We also investigated the quality of information encoded by two different representations of tactile sensing data: one based on the artificial apical tuft of bio-inspired tactile sensors, and another based on PCA eigenvalues. The results and effectiveness of our learning framework were demonstrated on a real 7-DOF robot arm and gripper outfitted with tactile sensors.
# Climbing and Wheeled Robots
# Magnetic Field Modeling of Linear Halbach Array for Wall-Climbing Robot Based on Radial Basis Function Neural Network
## Keywords:
- AI-Based Methods
- Dynamics
## Abstract:
Aiming at the problem that it is difficult to calculate the force of permanent magnets in the magnetic field, this paper proposes a nonlinear mechanical model of linear array magnetic field based on radial basis function neural network (RBFNN). Combined with the linear Halbach array adsorption module of the wall-climbing robot, the three-dimensional geometric magnetic fields of four typical linear array permanent magnets were constructed, and the theoretical models of the interaction between the magnetic fields were given respectively. Further, the finite element simulation calculation of the magnetic force was carried out using COMSOL Multiphysics software. According to the parametric scanning results of the orthogonal test, a nonlinear intelligent prediction model of the force between magnetic fields with local loss sensitivity is established by using the RBFNN numerical fitting method. The average deviation of the network test set is 1.19, and the standard deviation is 0.80. The intelligent prediction model has strong general performance, faster convergence speed and stronger flexibility, which provides a theoretical basis for the interaction and control of array magnetic fields.
# OmniWheg: An Omnidirectional Wheel-Leg Transformable Robot
## Keywords:
- Wheeled Robots
- Legged Robots
- Climbing Robots
## Abstract:
This paper presents the design, analysis, and performance evaluation of an omnidirectional transformable wheel-leg robot called OmniWheg. We design a novel mechanism consisting of a separable omni-wheel and 4-bar linkages, allowing the robot to transform between omni-wheeled and legged modes smoothly. In wheeled mode, the robot can move in all directions and efficiently adjust the relative position of its wheels, while it can overcome common obstacles in legged mode, such as stairs and steps. Unlike other articles studying whegs, this implementation with omnidirectional wheels allows the correction of misalignments between right and left wheels before traversing obstacles, which effectively improves the success rate and simplifies the preparation process before the wheel-leg transformation. We describe the design concept, mechanism, and the dynamic characteristic of the wheel-leg structure. We then evaluate its performance in various scenarios, including passing obstacles, climbing steps of different heights, and turning/moving omnidirectionally. Our results confirm that this mobile platform can overcome common indoor obstacles and move flexibly on the flat ground with the new transformable wheel-leg mechanism, while keeping a high degree of stability.
# SCALER: A Tough Versatile Quadruped Free-Climber Robot
## Keywords:
- Climbing Robots
- Legged Robots
- Grippers and Other End-Effectors
## Abstract:
This paper introduces SCALER, a quadrupedal robot that demonstrates climbing on bouldering walls, overhangs, ceilings and trotting on the ground. SCALER is one of the first high-degrees of freedom four-limbed robots that can free-climb under the Earth's gravity and one of the most mechanically efficient quadrupeds on the ground. Where other state-of-the-art climbers specialize in climbing, SCALER promises practical free-climbing with payload textit{and} ground locomotion, which realizes true versatile mobility. A new climbing gait, SKATE gait, increases the payload by utilizing the SCALER body linkage mechanism. SCALER achieves a maximum normalized locomotion speed of 1.87 /s, or 0.56 m/s on the ground and 1.0 /min, or 0.35 m/min in bouldering wall climbing. Payload capacity reaches 233 % of the SCALER weight on the ground and 35 % on the vertical wall. Our GOAT gripper, a mechanically adaptable underactuated two-finger gripper, successfully grasps convex and non-convex objects and supports SCALER.
# Microspine Design for Additive Manufacturing
## Keywords:
- Climbing Robots
- Grippers and Other End-Effectors
- Additive Manufacturing
## Abstract:
Microspine grippers allow robots to ascend steep rocky slopes and cliff faces, enabling scientific exploration of exposed strata on Earth and other solar system bodies. Historically, the Shape Deposition Manufacturing (SDM) process has been used to fabricate multi-material suspensions for load-sharing among multiple microspines. We instead apply the Hybrid Deposition Manufacturing (HDM) process to microspine fabrication, and we further propose a novel 3D-printed microspine suspension design that can be manufactured via Fused Deposition Manufacturing (FDM) alone, using a single flexible material with an embedded fishhook. We use a model of microspine stiffness that allows designers to compensate for order-of-magnitude changes in material tensile modulus by adjusting geometric parameters of the design. The stiffness model and the FDM microspine design are validated through tensile testing, and mechanical properties of the HDM and FDM designs are compared against a standard SDM microspine design. We demonstrate that the FDM process can produce microspines with equivalent normal and axial stiffness and superior maximum load and fatigue response to SDM microspines, and discuss additional advantages of the FDM process for rapid prototyping and broader accessibility.
# Design, Fabrication, and Characterization of a Hybrid Bionic Spherical Robotics with Multilegged Feedback Mechanism
## Keywords:
- Engineering for Robotic Systems
- Simulation and Animation
- Motion Control
## Abstract:
Spherical robots have many desirable traits when designing mass efficient systems interacted with unstructured terrain. In this paper, we propose a hybrid bionic spherical robot based on the morphological properties of sea urchins and the movement characteristics of tumbleweeds. This robot enables it to move freely in harsh terrain with the distributed high-aspect-ratio telescopic units, where our control strategy is based on the a central pattern generator and combines foot pressure measurements and actuator state information. In particular, these data from multiple foot pressure sensors also are used to compute the robots' center of mass, with evaluating locomotion state during rolling maneuvers. The experimental results show the ability of our design to provide reliable pose estimates, also overcoming a challenge in the field of mobile robotics, including switch directions flexibly in harsh terrain due to their anisotropy.
# The Concept of Rod-Driven Locomotion for Spherical Lunar Exploration Robots
## Keywords:
- Space Robotics and Automation
## Abstract:
A spherical robotic probe has several advantages in rough environments and has therefore raised interest for application in planetary exploration. A sphere is well-suited to protect high-sensitive payloads, however, the locomotion system for planetary surfaces raises several challenges. This paper presents a novel locomotion system consisting of linear actuators which are usable in a multi-functional fashion. Apart from pushing and bringing leverage for locomotion the extendable rods enable a tripod mode for improved sensing. The developed solutions offer a mathematical-physical system description, simple algorithms for the control of locomotion and balancing as well as general calculations for determining the maximum achievable performance parameters of such a robot. The first built prototype shows the basic suitability of the system and reveals directions for further research.
# Nonlinear Model Predictive Control with Cost Function Scheduling for a Wheeled Mobile Robot
## Keywords:
- Wheeled Robots
- Optimization and Optimal Control
- Motion and Path Planning
## Abstract:
Designing a cost function for nonlinear model predictive control (MPC) with a sparse/binary stage cost is challenging. This paper proposes a novel MPC approach with a scheduled quadratic stage cost function that approximates the true stage cost in order to optimally control a nonlinear system with a sparse/binary stage cost. The cost function parameter is optimally scheduled by a parameter scheduling policy obtained by solving a Markov decision process (MDP) constructed from sampled trajectories from any nonlinear MPC solver. The proposed approach is implemented into a differential drive wheeled mobile robot (WMR) designed for smart warehousing via the robot operating system (ROS) framework. The simulation and experimental results successfully demonstrate the effectiveness of our MPC approach in cases of the point stabilization problem of a differential drive WMR.
# Caterpillar-Inspired Insect-Scale Climbing Robot Using Dry Adhesives
## Keywords:
- Climbing Robots
- Micro/Nano Robots
## Abstract:
Surface-to-surface transitions, vertical and inverted locomotion, and high payload capacity are important requirements for a climbing robot. Despite many previous approaches, the miniaturization of climbing robots that satisfy these requirements is still a big challenge. In this paper, we present an insect-scale wheeled climbing robot that employs a low-cost dry adhesive technology. The design, inspired by caterpillars, consists of 2 main links that are connected by a pivot joint. The prototype robot measures a length of 40 mm and a width of 10 mm, and it weighs 1.7 g. On a horizontal surface, the robot moves with a speed of 12.3 mm/s and can drag a load weight of 10 g (six times its weight) at a speed of 4 mm/s. The high torque-to-weight ratio achieved by two micro-geared ultrasonic motors permits vertical and inverted locomotion while carrying a high payload capacity (120% of the robot’s weight). The locomotion strategy for surface-to-surface transitions, i.e., movements at right angle corners, is substantiated by the functionality of the pivot joint. To satisfy the design requirements, many dry adhesive tapes are evaluated, and the climbing robot with an appropriate adhesion force is demonstrated.
# Electro-Hydraulic Rolling Soft Wheel: Design, Hybrid Dynamic Modeling, and Model Predictive Control (I)
## Keywords:
- Product Design, Development and Prototyping
- Dynamics
- Optimization and Optimal Control
## Abstract:
Locomotion through rolling is attractive compared to other forms of locomotion thanks to uniform designs, high degree of mobility, dynamic stability, and self-recovery from collision. Despite previous efforts to design rolling soft systems, pneumatic and other soft actuators are often limited in terms of high-speed dynamics, system integration, and/or functionalities. Furthermore, mathematical description of the rolling dynamics for this type of robot and how the models can be used for speed control are often not mentioned. This article introduces a cylindrical-shaped shell-bulging rolling soft wheel that employs an array of 16 folded HASEL actuators as a mean for improved rolling performance. The actuators represent the soft components with discrete forces that propel the wheel, whereas the wheel’s frame is rigid but allows for smooth, continuous change in position and speed. We discuss the interplay between the electrical and mechanical design choices, the modeling of the wheel’s hybrid (continuous and discrete) dynamic behavior, and the implementation of a model predictive controller (MPC) for the robot’s speed. With the balance of several design factors, we show the wheel’s ability to carry integrated hardware with a maximum rolling speed at 0.7 m/s (or 2.2 body lengths per second), despite its total weight of 979 g, allowing the wheel to outperform the existing rolling soft wheels with comparable weights and sizes. We also show that the MPC enables the wheel to accelerate and leverage its inherent braking capability to reach desired speeds—a critical function that did not exist in previous rolling soft systems.
# Motion and Path Planning 4
# Linear MPC-Based Motion Planning for Autonomous Surgery
## Keywords:
- Motion and Path Planning
- Medical Robots and Systems
- Optimization and Optimal Control
## Abstract:
Within the context of Robotic Minimally Invasive Surgery (R-MIS), we propose a novel linear model predictive controller formulation for the coordination of multiple autonomous robotic arms. The controller is synthesized by formulating a linear approximation of non-linear constraints, which allows the controller to be both computationally faster and better performing due to the increased prediction horizon allowed within the real-time control requirements for the proposed surgical application. The solution is validated under the expected constraints of a surgical scenario in which multiple laparoscopic tools must move and coordinate in a shared environment.
# Disk-Graph Probabilistic Roadmap: Biased Distance Sampling for Path Planning in a Partially Unknown Environment
## Keywords:
- Motion and Path Planning
- Range Sensing
- Autonomous Agents
## Abstract:
In this paper, we propose a new sampling-based path planning approach, focusing on the challenges linked to autonomous exploration. Our method relies on the definition of a disk graph of free-space bubbles, from which we derive a biased sampling function that expands the graph towards known free space for maximal navigability and frontiers discovery. The proposed method demonstrates an exploratory behavior similar to Rapidly-exploring Random Trees, while retaining the connectivity and flexibility of a graph-based planner. We demonstrate the interest of our method by first comparing its path planning capabilities against state-of-the-art approaches, before discussing exploration-specific aspects, namely replanning capabilities and incremental construction of the graph. A simple frontiers-driven exploration controller derived from our planning method is also demonstrated using the Pioneer platform.
# Elevation State-Space: Surfel-Based Navigation in Uneven Environments for Mobile Robots
## Keywords:
- Motion and Path Planning
- Field Robots
## Abstract:
This paper introduces a new method for robot motion planning and navigation in uneven environments through a surfel representation of underlying point clouds. The proposed method addresses the shortcomings of state-of-the-art navigation methods by incorporating both kinematic and physical constraints of a robot with standard motion planning algorithms (e.g., those from the Open Motion Planning Library), thus enabling efficient sampling-based planners for challenging uneven terrain navigation on raw point cloud maps. Unlike techniques based on Digital Elevation Maps (DEMs), our novel surfel-based state-space formulation and implementation are based on raw point cloud maps, allowing for the modeling of overlapping surfaces such as bridges, piers, and tunnels. Experimental results demonstrate the robustness of the proposed method for robot navigation in real and simulated unstructured environments. The proposed approach also optimizes planners' performances by boosting their success rates up to 5x for challenging unstructured terrain planning and navigation, thanks to our surfel-based approach's robot constraint-aware sampling strategy. Finally, we provide an open-source implementation of the proposed method to benefit the robotics community.
# Locomotion Policy Guided Traversability Learning Using Volumetric Representations of Complex Environments
## Keywords:
- Motion and Path Planning
- Legged Robots
- Deep Learning Methods
## Abstract:
Despite the progress in legged robotic locomotion, autonomous navigation in unknown environments remains an open problem. Ideally, the navigation system utilizes the full potential of the robots' locomotion capabilities while operating within safety limits under uncertainty. The robot must sense and analyze the traversability of the surrounding terrain, which depends on the hardware, locomotion control, and terrain properties. It may contain information about the risk, energy, or time consumption needed to traverse the terrain. To avoid hand-crafted traversability cost functions we propose to collect traversability information about the robot and locomotion policy by simulating the traversal over randomly generated terrains using a physics simulator. Thousand of robots are simulated in parallel controlled by the same locomotion policy used in reality to acquire 57 years of real-world locomotion experience equivalent. For deployment on the real robot, a sparse convolutional network is trained to predict the simulated traversability cost, which is tailored to the deployed locomotion policy, from an entirely geometric representation of the environment in the form of a 3D voxel-occupancy map. This representation avoids the need for commonly used elevation maps, which are error-prone in the presence of overhanging obstacles and multi-floor or low-ceiling scenarios. The effectiveness of the proposed traversability prediction network is demonstrated for path planning for the legged robot ANYmal in various indoor and natural environments.
# Jerk-Continuous Online Trajectory Generation for Robot Manipulator with Arbitrary Initial State and Kinematic Constraints
## Keywords:
- Motion and Path Planning
- Industrial Robots
- Manipulation Planning
## Abstract:
This work presents an online trajectory generation algorithm using a sinusoidal jerk profile. The generator takes initial acceleration, velocity and position as input, and plans a multi-segment trajectory to a goal position under jerk, acceleration, and velocity limits. By analyzing the critical constraints and conditions, the corresponding closed-form solution for the time factors and trajectory profiles are derived. The proposed algorithm was first derived in Mathematica and then converted into a C++ implementation. Finally, the algorithm was utilized and demonstrated in ROS & Gazebo using a UR3 robot. Both the Mathematica and C++ implementations can be accessed at https://github.com/Haoran-Zhao/Jerk-continuous-online-trajectory-generator-with-constraints.git
# Imitation Learning and Model Integrated Excavator Trajectory Planning
## Keywords:
- Motion and Path Planning
- Robotics and Automation in Construction
- Imitation Learning
## Abstract:
Automated excavation is promising to improve the safety and efficiency of excavators, and trajectory planning is one of the most important techniques. In this paper, we propose a two-stage method that integrates data-driven imitation learning and model-based trajectory optimization to generate optimal trajectories for autonomous excavators. We firstly train a deep neural network using demonstration data to mimic the operation patterns of human experts under various terrain states including their geometry shape and material type. Then, for a particular terrain, we use a stochastic trajectory optimization method to improve the trajectory generated by the neural network to guarantee kinematics feasibility, improve smoothness, satisfy hard constraints, and achieve desired excavation volumes. We test the proposed algorithm on a Franka robot arm. The experimental results show that the proposed two-stage algorithm by combing expert knowledge and model optimization can increase the excavation weights by up to 24.77% meanwhile with low variance.
# Online Complete Coverage Path Planning of a Reconfigurable Robot Using Glasius Bio-Inspired Neural Network and Genetic Algorithm
## Keywords:
- Motion and Path Planning
- Service Robotics
- AI-Based Methods
## Abstract:
Area coverage is crucial for robotics applications such as cleaning, painting, exploration, and inspections. Hinged reconfigurable robots have been introduced for these application domains to improve the area coverage performance. However, the existing coverage algorithms of hinged reconfigurable robots require improvements in the aspects; consideration of beyond a limited set of reconfigurable shapes, coordinated reconfiguration and navigation, and online decision-making. Therefore, this paper proposes a novel online Complete Coverage Path Planning (CCPP) method for a hinged reconfigurable robot. The proposed CCPP method is designed with two sub-methods, the Global Coverage Path Planning (GCPP) and Local Coverage Path Planning (LCPP). The GCPP method has been implemented, adapting a Glasius Bio-inspired Neural Network (GBNN) that performs online path planning considering a fixed shape for the robot. Obstacle regions that the GCPP would not adequately cover due to access constraints are covered by the LCPP method that considers concurrent reconfiguration and navigation of the robot. A genetic algorithm determines the reconfiguration parameters that ascertain collision-free coverage and access of obstacle regions. Experimental results validate that the proposed online CCPP method is effective in ascertaining the complete area coverage in heterogeneous environments, including dynamic workspaces. Furthermore, the deployment of the LCPP method can considerably improve the coverage.
# Quantity Over Quality: Training an AV Motion Planner with Large Scale Commodity Vision Data
## Keywords:
- Motion and Path Planning
- Autonomous Vehicle Navigation
- Deep Learning Methods
## Abstract:
With the Autonomous Vehicle (AV) industry shifting towards machine-learned approaches for motion planning, the performance of self-driving systems is starting to rely heavily on large quantities of expert driving demonstrations. However, collecting this demonstration data typically involves expensive HD sensor suites (LiDAR + RADAR + cameras), which quickly becomes financially infeasible at the scales required. This motivates the use of commodity sensors like cameras for data collection, which are an order of magnitude cheaper than HD sensor suites, but offer lower fidelity. Leveraging these sensors for training an AV motion planner opens a financially viable path to observe the 'long tail' of driving events.
As our main contribution we show it is possible to train a high-performance motion planner using commodity vision data which outperforms planners trained on HD-sensor data for a fraction of the cost. To the best of our knowledge, we are the first to demonstrate this using real-world data. We compare the performance of the autonomy system on these two different sensor configurations, and show that we can compensate for the lower sensor fidelity by means of increased quantity: a planner trained on 100h of commodity vision data outperforms the one with 25h of expensive HD data. We also share the engineering challenges we had to tackle to make this work.
# TIGRIS: An Informed Sampling-Based Algorithm for Informative Path Planning
## Keywords:
- Motion and Path Planning
- Field Robots
## Abstract:
Informative path planning is an important and challenging problem in robotics that remains to be solved in a manner that allows for wide-spread implementation and real-world practical adoption. Among various reasons for this, one is the lack of approaches that allow for informative path planning in high-dimensional spaces and non-trivial sensor constraints. In this work we present a sampling-based approach that allows us to tackle the challenges of large and high-dimensional search spaces. This is done by performing informed sampling in the high-dimensional continuous space and incorporating potential information gain along edges in the reward estimation. This method rapidly generates a global path that maximizes information gain for the given path budget constraints. We discuss the details of our implementation for an example use case of searching for multiple objects of interest in a large search space using a fixed-wing UAV with a forward-facing camera. We compare our approach to a sampling-based planner baseline and demonstrate how our contributions allow our approach to consistently out-perform the baseline by 18.0%. With this we thus present a practical and generalizable informative path planning framework that can be used for very large environments, limited budgets, and high dimensional search spaces, such as robots with motion constraints or high-dimensional configuration spaces.
# Biologically-Inspired Robots 4
# Online Learning Feedback Control Method Considering Hysteresis for Musculoskeletal Structures
## Keywords:
- Biomimetics
- Learning from Experience
- Tendon/Wire Mechanism
## Abstract:
While the musculoskeletal humanoid has various biomimetic benefits, its complex modeling is difficult, and many learning control methods have been developed. However, for the actual robot, the hysteresis of its joint angle tracking is still an obstacle, and realizing target posture quickly and accurately has been difficult. Therefore, we develop a feedback control method considering the hysteresis. To solve the problem in feedback controls caused by the closed-link structure of the musculoskeletal body, we update a neural network representing the relationship between the error of joint angles and the change in target muscle lengths online, and realize target joint angles accurately in a few trials. We compare the performance of several configurations with various network structures and loss definitions, and verify the effectiveness of this study on an actual musculoskeletal humanoid, Musashi.
# Realization of Seated Walk by a Musculoskeletal Humanoid with Buttock-Contact Sensors from Human Constrained Teaching
## Keywords:
- Biomimetics
- Soft Sensors and Actuators
- Tendon/Wire Mechanism
## Abstract:
In this study, seated walk, a movement of walking while sitting on a chair with casters, is realized on a musculoskeletal humanoid from human teaching. The body is balanced by using buttock-contact sensors implemented on the planar interskeletal structure of the human mimetic musculoskeletal robot. Also, we develop a constrained teaching method in which one-dimensional control command, its transition, and a transition condition are described for each state in advance, and a threshold value for each transition condition such as joint angles and foot contact sensor values is determined based on human teaching. Complex behaviors can be easily generated from simple inputs. In the musculoskeletal humanoid MusashiOLegs, forward, backward, and rotational movements of seated walk are realized.
# A Control Architecture of a Distributed Actuator System for a Bio-Inspired Spine
## Keywords:
- Biologically-Inspired Robots
- Biomimetics
- Actuation and Joint Mechanisms
## Abstract:
Control of an articulated spine is important for humanoids' dynamic and balanced motion. Although there have been many spinal structures for humanoids, their actuation is still limited due to the usage of geared-motors for joints. This paper introduces position control of a distributed electromechanical spine in a vertical plane. The spine dynamics model is approximated as an open chain. Gravitational and spring torques are compensated for the control. Moreover, torque-to-current conversion for the actuator is developed. Experimental results show the implemented control of the electromechanical spine for undulatory motions.
# Development of a Conveyor-Type Object Release Mechanism for a Parallel Gripper with a Mushroom-Shaped Gecko-Inspired Surface
## Keywords:
- Grasping
- Biologically-Inspired Robots
- Actuation and Joint Mechanisms
## Abstract:
It is known that the surface microstructure, which mimics the surface of a gecko's foot, exerts a large gripping force with a tiny contact force. By applying this structure to the fingertips of a two-fingered parallel gripper, stable grasping can be achieved independent of the wetting and frictional state of the contact surface. However, when releasing an object, the adhesive force of the microstructure is large, which hinders the release of the object. In this study, we developed a releasing mechanism using a conveyor mechanism, focusing on the characteristic of the micro-protrusion structure that easily peels off in the direction of rotation. This mechanism is driven in conjunction with the gripper's grasping and releasing motions, and experiments have confirmed that it can stably release the object.
# Instantaneous Force Generation Mechanism Based on the Striking Motion of Mantis shrimp—Design and Control Method of Cavitation by Simulation and Experiment
## Keywords:
- Biomimetics
- Soft Robot Applications
- Dynamics
## Abstract:
In this paper, we describe simulations and experiments on the occurrence of cavitation with an instantaneous force generation mechanism based on the motion of the mantis shrimp. The aim of this study is to strengthen the striking force of the developed mechanism by realizing the mechanism of cavitation occurrence. This paper presents a motion and cavitation model for the developed mechanism and provides the results of the simulations and experiments considering the occurrence of cavitation. In previous studies, mantis shrimp have been shown to have two consecutive impacts on a hard object with cavitation in water. However, no robot can imitate the striking mechanism of the mantis shrimp and replicate two consecutive impacts. In this study, the mechanism was designed and developed based on a mantis shrimp model. From the experiment, it was observed that the developed mechanism caused cavitation only at the point of impact, rather than during arm swing. This result suggested that the striking force was strengthened, providing insight into the striking mechanism of the mantis shrimp.
# Upside-Down Brachiation Robot Using Elastic Energy Stored through Soft Body Deformation
## Keywords:
- Soft Robot Applications
- Soft Robot Materials and Design
- Flexible Robotics
## Abstract:
Storing elastic energy in a soft body and releasing it instantly enables ultrafast movement beyond muscle capability, which small animals (mainly arthropods) realize. We applied this mechanism to a soft robot to achieve locomotion on top of a tubular surface such as a branch (i.e., upside-down brachiation). To achieve arboreal locomotion, the robot must have strong grippers to support its body and minimize the duration of time when one gripper is off the branch. By using a simulation model and prototype, we demonstrated that storing and releasing elastic energy in a soft body satisfies these requirements, allowing us to fabricate a lightweight robot. The prototype completed one step of the locomotion process in 0.22 secs, making it 2.3 times faster than the original speed of the mounted motor. In addition, we confirmed that the robot climbs 0# to 90-degree branches.
# Learning of Balance Controller Considering Changes in Body State for Musculoskeletal Humanoids
## Keywords:
- Biomimetics
- Learning from Experience
- Bioinspired Robot Learning
## Abstract:
The musculoskeletal humanoid is difficult to modelize due to the flexibility and redundancy of its body, whose state can change over time, and so balance control of its legs is challenging. There are some cases where ordinary PID controls may cause instability. In this study, to solve these problems, we propose a method of learning a correlation model among the joint angle, muscle tension, and muscle length of the ankle and the zero moment point to perform balance control. In addition, information on the changing body state is embedded in the model using parametric bias, and the model estimates and adapts to the current body state by learning this information online. This makes it possible to adapt to changes in upper body posture that are not directly taken into account in the model, since it is difficult to learn the complete dynamics of the whole body considering the amount of data and computation. The model can also adapt to changes in body state, such as the change in footwear and change in the joint origin due to recalibration. The effectiveness of this method is verified by a simulation and by using an actual musculoskeletal humanoid, Musashi.
# Locomotion Via Active Suction in a Sea Star-Inspired Soft Robot
## Keywords:
- Biologically-Inspired Robots
- Soft Robot Applications
- Hydraulic/Pneumatic Actuators
## Abstract:
Some marine animals, such as sea stars, have developed versatile adhesive appendages that can be used for a variety of behaviors including sticking to surfaces, manipulating objects, and locomoting. These appendages couple reversible adhesion capabilities with muscular structures that can do work on the world while still being soft enough to conform to various surfaces and to squeeze through tight spaces. We took inspiration from the hydraulic tube feet of sea star to create modules consisting of soft active suction discs and soft pneumatic linear actuators. Tube feet convert fluid motion into linear actuation using soft tubes that are constrained radially. In this work, we study the tradeoff between the stiffness of such radial constraints, and the ability of the linear actuators to apply axial forces. The adhesive force of the suction disc is dependent on both the pressure differential between the suction cavity and the environment and the deformation within the body of the disc while it is being loaded. We show that the tube foot modules are capable of creating locomotion over flat surfaces, up small steps, and in a confined space due to the redundancy caused by an array of actuators. We also show that active suction not only enables the use of softer tube foot actuators, but sensing the active suction line provides feedback to increase the efficiency of locomotion over obstacles.
# Joint-Space CPG for Safe Foothold Planning and Body Pose Control During Locomotion and Climbing
## Keywords:
- Biologically-Inspired Robots
- Legged Robots
- Biomimetics
## Abstract:
From insects to larger mammals, legged animals can be seen easily traversing a wide variety of challenging environments, by carefully selecting, reaching, and exploiting high-quality contacts with the terrain. In contrast, existing robotic foothold planning methods remain computationally expensive, often relying on exhaustive search and/or (often offline) optimization methods, thus limiting their adoption for real-life robotic deployments. In this work, we propose a low-cost, bio-inspired foothold planning method for legged robots, which replicates the mechanism of the central nervous system of legged mammals. We develop a low-level joint-space CPG model along with a high-level vision-based controller that can inexpensively predict future foothold locations and locally optimize them based on a potential field based approach. Specifically, by reasoning about the quality of ground contacts and the robot's stability through the high-level vision-based controller, our CPG model smoothly and iteratively updates relevant locomotion parameters to both optimize foothold locations and body pose, directly in the joint space of the robot for easier implementation. We experimentally validate our control model on a modular hexapod on various locomotion tasks in obstacle-rich environments as well as on stair climbing. Our results show that our method enables stabler and steadier locomotion, yielding higher-quality feedback from onboard sensors by minimizing the effect of slippage and unexpected impacts.
# Distributed Robot Systems
# Real-Time Distributed Multi-Robot Target Tracking Via Virtual Pheromones
## Keywords:
- Distributed Robot Systems
- Search and Rescue Robots
- Autonomous Vehicle Navigation
## Abstract:
Actively searching for targets using a multi-agent system in an unknown environment poses a two-pronged problem, where on the one hand we need agents to cover as much of the environment as possible and on the other have a higher density of agents where there are potential targets to maximize detection performance. This paper proposes a fully distributed solution for an ad hoc network of agents to cooperatively search an unknown environment and actively track found targets. The solution combines a distributed pheromone-based coverage control strategy with a distributed target selection mechanism.
# Conservative Filtering for Heterogeneous Decentralized Data Fusion in Dynamic Robotic Systems
## Keywords:
- Distributed Robot Systems
- Multi-Robot Systems
- Sensor Fusion
## Abstract:
This paper presents a method for Bayesian multi-robot peer-to-peer data fusion where any pair of autonomous robots hold non-identical, but overlapping parts of a global joint probability distribution, representing real world inference tasks (e.g., mapping, tracking). It is shown that in dynamic stochastic systems, filtering, which corresponds to marginalization of past variables, results in direct and hidden dependencies between variables not mutually monitored by the robots, which might lead to an overconfident fused estimate. The paper makes both theoretical and practical contributions by providing (i) a rigorous analysis of the origin of the dependencies and (ii) a conservative filtering algorithm for heterogeneous data fusion in dynamic systems that can be integrated with existing fusion algorithms. This work uses factor graphs as both the analysis tool and the inference engine. Each robot in the network maintains a local factor graph and communicates only relevant parts of it (a sub-graph) to its neighboring robot. We discuss the applicability to various multi-robot robotic applications and demonstrate the performance using a multi-robot multi-target tracking simulation, showing that the proposed algorithm produces conservative estimates at each robot.
# Decay-Based Error Correction in Collective Robotic Construction
## Keywords:
- Distributed Robot Systems
- Swarm Robotics
- Assembly
## Abstract:
Multi-robot systems have been shown to build large-scale, blueprint-specific structures using distributed, environmentally-mediated coordination. Little attention, however, has been devoted to error propagation and mitigation. In this paper, we introduce a detailed simulation of TERMES, a prototypical construction system, in which robots have realistic error profiles. We use this simulator and 32 randomly generated 250-brick blueprints to show that action errors can have significant long-term effects. We study the spatio-temporal error distribution and introduce and characterize the efficacy of a simple decay-based error correction mechanism. Although inefficient, this type of error correction is promising because it can be performed by robots with the same limited sensory capabilities as those who place bricks. To limit the impact on the construction rate, we also examine decay mechanisms informed by spatial and temporal error distributions. The incorporation of decay in our building process increases the probability of successful completion by ~4, at the expense of ~1/4 decrease in construction rate.
# Perceive, Represent, Generate: Translating Multimodal Information to Robotic Motion Trajectories
## Keywords:
- Multi-Modal Perception for HRI
- Deep Learning Methods
- Human-Robot Collaboration
## Abstract:
We present **Perceive-Represent-Generate** (PRG), a novel three-stage framework that maps perceptual information of different modalities (e.g., visual or sound), corresponding to a series of instructions, to a sequence of movements to be executed by a robot. In the first stage, we perceive and preprocess the given inputs, isolating individual commands from the complete instruction provided by a human user. In the second stage we encode the individual commands into a multimodal latent space, employing a deep generative model. Finally, in the third stage we convert the latent samples into individual trajectories and combine them into a single dynamic movement primitive, allowing its execution by a robotic manipulator. We evaluate our pipeline in the context of a novel robotic handwriting task, where the robot receives as input a word through different perceptual modalities (e.g., image, sound), and generates the corresponding motion trajectory to write it, creating coherent and high-quality handwritten words.
# SMA-NBO: A Sequential Multi-Agent Planning with Nominal Belief-State Optimization in Target Tracking
## Keywords:
- Distributed Robot Systems
- Cooperating Robots
- Reactive and Sensor-Based Planning
## Abstract:
In target tracking with mobile multi-sensor systems, sensor deployment impacts the observation capabilities and the resulting state estimation quality. Based on a partially observable Markov decision process (POMDP) formulation comprised of the observable sensor dynamics, unobservable target states, and accompanying observation laws, we present a distributed information-driven solution approach to the multi-agent target tracking problem, namely, sequential multi-agent nominal belief-state optimization (SMA-NBO). SMA-NBO seeks to minimize the expected tracking error via receding horizon control including a heuristic expected cost-to-go (HECTG). SMA-NBO incorporates a computationally efficient approximation of the target belief-state over the horizon. The agent-by-agent decision-making is capable of leveraging on-board (edge) compute for selecting (sub-optimal) target-tracking maneuvers exhibiting non-myopic cooperative fleet behavior. The optimization problem explicitly incorporates semantic information defining target occlusions from a world model. To illustrate the efficacy of our approach, a random occlusion forest environment is simulated. SMA-NBO is compared to other baseline approaches. The simulation results show SMA-NBO 1) maintains tracking performance and reduces the computational cost by replacing the calculation of the expected target trajectory with a single sample trajectory based on maximum a posteriori estimation; 2) generates cooperative fleet decision by sequentially optimizing single-agent policy with efficient usage of other agents' policy of intent; 3) aptly incorporates the multiple weighted trace penalty (MWTP) HECTG, which improves tracking performance with a computationally efficient heuristic.
# Influence of Variable Leg Elasticity on the Stability of Quadrupedal Gaits
## Keywords:
- Natural Machine Motion
- Legged Robots
- Passive Walking
## Abstract:
Several template models have been developed to facilitate the analysis of limit-cycles for quadrupedal locomotion. The parameters in the model are usually fixed; however, biology shows that animals change their leg stiffness according to the locomotion velocity, and this adaptability invariably affects the stability of the gait. This paper provides an analysis of the influence of this variable leg stiffness on the stability of different quadrupedal gaits. The analysis exploits a simplified quadrupedal model with compliant legs and shoulder joints represented as torsional springs. This model can reproduce the most common quadrupedal gaits observed in nature. The stability of such emerging gaits is then checked. Afterward, an optimization process is used to search for the system parameters that guarantee maximum gait stability. Our study shows that using the highest feasible leg swing frequency and adopting a leg stiffness that increases with the speed of locomotion noticeably improves the gait stability over a wide range of horizontal velocities while reducing the oscillations of the trunk. This insight can be applied in the design of novel elastic quadrupedal robots, where variable stiffness actuators could be employed to improve the overall locomotion behavior.
# Learning to Act with Affordance-Aware Multimodal Neural SLAM
## Keywords:
- Multi-Modal Perception for HRI
- SLAM
- Integrated Planning and Learning
## Abstract:
Recent years have witnessed an emerging paradigm shift toward embodied artificial intelligence, in which an agent must learn to solve challenging tasks by interacting with its environment. There are several challenges in solving embodied multimodal tasks, including long-horizon planning, vision-and-language grounding, and efficient exploration. We focus on a critical bottleneck, namely the performance of planning and navigation. To tackle this challenge, we propose a Neural SLAM approach that, for the first time, utilizes several modalities for exploration, predicts an affordance-aware semantic map, and plans over it at the same time. This significantly improves exploration efficiency, leads to robust long# horizon planning, and enables effective vision-and-language grounding. With the proposed Affordance-aware Multimodal Neural SLAM (AMSLAM) approach, we obtain more than 40% improvement over prior published work on the ALFRED benchmark and set a new state-of-the-art generalization performance at a success rate of 23.48% on the test unseen scenes.
# Learning to Assess Danger from Movies for Cooperative Escape Planning in Hazardous Environments
## Keywords:
- Multi-Modal Perception for HRI
- Search and Rescue Robots
## Abstract:
There has been a plethora of work towards improving robot perception and navigation, yet their application in hazardous environments, like during a fire or an earthquake, is still at a nascent stage. We hypothesize two key challenges here: first, it is difficult to replicate such scenarios in the real world, which is necessary for training and testing purposes. Second, current systems are not fully able to take advantage of the rich multi-modal data available in such hazardous environments. To address the first challenge, we propose to harness the enormous amount of visual content available in the form of movies and TV shows, and develop a dataset that can represent hazardous environments encountered in the real world. The data is annotated with high-level danger ratings for realistic disaster images, and corresponding keywords are provided that summarize the content of the scene. In response to the second challenge, we propose a multi-modal danger estimation pipeline for collaborative human-robot escape scenarios. Our Bayesian framework improves danger estimation by fusing information from robot's camera sensor and language inputs from the human. Furthermore, we augment the estimation module with a risk-aware planner that helps in identifying safer paths out of the dangerous environment. Through extensive simulations, we exhibit the advantages of our multi-modal perception framework that gets translated into tangible benefits such as higher success rate in a collaborative human-robot mission.
# Distributed Deployment with Multiple Moving Robots for Long Distance Complex Pipe Inspection
## Keywords:
- Distributed Robot Systems
- Biomimetics
- Flexible Robotics
## Abstract:
In this study, we propose a method to reduce the traveling load by designing a distributed robot arrangement that considers the shape of a
pipeline for a cabled in-pipe mobile robot. The objective of this study
is to establish a method to reduce the friction acting on the wires of a self-propelled in-pipe mobile robot and develop a robotic system that
can inspect long-distance pipes. This study contributes the purpose of this research in that it proposes a model for estimating the tension acting on the wires of a mobile robot in a pipe and describes a method for reducing the traveling load using a distributed arrangement of robots. The friction acting on the wires in the bent pipe becomes a load for the robots moving in the pipe while towing the wires. Therefore, it is difficult for these robots to inspect complex, long-distance pipelines. Furthermore, we clarified the factors that cause friction forces in long-distance pipes and modeled and quantified
the friction forces acting on the wires in the pipes so that each factor could be addressed. Using this model, we propose a distributed deployment method, in which multiple mobile robots are deployed. By driving two robots separated by a distance, we confirmed that two robots could move at 2.5 mm/s in a pipeline that could not be moved by a single robot. Moreover, we proposed a method for controlling the robot according to the load acting on it and confirmed that the robot equipped with this control could inspect a narrow pipe with an inner diameter of 108 mm, where a load of approximately 340 N acted on the back end of the robot, with an efficiency that was approximately 1.7 times higher. This result has the potential to enable the configuration
and control of robots, which would be difficult to
# Medical Robots and Systems 4
# Time-Optimal Synchronous Terminal Trajectory Planning for Coupling Motions of Robotic Flexible Endoscope
## Keywords:
- Flexible Robotics
- Surgical Robotics: Planning
- Surgical Robotics: Steerable Catheters/Needles
## Abstract:
The robotic flexible endoscope is developed rapidly in the field of surgery robots due to its high flexibility and safety. However, some inherent features, e.g., high nonlinearity, material creep, complex dynamic hysteresis behaviors, and the unknown coupling effects between bending and twisting motions, can lead to the significant degradation on three-dimensional (3-D) positioning performance of the endoscope. Aiming at these challenges, this paper built a practical multi-motion hysteresis phenomenon model for the bending and twisting motions of the robotic flexible endoscope with consideration of the coupling effects. Then, the time-optimal synchronous terminal motion planner is first proposed for the 3-D motions of the robotic endoscope to decouple the coupling effects in an intuitive separate control scheme. Finally, a series of hardware experiments are conducted on a robotic flexible ureteroscope platform. The accuracy of the proposed model and the trajectory-planning-based decoupling strategy is comprehensively validated. Particularly, the experimental results with the proposed trajectory planner show the satisfactory performance of vibration suppression and over-shoot suppression.
# Robotic Actuation and Control of a Catheter for Structural Intervention Cardiology
## Keywords:
- Surgical Robotics: Steerable Catheters/Needles
- Medical Robots and Systems
- Surgical Robotics: Planning
## Abstract:
Structural intervention cardiology (SIC) interventions are crucial procedures for correcting heart valves, wall, and muscle form defects. However, the possibility of embolization or perforation, as well as the lack of transparent vision and autonomous surgical equipment, make it difficult for the clinician. In this paper, we propose a robot-assisted tendon-driven catheter and machine learning-based path planner to overcome these challenges. Firstly, an analytical inverse kinematic model is constructed to convert the tip location in the Cartesian space to the tendons’ displacement. Then inverse reinforcement learning algorithm is employed to calculate the the optimal path to avoid possible collisions between the catheter tip and the atrial wall. Moreover, a closed-loop feedback controller is adopted to improve positioning accuracy in a direct distal position measurement manner. Simulation and experiments are designed and conducted to demonstrate the feasibility and performance of the proposed system.
# A Kinematic Modeling and Control Scheme for Different Robotic Endoscopes: A Rudimentary Research Prototype
## Keywords:
- Medical Robots and Systems
- Flexible Robotics
- Visual Tracking
## Abstract:
In image-guided robotic surgery, there exist different endoscopes coupled either with specialized surgical robots (SSRs) or general industrial robots (GIRs). In general, SSRs mechanically respect the remote-center-of-motion (RCM) constraints with directly and explicitly controllable degrees-of-freedom (DoFs), whereas GIRs meet the constraints at the algorithmic level in an implicit manner, with a loss of direct control of some RCM DoFs. Conventionally, different robotic endoscopes are treated as different monolithic systems. Then, kinematic models and control schemes are separately established to automate different robotic endoscopes. This means that a similar analysis must be followed for each system, which is tedious and time-consuming. This paper introduces a modular method to analyze the individual kinematics of the robotic holder, the endoscope shaft and the surgical endoscope with RCM constraints explicitly handled. For achieving automation, the integrated kinematics of a generic robotic endoscope is determined by combining the kinematics of the modular elements. Considering that cameras are intrinsically embedded sensors, a visual servo control scheme applicable to different robotic endoscopes is formulated to incorporate four explicit (virtual) DoFs characterizing the RCM constraints in the control law. Simulations and experiments performed using three different robotic endoscopes validate the effectiveness and practicality of the kinematic modeling and control scheme for automatic field-of-view adjustment.
# Real-Time Intraoperative Surgical Guidance System in the Da Vinci Surgical Robot Based on Transrectal Ultrasound/photoacoustic Imaging with Photoacoustic Markers: An Ex Vivo Demonstration
## Keywords:
- Medical Robots and Systems
- Software-Hardware Integration for Robot Systems
## Abstract:
This paper introduces an integrated real-time intraoperative surgical guidance system, in which an endoscope camera of da Vinci surgical robot and a transrectal ultrasound (TRUS) transducer are co-registered using photoacoustic markers that are detected in both fluorescence (FL) and photoacoustic (PA) imaging. The co-registered system enables the TRUS transducer to track the laser spot illuminated by a pulsed-laser-diode attached to the surgical instrument, providing both FL and PA images of the surgical region-of-interest (ROI). As a result, the generated photoacoustic marker is visualized and localized in the da Vinci endoscopic FL images, and the corresponding tracking can be conducted by rotating the TRUS transducer to display the PA image of the marker. A quantitative evaluation revealed that the average registration and tracking errors were 0.84 mm and 1.16°, respectively. This study shows that the co-registered photoacoustic marker tracking can be effectively deployed intraoperatively using TRUS+PA imaging providing functional guidance of the surgical ROI.
# Model-Free and Uncalibrated Visual-Feedback Control of Magnetically-Actuated Flexible Endoscopes
## Keywords:
- Flexible Robotics
- Surgical Robotics: Steerable Catheters/Needles
- Visual Servoing
## Abstract:
Magnetically-actuated flexible endoscopes (MAFE) have been well used in minimally-invasive surgery because they can be steered by a magnetic field thus more flexible than traditional endoscopes. Model-free and uncalibrated visual feedback control makes it possible to manipulate MAFE with a magnetic field without external tracking systems. Because no extra sensor is required to obtain position and posture information, the size of MAFE can be made smaller. However, the traditional control method focuses on 2DoF control, which lacks control over the posture of the end of MAFE. In this way, the friction between MAFE and tissue may cause injury during the advancement of the endoscope. In this paper, we propose algorithms to enhance the pose control of MAFE to 4DoF and 5DoF based on model-free and uncalibrated visual-feedback control. Experiments in structured environments verify that the control algorithms can realize 4DoF manual navigation and 5DoF automatic navigation.
# Design, Teleoperation Control and Experimental Validation of a Dexterous Robotic Flexible Endoscope for Laparoscopic Surgery
## Keywords:
- Medical Robots and Systems
- Surgical Robotics: Laparoscopy
- Flexible Robotics
## Abstract:
Existing robotic endoscopes for laparoscopic surgery, predominantly rigid or limited in dexterity, occupy a large motion space1. The large occupied motion space necessitates large incisions and reduces the motion space for surgeons to simultaneously operate other surgical instruments. Meanwhile, surgeons only have limited view adjustment capability to avoid occlusion and they often have to lift/push some organs to observe occluded target lesions in some operations such as cholecystectomy. The situation gets worse when the operations are on obese patients. In this paper, we develop a novel dexterous robotic flexible endoscope (DRFE), which is comprised of a concentric cable-driven structure and a 2-DoF articulated joint attached to the end of DRFE, for laparoscopic surgery. The proposed design occupies much less motion space both inside and outside human body as compared to conventional robotic flexible endoscopes. When used in surgery, the part of the endoscope outside the body can remain still, which reduces the risk of expanding the incision and simplifies the structure of the remote center mechanism. Simulation and experimental studies are performed to validate the effectiveness of the proposed device in the improvement of vision occlusion and usability. Initial results reveal that the DRFE is highly dexterous and accurate in observing lesions with vision occlusion.
# A Miniature Continuum Robot with Integrated Piezoelectric Beacon Transducers and Its Ultrasonic Shape Detection in Robot-Assisted Minimally Invasive Surgeries
## Keywords:
- Surgical Robotics: Steerable Catheters/Needles
- Medical Robots and Systems
- Flexible Robotics
## Abstract:
Minimally invasive surgeries (MIS) or natural orifice transluminal endoscopic surgeries (NOTES) such as the transurethral resection of bladder tumor (TURBT) require the surgical robot to be miniaturized to perform surgical procedures in confined spaces. However, the surgical robot’s tiny size poses problems in its fabrication and shape sensing. In this paper, a miniature continuum surgical robot is proposed with a unique laminated structure which can be fabricated through a 2D lamination process and converted into 3D through folding. This multi-material laminated structure also facilitates the integration of tiny piezoelectric transducers on the robot’s surface as beacons to generate ultrasonic waves for shape detection. A novel beacon total focusing method (b-TFM) algorithm is developed to process the received ultrasonic data and create a high-quality ultrasonic image from which the shape of the continuum robot can be extracted. The proposed robot and the ultrasonic shape detection method are validated through simulations and experiments. The error in the open-loop trajectory control is less than 4 mm without compensation, and the error in the ultrasonic shape detection is less than 1 mm. This confirms the possibility of improving the trajectory control accuracy by using the detected shape as a feedback for closed-loop control.
# A Domain-Adapted Machine Learning Approach for Visual Evaluation and Interpretation of Robot-Assisted Surgery Skills
## Keywords:
- Medical Robots and Systems
- Human-Robot Collaboration
- Representation Learning
## Abstract:
In this study, we present an intuitive machine learning-based approach to evaluate and interpret surgical skills level of a participant working with robotic platforms. The proposed method is domain-adapted, i.e., jointly utilizes an end-to-end learning approach for smoothness detection and domain knowledge-based metrics such as fluidity and economy of motion for extracting skills-related features within a given trajectory. An advantage of our approach compared to similar stochastic or deep learning models is its intuitive and transparent manner for extraction and visualization of skills-related features within the data. We illustrate the performance of our proposed method on trials of the JIGSAWS data set as well as our own experimental data gathered from Phantom Premium 1.5A Haptic Device. This approach utilized tSNE technique and provides visualized low-dimensional representation for different trials that highlights nuanced information within the executive task and returns unusual or faulty trials as outliers far away from their normal skill or participant clusters. This information regarding the input trajectory can be used for evaluation and education applications such as learning curve analysis in surgical assessment and training programs.
# Automating Surgical Peg Transfer: Calibration with Deep Learning Can Exceed Speed, Accuracy, and Consistency of Humans (I)
## Keywords:
- Calibration and Identification
- Deep Learning in Grasping and Manipulation
- Kinematics
## Abstract:
Peg transfer is a well-known surgical training task in the Fundamentals of Laparoscopic Surgery (FLS). While human sur-geons teleoperate robots such as the da Vinci to perform this task with high speed and accuracy, it is challenging to automate. This paper presents a novel system and control method using a da Vinci Research Kit (dVRK) surgical robot and a Zivid depth sensor, and a human subjects study comparing performance on three variants of the peg-transfer task: unilateral, bilateral without handovers, and bilateral with handovers. The system combines 3D printing, depth sensing, and deep learning for calibration with a new analytic inverse kinematics model and time-minimized motion controller. In a controlled study of 3384 peg transfer trials performed by the system, an expert surgical resident, and 9 volunteers, results suggest that the system achieves accuracy on par with the experienced surgical resident and is significantly faster and more consistent than the surgical resident and volunteers. The system also exhibits the highest consistency and lowest collision rate. To our knowledge, this is the first autonomous system to achieve “superhuman” performance on a standardized surgical task. All data is available at https://sites.google.com/view/surgicalpegtransfer.
# Computer Vision for Automation 1
# RGB-X Classification for Electronics Sorting
## Keywords:
- Computer Vision for Automation
- Deep Learning for Visual Perception
- Recognition
## Abstract:
Effectively disassembling and recovering materials from Waste Electrical and Electronic Equipment (WEEE) is a critical step in moving global supply chains from carbon-intensive, mined materials to recycled and renewable ones. Traditional recycling processes rely on shredding and sorting waste streams, but for WEEE, which is comprised of numerous dissimilar materials in a small volume, we explore targeted disassembly of numerous objects for improved material recovery. Since many WEEE objects can look very similar due to common features, but their material composition and internal component layout can vary, it is critical to have an accurate classifier for subsequent disassembly steps for accurate material separation and recovery. This work introduces RGB-X, a multi-modal image classification approach, that innovatively utilizes key features from external RGB images with those generated from X-ray images to very accurately classify electronic objects. More specifically, this work develops Iterative Class Activation Mapping (iCAM), a novel network architecture that explicitly focuses on the finer-details in the multi-modal feature maps that are needed for accurate electronic object classification. Electronic objects lack large and well annotated X-ray datasets for training due to expense and need of expert guidance. To overcome this constraint, we present a novel way of creating a synthetic dataset using domain randomization applied to the X-ray domain. The combined RGBX approach gives us an accuracy of 98.6% on 10 generations of modern smartphones, which is greater than their individual accuracies of 89.1% (RGB) and 97.9% (X-ray) independently. We provide experimental results3 to corroborate our results.
# CPQNet: Contact Points Quality Network for Robotic Grasping
## Keywords:
- Computer Vision for Automation
- Deep Learning in Grasping and Manipulation
- Grasping
## Abstract:
In typical data-based grasping methods, a grasp based on parallel-jaw grippers is parameterized by the center of the gripper, the rotation angle, and the gripper opening width so as to predict the quality and pose of grasps at every pixel. In contrast, a grasp is represented using only two contact points for contact-points-based grasp representation, which allows for fusion with tactile sensors more naturally. In this work, we propose a method using contact-points-based grasp representation to get a robust grasp using only one contact points quality map generated by a neural network, which significantly reduces the complexity of the network with fewer parameters. We provide a synthetic dataset including depth image and contact points quality map generated by thousands of 3D models. We also provide the method for data generation, which can be used for contact-points-based multi-fingers grasp. Experiments show that contact points quality network can plan an available grasp in 0.15 seconds. The grasping success rate for unknown household objects is 94%. Our method is also available for deformable objects with a success rate of 95%. The dataset and reference code can be found on the project website: https://sites.google.com/view/cpqnet.
# SESR: Self-Ensembling Sim-To-Real Instance Segmentation for Auto-Store Bin Picking
## Keywords:
- Computer Vision for Automation
- Object Detection, Segmentation and Categorization
- Deep Learning Methods
## Abstract:
Instance segmentation is an important task for supporting robotic grasping in auto-store scenarios. Accurate segmentation usually relies on the quantity and quality of available annotated training data. However, it requires tremendous cost to obtain these labels. In this work, without requiring any human annotations on real data, our proposed self-ensembling sim-to-real network, namely SESR, is able to generate precise instance masks for a wide variety of supermarket goods. We design our SESR with a teacher model and a student model trained with a self-ensembling strategy. We adopt different levels of consistency to bridge the sim-to-real gap and boost the model generalization ability. Also, we compile an auto-store bin-picking dataset covering various goods. Extensive experiments on both unseen scenarios and unseen objects validate the effectiveness and superiority of our method over others, and the robot arm demonstrations further show that our segmentation results can support real-time auto-store bin picking.
# Visual Odometry in HDR Environments by Using Spatially Varying Exposure Camera
## Keywords:
- Vision-Based Navigation
- SLAM
- Computer Vision for Automation
## Abstract:
The accuracy and robustness of visual odometry (VO) is significantly affected by the high dynamic range (HDR) environments, because traditional cameras have a limited dynamic range and inevitably miss information in both overexposed and underexposed areas. To overcome the above challenge, we use an spatially varying exposure (SVE) camera, which captures four images with different exposure levels simultaneously. Then, we propose a VO pipeline that leverages the advantages of the SVE camera. Specifically, we extract ORB features from four images in parallel firstly instead of fusing four images, then perform merging and filtering to provide more robust features. We demonstrate that the proposed system outperforms comparable state-of-the-art methods in terms of robustness and accuracy. The real-time performance of the proposed system is also guaranteed due to the elaborate design of the parallel algorithm.
# Trifocal Tensor and Relative Pose Estimation from 8 Lines and Known Vertical Direction
## Keywords:
- Vision-Based Navigation
- SLAM
- Computer Vision for Automation
## Abstract:
In this paper, we present a relative pose estimation algorithm based on lines knowing the vertical direction associated to each image. We demonstrate that a closed-form solution requiring only eight lines between three views is possible. As a linear solution, it is shown that our approach outperforms the standard trifocal estimation based on 13 triplets of lines and can be efficiently inserted into an hypothesize-and-test framework such as RANSAC. We also study our approach on different singular configurations of lines. The method is evaluated on both synthetic data and real-world sequences from KITTI and the Zürich Urban Micro Aerial Vehicle datasets. Our method is compared to 13 lines algorithm as well to points based methods such as 7-points, 5-points and 3-points.
# Lidar with Velocity: Motion Distortion Correction of Point Clouds from Oscillating Scanning Lidars
## Keywords:
- Computer Vision for Transportation
- Visual Tracking
- Intelligent Transportation Systems
## Abstract:
Lidar point cloud distortion from moving object is an important problem in autonomous driving, and recently becomes more demanding with the emerging of oscillating type lidars, which feature back-and-forth scanning patterns and complex distortions. Accurately correcting the point cloud distortion would not only describe the 3D moving objects more accurately, but also enable accurate estimation of moving objects' velocities with enhanced prediction and tracking capabilities. A lidar and camera fusion approach is proposed to correct the oscillating lidar distortions with full velocity estimation. Lidar measures the time-of-flight distance accurately in the radial direction but only with sparse angular information while camera as a complementary sensor could provide a dense angular resolution. In addition, the proposed framework utilizes a probabilistic Kalman-filter approach to combine the estimated velocities and track the moving objects with their real-time velocities and correct point clouds. The proposed framework is evaluated on real road data and consistently outperforms other methods. The complete framework is open-sourced (https://github.com/ISEE-Technology/lidar-with-vel ocity) to accelerate the adoption of the emerging lidars.
# A Flexible and Robust Vision Trap for Automated Part Feeder Design
## Keywords:
- Computer Vision for Automation
- Assembly
## Abstract:
Fast, robust, and flexible part feeding is essential for enabling automation of low volume, high variance assembly tasks. An actuated vision-based solution on a traditional vibratory feeder, referred to here as a vision trap, should in principle be able to meet these demands for a wide range of parts. However, in practice, the flexibility of such a trap is limited as an expert is needed to both identify manageable tasks and to configure the vision system. We propose a novel approach to vision trap design in which the identification of manageable tasks is automatic and the configuration of these tasks can be delegated to an automated feeder design system. We show that the trap's capabilities can be formalized in such a way that it integrates seamlessly into the ecosystem of automated feeder design. Our results on six canonical parts show great promise for autonomous configuration of feeder systems.
# Leveraging Local Planar Motion Property for Robust Visual Matching and Localization
## Keywords:
- Localization
- Service Robotics
## Abstract:
One primary difficulty preventing the visual localization for service robots is the robustness against changes, including environmental changes and perspective changes. In recent years, learning-based feature matching methods have been widely studied and effectively verified in practical applications. Learning-based feature matching effectively solves the problem of environmental changes, including illumination changes and man-made changes. However, there is still room for improvement dealing with large perspective changes. In this paper, we leverage local planar motion property to simplify the affine transform and propose an augmentation-based feature matching method that greatly enhances the robustness to perspective changes. The proposed feature matching approach maintains low matching costs as the augmentation is performed on the simplified affine matrix space. Combined with the motion property aided minimal solution for pose estimation, an end-to-end robust visual localization system is proposed which is shown to bring 67% improvement in localization performance under large perspective changes in publicly available OpenLORIS dataset, while increasing computational cost by only 20% by using batch processing techniques with a single GPU. In addition, a guide for map frame selection is presented to support robust localization with very sparse map frames in storage. Experiments on the classified dataset with environmental changes and perspective changes validate the effectiveness of the proposed system.
# AFR: An Efficient Buffering Algorithm for Cloud Robotic Systems
## Keywords:
- Software, Middleware and Programming Environments
- Networked Robots
- Agent-Based Systems
## Abstract:
Communication between robots and the server is a major problem for cloud robotic systems. In this paper, we address the problem caused by data loss during such communications, and propose an efficient buffering algorithm, called AFR, to solve the problem. We model the problem into an optimization problem to maximize the received Quantity of Information (QoI). Our AFR algorithm is formally proved to achieve near-optimal QoI, which has a lower bound that is a constant multiple of the unrealizable optimal QoI. We implement our AFR algorithm in ROS without changing the interface or API for the applications. Our experiments on two cloud robot applications show that our AFR algorithm can efficiently and effectively reduce the impact of data loss. For the remote mapping application, the RMSE caused by data loss can be reduced by about 20%. For the remote tracking application, the probability of tracking failure caused by data loss can be reduced from about 40%-60% to under 10%. Meanwhile, our AFR algorithm introduces time overhead of under 10 microseconds.
# Award Session VII
# Robot Learning of Mobile Manipulation with Reachability Behavior Priors
(Finalist for IROS Best Paper Award on Mobile Manipulation Sponsored by OMRON Sinic X Corp.)
## Keywords:
- Mobile Manipulation
- Reinforcement Learning
- Transfer Learning
## Abstract:
Mobile Manipulation (MM) systems are ideal candidates for taking up the role of a personal assistant in unstructured real-world environments. Among other challenges, MM requires effective coordination of the robot's embodiments for executing tasks that require both mobility and manipulation. Reinforcement Learning (RL) holds the promise of endowing robots with adaptive behaviors, but most methods require prohibitively large amounts of data for learning a useful control policy. In this work, we study the integration of robotic reachability priors in actor-critic RL methods for accelerating the learning of MM for reaching and fetching tasks. Namely, we consider the problem of optimal base placement and the subsequent decision of whether to activate the arm for reaching a 6D target. For this, we devise a novel Hybrid RL method that handles discrete and continuous actions jointly, resorting to the Gumbel-Softmax reparameterization. Next, we train a reachability prior using data from the operational robot workspace, inspired by classical methods. Subsequently, we derive Boosted Hybrid RL (BHyRL), a novel algorithm for learning Q-functions by modeling them as a sum of residual approximators. Every time a new task needs to be learned, we can transfer our learned residuals and learn the component of the Q-function that is task-specific, hence, maintaining the task structure from prior behaviors. Moreover, we find that regularizing the target policy with a prior policy yields more expressive behaviors. We evaluate our method in simulation in reaching and fetching tasks of increasing difficulty, and we show the superior performance of BHyRL against baseline methods. Finally, we zero-transfer our learned 6D fetching policy with BHyRL to our MM robot TIAGo++.
# A Hybrid Learning and Optimization Framework to Achieve Physically Interactive Tasks with Mobile Manipulators
(Finalist for IROS Best Paper Award on Mobile Manipulation Sponsored by OMRON Sinic X Corp.)
## Keywords:
- Compliance and Impedance Control
- Mobile Manipulation
- Imitation Learning
## Abstract:
This paper proposes a hybrid learning and optimization framework for mobile manipulators for complex and physically interactive tasks. The framework exploits the MOCA-MAN interface to obtain intuitive and simplified human demonstrations and Gaussian Mixture Model(GMM)/Gaussian Mixture Regression(GMR) to encode and generate the learned task requirements in terms of position, velocity, and force profiles. Next, using the desired trajectories and force profiles generated by GMM/GMR, the impedance parameters of a Cartesian impedance controller are optimized online through a Quadratic Program augmented with an energy tank to ensure the passivity of the controlled system. Two experiments are conducted to validate the framework, comparing our method with two approaches with constant stiffness (high and low). The results showed that the proposed method outperforms the other two cases in terms of trajectory tracking and generated interaction forces, even in the presence of disturbances such as unexpected end-effector collisions.
# Contrastive 3D Shape Completion and Reconstruction for Agricultural Robots Using RGB-D Frames
(Finalist for IROS Best Paper Award on Agri-Robotics Sponsored by YANMAR)
## Keywords:
- Robotics and Automation in Agriculture and Forestry
- Deep Learning for Visual Perception
- RGB-D Perception
## Abstract:
Monitoring plants and fruits is important in modern agriculture, with applications ranging from high-throughput phenotyping to autonomous harvesting. Obtaining highly accurate 3D measurements under real agricultural conditions is a challenging task. In this paper, we address the problem of estimating the 3D shape of fruits when only a partial view is available. We propose a pipeline that exploits high-resolution 3D data in the learning phase but only requires a single RGB-D frame to predict the 3D shape of a complete fruit during operation. To achieve this, we first learn a latent space of potential fruit appearances that we can decode into an SDF volume. With the pretrained, frozen decoder, we subsequently learn an encoder that can produce meaningful latent vectors from a single RGB-D frame. The experiments presented in this paper suggest that our approach can predict the 3D shape of whole fruits online, needing only 4ms for inference. We evaluate our approach in controlled environments and illustrate its deployment in greenhouses without modifications.
# Instance Segmentation for Autonomous Log Grasping in Forestry Operations
(Finalist for IROS Best Paper Award on Agri-Robotics Sponsored by YANMAR)
## Keywords:
- Robotics and Automation in Agriculture and Forestry
- Data Sets for Robotic Vision
- Object Detection, Segmentation and Categorization
## Abstract:
Wood logs picking is a challenging task to automate. Indeed, logs usually come in cluttered configurations, randomly orientated and overlapping. Recent work on log picking automation usually assume that the logs’ pose is known, with little consideration given to the actual perception problem. In this paper, we squarely address the latter, using a data-driven approach. First, we introduce a novel dataset, named TimberSeg 1.0, that is densely annotated, i.e., that includes both bounding boxes and pixel-level mask annotations for logs. This dataset comprises 220 images with 2500 individually segmented logs. Using our dataset, we then compare three neural network architectures on the task of individual logs detection and segmentation; two region-based methods and one attention-based method. Unsurprisingly, our results show that axis-aligned proposals, failing to take into account the directional nature of logs, underperform with 19.03 mAP. A rotation-aware proposal method significantly improve results to 31.83 mAP. More interestingly, a Transformer-based approach, without any inductive bias on rotations, outperformed the two others, achieving a mAP of 57.53 on our dataset. Our use case demonstrates the limitations of region-based approaches for cluttered, elongated objects. It also highlights the potential of attention-based methods on this specific task, as they work directly at the pixel-level. These encouraging results indicate that such a perception system could be used to assist the operators on the short-term, or to fully automate log picking operations in the future.
# Explicitly Incorporating Spatial Information to Recurrent Networks for Agriculture
(Finalist for IROS Best Paper Award on Agri-Robotics Sponsored by YANMAR)
## Keywords:
- Deep Learning for Visual Perception
- Robotics and Automation in Agriculture and Forestry
- Semantic Scene Understanding
## Abstract:
In agriculture, the majority of vision systems perform still image classification. Yet, recent work has highlighted the potential of spatial and temporal cues as a rich source of information to improve the classification performance. In this paper, we propose novel approaches to explicitly capture both spatial and temporal information to improve the classification of deep convolutional neural networks. We leverage available RGB-D images and robot odometry to perform inter-frame feature map spatial registration. This information is then fused within recurrent deep learnt models, to improve their accuracy and robustness. We demonstrate that this can considerably improve the classification performance with our best performing spatial-temporal model (ST-Atte) achieving absolute performance improvements for intersection-over-union (IoU[%]) of 4.7 for crop-weed segmentation and 2.6 for fruit (sweet pepper) segmentation. Furthermore, we show that these approaches are robust to variable framerates and odometry errors, which are frequently observed in real-world applications.
# Multimodal Aerial-Tethered Robot for Tree Canopy Exploration
(Finalist for IROS Best Paper Award on Agri-Robotics Sponsored by YANMAR)
## Keywords:
- Aerial Systems: Mechanics and Control
- Biologically-Inspired Robots
- Robotics and Automation in Agriculture and Forestry
## Abstract:
Forest canopies are the biggest habitat for terrestrial life, yet our understanding of environmental processes and biodiversity inside the canopy continues to be limited due to labour and resource intensive data collection. Existing aerial and climbing robots also struggle to access these complex environments, while animals easily navigate them using multiple means of locomotion. Following this insight we present a robot with multimodal mobility obtained by combining aerial and tethered locomotion. After the robot is deployed at the top of the tree, it can descend with the tether and maneuver around leaves and branches with its thrusters. The tether increases robustness and safety and allows for resting as well as emergency retrieval of the system. The aerial locomotion grants the system the ability to move in a conical 3D space constrained by the tether. We modelled the static system and validated the impact of design parameters on it. A simple control architecture for teleoperation is discussed and its performance is analyzed. The proposed multimodal mobility is demonstrated in preliminary outdoor tests, which show how our robot can move within the canopy while continuously monitoring the environment.
# Brain-Machine Interfaces and Natural Language Interaction
# Lightmyography Based Decoding of Human Intention Using Temporal Multi-Channel Transformers
## Keywords:
- Brain-Machine Interfaces
- Wearable Robotics
## Abstract:
For the development of muscle-machine interfaces (MuMIs), researchers have relied mainly on Electromyography (EMG) signals. However, these signals require complex hardware systems, as well as specialized signal processing and feature extraction methods. To overcome these issues, in our previous work, we proposed a novel MuMI for decoding human intention and motion, called Lightmyography (LMG). To improve the performance of this interface even further, in this work, we employ two novel deep learning techniques called Temporal Multi-Channel Transformer (TMC-T) and Temporal Multi-Channel Vision Transformer (TMC-ViT) for the classification of hand gestures based on the LMG data. The performance of these two Transformer-based methods is evaluated and compared with other well-known deep learning and classical machine learning methods. This work also addresses the influence of varying parameters defined during the training phase of decoding models, such as the size and shape of the input data packet. A series of data augmentation techniques were also employed to generate synthetic data and increase the dataset size so as to train deep learning models more efficiently.
# Dynamic Network Model for Multi-Domain End-To-End Task-Oriented Dialogue System
## Keywords:
- Natural Dialog for HRI
- Intention Recognition
- Service Robotics
## Abstract:
Dialogue State Tracking (DST) is an important part in task-oriented dialog system, whose target is to infer the current dialog states and user intentions according to the dialog history information. To this end, we have achieved improvements to the existing work and proposed a dynamic network model suitable for multi-domain dialog, which can explicitly use domain information and better cope with zeroshot tasks. The model is composed of three modules: an encoder,a decoder and a slot classifier. The encoder module introduces a mixed-separate framework so that it can obtain the feature information of each domain on the premise of extracting the shared information between all domains. The experimental results show that the model achieves joint accuracy of 48.38% for the five domains of MultiWOZ, which is superior to existing models. Besides, by simulating the zero-shot scenario,the knowledge transferability of the model has also been well proven.Finally, in order to verify the effectiveness of the robot simulation system, this paper also uses the robot simulation technology to simulate the common tasks of helping users complete the task of taking items in the home environment service.
# Hey Haru, Let’s Be Friends! Using the Tiers of Friendship to Build Rapport through Small Talk with the Tabletop Robot Haru
## Keywords:
- Robot Companions
- Emotional Robotics
- AI-Enabled Robotics
## Abstract:
Conversation can play an essential role in forging bonds between humans and social robots, however, participants need to feel like they are being listened to, remembered, and cared about in order to effectively build rapport. In this paper, we propose a novel strategy for conducting small talk with a social robot. Our approach is known as the Tiers of Friendship. It is centered around three core design elements: 1) Persuasive content and character is provided through topic modules created by professional creative writers to ensure engaging conversational content and a compelling personality for the social robot. 2) Conversational memory is achieved by allowing topic modules to specify required information that can learned through conversation or recalled from previous interactions and organizing topic modules into a hierarchy that enforces information requirements between topics. 3) Dynamicity in conversation is promoted through topic navigation that supports fluid transitions to topics of human interest and employs elements of random ordering to create fresh conversation experiences.
In this paper, we show how the tiers of friendship can be used to generate conversation content for a social robot that encourages the development of rapport. We describe a working implementation of a small talk system for a social robot based on the tiers of friendship that combines off-the-shelf ASR and NLU components and custom robot behavior components implemented via behavior trees on ROS. Finally, in order to evaluate our approach’s effectiveness, we conduct an elicitation survey that evaluates conversations in terms of perceived engagement, personality traits, and rapport expectation and discuss the implications for social robotics.
# Givenness Hierarchy Informed Optimal Document Planning for Situated Human-Robot Interaction
## Keywords:
- Natural Dialog for HRI
- AI-Based Methods
- Task Planning
## Abstract:
Robots that use natural language in collaborative tasks must refer to objects in their environment. Recent work has shown the utility of the linguistic theory of the Givenness Hierarchy (GH) in generating appropriate referring forms. But before referring expression generation, collaborative robots must determine the content and structure of a sequence of utterances, a task known as document planning in the natural language generation community. This problem presents additional challenges for robots in situated contexts, where described objects change both physically and in the minds of their interlocutors. In this work, we consider how robots can “think ahead” about the objects they must refer to and how to refer to them, sequencing object references to form a coherent, easy to follow chain. Specifically, we leverage GH to enable robots to plan their utterances in a way that keeps objects at a high cognitive status, which enables use of concise, anaphoric referring forms. We encode these linguistic insights as a mixed integer program within a planning context, formulating constraints to concisely and efficiently capture GH-theoretic cognitive properties. We demonstrate that this GH-informed planner generates sequences of utterances with high inter-sentential coherence, which we argue should enable substantially more efficient and natural human-robot dialogue.
# DoRO: Disambiguation of Referred Object for Embodied Agents
## Keywords:
- Natural Dialog for HRI
- Human Factors and Human-in-the-Loop
- Human-Robot Collaboration
## Abstract:
Robotic task instructions often involve a referred object that the robot must locate (ground) within the environment. While task intent understanding is an essential part of natural language understanding, less effort is made to resolve ambiguity that may arise while grounding the task. Existing works use vision-based task grounding and ambiguity detection, suitable for a fixed view and a static robot. However, the problem magnifies for a mobile robot, where the ideal view is not known beforehand. Moreover, a single view may not be sufficient to locate all the object instances in the given area, which leads to inaccurate ambiguity detection. Human intervention is helpful only if the robot can convey the kind of ambiguity it is facing. In this article, we present DoRO (Disambiguation of Referred Object), a system that can help an embodied agent to disambiguate the referred object by raising a suitable query whenever required. Given an area where the intended object is, DoRO finds all the instances of the object by aggregating observations from multiple views while exploring & scanning the area. It then raises a suitable query using the information from the grounded object instances. Experiments conducted with the AI2Thor simulator show that DoRO not only detects the ambiguity more accurately but also raises verbose queries with more accurate information from the visual-language grounding.
# Following Natural Language Instructions for Household Tasks with Landmark Guided Search and Reinforced Pose Adjustment
## Keywords:
- Natural Dialog for HRI
- Multi-Modal Perception for HRI
- Human-Centered Robotics
## Abstract:
We study the challenging problem of following natural language instructions on a mobile manipulator robot. This task is challenging because it requires the robot to integrate the semantics of the unconstrained natural language instructions with the robot's egocentric visual observations of the environment which are typically incomplete and noisy. To address these challenges, we propose a method that is able to use visible landmarks to more efficiently explore the environment in search of the objects described by the natural language instructions. Additionally, we propose using a pose adjustment policy during manipulation planning to help the robot recover from noisy visual observations. We show that this policy can be trained through experience with reinforcement learning as well as with human-in-the-loop feedback. We evaluate our approach on the popular ALFRED instruction following benchmark and show that these methods achieve state-of-the-art performance (35.41%) with a substantial (8.92% absolute) gap from prior work.
# SEMG-Based Minimally Supervised Regression Using Soft-DTW Neural Networks for Robot Hand Grasping Control
## Keywords:
- Manipulation Planning
- Multifingered Hands
- Telerobotics and Teleoperation
## Abstract:
One of the major challenges in robotics consists in developing successful control strategies for robotic grasping devices. In this scenario, one of the most interesting approaches regards the exploitation of surface electromyography(sEMG.) In this work, we propose a novel sEMG-based **minimally supervised** regression approach capable of performing nonlinear fitting without the necessity for point-by-point training data labelling. The proposed method exploits a differentiable version of the Dynamic Time Warping (DTW) similarity # referred to as soft-DTW divergence # as loss function for a flexible neural network architecture. This is a different paradigm with respect to state-of-the-art approaches in which sEMG-based control of robot hands is mainly realized using supervised or unsupervised machine learning based regression. An experimental session was carried out involving 10 healthy subjects in an offline experiment for systematic and statistical evaluations, and an online experiment for the evaluation of the control of a robot hand. The reported results demonstrate that the proposed soft-DTW neural network can be trained by means of a labelling that does not require to be temporally aligned with the sEMG training dataset, while reporting performances comparable with a standard mean square error(MSE)-based neural network. Also, the subjects were able to successfully control a robot hand for grasping motions and tasks with error levels comparable to state-of-the-art regression approaches.
# Hand Gesture Recognition Via Transient sEMG Using Transfer Learning of Dilated Efficient CapsNet: Towards Generalization for Neurorobotics
## Keywords:
- Brain-Machine Interfaces
- Physically Assistive Devices
- Neurorobotics
## Abstract:
There has been an accelerated surge in utilizing the deep neural network to decode central and peripheral activations of the human nervous system to boost the spatiotemporal resolution of neural interfaces used in human-centered robotic systems, such as prosthetics, and exoskeletons. Deep learning methods are proven to achieve high accuracy but are also challenged by their assumption of having access to massive training samples. {Objective:} In this letter, we propose Dilated Efficient CapsNet to improve the predictive performance when the available individual data is minimal and not enough to train an individualized network for controlling a personalized robotic system. {Method:} We proposed the concept of transfer learning for a new design of the dilated efficient capsular neural network to relax the need of having access to massive individual data and utilize the field knowledge which can be learned from a group of participants. In addition, instead of using complete sEMG signals, we only use the transient phase, reducing the volume of training samples to 20% of the original and maximizing the agility. {Results:} In experiments, we validate the performance with various amounts of injected personalized training data (from 25% to 100% of transient phase). The results support the use of the proposed transfer learning approach based on the dilated capsular neural network when the knowledge domain learned on a small number of subjects can be utilized to minimize the need for new data from new subjects. The model focuses only on the transient phase which is a challenging neural interfacing problem.
# Deep Augmentation for Electrode Shift Compensation in Transient High-Density sEMG: Towards Application in Neurorobotics
## Keywords:
- Brain-Machine Interfaces
- Physically Assistive Devices
- Neurorobotics
## Abstract:
Going beyond the traditional sparse multi-channel peripheral human-machine interface that has been used widely in neurorobotics, high-density surface electromyography (HD-sEMG) has shown significant potential for decoding upper-limb motor control. We have recently proposed heterogeneous temporal dilation of LSTM in a deep neural network architecture for a large number of gestures (>60), securing spatial resolution and fast convergence. However, several fundamental questions remain unanswered. One problem targeted explicitly in this paper is the issue of ``electrode shift,'' which can happen specifically for high-density systems and during doffing and donning the sensor grid. Another real-world problem is the question of transient versus plateau classification, which connects to the temporal resolution of neural interfaces and seamless control. In this paper, for the first time, we implement gesture prediction on the transient phase of HD-sEMG data while robustifying the human-machine interface decoder to electrode shift. For this, we propose the concept of deep data augmentation for transient HD-sEMG. We show that without using the proposed augmentation, a slight shift of 10mm may drop the decoder's performance to as low as 20%. Combining the proposed data augmentation with a 3D Convolutional Neural Network (CNN), we recovered the performance to 84.6% while securing a high spatiotemporal resolution, robustifying to the electrode shift, and getting closer to large-scale adoption by the end-users, enhancing resiliency.
# Telerobotics and Teleoperation 1
# Adaptive Wave Reconstruction through Regulated-BMFLC for Transparency-Enhanced Telerobotics Over Delayed Networks (I)
## Keywords:
- Telerobotics and Teleoperation
- Haptics and Haptic Interfaces
- Physical Human-Robot Interaction
## Abstract:
Bilateral telerobotic systems have attracted a great deal of interest during the last two decades. The major challenges in this field are the transparency and stability of remote force rendering that are affected by network delays causing asynchrony between the actions and the corresponding reactions. In addition, the overactivation of stabilizers further degrades the fidelity of the rendered force field. In this paper, a real-time frequency-based delay compensation approach is proposed to maximize transparency while reducing the activation of the stabilization layer. The algorithm uses a Regulated Bound-limited Multiple Fourier Linear Combiner (R-BMFLC) to extract the dominant frequency of force waves. The estimated weights are used in conjunction with the relatively phase-lead harmonic kernels to reconstruct the signal and generate a compensated wave to reduce the effect of the delay. The reconstructed force will then pass through a modulated time-domain passivity controller to guarantee the stability of the system. We will show that the proposed technique will reduce the force tracking error by 40% and the activation of the stabilizer by 79%. It will be shown, for the first time, that through the utilization of online adaptive frequency-based prediction, the asynchrony between transmitted waves through delayed networks can be significantly mitigated while stability can be guaranteed with less activation of the stabilization layer.
# Analysis of User Behavior and Workload During Simultaneous Tele-Operation of Multiple Mobile Manipulators
## Keywords:
- Telerobotics and Teleoperation
- Product Design, Development and Prototyping
- Multi-Robot Systems
## Abstract:
This paper discusses the tele-operation system for multiple mobile manipulators. If a single person could freely tele-operate multiple mobile manipulators simultaneously, it would be a great step toward the goal of ”avatar-symbiotic society” allowing people to live beyond the constraints of their bodies, space, and time. At present, however, such a teleoperation system has not been developed. Therefore, we built a prototype system to tele-operate two mobile manipulators and conducted a subject experiment on a pick-and-place task to investigate the tele-operator's task performance, workload and gaze behavior. By analyzing these results, we obtained guidelines to design tele-operation system for multiple robots.
# Variable Impedance Control for Safety and Usability in Telemanipulation
## Keywords:
- Telerobotics and Teleoperation
- Safety in HRI
- Compliance and Impedance Control
## Abstract:
In recent years, haptic telemanipulation has been introduced to control robots remotely with an input device that generates force feedback. Compliant control strategies are needed to ensure safe interaction between humans and robots. Accurate and precise manipulation requires a stiff setup of the impedance parameters, while safety demands for low stiffness. This paper proposes an impedance-based control approach that combines stiff manipulation with a safety mechanism that adapts compliance when required. We introduce three system modes: operation, safety and recovery mode. If the external forces exceed a defined force threshold, the system switches to the compliant safety mode. A user input triggers the recovery process that increases the stiffness back to its nominal value. This paper suggests an energy tank, which limits the change of stiffness to ensure stability during recovering phase. We validate the functionality of this approach using a real telemanipulation setup and show that the suggested tank enables recovery even from large displacements.
# Block-Based Novel Haptic Data Reduction for Time-Delayed Teleoperation
## Keywords:
- Telerobotics and Teleoperation
- Haptics and Haptic Interfaces
- Force and Tactile Sensing
## Abstract:
This work proposes a novel haptic data reduction scheme for time-delayed teleoperation by coding information as blocks. State-of-the-art (SOTA) haptic data reduction approaches are mainly sampled-based schemes. They encode haptic signals sample by sample in order to minimize the introduced coding delay. In contrast, our proposed block-based coding approach transmits a sample block as a single unit (haptic packet). Although it introduces additional algorithmic delays that are proportional to the block length, block coding has benefits since the packet rate is easy to control, the coding approach can be lossless, and the intra-block information can be employed to improve the force feedback quality. We further develop an energy adjustment approach that uses the information in a block to mitigate force oscillations caused by the Time Domain Passivity Approach. Simulation experiments and subjective tests demonstrate that our method reduces network load and significantly increases force feedback quality compared with the SOTA sample-based coding schemes, particularly for mid# to high-latency networks and low packet rates.
# Skill-CPD: Real-Time Skill Refinement for Shared Autonomy in Manipulator Teleoperation
## Keywords:
- Telerobotics and Teleoperation
- Manipulation Planning
- Human-Centered Automation
## Abstract:
Advanced wireless communication networks provide lower latency and a higher transmission rate. Although this is an enabler for many new teleoperation applications, the risk of network instability or packet drop is still unavoidable. Real-time manipulator teleoperation requires data transmission with no discontinuity. Shared autonomy (SA) is a standard method to mitigate this issue. In this way, if the data from the remote side is unavailable, the controller can continue based on the previously observed models. However, due to the spatial gap between human and robot trajectories, indisputable fluctuations occur, which cause issues in teleoperation applications. This motivates us to propose a new skill refinement strategy to modify the previously trained skill and mitigate the sudden unwanted motions within the control takeover phase. To this end, our approach comprises applying the Hidden Semi-Markov Model (HSMM) and Linear Quadratic Tracker (LQT) in combination to learn and predict the user's intentions and then exploiting Coherent Point Drift (CPD) to refine the executable trajectory. We test our method both in simulation and in the real world for 2D English letter drawing and 3D robot-assisted feeding scenarios. Our experimental results using the Kinova Movo platform show that the proposed refinement approach generates a stable trajectory and mitigates the control switching inconsistency.
# Haptic Teleoperation of High-Dimensional Robotic Systems Using a Feedback MPC Framework
## Keywords:
- Telerobotics and Teleoperation
- Whole-Body Motion Planning and Control
- Legged Robots
## Abstract:
Model Predictive Control (MPC) schemes have proven their efficiency in controlling high degree-of-freedom (DoF) complex robotic systems. However, they come at a high computational cost and an update rate of about tens of hertz. This relatively slow update rate hinders the possibility of stable haptic teleoperation of such systems since the slow feedback loops can cause instabilities and loss of transparency to the operator. This work presents a novel framework for transparent teleoperation of MPC-controlled complex robotic systems. In particular, we employ a feedback MPC approach and exploit its structure to account for the operator input at a fast rate which is independent of the update rate of the MPC loop itself. We demonstrate our framework on a mobile manipulator platform and show that it significantly improves haptic teleoperation's transparency and stability. We also highlight that the proposed feedback structure is constraint satisfactory and does not violate any constraints defined in the optimal control problem. To the best of our knowledge, this work is the first realization of the bilateral teleoperation of a legged manipulator using a whole-body MPC framework.
# Manipulability-Aware Shared Locomanipulation Motion Generation for Teleoperation of Mobile Manipulators
## Keywords:
- Telerobotics and Teleoperation
- Motion Control
- Redundant Robots
## Abstract:
The teleoperation of mobile manipulators may pose significant challenges, demanding complex interfaces and causing a substantial burden to the human operator due to the need to switch continuously from the manipulation of the arm to the control of the mobile platform. Hence, several works have considered to exploit shared control techniques to overcome this issue and, in general, to facilitate the task execution.
This work proposes a manipulability-aware shared locomanipulation motion generation method to facilitate the execution of telemanipulation tasks with mobile manipulators. The method uses the manipulability level of the end-effector to control the generation of the mobile base and manipulator motions, facilitating their simultaneous control by the operator while executing telemanipulation tasks. Therefore, the operator can exclusively control the end-effector, while the underlying architecture generates the mobile platform commands depending on the end-effector manipulability level.
The effectiveness of this approach is demonstrated with a number of experiments in which the CENTAURO robot, a hybrid leg-wheel platform with an anthropomorphic upper body, is teleoperated to execute a set of telemanipulation tasks.
# Fast Reflexive Grasping with a Proprioceptive Teleoperation Platform
## Keywords:
- Telerobotics and Teleoperation
- Grasping
- Human-Robot Collaboration
## Abstract:
We present a proprioceptive teleoperation system that uses a reflexive grasping algorithm to enhance the speed and robustness of pick-and-place tasks. The system consists of two manipulators that use quasi-direct-drive actuation to provide highly transparent force feedback. The end-effector has bimodal force sensors that measure 3-axis force information and 2-dimensional contact location. This information is used for anti-slip and re-grasping reflexes. When the user makes contact with the desired object, the re-grasping reflex aligns the gripper fingers with antipodal points on the object to maximize the grasp stability. The reflex takes only 150ms to correct for inaccurate grasps chosen by the user, so the user's motion is only minimally disturbed by the execution of the re-grasp. Once antipodal contact is established, the anti-slip reflex ensures that the gripper applies enough normal force to prevent the object from slipping out of the grasp. The combination of proprioceptive manipulators and reflexive grasping allows the user to complete teleoperated tasks with precision at high speed.
# Design Interface Mapping for Efficient Free-Form Tele-Manipulation
## Keywords:
- Telerobotics and Teleoperation
- Design and Human Factors
- Human Factors and Human-in-the-Loop
## Abstract:
Motion tracking interfaces are intuitive for free-form teleoperation tasks. However, efficient manipulation control can be difficult with such interfaces because of issues like the interference of unintended motions and the limited precision of human motion control. The limitation in control efficiency reduces the operator's performance and increases their workload and frustration during robot teleoperation. To improve the efficiency, we proposed separating controlled degrees of freedom (DoFs) and adjusting the motion scaling ratio of a motion tracking interface. The motion tracking of handheld controllers from a Virtual Reality system was used for the interface. We separated the translation and rotational control into: 1) two controllers held in the dominant and non-dominant hands and 2) hand pose tracking and trackpad inputs of a controller. We scaled the control mapping ratio based on 1) the environmental constraints and 2) the teleoperator's control speed. We further conducted a user study to investigate the effectiveness of the proposed methods in increasing efficiency. Our results show that the separation of position and orientation control into two controllers and the environment-based scaling methods perform better than their alternatives.
# Calibration and Identification
# Simultaneous Calibration of Multiple Revolute Joints for Articulated Vision Systems Via SE(3) Kinematic Bundle Adjustment
## Keywords:
- Calibration and Identification
- Computer Vision for Automation
## Abstract:
We propose a visual-based approach to calibrate kinematic structure of low degree-of-freedom (DoF) articulated systems. For industrial robots, the kinematic accuracy of end-effector (EE) is known with certitude. Standard hand-eye calibration (HEC) yields excellent eye-to-hand relations by explicitly estimating EE-mounted camera poses from the Perspective-n-Point (PnP) problem of a single calibration rig. However, these methods struggle when the ideal kinematic model is unknown or inaccurate, which are typical in customized serial chains such as articulated vision systems (AVS). Inspired by bundle adjustment (BA) in structure-from-motion (SfM) methods, we proposed an approach, dubbed KBA, to simultaneously localize multiple joint axes at the kinematic level instead of in the 3D space. To achieve this, we design a robust multi-checkerboard detector to enlarge the kinematic coverage of end-effector samples, which are usually limited by sensor's field of view (FoV). The overall optimization problem is formulated and solved using Lie group SE(3)---suitable for integration into modern simultaneous localization and mapping (SLAM) and SfM systems. In addition to simulated scenes, the experimental results with articulated monocular (AMV) and binocular vision (ABV) confirm that the proposed method is applicable to real serial kinematic chains and enables bio-mimicking 3D vision tasks such as stereo reconstruction in motion.
# DXQ-Net: Differentiable LiDAR-Camera Extrinsic Calibration Using Quality-Aware Flow
## Keywords:
- Calibration and Identification
- Deep Learning Methods
## Abstract:
Accurate LiDAR-camera extrinsic calibration is a precondition for many multi-sensor systems in mobile robots. Most calibration methods rely on laborious manual operations and calibration targets. While working online, the calibration methods should be able to extract information from the environment to construct the cross-modal data association. Convolutional neural networks (CNNs) have powerful feature extraction ability and have been used for calibration. However, most of the past methods solve the extrinsic as a regression task, without considering the geometric constraints involved. In this paper, we propose a novel end-to-end extrinsic calibration method named DXQ-Net, using a differentiable pose estimation module for generalization. We formulate a probabilistic model for LiDAR-camera calibration flow, yielding a prediction of uncertainty to measure the quality of LiDAR-camera data association. Testing experiments illustrate that our method achieves a competitive with other methods for the translation component and state-of-the-art performance for the rotation component. Generalization experiments illustrate that the generalization performance of our method is significantly better than other deep learning-based methods.
# CSA-SVM Method for Internal Cavitation Defects Detection and Its Application of District Heating Pipes
## Keywords:
- Calibration and Identification
- In-Hand Manipulation
- Marine Robotics
## Abstract:
The goal of this paper is to develop an ultrasonic detection device that can be mounted on an underwater snake vehicle (USV) for underwater district heating pipe (DHP) detection in the future. Ultrasonic detection technology (UDT) is the detection means used, and the cavitation defects in polyurethane (PUR) layer of DHPs are the object being detected. Due to the large thickness of PUR layer and the complex interface information of multi-layer structure, detecting defects of DHPs quantitatively is a difficult task. To address this issue, this paper proposes an approach that combines feature extraction and crow search algorithm (CSA) optimized support vector machine (SVM). Firstly, the main parameters and detection method of UDT are designed after investigation. Secondly, defective signals are pre-processed by signal processing to extract the features form three domains. Finally, four different classifiers are used to identify cavitation defects based on the feature-set. When compared among optimized random forest (RF), k-nearest neighbor (KNN), and ordinary SVM, the experimental results show that CSA-SVM had the highest accuracy in defect size prediction, and the validation-experiment verifies the practicability and feasibility of the CSA-SVM classifier. All experiments illustrate that the issue could be well solved by our method.
# Industrial Robot Parameter Identification Using a Constrained Instrumental Variable Method
## Keywords:
- Calibration and Identification
- Industrial Robots
## Abstract:
Robot identification is a prolific topic that has a long history with results spanning recent decades. Recent years have witnessed a renew of interest in this problem due in part to a rapid increase in robotic hardware platforms capable of accurate model-based control. The most popular methods exploit the fact that the inverse dynamic model is linear to the dynamic parameters. Because we identify robots with closed-loop procedures, an Instrumental Variable approach called IDIM-IV (Inverse Dynamic Identification Model with Instrumental Variable estimation) that combines the direct and inverse dynamic models to prevent from correlation between errors has been successfully validated. However, IDIM-IV does not guarantee that the direct dynamic model will be well-posed during its iterations because of possible modeling errors. In this paper, we combine physical constraints and IDIM-IV to address this deficiency for IDIM-IV. This new constrained IV approach, called PC-IDIM-IV (Physically Consistent IDIM-IV), consists of two nested iterative algorithms: an outer one that is IDIM-IV and an inner one that accounts for the physical constraints solved by a Gauss-Newton algorithm. Experimental results and comparisons with other methods carried out with the TX40 robot show the feasibility of PC-IDIM-IV.
# TEScalib: Targetless Extrinsic Self-Calibration of LiDAR and Stereo Camera for Automated Driving Vehicles with Uncertainty Analysis
## Keywords:
- Calibration and Identification
- Intelligent Transportation Systems
- Computer Vision for Transportation
## Abstract:
In this paper, we present TEScalib, a novel extrinsic self-calibration approach of LiDAR and stereo camera using the geometric and photometric information of surrounding environments without any calibration targets for automated driving vehicles. Since LiDAR and stereo camera are widely used for sensor data fusion on automated driving vehicles, their extrinsic calibration is highly important. However, most of the LiDAR and stereo camera calibration approaches are mainly target-based and therefore time consuming. Even the newly developed targetless approaches in last years are either inaccurate or unsuitable for driving platforms.
To address those problems, we introduce TEScalib. By applying a 3D mesh reconstruction-based point cloud registration, the geometric information is used to estimate the LiDAR to stereo camera extrinsic parameters accurately and robustly. To calibrate the stereo camera, a photometric error function is builded and the LiDAR depth is involved to transform key points from one camera to another. During driving, these two parts are processed iteratively. Besides that, we also propose an uncertainty analysis for reflecting the reliability of the estimated extrinsic parameters. Our TEScalib approach evaluated on the KITTI dataset achieves very promising results.
# Extrinsic Calibration of a 2D Laser Rangefinder and a Depth-Camera Using an Orthogonal Trihedron
## Keywords:
- Calibration and Identification
- Sensor Fusion
- SLAM
## Abstract:
2D laser rangefinders and depth-cameras are usually equipped on service robots. But there are rarely calibration methods of them. This paper proposes an extrinsic calibration method of a 2D laser rangefinder and a depth-camera using an orthogonal trihedron. The trihedron with orthogonal assumptions is taken as a reference frame to roughly estimate the relative pose between the sensors by solving a perspective-three-point (P3P) problem and basis-to-basis correspondence. Then, the estimated relative pose is refined via non-linear optimization based on line-to-plane constraints. Unlike other works which require enough motion, only one-shot observation is required, and it is insensitive to sensor ranging noise and the manufacturing errors of calibration targets. Verified by simulation and real experiments, the proposed method is simple, effective and accurate.
# Continuous Calibration and Narrow Compensation Algorithm to Estimate a Joint Axis under the Various Conditions with Unit Sensor
## Keywords:
- Calibration and Identification
- Sensor Fusion
- Wearable Robotics
## Abstract:
Wearable robots have been developed to aid or substitute the gait locomotion of humans. To assist gait locomotion based on the intention of a wearer, a gait pattern analysis is required with a wearable sensor by measuring body information, i.e., a joint angular velocity. However, measuring a precise joint angular velocity is difficult because the attachment position of a sensor has a curvature and an anatomical joint axis which is invisible. Therefore, a sensor calibration algorithm, which aligns a sensor axis into an anatomical joint axis, is required to provide an optimal assist for a wearer. Hence, in this paper, a new and simple sensor calibration algorithm is proposed with a unit sensor. Since a wearer shakes the body or collides with the ground when walking, the attachment position of a sensor may be changed. Thus, a continuous sensor compensation algorithm is also proposed. Additionally, the effectiveness of this new algorithm is demonstrated by gait locomotion experiments on various paths.
# Visual-Inertial-Aided Online MAV System Identification
## Keywords:
- Calibration and Identification
- Vision-Based Navigation
- Aerial Systems: Applications
## Abstract:
System modeling and parameter identification of micro aerial vehicles (MAV) are crucial for robust autonomy, especially under highly dynamic motions. Visual-inertial-aided online parameter identification has recently seen research atten# tion due to the demanding of adaptation to platform configura# tion changes with minimal onboard sensor requirements. To this end, we design an online MAV system identification algorithm to tightly fuse visual, inertial and MAV aerodynamic informa# tion within a lightweight multi-state constraint Kalman filter (MSCKF) framework. In particular, while one could blindly fuse the MAV dynamic-induced relative motion constraints in EKF, we numerically show that due to the (quadrotor) MAV system modeling inaccuracy, they often become overconfident and negatively impact the state estimates. As such, we leverage the Schmidt-Kalman filter (SKF) for MAV system parameter identification to prevent corruption of state estimates. Through extensive simulations and real-world experiments, we validate the proposed SKF-based scheme and demonstrate its ability to perform robust system identification even in the presence of an inconsistent MAV dynamic model under different motions.
# Efficient Extrinsic Calibration of Multi-Sensor 3D LiDAR Systems for Autonomous Vehicles Using Static Objects Information
## Keywords:
- Calibration and Identification
- Sensor Fusion
- Optimization and Optimal Control
## Abstract:
For an autonomous vehicle, the ability to sense its surroundings and to build an overall representation of the environment by fusing different sensor data streams is fundamental. To this end, the poses of all sensors need to be accurately determined. Traditional calibration methods are based on: 1) using targets specifically designed for calibration purposes in controlled environments, 2) optimizing a quality metric of the point clouds collected while traversing an unknown but static environment, or 3) optimizing the match among per-sensor incremental motion observations along a motion path fulfilling special requirements. In real scenarios, however, the online applicability of these methods can be limited, as they are typically highly dynamic, contain degenerate paths, and require fast computations. In this paper, we propose an approach that tackles some of these challenges by formulating the calibration problem as a joint but structured optimization problem of all sensor calibrations that takes as input a summary of the point cloud information consisting of ground points and pole detections. We demonstrate the efficiency and quality of the results of the proposed approach in a set of experiments with LiDAR simulation and real data from an urban trip.
# Navigation Systems 4
# Online Mapping and Motion Planning under Uncertainty for Safe Navigation in Unknown Environments (I)
## Keywords:
- Autonomous Vehicle Navigation
- Motion and Path Planning
- Motion Control
## Abstract:
Safe autonomous navigation is an essential and challenging problem for robots operating in highly unstructured or completely unknown environments. Under these conditions, not only robotic systems must deal with limited localisation information but also their manoeuverability is constrained by their dynamics and often suffer from uncertainty. In order to cope with these constraints, this article proposes an uncertainty-based framework for mapping and planning feasible motions online with probabilistic safety guarantees. The proposed approach deals with the motion, probabilistic safety, and online computation constraints by: (i) incrementally mapping the surroundings to build an uncertainty-aware representation of the environment, and (ii) iteratively (re)planning trajectories to goal that are kinodynamically feasible and probabilistically safe through a multi-layered sampling-based planner in the belief space. In-depth empirical analyses illustrate some important properties of this approach, namely: (a) the multilayered planning strategy enables rapid exploration of the high-dimensional belief space while preserving asymptotic optimality and completeness guarantees, and (b) the proposed routine for probabilistic collision checking results in tighter probability bounds in comparison to other uncertainty-aware planners in the literature. Furthermore, real-world in-water experimental evaluation on a nonholonomic torpedo-shaped autonomous underwater vehicle and simulated trials in an urban environment on an unmanned aerial vehicle demonstrate the efficacy of the method and its suitability for systems with limited on-board computational power.
# Drift Reduced Navigation with Deep Explainable Features
## Keywords:
- Autonomous Vehicle Navigation
- Perception-Action Coupling
- Visual Learning
## Abstract:
Modern autonomous vehicles (AVs) often rely on vision, LIDAR, and even radar-based simultaneous localization and mapping (SLAM) frameworks for precise localization and navigation. However, modern SLAM frameworks often lead to unacceptably high levels of drift (i.e., localization error) when AVs observe few visually distinct features or encounter occlusions due to dynamic obstacles. This paper argues that minimizing drift must be a key desiderata in AV motion planning, which requires an AV to take active control decisions to move towards feature-rich regions while also minimizing conventional control cost. To do so, we first introduce a novel data-driven perception module that observes LIDAR point clouds and estimates which features/regions an AV must navigate towards for drift minimization. Then, we introduce an interpretable model predictive controller (MPC) that moves an AV toward such feature-rich regions while avoiding visual occlusions and gracefully trading off drift and control cost. Our experiments on challenging, dynamic scenarios in the state-of-the-art CARLA simulator indicate our method reduces drift up to 76.76% compared to benchmark approaches.
# A Robust and Fast Occlusion-Based Frontier Method for Autonomous Navigation in Unknown Cluttered Environments
## Keywords:
- Autonomous Vehicle Navigation
- Motion and Path Planning
- Range Sensing
## Abstract:
Navigation through unknown, cluttered environments is a fundamental and challenging task for autonomous vehicles as they must deal with a myriad of obstacle configurations typically unknown a priori. Challenges arise because obstacles of unknown shapes and dimensions can create occlusions limiting sensor field of view and leading to uncertainty in motion planning. In this paper we propose to leverage such occlusions to quickly explore and cover unknown cluttered environments. Specifically, this work presents a novel occlusion-aware frontier-based approach that estimates gaps in point cloud data and shadows in the field of view to generate waypoints to navigate. Our scheme also proposes a breadcrumbing technique to save states of interest during exploration that can be exploited in future missions. For the latter aspect we focus primarily on the generation of the minimum number of breadcrumbs that will increase coverage and visibility of an explored environment. Extensive simulations and experiment results on an unmanned ground vehicle (UGV) are demonstrated to validate the proposed technique, showing improvements over traditional state of the art frontier-based exploration methods.
# Bubble Planner: Planning High-Speed Smooth Quadrotor Trajectories Using Receding Corridors
## Keywords:
- Autonomous Vehicle Navigation
- Motion and Path Planning
- Aerial Systems: Applications
## Abstract:
Quadrotors are agile platforms. With human experts, they can perform extremely high-speed flights in cluttered environments. However, fully autonomous flight at high speed remains a significant challenge. In this work, we propose a motion planning algorithm based on the corridor-constrained minimum control effort trajectory optimization (MINCO) framework. Specifically, we use a series of overlapping spheres to represent the free space of the environment and propose two novel designs that enable the algorithm to plan high-speed quadrotor trajectories in real-time. One is a sampling-based corridor generation method that generates spheres with large overlapped areas (hence overall corridor size) between two neighboring spheres. The second is a Receding Horizon Corridors (RHC) strategy, where part of the previously generated corridor is reused in each replan. Together, these two designs enlarge the corridor spaces in accordance with the quadrotor's current state and hence allow the quadrotor to maneuver at high speeds. We benchmark our algorithm against other state-of-the-art planning methods to show its superiority in simulation. Comprehensive ablation studies are also conducted to show the necessity of the two designs. The proposed method is finally evaluated on an autonomous LiDAR-navigated quadrotor UAV in woods environments, achieving flight speeds over 13.7 m/s without any prior map of the environment or external localization facility.
# Temporal Context for Robust Maritime Obstacle Detection
## Keywords:
- Autonomous Vehicle Navigation
- Marine Robotics
- Semantic Scene Understanding
## Abstract:
Robust maritime obstacle detection is essential for fully autonomous unmanned surface vehicles (USVs). The currently widely adopted segmentation-based obstacle detection methods are prone to misclassification of object reflections and sun glitter as obstacles, producing many false positive detections, effectively rendering the methods impractical for USV navigation. However, water-turbulence-induced temporal appearance changes on object reflections are very distinctive from the appearance dynamics of true objects. We harness this property to design WaSR-T, a novel maritime obstacle detection network, that extracts the temporal context from a sequence of recent frames to reduce ambiguity. By learning the local temporal characteristics of object reflection on the water surface, WaSR-T substantially improves obstacle detection accuracy in the presence of reflections and glitter. Compared with existing single-frame methods, WaSR-T reduces the number of false positive detections by 41% overall and by over 53% within the danger zone of the boat, while preserving a high recall, and achieving new state-of-the-art performance on the challenging MODS maritime obstacle detection benchmark. The code, pretrained models and extended datasets are available at: https://github.com/lojzezust/WaSR-T
# Information-Aware Guidance for Magnetic Anomaly Based Navigation
## Keywords:
- Autonomous Vehicle Navigation
- Task and Motion Planning
- Optimization and Optimal Control
## Abstract:
In the absence of an absolute positioning system, such as GPS, autonomous vehicles are subject to accumulation of position error which can interfere with reliable performance. Improved navigational accuracy without GPS enables vehicles to achieve a higher degree of autonomy and reliability, both in terms of decision making and safety. This paper details the use of two path planning algorithms for autonomous agents when using magnetic field anomalies to localize themselves within a map. Both techniques use the information content in the environment in distinct ways and is aimed at reducing the localization uncertainty. The first method is based on a nonlinear observability metric of the vehicle model, while the second is an information-theory based technique which minimizes the expected entropy of the system. These conditions are used to design guidance laws that minimize the localization uncertainty and is verified both in simulation and hardware experiments.
# Unified Automatic Control of Vehicular Systems with Reinforcement Learning (I)
## Keywords:
- Path Planning for Multiple Mobile Robots or Agents
- Reinforcement Learning
- Automation Technologies for Smart Cities
## Abstract:
Emerging vehicular systems with increasing proportions of automated components present opportunities for optimal control to mitigate congestion and increase efficiency. There has been recent interest in applying deep reinforcement learning (DRL) to these nonlinear dynamical systems for the automatic design of effective control strategies. Despite conceptual advantages of DRL being model-free, studies typically nonetheless rely on training setups that are painstakingly specialized to specific vehicular systems. This is a key challenge to efficient analysis of diverse vehicular and mobility systems. To this end, this article contributes a streamlined methodology for vehicular microsimulation and discovers high performance control strategies with minimal manual design. A variable-agent, multi-task approach is presented for optimization of vehicular Partially Observed Markov Decision Processes. The methodology is experimentally validated on mixed autonomy traffic systems, where fractions of vehicles are automated; empirical improvement, typically 15-60% over a human driving baseline, is observed in all configurations of six diverse open or closed traffic systems. The study reveals numerous emergent behaviors resembling wave mitigation, traffic signaling, and ramp metering. Finally, the emergent behaviors are analyzed to produce interpretable control strategies.
# SphereMap: Dynamic Multi-Layer Graph Structure for Rapid Safety-Aware UAV Planning
## Keywords:
- Autonomous Vehicle Navigation
- Planning under Uncertainty
- Mapping
## Abstract:
A flexible topological representation consisting of a two-layer graph structure built on-board an Unmanned Aerial Vehicle (UAV) by continuously filling the free space of an occupancy map with intersecting spheres is proposed in this letter. Most state-of-the-art planning methods find the shortest paths while keeping the UAV at a pre-defined distance from obstacles. Planning over the proposed structure reaches this pre-defined distance only when necessary, maintaining a safer distance otherwise, while also being orders of magnitude faster than other state-of-the-art methods. Furthermore, we demonstrate how this graph representation can be converted into a lightweight shareable topological-volumetric map of the environment, which enables decentralized multi-robot cooperation. The proposed approach was successfully validated in several kilometers of real subterranean environments, such as caves, devastated industrial buildings, and in the harsh and complex setting of the final event of the DARPA SubT Challenge, which aims to mimic the conditions of real search and rescue missions as closely as possible, and where our approach achieved the 2nd place in the virtual track.
# AIB-MDP: Continuous Probabilistic Motion Planning for Automated Vehicles by Leveraging Action Independent Belief Spaces
## Keywords:
- Autonomous Vehicle Navigation
- Motion and Path Planning
## Abstract:
While automated research vehicles are already populating the roads, their commercial availability at scale is still to come. Presumably, one of the key challenges is to derive behaviors that are safe and comfortable but at the same time not overcautious, despite considerable uncertainties. These uncertainties stem from imperfect perception, occlusions and limited sensor range, but also from the unknown future behavior of other traffic participants. A holistic uncertainty treatment, for example in a general POMDP formulation, often induces a strong limitation on the action space due to the need for real-time capability. Further, related approaches often do not account for the need for verifiable safety, including traffic rule compliance. The proposed approach is targeted towards scenarios with clear precedence. It is based on an MDP with an action-independent belief (AIB-MDP): We assume that the future belief over the trajectories of other traffic participants is independent of the ego vehicle’s behavior. Thus, the future belief can be predicted and simplified in an upstream module, independent of motion planning. This modularization facilitates subsequent ego motion planning in a continuous action space despite the thorough uncertainty consideration.
# SLAM 5
# InCOpt: Incremental Constrained Optimization Using the Bayes Tree
## Keywords:
- SLAM
- Localization
- Mapping
## Abstract:
In this work, we investigate the problem of incrementally solving constrained non-linear optimization problems formulated as factor graphs. Prior incremental solvers were either restricted to the unconstrained case or required periodic batch relinearizations of the objective and constraints which are expensive and detract from the online nature of the algorithm. We present InCOpt, an Augmented Lagrangian-based incremental constrained optimizer that views matrix operations as message passing over the Bayes tree. We first show how the linear system, resulting from linearizing the constrained objective, can be represented as a Bayes tree. We then propose an algorithm that views forward and back substitutions, which naturally arise from solving the Lagrangian, as upward and downward passes on the tree. Using this formulation, InCOpt can exploit properties such as fluid/online relinearization leading to increased accuracy without a sacrifice in runtime. We evaluate our solver on different applications (navigation and manipulation) and provide an extensive evaluation against existing constrained and unconstrained solvers.
# S3LAM: Structured Scene SLAM
## Keywords:
- SLAM
## Abstract:
We propose a new SLAM system that uses the semantic segmentation of objects and structures in the scene. Semantic information is relevant as it contains high level information which may make SLAM more accurate and robust. Our contribution is twofold: i) A new SLAM system based on ORB-SLAM2 that creates a semantic map made of clusters of points corresponding to objects instances and structures in the scene. ii) A modification of the classical Bundle Adjustment formulation to constrain each cluster using geometrical priors, which improves both camera localization and reconstruction and enables a better understanding of the scene. We evaluate our approach on sequences from several public datasets and show that it improves camera pose estimation with respect to state of the art.
# Fast Structural Representation and Structure-Aware Loop Closing for Visual SLAM
## Keywords:
- SLAM
- Localization
- Range Sensing
## Abstract:
Perceptual Aliasing is one of the main problems in simultaneous localization and mapping (SLAM). Wrong associations between different places may lead to failure of the whole map. Research on structure information is rarely investigated among existing solutions to this problem. In cases of visual SLAM without sensors, such as LiDAR or Inertial Measurement Unit (IMU), structure information can rarely be obtained due to the sparsity of 3D points, which also makes structure analysis complex. This study provides a spherical harmonics (SH) based fast structural representation (SH-FS) in visual SLAM using sparse point clouds, which extracts the structure information from sparse points into single vector. SH-FS was applied in conventional feature-based loop closing process. Furthermore, a structure-aware loop closing method in visual SLAM was proposed to improve the robustness of SLAM systems. Moreover, our methods show a favorable performance in extensive experiments on different large-scale real world datasets.
# Efficient 2D Graph SLAM for Sparse Sensing
## Keywords:
- SLAM
## Abstract:
Simultaneous localization and mapping (SLAM) plays a vital role in mapping unknown spaces and aiding autonomous navigation. Virtually all state-of-the-art solutions today for 2D SLAM are designed for dense and accurate sensors such as laser range-finders (LiDARs). However, these sensors are not suitable for resource-limited nano robots, which become increasingly capable and ubiquitous nowadays, and these robots tend to mount economical and low-power sensors that can only provide sparse and noisy measurements. This introduces a challenging problem called SLAM with sparse sensing. This work addresses the problem by adopting the form of the state-of-the-art graph-based SLAM pipeline with a novel frontend and an improvement for loop closing in the backend, both of which are designed to work with sparse and uncertain range data. Experiments show that the maps constructed by our algorithm have superior quality compared to prior works on sparse sensing. Furthermore, our method is capable of running in real-time on a modern PC with an average processing time of 1/100th the input interval time.
# Spectral Measurement Sparsification for Pose-Graph SLAM
## Keywords:
- SLAM
- Localization
- Mapping
## Abstract:
Simultaneous localization and mapping (SLAM) is a critical capability in autonomous navigation, but in order to scale SLAM to the setting of "lifelong" SLAM, particularly under memory or computation constraints, a robot must be able to determine what information should be retained and what can safely be forgotten. In graph-based SLAM, the number of edges (measurements) in a pose graph determines both the memory requirements of storing a robot's observations and the computational expense of algorithms deployed for performing state estimation using those observations; both of which can grow unbounded during long-term navigation. To address this, we propose a spectral approach for pose graph sparsification which maximizes the algebraic connectivity of the sparsified measurement graphs, a key quantity which has been shown to control the estimation error of pose graph SLAM solutions. Our algorithm, MAC (for "maximizing algebraic connectivity"), which is based on convex relaxation, is simple and computationally inexpensive, and admits formal post hoc performance guarantees on the quality of the solutions it provides. In experiments on benchmark pose-graph SLAM datasets, we show that our approach quickly produces high-quality sparsification results which retain the connectivity of the graph and, in turn, the quality of corresponding SLAM solutions, as compared to a baseline approach which does not consider graph connectivity.
# BOEM-SLAM: A Block Online EM Algorithm for the Visual-Inertial SLAM Backend
## Keywords:
- SLAM
- Optimization and Optimal Control
- Localization
## Abstract:
In this paper we present BOEM-SLAM, a backend for visual-inertial SLAM systems capable of creating a globally consistent trajectory and map without retaining the entire history of data. By leveraging the hidden Markov model structure, BOEM-SLAM can summarize historical data into sufficient statistics and then discard it. As a data-efficient algorithm, BOEM-SLAM addresses the growing computational costs and storage requirements of the SLAM backend. To demonstrate the performance of our algorithm we compare BOEM-SLAM to other fundamental approaches on both synthetic data and the EuRoC dataset. For evaluation on the EuRoC dataset, we use the open source okvis frontend and apply the Lie group state space representation and visual outlier removal. Overall, BOEM-SLAM shows a considerably lower computation time with comparable estimation performance. For example, the processing time of BOEM-SLAM is 50 times smaller than the optimization-based method using simulated data and 5 times smaller than the optimization-based method in the EuRoC dataset experiments.
# RO-LOAM: 3D Reference Object-Based Trajectory and Map Optimization in LiDAR Odometry and Mapping
## Keywords:
- SLAM
- Localization
- Mapping
## Abstract:
We propose an extension to the LiDAR Odometry and Mapping framework (LOAM) that enables reference object-based trajectory and map optimization. Our approach assumes that the location and geometry of a large reference object are known, e.g., as a CAD model from Building Information Modeling (BIM) or a previously captured dense point cloud model. We do not expect the reference object to be present in every LiDAR scan. Our approach uses the poses of the LOAM algorithm as an initial guess to refine them with scan-to-model alignment. To evaluate if the alignment was accurate, an EKF-based motion prior filtering step is employed. Subsequently, the past trajectory is optimized by adding the model-aligned pose as a pose graph constraint and the map of the LOAM algorithm is corrected to improve future localization and mapping. We evaluate our approach with data captured in a visual airplane inspection scenario inside an aircraft hangar. A 3D LiDAR sensor is mounted via a gimbal on an Unmanned Aerial Vehicle (UAV) and is continuously actuated. We compare the localization accuracy of the LOAM and R-LOAM algorithms when enabling or disabling our proposed reference object-based trajectory and map optimization extension. For three recorded datasets, enabling the proposed extension yields a reduction in Absolute Pose Error compared to conventional LOAM and R-LOAM, while being able to run online. This reduces drift and improves map quality.
# TwistSLAM: Constrained SLAM in Dynamic Environment
## Keywords:
- SLAM
## Abstract:
Classical visual simultaneous localization and mapping (SLAM) algorithms usually assume the environment to be rigid. This assumption limits the applicability of those algorithms as they are unable to accurately estimate the camera poses and world structure in real life scenes containing moving objects (e.g. cars, bikes, pedestrians, etc.). To tackle this issue, we propose TwistSLAM: a semantic, dynamic and stereo SLAM system that can track dynamic objects in the environment. Our algorithm creates clusters of points according to their semantic class. Thanks to the definition of inter-cluster constraints modeled by mechanical joints (function of the semantic class), a novel constrained bundle adjustment is then able to jointly estimate both poses and velocities of moving objects along with the classical world structure and camera trajectory. We evaluate our approach on several sequences from the public KITTI dataset and demonstrate quantitatively that it improves camera and object tracking compared to state-of-the-art approaches.
# Fast Sparse LiDAR Odometry Using Self-Supervised Feature Selection on Intensity Images
## Keywords:
- SLAM
- Vision-Based Navigation
## Abstract:
Ego-motion estimation is a fundamental building block of any autonomous system that needs to navigate in an environment. In large-scale outdoor scenes, 3D LiDARs are often used for this task, as they provide a large number of range measurements at high precision. In this paper, we propose a novel approach that exploits the intensity channel of 3D LiDAR scans to compute an accurate odometry estimate at a high frequency. In contrast to existing methods that operate on full point clouds, our approach extracts a sparse set of salient points from intensity images using data-driven feature extraction architectures originally designed for RGB images. These salient points are then used to compute the relative pose between successive scans. Furthermore, we propose a novel self-supervised procedure to fine-tune the feature extraction network online during navigation, which exploits the estimated relative motion but does not require ground truth data. The the experimental evaluation suggests that the proposed approach provides a solid ego-motion estimation at a much higher frequency than the sensor frame rate while improving its estimation accuracy online.
# Medical Robots and Systems 5
# Design and Evaluation of a Robotic Forceps with Flexible Wrist Joint Made of PEEK Plastic
## Keywords:
- Medical Robots and Systems
- Tendon/Wire Mechanism
- Force and Tactile Sensing
## Abstract:
This paper presents the design and evaluation of a robotic forceps in which the wrist joint is made of polyetheretherketone (PEEK) plastic. Due to the structural improvement of enclosing a flexible backbone of PTFE tube inside the wrist joint, the developed forceps simultaneously fulfills the requirements of small diameter, bending dexterity, sufficient axial stiffness, and even the control rigidity. The proposed robotic forceps employs pneumatic drive with wire actuation mechanism. For accurate motion control and external force estimation, we developed a novel inverse dynamics model considering the coupled dynamic effect between the wrist joint and the gripper motions. The position control accuracy of the wrist joint bending angle is at the level of 1° and is not affected by the simultaneous open–close motion of the gripper. The translation and grasping forces are beyond 4.5 N, enabling powerful tasks in laparoscopic surgery. Furthermore, the robotic forceps is capable of multi-DOF external force estimation. The estimation accuracy of the translation force is about 0.2 N, and the estimation accuracy of grasping force remains within 0.2 N regardless of the bending angle of the wrist joint. The performance evaluation results demonstrate that the developed forceps is eligible to be used in robotic-assisted laparoscopic surgery.
# External and Internal Sensor Fusion Based Localization Strategy for 6-DOF Pose Estimation of a Magnetic Capsule Robot
## Keywords:
- Medical Robots and Systems
## Abstract:
This paper introduces a novel localization approach for active capsule endoscopy that, for the first time, combines external magnetic field sensing and internal inertial sensing to realize 6-DOF pose estimation of a magnetic capsule robot. It utilizes an inertial measurement unit embedded in the capsule with an external magnetic sensor array to estimate the 6-DOF pose of the capsule, which does not require complicated structures of the capsule and the actuator or the implementation of specific motions of the magnets, and can achieve accurate and real-time localization of the capsule in a large workspace. We formulate the localization model and analyze the singularities of the method, and present the design approach to determine the configuration of the localization system for efficient and accurate localization in a 0.5m * 0.5m * 0.2m workspace. Simulation and real-world experiments are conducted to validate the effectiveness of the proposed localization strategy. Our results show that the proposed method can achieve a localization accuracy of 5.35 mm and 1.46° in position and orientation in the real-time tracking task at an update rate of 60 Hz. The presented method can be integrated with any magnetic actuation method to achieve closed-loop control of a magnetic capsule robot in the human body.
# Robotic Auscultation Over Clothes for Eliminating Gender Bias
## Keywords:
- Medical Robots and Systems
## Abstract:
During auscultation, patients in difficult age often feel embarrassed and uncomfortable when exposing their chests to doctors of different gender and being touched physically by doctors. We assume that an auscultation with robot technology can address the aforementioned gender-related issue. Toward eliminating gender bias during auscultation exam, this paper proposes a robotic platform which enables
to perform the automated auscultation over clothes. Our developed system is comprised of two folds: a depth image-based estimation system
of the listening positions over clothes with RGB-D camera and a contact
force adjustment system for minimizing the acoustic attenuation due to the clothes with a passive-actuated end# effector. Our preliminary results demonstrated the robotic platform enables to estimate the listening locations to hear the sounds of four cardiac valves over the clothes by combining the estimated skeletal structure with statistical anatomical data and acquire the maximized acoustic quality over the clothes by adjusting the contact force. The developed robotic platform has the potential to address the gender-related issues in auscultation.
# ANN-Based Optimization of Human Gait Data Obtained from a Robot-Mounted 3D Camera: A Multiple Sclerosis Case Study
## Keywords:
- Medical Robots and Systems
- Rehabilitation Robotics
- Bioinspired Robot Learning
## Abstract:
Assessment of gait consistency requires testing over a long walking distance. Robot-mounted 3D cameras represent a cost-effective, markerless technology of human gait analysis that can be applied for this purpose. However, the use of robotic platforms for gait analysis is limited by the low accuracy of 3D cameras. The aim of this study is to improve the accuracy of kinematic and spatio-temporal estimations obtained from a robot-mounted 3D camera by applying a supervised learning process, and then to verify the effectiveness of the proposed method for clinical use. Artificial neural networks have been trained using the reference data provided by a Vicon system, which lead to improved estimations. Then, gait characteristics in Multiple Sclerosis patients has been measured. Significant differences respect to Healthy Controls have been found mainly for hip flexion, pelvis tilt, pelvis rotation and stride length. The improvement of robot-mounted 3D camera estimations and their application to the analysis of gait impairment in a natural environment show the flexibility and adaptability that this setup can provide.
# Magnetic Microrobot Control Using an Adaptive Fuzzy Sliding-Mode Method
## Keywords:
- Medical Robots and Systems
- Micro/Nano Robots
- Motion Control
## Abstract:
The magnetic medical microrobots are influenced by diverse factors such as the medium, the geometry of the microrobot, and the imaging procedure. It is worth noting that the size limitations make it difficult or even impossible to obtain reliable physical properties of the system. In this research, to achieve a precise microrobot control using minimum knowledge about the system, an Adaptive Fuzzy Sliding-Mode Control (AFSMC) scheme is designed for the motion control problem of the magnetically actuated microrobots in presence of input saturation constraint. The AFSMC input consists of a fuzzy system designed to approximate an unknown nonlinear dynamical system and a robust term considered for mismatch compensation. According to the designed adaptation laws, the asymptotic stability is proved based on the Lyapunov theorem and Barbalat’s lemma. In order to evaluate the effectiveness of the proposed method, a comparative simulation study is conducted.
# An Easy-To-Deploy Combined Nasal/Throat Swab Robot with Sampling Dexterity and Resistance to External Interference
## Keywords:
- Medical Robots and Systems
- Soft Robot Applications
## Abstract:
Robots have been used extensively in the battle against the COVID-19 pandemic since its outbreak. One prominent direction is the use of robots for swab sampling, which not only solves the shortage of medical staffs, but also prevents them from being infected during the face-to-face sampling. However, massive deployment of sampling robots is still not achieved due to their high cost, safety concern, deployment complexity, et al. In this paper, we propose a flexible, safe and easy-to-deploy swab robot in a compact bench-top system. The sampling flexibility is enabled by a soft-rigid hybrid continuum mechanism, where the bio-mimetic rigid interior and soft exterior design guarantee the robot with both flexibility and safety. Besides, the integration of 3-D fiber Bragg grating (FBG) based shape sensor and multi-axis force sensor provides enhanced closed-loop control performance. A dedicated constrained compliance control (CCC) algorithm was developed to tackle those unexpected interactions during sampling, which ensures the validity and safety of the robot sampling under disturbance. The robot can perform nasal/throat swab sampling tasks as dexterous as human manual operation. Various experiments are carried out to validate our system and prove its feasibility, flexibility, high safety, and efficiency for both nasal/throat swab sampling tasks. The proposed easy-to-deploy system is promising to be massive duplicated for robotic swab sampling. end{abstract}
# Towards Autonomous Atlas-Based Ultrasound Acquisitions in Presence of Articulated Motion
## Keywords:
- Medical Robots and Systems
- Sensor-based Control
- Sensor Fusion
## Abstract:
Robotic ultrasound (US) imaging aims at overcoming some of the limitations of free-hand US examinations, e.g. difficulty in guaranteeing intra# and inter-operator repeatability. However, due to anatomical and physiological variations between patients and relative movement of anatomical substructures, it is challenging to robustly generate optimal trajectories to examine the anatomies of interest, in particular, when they comprise articulated joints. To address this challenge, this paper proposes a vision-based approach allowing autonomous robotic US limb scanning. To this end, an atlas MRI template of a human arm with annotated vascular structures is used to generate trajectories and register and project them onto patients' skin surfaces for robotic ultrasound acquisition. To effectively segment and accurately reconstruct the targeted 3D vessel, we make use of spatial continuity in consecutive US frames by incorporating channel attention modules into a U-Net-type neural network. The automatic trajectory generation method is evaluated on five volunteers with various articulated joint angles. In all cases, the system could successfully acquire the planned vascular structure on volunteers' limbs. For one volunteer the MRI scan was also available allowing the evaluation of the average radius of the scanned artery estimated from the proposed robotic ultrasound acquisition, resulting in a radius estimation (1.2pm0.05 mm) compared to the MRI ground truth (1.2pm0.04 mm).
# Optimization of Surgical Robotic Instrument Mounting in a Macro-Micro Manipulator Setup for Improving Task Execution (I)
## Keywords:
- Optimization and Optimal Control
- Surgical Robotics: Laparoscopy
- Mechanism Design
## Abstract:
In minimally invasive robotic surgery, the surgical instrument is usually inserted inside the patient’s body through a small incision, which acts as a remote center of motion (RCM). Serial-link manipulators can be used as macro robots on which microsurgical robotic instruments are mounted to increase the number of degrees of freedom of the system and ensure safe task and RCM motion execution. However, the surgical instrument needs to be placed in an appropriate configuration when completing the motion tasks. The contribution of this article is to present a novel framework that preoperatively identifies the best base configuration, in terms of Roll, Pitch, and Yaw angles, of the microsurgical instrument with respect to the macro serial-link manipulator’s end effector in order to achieve the maximum accuracy and dexterity in performing specified tasks. The framework relies on hierarchical quadratic programming for the control, genetic algorithm for the optimization, and on a resilience to error strategy to make sure deviations from the optimum do not affect the system’s performance. Simulation results show that the mounting configuration of the surgical instrument significantly impacts the performance of the whole macro–micro manipulator in executing the desired motion tasks, and both the simulation and experimental results demonstrate that the proposed optimization method improves the overall performance.
# Robotics and Automation in Agriculture and Construction 1
# Excavation of Fragmented Rocks with Multi-Modal Model-Based Reinforcement Learning
## Keywords:
- Robotics and Automation in Construction
- Manipulation Planning
- Force and Tactile Sensing
## Abstract:
This paper presents a multi-modal model-based reinforcement learning (MBRL) approach to the excavation of fragmented rocks, which are very challenging to model due to their highly variable sizes and geometries, and visual occlusions. A multi-modal recurrent neural network (RNN) learns the dynamics of bucket-terrain interaction from a small physical dataset, with a discrete set of motion primitives encoded with domain knowledge as the action space. Then a model predictive controller (MPC) tracks a global reference path using multi-modal feedback. We show that our RNN-based dynamics function achieves lower prediction errors compared to a feed-forward neural network baseline, and the MPC is able to significantly outperform manually designed strategies on such a challenging task.
# Model Learning and Predictive Control for Autonomous Obstacle Reduction Via Bulldozing
## Keywords:
- Robotics and Automation in Construction
- Model Learning for Control
- Mining Robotics
## Abstract:
We investigate how employing model learning methods in concert with model predictive control (MPC) can be used to automate obstacle reduction to mitigate risks to Combat Engineers operating construction equipment in an active battlefield. We focus on the task of earthen berm removal using a bladed vehicle. We introduce a novel data-driven formulation for earthmoving dynamics that enables prediction of the vehicle and detailed terrain state over a one second horizon. In a simulation environment, we first record demonstrations from a human operator and then train two different earthmoving models to produce predictions of the high-dimensional state using under six minutes of data. Optimization over the learned model is performed to select an action sequence, constrained to a 2D space of template action trajectories. Simple recovery controllers are implemented to improve controller performance when the model predictions degrade. This system yields near human-level performance on a berm removal task, indicating that model learning and predictive control is a promising data-efficient approach to autonomous earthmoving.
# Design and Motion Planning for a Reconfigurable Robotic Base
## Keywords:
- Robotics and Automation in Construction
- Motion Control
- Mechanism Design
## Abstract:
A robotic platform for mobile manipulation needs to satisfy two contradicting requirements for many real-world applications: A compact base is required to navigate through cluttered indoor environments, while the support needs to be large enough to prevent tumbling or tip over, especially during fast manipulation operations with heavy payloads or forceful interaction with the environment. This paper proposes a novel robot design that fulfills both requirements through a versatile footprint. It can reconfigure its footprint to a narrow configuration when navigating through tight spaces and to a wide stance when manipulating heavy objects. Furthermore, its triangular configuration allows for high-precision tasks on uneven ground by preventing support switches. A model predictive control strategy is presented that unifies planning and control for simultaneous navigation, reconfiguration, and manipulation. It converts task-space goals into whole-body motion plans for the new robot. The proposed design has been tested extensively with a hardware prototype. The footprint reconfiguration allows to almost completely remove manipulation induced vibrations. The control strategy proves effective in both lab experiment and during a real-world construction task.
# External Load Estimation of Hydraulically Driven Construction Machinery from Cylinder Pressures and Link Accelerations
## Keywords:
- Robotics and Automation in Construction
- Force and Tactile Sensing
- Telerobotics and Teleoperation
## Abstract:
Remotely controlled hydraulically driven robots are expected to play an important role in extreme environments such as disaster sites, and force feedback is effective for improving the fidelity of the remote environment and the work efficiency. However, it is not reasonable to attach a force sensor directly to the end-point of a hydraulically driven robot. In a previous study, the authors showed that the impact forces, which are important information to improve the fidelity of the remote environment and work efficiency, can be estimated by using the information of acceleration of each link in addition to the cylinder pressures. In this paper, we investigated how many accelerometers and where those accelerometers should be attached on each link by using an index called GDOP (Geometric Dilution Of Precision) to improve the accuracy of impact force estimation. The experimental results show that although the estimation accuracy could not be improved significantly by rearranging the accelerometers, the effect of reducing the noise of the estimated load due to the sensor noise was confirmed.
# Connected Reconfiguration of Polyominoes Amid Obstacles Using RRT*
## Keywords:
- Robotics and Automation in Construction
- Computational Geometry
- Task and Motion Planning
## Abstract:
This paper investigates using a sampling-based approach, the RRT*, to reconfigure a 2D set of connected tiles in complex environments, where multiple obstacles might be present. Since the target application is automated building of discrete, cellular structures using mobile robots, there are constraints that determine what tiles can be picked up and where they can be dropped off during reconfiguration. We compare our approach to two algorithms as global and local planners, and show that we are able to find more efficient build sequences using a reasonable amount of samples, in environments with varying degrees of obstacle space.
See overview video at https://youtu.be/Fp0MUag8po4.
# Autonomous Mobile 3D Printing of Large-Scale Trajectories
## Keywords:
- Robotics and Automation in Construction
- Motion and Path Planning
- Additive Manufacturing
## Abstract:
Mobile 3D Printing (M3DP), using printing-in-motion, is a powerful paradigm for automated construction. A mobile robot, equipped with its own power, materials and an arm-mounted extruder, simultaneously navigates and creates its environment. Such systems can be highly scalable, parallelizable and flexible. However, planning and controlling the motion of the arm and base at the same time is challenging and most deployments either avoid robot-base motion entirely or use human prescribed robot-base paths. In a previous paper, we developed a high-level planning algorithm to automate M3DP given a print task. The generated robot-base paths avoid collisions and maintain task reachability. In this paper, we extend this work to robot control. We develop and compare three different ways to integrate the long-duration planned path with a short horizon Model Predictive Controller. Experiments are carried out via a new M3DP system — Armstone. We evaluate and demonstrate our algorithm in a 250 m long multi# layer print which is about 5 times longer than any previous physical printing-in-motion system.
# Soil-Adaptive Excavation Using Reinforcement Learning
## Keywords:
- Robotics and Automation in Construction
- Reinforcement Learning
- Hydraulic/Pneumatic Actuators
## Abstract:
In this letter, we present an excavation controller for a full-sized hydraulic excavator that can adapt online to different soil characteristics. Soil properties are hard to predict and can vary even within one scoop, which requires a controller that can adapt online to the encountered soil conditions. The objective is to fill the bucket with excavation material while respecting machine limitations to prevent stalling or lifting of the machine. To this end, we train a control policy in simulation using RL. The soil interactions are modeled based on the FEE with heavily randomized soil parameters to expose the agent to a wide range of different conditions. The agent learns to output joint velocity commands, which can be directly applied to the standard proportional valves of the real machine. We test the controller on a 12-ton excavator in different types of soils. The experiments demonstrate that the controller can adapt online to changing conditions without the explicit knowledge of the soil parameters, solely from proprioceptive observations, which are easily measurable.
# Loading an Autonomous Large-Scale Dump Truck: Path Planning Based on Motion Data from Human-Operated Construction Vehicles
## Keywords:
- Robotics and Automation in Construction
- Motion and Path Planning
- Field Robots
## Abstract:
A large-scale dump truck that automatically transports earth and sand in cooperation with a human-operated backhoe is of interest to the construction industry. A human-operated dump truck generally drives slightly past the desired loading position and then backs up to it for loading the sediment. The turning and loading positions are subjectively decided according to the working posture of the backhoe and the surrounding environment, and the safety margin of cooperative works. Backhoe operators want to perform the same maneuvers for human-operated/automated dump trucks. The movements of the autonomous vehicle should be similar to those of a human-operated one. However, it is difficult to derive a human-like path that does more than minimize costs. This study proposes a path-planning method that generates a path including a turning back, according to the changing backhoe position and surrounding conditions. We modeled the positional relationship during loading between a backhoe and dump truck, determining the loading and turning positions and related parameters from operational data collected in trials with human-operated construction vehicles. The proposed method allowed the autonomous dump truck path to resemble a human-like one. The authors have retrofitted an existing large-scale six-wheeled dump truck for automatic operation. Automatic loading in cooperation with a human-operated backhoe was realized all 17 times using the retrofitted dump. The average stopping accuracy was 0.57 m and 9.7 deg.
# Towards Autonomous Visual Navigation in Arable Fields
## Keywords:
- Robotics and Automation in Agriculture and Forestry
- Vision-Based Navigation
- Agricultural Automation
## Abstract:
Autonomous navigation of a robot in agricultural fields is essential for every task from crop monitoring to weed management and fertilizer application. Many current approaches rely on accurate GPS, however, such technology is expensive and can be impacted by lack of coverage. As such, autonomous navigation through sensors that can interpret their environment (such as cameras) is important to achieve the goal of autonomy in agriculture. In this paper, we introduce a purely vision-based navigation scheme that is able to reliably guide the robot through row-crop fields using computer vision and signal processing techniques without manual intervention. Independent of any global localization or mapping, this ap# proach is able to accurately follow the crop-rows and switch between the rows, only using onboard cameras. The proposed navigation scheme can be deployed in a wide range of fields with different canopy shapes in various growth stages, creating a crop agnostic navigation approach. This was completed under various illumination conditions using simulated and real fields where we achieve an average navigation accuracy of 3.82cm with minimal human intervention (hyper-parameter tuning) on BonnBot-I. Keywords — Robotics and Automation in Agriculture and Forestry; Agricultural Automation; Vision-Based Navigation.
# Recognition
# STEADY: Simultaneous State Estimation and Dynamics Learning from Indirect Observations
## Keywords:
- Dynamics
- Probabilistic Inference
- Machine Learning for Robot Control
## Abstract:
Accurate kinodynamic models play a crucial role in many robotics applications such as off-road navigation and high-speed driving. Many state-of-the-art approaches for learning stochastic kinodynamic models, however, require precise measurements of robot states as labeled input/output examples, which can be hard to obtain in outdoor settings due to limited sensor capabilities and the absence of ground truth. In this work, we propose a new technique for learning neural stochastic kinodynamic models from noisy and indirect observations by performing simultaneous state estimation and dynamics learning. The proposed technique iteratively improves the kinodynamic model in an expectation-maximization loop, where the E Step samples posterior state trajectories using particle filtering, and the M Step updates the dynamics to be more consistent with the sampled trajectories via stochastic gradient ascent. We evaluate our approach on both simulation and real-world benchmarks and compare it with several baseline techniques. Our approach not only achieves significantly higher accuracy but is also more robust to observation noise, thereby showing promise for boosting the performance of many other robotics applications.
# Smart Explorer: Recognizing Objects in Dense Clutter Via Interactive Exploration
## Keywords:
- Recognition
- RGB-D Perception
## Abstract:
Recognizing objects in dense clutter accurately makes significant contribution to a wide variety of robotic manipulation tasks including grasping, packing, rearranging and many others. However, the visual recognition model usually misses objects because of the significant occlusion among instances and causes incorrect prediction due to the visual ambiguity with the high object crowdedness. In this paper, we propose an interactive exploration framework called Smart Explorer for recognizing all objects in dense clutters. Our Smart Explorer physically interacts with the clutter to maximize the recognition performance while minimize the number of motions, where the false positives and negatives can be alleviated effectively with the optimal accuracy-efficiency trade-offs. Specifically, we first collect the multi-view RGB-D images of the clutter and reconstruct the corresponding point cloud. By aggregating the instance segmentation of RGB images across views, we acquire the instance-wise point cloud partition of the clutter through which the existed classes and the number of objects for each class are predicted. The pushing actions for effective physical interaction are generated to sizably reduce the recognition uncertainty that consists of the instance segmentation entropy and multi-view object disagreement. Therefore, the optimal accuracy-efficiency trade-off of object recognition in dense clutter is achieved via iterative instance prediction and physical interaction. Extensive experiments demonstrate that our Smart Explorer boosts acquires promising recognition accuracy with only a few actions, which also outperforms the random pushing by a large margin.
# LSDNet: A Lightweight Self-Attentional Distillation Network for Visual Place Recognition
## Keywords:
- Recognition
- Representation Learning
- Deep Learning for Visual Perception
## Abstract:
Abstract— Visual Place Recognition (VPR) has become an indispensable capacity for mobile robots to operate in large-scale environments. Existing methods in this field mostly focus on exploring high-performance encoding strategies, while few attempts are devoted to lightweight models that balance performance and computational cost. In this work, we propose a Lightweight Self-attentional Distillation Network (LSDNet) aiming to obtain advantages of both performance and efficiency. (1) From a performance perspective, an attentional encoding strategy is proposed to integrate crucial information in the scene. It extends the NetVLAD architecture with a self-attention module to facilitate non-local information interaction between local features. Through further visual word vector rescaling, the final image representation can benefit from both non-local spatial integration and cluster-wise weighting. (2) From an efficiency perspective, LSDNet is built upon a lightweight backbone. To maintain comparable performance to large backbone models, a dual distillation strategy is proposed. It prompts LSDNet to learn both encoding patterns in the hidden space and feature distributions in the encoding space from the teacher model. Through distillation-augmented training, LSDNet is able to rival the teacher model and outperform SOTA global representations with the same lightweight backbone.
# STUN: Self-Teaching Uncertainty Estimation for Place Recognition
## Keywords:
- Recognition
- Localization
- Probabilistic Inference
## Abstract:
Place recognition is key to Simultaneous Localization and Mapping (SLAM) and spatial perception. However, a place recognition in the wild often suffers from erroneous predictions due to image variations, e.g., viewpoints and street appearance. Integrating uncertainty estimation into the life cycle of place recognition is a promising method to mitigate the impact of variations on place recognition performance. However, existing uncertainty estimation approaches in this vein are either computationally inefficient (e.g., Monte Carlo dropout) or at the cost of dropped accuracy. This paper proposes STUN, a self-teaching framework that learns to simultaneously predict the place and estimate the prediction uncertainty given an input image. To this end, we first train a teacher net using a standard metric learning pipeline to produce embedding priors. Then, supervised by the pretrained teacher net, a student net with an additional variance branch is trained to finetune the embedding priors and estimate the uncertainty sample by sample. When it comes to the online inference phase, we only use the student net to generate a place prediction in conjunction with the uncertainty. When compared with place recognition systems that are ignorant to the uncertainty, our framework features the uncertainty estimation for free without sacrificing any prediction accuracy or incurring extra computation loads. Our experimental results on the large-scale Pittsburgh30k dataset demonstrate that STUN outperforms the state-of-the-art methods in both recognition accuracy and the quality of uncertainty estimation.
# Self-Supervised Reinforcement Learning for Active Object Detection
## Keywords:
- Recognition
- Deep Learning for Visual Perception
- Integrated Planning and Learning
## Abstract:
Active object detection (AOD) offers significant advantage in expanding the perceptual capacity of a robotics system. AOD is formulated as a sequential action decision process to determine optimal viewpoints to identify objects of interest in a visual scene. While reinforcement learning (RL) has been successfully used to solve many AOD problems, conventional RL methods suffer from (i) sample inefficiency, and (ii) unstable out# come due to inter-dependencies of action type (direction of view change) and action range (step size of view change). To address these issues, we propose a novel self-supervised RL method, which employs self-supervised representations of viewpoints to initialize the policy network, and a self-supervised loss on action range to enhance the network parameter optimization. The output and target pairs of self-supervised learning loss are automatically generated from the policy network online prediction and a range shrinkage algorithm (RSA), respectively. The proposed method is evaluated and benchmarked on two public datasets (T-LESS and AVD) using on-policy and off-policy RL algorithms. The results show that our method enhances detection accuracy and achieves faster convergence on both datasets. By evaluating on a more complex environment with a larger state space (where viewpoints are more densely sampled), our method achieves more robust and stable performance. Our experiment on real robot application scenario to disambiguate similar objects in a cluttered scene has also demonstrated the effectiveness of the proposed method.
# ReINView: Re-Interpreting Views for Multi-View 3D Object Recognition
## Keywords:
- Recognition
- Computer Vision for Manufacturing
- Computer Vision for Automation
## Abstract:
Multi-view-based 3D object recognition is important in robot-environment interaction. However, recent methods simply extract features from each view via convolutional neural networks (CNNs) and then fuse these features together to make predictions. These methods ignore the inherent ambiguities of each view caused due to 3D-2D projection. To address this problem, we propose a novel deep framework for multi-view-based 3D object recognition. Instead of fusing the multi-view features directly, we design a re-interpretation module (ReINView) to eliminate the ambiguities at each view. To achieve this, ReINView re-interprets view features patch by patch by using their context from nearby views, considering that local patches are generally co-visible at nearby viewpoints. Since contour shapes are essential for 3D object recognition as well, ReINView further performs view-level re-interpretation, in which we use all the views as context sources since the target contours to be re-interpreted are globally observable. The re-interpreted multi-view features can better reflect the 3D global and local structures of the object. Experiments on both ModelNet40 and ModelNet10 show that the proposed model outperforms state-of-the-art methods in 3D object recognition.
# Dual-Camera High Magnification Surveillance System with Non-Delay Gaze Control and Always-In-Focus Function in Indoor Scenes
## Keywords:
- Environment Monitoring and Management
- Surveillance Robotic Systems
## Abstract:
This study proposes a dual-camera system for indoor high magnification surveillance which is capable of achieving always-in-focus and non-delay gaze control based on high-speed vision. The users are enabled to move the mouse freely on the wide-view screen while observing its in-focal zoom-in monitoring video in real-time. The proposed system consists of a wide-angle camera for wide-view and a Galvano mirror-enabled ultra-fast pan-tilt-zoom (PTZ) camera for zoom-in view. To achieve always-in-focus, a high-speed focus scanning system is proposed that is comprised of a high-speed camera, a parfocal zoom lens, and a gear mechanism. Through continuously reciprocating rotational motion of the focusing ring driven by the servo motor, the high-speed camera captures sets of images with varying focal distances. Moreover, we proposed a most-in-focus (MIF) frame extraction algorithm to select the sharpest images as output. The experimental results are obtained to confirm the effectiveness of our system.
# Point Label Aware Superpixels for Multi-Species Segmentation of Underwater Imagery
## Keywords:
- Environment Monitoring and Management
- Semantic Scene Understanding
## Abstract:
Monitoring coral reefs using underwater vehicles increases the range of marine surveys and availability of historical ecological data by collecting significant quantities of images. Analysis of this imagery can be automated using a model trained to perform semantic segmentation, however it is too costly and time-consuming to densely label images for training supervised models. In this letter, we leverage photo-quadrat imagery labeled by ecologists with sparse point labels. We propose a point label aware method for propagating labels within superpixel regions to obtain augmented ground truth for training a semantic segmentation model. Our point label aware superpixel method utilizes the sparse point labels, and clusters pixels using learned features to accurately generate single-species segments in cluttered, complex coral images. Our method outperforms prior methods on the UCSD Mosaics dataset by 3.62% for pixel accuracy and 8.35% for mean IoU for the label propagation task, while reducing computation time reported by previous approaches by 76%. We train a DeepLabv3+ architecture and outperform state-of-the-art for semantic segmentation by 2.91% for pixel accuracy and 9.65% for mean IoU on the UCSD Mosaics dataset and by 4.19% for pixel accuracy and 14.32% for mean IoU on the Eilat dataset.
# Mapping of Spatiotemporal Scalar Fields by Mobile Robots Using Gaussian Process Regression
## Keywords:
- Environment Monitoring and Management
- Marine Robotics
- Field Robots
## Abstract:
Spatiotemporal maps are data-driven estimates of time changing phenomena. For environmental science, rather than collect data from an array of static sensors, a mobile sensor platform could reduce setup time and cost, maintain flexibility to be deployed to any area of interest, and provide active feedback during observations. While promising, mapping is challenging with mobile sensors because vehicle constraints limit not only where, but also when observations can be made. By assuming spatial and temporal correlations in the data through kernel functions, this paper uses Gaussian process regression (GPR) to generate a maximum likelihood estimate of the phenomenon while also tracking the estimate uncertainty. Spatiotemporal mapping by GPR is simulated for a single fixed-path mobile robot observing a latent spatiotemporal scalar field. The learned spatiotemporal map captures the structure of the latent scalar field with the largest uncertainties in areas the robot never visited.
# Safety in HRI
# PSM: A Predictive Safety Model for Body Motion Based on the Spring-Damper Pendulum
## Keywords:
- Safety in HRI
- Human-Centered Robotics
- Probability and Statistical Methods
## Abstract:
Quantifying the safety of the human body orientation is an important issue in human-robot interaction. Knowing the changing physical constraints on human motion can improve inspection of safe human motions and bring essential information about stability and normality of human body orientations with real-time risk assessment. Also, this information can be used in cooperative robots and monitoring systems to evaluate and interact in the environment more freely. Furthermore, the workspace area can be more deterministic with the known physical characteristics of safety. Based on this motivation, we propose a novel predictive safety model (PSM) that relies on the information of an inertial measurement unit on the human chest. The PSM encompasses a 3-Dofs spring-damper pendulum model that predicts human motion based on a safe motion dataset. The estimated safe orientation of humans is obtained by integrating a safety dataset and an elastic spring-damper model in a way that the proposed approach can realize complex motions at different safety levels. We did experiments in a real-world scenario to verify our novel proposed model. This novel approach can be used in different guidance/assistive robots and health monitoring systems to support and evaluate the human condition, particularly elders.
# Physical Adversarial Attack on a Robotic Arm
## Keywords:
- Safety in HRI
- Localization
- AI-Based Methods
## Abstract:
Collaborative Robots (cobots) are regarded as highly safety-critical cyber-physical systems (CPSs) owing to their close physical interactions with humans. In settings such as smart factories, they are frequently augmented with AI. For example, in order to move materials, cobots utilize object detectors based on deep learning models. Deep learning, however, has been demonstrated as vulnerable to adversarial attacks: a minor change (noise) to benign input can fool the underlying neural networks and lead to a different result. While existing works have explored such attacks in the context of picture/object classification, less attention has been given to attacking neural networks used for identifying object locations and demonstrating that this can actually lead to a physical attack in a real CPS. In this paper, we propose a method to generate adversarial patches for the object detectors of CPSs, to miscalibrate them and cause potentially dangerous physical effects. In particular, we evaluate our method on an industrial robotic arm for card gripping, demonstrating that it can be misled into clipping the operator’s hand instead of the card. To our knowledge, this is the first work to attack object locations and lead to an incident on human users by an actual system.
# Regularized Deep Signed Distance Fields for Reactive Motion Generation
## Keywords:
- Safety in HRI
- Machine Learning for Robot Control
- Deep Learning Methods
## Abstract:
Autonomous robots should operate in real-world dynamic environments and collaborate with humans in tight spaces. A key component for allowing robots to leave structured lab and manufacturing settings is their ability to evaluate online and real-time collisions with the world around them. Distance-based constraints are fundamental for enabling robots to plan their actions and act safely, protecting both humans and their hardware. However, different applications require different distance resolutions, leading to various heuristic approaches for measuring distance fields w.r.t. obstacles, which are computationally expensive and hinder their application in dynamic obstacle avoidance use-cases. We propose Regularized Deep Signed Distance Fields (ReDSDF), a single neural implicit function that can compute smooth distance fields at any scale, with fine-grained resolution over high-dimensional manifolds and articulated bodies like humans, thanks to our effective data generation and a simple inductive bias during training. We demonstrate the effectiveness of our approach in representative simulated tasks for whole-body control (WBC) and safe Human-Robot Interaction (HRI) in shared workspaces. Finally, we provide proof of concept of a real-world application in a HRI handover task with a mobile manipulator robot.
# Safe and Ergonomic Human-Drone Interaction in Warehouses
## Keywords:
- Safety in HRI
- Motion and Path Planning
- Aerial Systems: Applications
## Abstract:
This paper presents an application of human-drone interaction (HDI) for inventory management in a warehouse 4.0 that aims at improving the operators’ safety and well-being together with increasing efficiency and reducing production costs. In our work, the speed and separation monitoring (SSM) methodology is applied for the first time to HDI, in analogy to the human-robot interaction (HRI) ISO safety requirements as well as the rapid upper limb assessment (RULA), for evaluating the operator’s ergonomic posture during the interaction with the drone. With the aim of validating the proposed approach in a realistic scenario, a quadrotor is controlled to perform a pick and place task along a desired trajectory, from the picking bay to the palletizing area where the operator is located, avoiding collisions with the warehouse shelves by implementing the artificial potential field technique (APF) for planning and the linear quadratic regulator (LQR) and iterative LQR (iLQR) algorithms for tracking. The obtained results of the HDI architecture simulations are presented and discussed in detail proving the effectiveness of the proposed method for a safe and ergonomic HDI.
# Robot Contact Reflexes: Adaptive Maneuvers in the Contact Reflex Space
## Keywords:
- Safety in HRI
- Performance Evaluation and Benchmarking
- Reactive and Sensor-Based Planning
## Abstract:
In order to transform a robot into an intelligent machine it needs to be enabled to react to unforeseen events (most importantly collisions) during task execution and have a plan on how to continue the task afterwards. This requires a flexible operational framework that allows to define adaptive reactions and interactions with the motion generation and task planning stage. Within this work we first reason about the choices the robot has for reactions to unforeseen events such as collisions with respect to safety of humans in the workspace, the robot itself and the environment as well as the successful task execution. We further present a flexible reflex engine together with a concept of integration into the motion generation and control work flow. The reflex engine and it’s reflex maneuvers are a combination of state machines and decision trees that take into account the state of the robot and the world. It is capable of choosing safe reactions and can differentiate between different levels of contact severity and according reaction sets. Several reflex maneuvers are evaluated towards safety performance criteria in real robot experiments using an ISO/TS 15066 conform measurement device. Some of the tested reflexes are furthermore integrated into an implementation of the proposed approach for a simple real world example task where the robot needs to pickup a container and dispose it’s content into a bin.
# Suppressing Delay-Induced Oscillations in Physical Human-Robot Interaction with an Upper-Limb Exoskeleton Using Rate-Limiting
## Keywords:
- Safety in HRI
- Physical Human-Robot Interaction
- Prosthetics and Exoskeletons
## Abstract:
In physical human-robot interaction (pHRI) enabled by admittance control, delay-induced oscillations arising from both the neuromuscular time-delays of the human and electromechanical delays of the robot can cause unsafe instability in the system. This study presents and evaluates rate-limiting as a means to overcome such instability, and provides a new perspective on how rate-limiting can benefit pHRI. Specifically, a rate-limited and time-delayed human-in-the-loop (HITL) model is analyzed to show not only how the rate-limiter can transform an unstable equilibrium (due to time-delay) into a stable limit-cycle, but also how a desired upper-bound on the range of persistent oscillations can be achieved by appropriately setting the rate-limiter threshold. In addition, a study involving 10 subjects and the EXO-UL8 upper-limb exoskeleton, and consisting of 16 trials # 4 rate-limiter thresholds by 4 time-delays # is performed to: (1) validate the relationships between time-delays, rate-limits, and position bounds on persistent oscillations, and (2) demonstrate the effectiveness of rate-limiting for recovery from delay-induced oscillations without interfering with regular operation. Agreement of experimental results with the theoretical developments supports the feasibility of incorporating rate-limiting in admittance-controlled pHRI systems as a safety mechanism.
# Safety Compliant Control for Robotic Manipulator with Task and Input Constraints
## Keywords:
- Safety in HRI
- Robot Safety
- Dexterous Manipulation
## Abstract:
Increasingly, robots are working in close proximity with humans, and in dynamically changing environments. We present a new control architecture that guarantees safety under such conditions, while simultaneously ensuring that task goals are satisfied. Our approach combines Control Barrier Functions (to provide safety guarantees) with Rapidly Exponentially Stabilizing Control Lyapunov functions (to satisfy task constraints and ensure exponential convergence). We formulate the problem completely in the operational space, using super ellipsoids to define safe sets which are dynamically adapted to restrict the robot's operational space in response to moving obstacles (including humans). Control barrier functions, which can be implemented in real-time using quadratic programming, ensure the forward invariance of these safe sets, while minimally perturbing prescribed control trajectories. We demonstrate our approach on a seven degree-of-freedom Kuka LBR iiwa robotic manipulator, both in a physics engine-based simulation and with real hardware experiments.
# Safe and Efficient Exploration of Human Models During Human-Robot Interaction
## Keywords:
- Safety in HRI
- Robust/Adaptive Control
- Modeling and Simulating Humans
## Abstract:
Many collaborative human-robot tasks require the robot to stay safe and work efficiently around humans. Since the robot can only stay safe with respect to its own model of the human, we want the robot to learn a good model of the human in order to act both safely and efficiently. This paper studies methods that enable a robot to safely explore the space of a human-robot system to improve the robot's model of the human, which will consequently allow the robot to access a larger state space and better work with the human. In particular, we introduce active exploration under the framework of energy-function based safe control, investigate the effect of different active exploration strategies, and finally analyze the effect of safe active exploration on both analytical and neural network human models.
# Evaluation of On-Robot Capacitive Proximity Sensors with Collision Experiments for Human-Robot Collaboration
## Keywords:
- Safety in HRI
- Robot Safety
- Performance Evaluation and Benchmarking
## Abstract:
A robot must comply with very restrictive safety standards in close human-robot collaboration applications. These standards limit the robot’s performance because of speed reductions to avoid potentially large forces exerted on humans during collisions. On-robot capacitive proximity sensors (CPS) can serve as a solution to allow higher speeds and thus better productivity. They allow early reactive measures before contacts occur to reduce the forces during collisions. An open question on designing the systems is the selection of an adequate activation distance to trigger safety measures for a specific robot while considering latency and detection robustness. Furthermore, the systems’ actual effectiveness of impact attenuation and performance gain has not been evaluated before. In this work, we define and conduct a unified test procedure based on collision experiments to determine these parameters and investigate the performance gain. Two capacitive proximity sensor systems are evaluated on this test strategy on two robots. A significant performance increase can be achieved, since a small detection distance doubles robot operation speed while maintaining the same contact force as without Capacitive Proximity Sensor (CPS). This work can serve as a reference guide for designing, configuring and implementing future on-robot CPS.
# Humanoid and Bipedal Locomotion
# Terrain-Adaptive, ALIP-Based Bipedal Locomotion Controller Via Model Predictive Control and Virtual Constraints
## Keywords:
- Humanoid and Bipedal Locomotion
- Legged Robots
## Abstract:
This paper presents a gait controller for bipedal robots to achieve highly agile walking over various terrains given local slope and friction cone information. Without these considerations, untimely impacts can cause a robot to trip and inadequate tangential reaction forces at the stance foot can cause slippages. We address these challenges by combining, in a novel manner, a model based on an Angular Momentum Linear Inverted Pendulum (ALIP) and a Model Predictive Control (MPC) foot placement planner that is executed by the method of virtual constraints. The process starts with abstracting from the full dynamics of a Cassie 3D bipedal robot, an exact low-dimensional representation of its center of mass dynamics, parameterized by angular momentum. Under a piecewise planar terrain assumption and the elimination of terms for the angular momentum about the robot's center of mass, the centroidal dynamics about the contact point become linear and have dimension four. Importantly, we include the intra-step dynamics at uniformly-spaced intervals in the MPC formulation so that realistic workspace constraints on the robot's evolution can be imposed from step-to-step. The output of the low-dimensional MPC controller is directly implemented on a high-dimensional Cassie robot through the method of virtual constraints. In experiments, we validate the performance of our control strategy for the robot on a variety of surfaces with varied inclinations and textures.
# Robust Contact State Estimation in Humanoid Walking Gaits
## Keywords:
- Humanoid and Bipedal Locomotion
- Legged Robots
## Abstract:
In this article, we propose a deep learning framework that provides a unified approach to the problem of leg contact detection in humanoid robot walking gaits. Our formulation accomplishes to accurately and robustly estimate the contact state probability for each leg (i.e., stable or slip/no contact). The proposed framework employs solely proprioceptive sensing and although it relies on simulated ground-truth contact data for the classification process, we demonstrate that it generalizes across varying friction surfaces and different legged robotic platforms and, at the same time, is readily transferred from simulation to practice. The framework is quantitatively and qualitatively assessed in simulation via the use of ground-truth contact data and is contrasted against state-of-the-art methods with an ATLAS, a NAO, and a TALOS humanoid robot. Furthermore, its efficacy is demonstrated in base estimation with a real TALOS humanoid. To reinforce further research endeavors, our implementation is offered as an open-source ROS/Python package, coined Legged Contact Detection (LCD).
# Uniform Global Exponential Stabilizing Passivity-Based Tracking Controller Applied to Planar Biped Robots
## Keywords:
- Humanoid and Bipedal Locomotion
- Underactuated Robots
- Legged Robots
## Abstract:
This paper presents a novel control approach, based on the interconnection and damping-assignment passivity-based control (IDA-PBC), to achieve stable and periodic walking for underactuated planar biped robots with one degree of underactuation. The system's physical structure is preserved by assigning a target port-Hamiltonian dynamics to the closed-loop system, which also ensures passivity. The control design ensures that the tracking error to the desired periodic gait converges exponentially to zero, and the convergence rate can be adjusted via gain tuning. Besides, through the hybrid zero dynamics, the stability of the full-order system can be retrieved from the stability of the orbit created in a lower-dimensional manifold. The proposed approach is the first example of a tracking controller based on the IDA-PBC applied to underactuated biped robots. Numerical simulations on a five-link planar biped robot with unactuated ankles validate the approach and show the performance of the closed-loop system.
# Learning Dynamic Bipedal Walking across Stepping Stones
## Keywords:
- Humanoid and Bipedal Locomotion
- Legged Robots
- Reinforcement Learning
## Abstract:
In this work, we propose a learning approach for 3D dynamic bipedal walking when footsteps are constrained to stepping stones. While recent work has shown progress on this problem, real-world demonstrations have been limited to relatively simple open-loop, perception-free scenarios. Our main contribution is a more advanced learning approach that enables real-world demonstrations, using the Cassie robot, of closed-loop dynamic walking over moderately difficult stepping-stone patterns. Our approach first uses reinforcement learning (RL) in simulation to train a controller that maps footstep commands onto joint actions without any reference motion information. We then learn a model of that controller's capabilities, which enables prediction of feasible footsteps given the robot's current dynamic state. The resulting controller and model are then integrated with a real-time overhead camera system for detecting stepping stone locations. For evaluation, we develop a benchmark set of stepping stone patterns, which are used to test performance in both simulation and the real world. Overall, we demonstrate that sim-to-real learning is extremely promising for enabling dynamic locomotion over stepping stones. We also identify challenges remaining that motivate important future research directions.
# Humanoid Balance Control Using Centroidal Angular Momentum Based on Hierarchical Quadratic Programming
## Keywords:
- Humanoid and Bipedal Locomotion
- Optimization and Optimal Control
## Abstract:
Maintaining balance to external pushes is one of the most important features for a humanoid to walk in a real environment. In particular, methods for counteracting to pushes using the centroidal angular momentum (CAM) control have been actively developed. In this paper, a CAM control scheme based on hierarchical quadratic programming (HQP) is proposed. The scheme of the CAM control consists of CAM tracking control and initial pose return control, which is hierarchically operated based on HQP to ensure the priority of CAM tracking performance. The proposed method is implemented in a capture point (CP) feedback control framework. Through simulations and experiments, the proposed method demonstrated more stable balance control performance than the previous method when the humanoid is walking in the presence of external perturbation.
# Resolved Motion Control for 3D Underactuated Bipedal Walking Using Linear Inverted Pendulum Dynamics and Neural Adaptation
## Keywords:
- Humanoid and Bipedal Locomotion
- Legged Robots
- Neural and Fuzzy Control
## Abstract:
We present a framework to generate periodic trajectory references for a 3D under-actuated bipedal robot, using a linear inverted pendulum (LIP) based controller with adaptive neural regulation. We use the LIP template model to estimate the robot's center of mass (CoM) position and velocity and formulate a discrete controller that outputs the next footstep location to achieve a desired walking velocity. This controller is equipped on the frontal plane with a Neural-Network-based adaptive term that reduces the model mismatch between the template and physical robot that particularly affects the lateral motion. Then, the foot placement location computed for the LIP model is used to generate task space trajectories (CoM and swing foot trajectories) for the actual robot to realize stable walking. We use a real-time QP-based inverse kinematics algorithm that produces joint references from the task space trajectories in real-time, which makes the formulation independent of the knowledge of the robot dynamics. Finally, we implemented and evaluated the proposed approach in simulation and hardware experiments with a Digit robot obtaining stable periodic locomotion for both cases.
# Preemptive Foot Compliance to Lower Impact During Biped Robot Walking Over Unknown Terrain
## Keywords:
- Humanoid and Bipedal Locomotion
- Sensor-based Control
- Compliance and Impedance Control
## Abstract:
In this work, we present a novel method for ankle/foot compliance for biped humanoid robots walking over uneven terrain. Based on distributed plantar proximity sensing, we developed the Preemptive Foot Compliance (PFC) control that generates a Preemptive Ground Reaction Wrench that modifies the foot orientation to maximize the largest contact area to dampen the impact force produced at landing. PFC can be easily included in any walking controller for flat ground and become capable of walking on uneven terrains. The PFC was tested on two full-size humanoid robots running two different walking controllers, originally designed only for flat-ground walking. Both robots increase their capability to walk over uneven terrain and the walking impacts in flat grown were reduced by approximately 80%.
# Improved Biped Walking Performance Around the Kinematic Singularities of Biomimetic Four-Bar Knees
## Keywords:
- Passive Walking
- Humanoid and Bipedal Locomotion
- Biomimetics
## Abstract:
This paper studies the effects of replacing pin-joint knees in passive dynamic bipedal walkers with biomimetic four-bar knees. The kinetic model of the four-bar knees is presented in detail, and an analytical model of the passive walking dynamics is derived. The resulting four-bar kneed biped is compared with a pin-joint kneed walker, for their passive walking performance. The geometry of the four-bar knees used in the study is based on human anatomical data. It is found that the biomimetic four-bar knee configuration works to the advantage of the biped, especially around the extended-knee singular position. The four-bar knees are found to overperform the pin-joint ones, resulting in significant reduction of peak impact loads and energetic expenditure.
# Comparison of EKF-Based Floating Base Estimators for Humanoid Robots with Flat Feet
## Keywords:
- Humanoid and Bipedal Locomotion
- Humanoid Robot Systems
- Legged Robots
## Abstract:
Extended Kalman filtering is a common approach to achieve floating base estimation of a humanoid robot. These filters rely on measurements from an Inertial Measurement Unit (IMU) and relative forward kinematics for estimating the base position-and-orientation and its linear velocity along with the augmented states of feet position-and-orientation. We refer to such filters as flat-foot filters. However, the availability of only partial measurements often poses the question of consistency in the filter design. In this paper, we perform an experimental comparison of state-of-the-art flat-foot filters based on the representation choice of state, observation, matrix Lie group error and system dynamics evaluated for filter consistency and trajectory errors. The comparison is performed over simulated and real-world experiments conducted on the iCub humanoid platform. It is observed that filters on Lie groups that exploit properties of invariant filtering tend to perform better as consistent estimators while discrete-time filters in general provide higher accuracy along observable directions.
# Computer Vision for Automation 2
# ParaPose: Parameter and Domain Randomization Optimization for Pose Estimation Using Synthetic Data
## Keywords:
- Computer Vision for Automation
- Object Detection, Segmentation and Categorization
## Abstract:
Pose estimation is the task of determining the 6D position of an object in a scene. Pose estimation aid the abilities and flexibility of robotic set-ups. However, the system must be configured towards the use case to perform adequately. This configuration is time-consuming and limits the usability of pose estimation and, thereby, robotic systems.
Deep learning is a method to overcome this configuration procedure by learning parameters directly from the dataset. However, obtaining this training data can also be very time-consuming. The use of synthetic training data avoids this data collection problem, but a configuration of the training procedure is necessary to overcome the domain gap problem. Additionally, the pose estimation parameters also need to be configured. This configuration is jokingly known as grad student descent as parameters are manually adjusted until satisfactory results are obtained.
This paper presents a method for automatic configuration using only synthetic data. This is accomplished by learning the domain randomization during network training, and then using the domain randomization to optimize the pose estimation parameters. The developed approach shows state-of-the-art performance of 82.0 % recall on the challenging OCCLUSION dataset, outperforming all previous methods with a large margin. These results prove the validity of automatic set-up of pose estimation using purely synthetic data.
# Jacobian Computation for Cumulative B-Splines on SE(3) and Application to Continuous-Time Object Tracking
## Keywords:
- Computer Vision for Automation
- Visual Tracking
- Kinematics
## Abstract:
In this paper we propose a method that estimates the SE(3) continuous trajectories (orientation and translation) of the dynamic rigid objects present in a scene, from multiple RGB-D views. Specifically, we fit the object trajectories to cumulative B-Splines curves, which allow us to interpolate, at any intermediate time stamp, not only their poses but also their linear and angular velocities and accelerations. Additionally, we derive in this work the analytical SE(3) Jacobians needed by the optimization, being applicable to any other approach that uses this type of curves. To the best of our knowledge this is the first work that proposes 6-DoF continuous-time object tracking, which we endorse with significant computational cost reduction thanks to our analytical derivations. We evaluate our proposal in synthetic data and in a public benchmark, showing competitive results in localization and significant improvements in velocity estimation in comparison to discrete-time approaches.
# Intensity Image-Based LiDAR Fiducial Marker System
## Keywords:
- Computer Vision for Automation
- Range Sensing
- Object Detection, Segmentation and Categorization
## Abstract:
The fiducial marker system for LiDAR is crucial for the robotic application but it is still rare to date. In this paper, an Intensity Image-based LiDAR Fiducial Marker (IILFM) system is developed. This system only requires an unstructured point cloud with intensity as the input and it has no restriction on marker placement and shape. A marker detection method that locates the predefined 3D fiducials in the point cloud through the intensity image is introduced. Then, an approach that utilizes the detected 3D fiducials to estimate the LiDAR 6-DOF pose that describes the transmission from the world coordinate system to the LiDAR coordinate system is developed. Moreover, all these processes run in real-time (approx 40 Hz on Livox Mid-40 and approx 143 Hz on VLP-16). Qualitative and quantitative experiments are conducted to demonstrate that the proposed system has similar convenience and accuracy as the conventional visual fiducial marker system. The codes and results are available at: https://github.com/York-SDCNLab/IILFM.
# Multi-Modal Non-Isotropic Light Source Modelling for Reflectance Estimation in Hyperspectral Imaging
## Keywords:
- RGB-D Perception
- Sensor Fusion
- Calibration and Identification
## Abstract:
Estimating reflectance is key when working with hyperspectral cameras. The modelling of light sources can aid reflectance estimation, however, it is commonly overlooked. The key contribution of this paper is a physics-based, data-driven model formed by a Gaussian Process (GP) with a unique mean function capable of modelling a light source with an asymmetric radiant intensity distribution (RID) and a configurable attenuation function. This is referred to as the light-source-mean model. Moreover, we argue that by utilising multi-modal sensing information, we can achieve improved reflectance estimation using the proposed light source model with shape information obtained by depth cameras. An existing reflectance estimation method, that solves the dichromatic reflectance model (DRM) via quadratic programming optimisation, is augmented with terms that allow input of shape information. Experiments in simulation show that the light-source-mean GP model had less error when compared to a parametric model. The improved reflectance estimation outperforms existing methods in simulation by reducing the error by 96.8% on average when compared to existing works. We further validate the improved reflectance estimation method through a multi-modal classification application.
# LiSnowNet: Real-Time Snow Removal for LiDAR Point Clouds
## Keywords:
- Deep Learning for Visual Perception
- Computer Vision for Automation
- Deep Learning Methods
## Abstract:
Light Detection And Rangings (LiDARs) have been widely adopted to modern self-driving vehicles, providing 3D information of the scene and surrounding objects. However, adverser weather conditions still pose significant challenges to LiDARs since point clouds captured during snowfall can easily be corrupted. The resulting noisy point clouds degrade downstream tasks such as mapping. Existing works in de-noising point clouds corrupted by snow are based on nearest-neighbor search, and thus do not scale well with modern LiDARs which usually capture 100k or more points at 10Hz. In this paper, we introduce an unsupervised de-noising algorithm, LiSnowNet, running 52x faster than the state-of-the-art methods while achieving superior performance in de-noising. Unlike previous methods, the proposed algorithm is based on a deep convolutional neural network and easily be deployed with hardware accelerators such as GPUs. In addition, we demonstrate how to use the proposed method for mapping even with corrupted point clouds.
# Application of Ghost-DeblurGAN to Fiducial Marker Detection
## Keywords:
- Computer Vision for Automation
- Object Detection, Segmentation and Categorization
- Autonomous Vehicle Navigation
## Abstract:
Feature extraction or localization based on the fiducial marker could fail due to motion blur in real-world robotic applications. To solve this problem, a lightweight generative adversarial network, named Ghost-DeblurGAN, for real-time motion deblurring is developed in this paper. Furthermore, on account that there is no existing deblurring benchmark for such a task, a new large-scale dataset, YorkTag, is proposed that provides pairs of sharp/blurred images containing fiducial markers. With the proposed model trained and tested on YorkTag, it is demonstrated that when applied along with fiducial marker systems to motion-blurred images, Ghost-DeblurGAN improves the marker detection significantly. The datasets and codes used in this paper are available at: https://github.com/York-SDCNLab/Ghost-DeblurGAN.
# Learning Important Regions Via Attention for Video Streaming on Cloud Robotics
## Keywords:
- Computer Vision for Automation
- Mobile Manipulation
- Networked Robots
## Abstract:
Cloud robotics, i.e., controlling robots from the cloud, make it possible to perform more complex processes, make robots smaller, and coordinate multi-robots by sharing information between robots and utilizing abundant computing resources. In cloud robotics, robots need to transmit videos to the cloud in real time to recognize their surroundings. Lowering the video quality reduces the bitrate in low bandwidth environments; however, this may lead to control errors and mis-recognition due to lack of detailed image features. Even with 5G, bandwidth fluctuates widely, especially in moving robots, making it difficult to upload high quality video consistently. To reduce bitrate while preserving Quality of Control (QoC), we propose a method of learning the important regions for a pre-trained autonomous agent using self-attention, and transmitting the video to the agent by controlling the image quality of each region on the basis of the estimated importance. The evaluation results demonstrate that our approach can maintain QoC while reducing the bitrate to 26% by setting important regions to high quality and the rest to low quality.
# Unsupervised Simultaneous Learning for Camera Re-Localization and Depth Estimation from Video
## Keywords:
- Computer Vision for Automation
- Localization
- Mapping
## Abstract:
We present an unsupervised simultaneous learning framework for the task of monocular camera re-localization and depth estimation from unlabeled video sequences. Monocular camera re-localization refers to the task of estimating the absolute camera pose from an instance image in a known environment, which has been intensively studied for alternative localization in GPS-denied environments. In recent works, camera re-localization methods are trained via supervised learning from pairs of camera images and camera poses. In contrast to previous works, we propose a completely unsupervised learning framework for camera re-localization and depth estimation, requiring only monocular video sequences for training. In our framework, we train two networks that estimate the scene coordinates using directions and the depth map from each image which are then combined to estimate the camera pose. The networks can be trained through the minimization of loss functions based on our loop closed view synthesis. In experiments with the 7-scenes dataset, the proposed method outperformed the re-localization of the state-of-the-art visual SLAM, ORB-SLAM3. Our method also outperforms state-of-the-art monocular depth estimation in a trained environment.
# HyperPocket: Generative Point Cloud Completion
## Keywords:
- Computer Vision for Automation
- Recognition
- Deep Learning Methods
## Abstract:
Scanning real-life scenes with modern registration devices typically give incomplete point cloud representations, mostly due to the limitations of the scanning process and 3D occlusions. Therefore, completing such partial representations remains a fundamental challenge of many computer vision applications. Most of the existing approaches aim to solve this problem by learning to reconstruct individual 3D objects in a synthetic setup of an uncluttered environment, which is far from a real-life scenario. In this work, we reformulate the problem of point cloud completion into an objects hallucination task. 
Thus, we introduce a novel autoencoder-based architecture called HyperPocket that disentangles latent representations and, as a result, enables the generation of multiple variants of the completed 3D point clouds. Furthermore, we split point cloud processing into two disjoint data streams and leverage a hypernetwork paradigm to fill the spaces, dubbed pockets, that are left by the missing object parts. As a result, the generated point clouds are smooth, plausible, and geometrically consistent with the scene. Moreover, our method offers competitive performances to the other state-of-the-art models, enabling a plethora of novel applications.
# Marine Robotics 1
# Flexible Collision-Free Platooning Method for Unmanned Surface Vehicle with Experimental Validations
## Keywords:
- Marine Robotics
- Autonomous Vehicle Navigation
- Collision Avoidance
## Abstract:
This paper addresses the flexible formation problem for unmanned surface vehicles in the presence of obstacles. Building upon the leader-follower formation scheme, a hybrid line-of-sight based flexible platooning method is proposed for follower vehicle to keep tracking the leader ship. A fusion artificial potential field collision avoidance approach is tailored to generate optimal collision-free trajectories for the vehicle to track. To steer the vehicle towards and stay within the neighborhood of the generated collision-free trajectory, a nonlinear model predictive controller is designed. Experimental results are presented to validate the efficiency of proposed method, showing that the the unmanned surface vehicle is able to track the leader ship without colliding with the surrounded static obstacles in the considered experiments.is able to track the leader ship without colliding with the surrounded static obstacles in the considered experiments.
# Development and Field Testing of an Optimal Path Following ASV Controller for Marine Surveys
## Keywords:
- Marine Robotics
- Field Robots
- Motion and Path Planning
## Abstract:
Marine autonomous vehicles deployed to conduct marine geophysical surveys are becoming an increasingly used asset in the commercial, academic, and defense industries. However, the ability to collect high-quality data from applicable sensors is directly related to the robustness of vehicle motion caused by environmental disturbances. In this paper we designed and integrated a new path following controller on an autonomous surface vehicle (ASV) that minimizes the linear and angular accelerations on the sensor’s local frame. Simulation and experimental results verify reduction of vehicle motion, improvement in path following, and improvement in preliminary sonar data quality compared to that of the existing proportional-yaw path following controller.
# Inertial-Measurement-Based Catenary Shape Estimation of Underwater Cables for Tethered Robots
## Keywords:
- Marine Robotics
## Abstract:
This paper deals with the estimation of the shape of a catenary for a negatively buoyant cable, connecting a pair of underwater robots in a robot chain. The new estimation method proposed here is based on the calculation of local tangents thanks to the data issued from inertial measurement units (IMUs), which are attached to the cable near its ends. This method is compared with a vision-based estimation method that was developed previously. Experiments are conducted, in the air and in a pool, using a motion capture system for ground truth. The results obtained show that the new method significantly improves the estimation of the catenary height. Actually, the identification of the cable shape is not affected by the limits of the camera’s field of view and by the image projection, resulting in increased accuracy and range, without singularities.
# Motion Attribute-Based Clustering and Collision Avoidance of Multiple In-Water Obstacles by Autonomous Surface Vehicle
## Keywords:
- Marine Robotics
- Collision Avoidance
- Autonomous Vehicle Navigation
## Abstract:
Navigation and obstacle avoidance in aquatic environments for autonomous surface vehicles (ASVs) in high-traffic maritime scenarios is still an open challenge, as the Convention on	the International Regulations for Preventing Collisions	at Sea (COLREGs) is not defined for multi-encounter situations. Current state-of-the-art methods resolve single-to-single encounters with sequential actions and assume that other obstacles follow COLREGs. Our work proposes a novel real-time non-myopic obstacle avoidance method, allowing an ASV that has only partial knowledge of the surroundings within the sensor radius to navigate in high-traffic maritime scenarios. Specifically, we achieve a holistic view of the feasible ASV action space able to avoid deadlock scenarios, by proposing (1) a clustering method based on motion attributes of other obstacles, (2) a geometric framework for identifying the feasible action space, and (3) a multi-objective optimization to determine the best action. Theoretical analysis and extensive realistic experiments in simulation considering real-world traffic scenarios demonstrate that our proposed real-time obstacle avoidance method is able to achieve safer trajectories than other state-of-the-art methods and that is robust to uncertainty present in the current information available to the ASV.
# Training Dynamic Motion Primitives Using Deep Reinforcement Learning to Control a Robotic Tadpole
## Keywords:
- Marine Robotics
- Bioinspired Robot Learning
- Reinforcement Learning
## Abstract:
Developing a good control strategy for biomimetic robots is challenging. Robust control methods require an accurate model of the robot. Nowadays, model-free methods are being extensively explored for the control and navigation of terrestrial robots. In this paper, we consider a novel deep reinforcement learning-based model-free swimming control for our bio-inspired robotic tadpole. To realize this, we utilize dynamic motion primitives, which can represent a large range of motion behaviors, and combine them with a decoupled reinforcement learning framework. The proposed architecture optimizes the motion primitives first to develop a travelling wave undulation pattern in the tail and then to navigate the robot along different predefined paths. Through this framework, effective swimming gait emerges, and the robot is able to navigate well on the surface of water. This framework combines the optimization potential of deep reinforcement learning with stability and generalization properties of dynamic motion primitives. We train and test our method on a simulated model of the robot to demonstrate the effectiveness of the method and also conduct experimental testing on the real robot to verify the results.
# Hydrodynamic Parameters Estimation Using Varying Forces and Numerical Integration Fitting Method
## Keywords:
- Marine Robotics
- Dynamics
- Performance Evaluation and Benchmarking
## Abstract:
This paper presents a new experimental method for the estimation of hydrodynamic parameters of underwater vehicles, namely the added mass and drag coefficients. The principle is to accurately record the movement of the vehicle in response to a known time-varying actuating force, and find an optimal solution for the parameters that allows simulating a velocity trajectory that fits the recorded trajectory. The optimal solution is obtained using a Numerical Integration Fitting method, which, employing an error minimization algorithm, successively generates velocity trajectories through numerical integration until the parameters converge. This method is applied to determine the hydrodynamic parameters of a torpedo-shaped Autonomous Underwater Vehicle (AUV). The hydrodynamic parameters obtained are compared and found to be close to their theoretical values. In addition, the use of a time-varying force is shown to provide better and more reliable results than the use of a constant or zero external force.
# An Underwater Target Perception Framework for Underwater Operation Scene
## Keywords:
- Object Detection, Segmentation and Categorization
- Surveillance Robotic Systems
- Cognitive Modeling
## Abstract:
This paper proposes an underwater target perception framework to comprehensively explore target information in underwater scenes, to improve the work efficiency and safety of underwater operations. This framework adopts a layered processing mechanism including water column imaging, constant false alarm rate detection (CFAR) detection, and local feature analysis, to accurately distinguish between false targets, static targets, and dynamic targets in the underwater scene, and obtain the motion trajectory of dynamic targets. The experiment is designed to simulate the underwater operation scene, and the results prove the effectiveness of the proposed framework.
# Soft Robot Materials and Design 2
# Self-Morphing Soft Parallel-And-Coplanar Electroadhesive Grippers Based on Laser-Scribed Graphene Oxide Electrodes
## Keywords:
- Grippers and Other End-Effectors
- Soft Sensors and Actuators
- Soft Robot Materials and Design
## Abstract:
Electroadhesion is a versatile and controllable adhesion mechanism that has been used extensively in robotics. Soft electroadhesion embodies electrostatic adhesion in soft materials and is required for shape-adaptive and safe grasping of curved objects and delicate materials. In this work, we present a soft electroadhesive fabrication method based on laser scribing graphene oxide on a silicone film, which is cost-effective, facile and green. The method can be used to generate complex electroadhesive patterns without molds or stencils. We then present a 2D finite element model to demonstrate the shape-changing behavior and electric field distributions of a dual-mode parallel dielectric elastomer actuation and coplanar electroadhesion structure. The soft electroadhesive fabrication method based on laser-scribed graphene oxide electrodes and its experimental characterization results, together with its shape-morphing simulation model are expected to enable the wider adoption of soft electroadhesion in future robotics.
# Embeddable Coiled Soft Sensor-Based Joint Angle Sensing for Flexible Surgical Manipulator
## Keywords:
- Medical Robots and Systems
- Soft Sensors and Actuators
- Flexible Robotics
## Abstract:
Tendon-driven flexible endoscopic surgical robots have been developed to access narrow curved paths without incision. Robot shape information is essential for precise control and to prevent unwanted tissue damage. In this paper, we propose a joint angle sensing method using coiled soft sensors to estimate the shape of the hyperredundant manipulator, which is commonly used in flexible endoscopic surgical robots. The soft sensors can be fabricated with small size and are highly stretchable, such that by being pre-stretched, they can be integrated between individual joints, maintain a center hollow, and sense both compression and extension. The pre-stretch length is experimentally selected by using the sensor linearity to maximize the potential sensitivity. We validated the proposed design using a two-degree of freedom (DOF) single joint manipulator by implementing two sensors; sensors at all joints could sense joint angle independently and simultaneously with a root-mean-square error (RMSE) less than 2.53°. Based on the proposed method, a two-DOF configuration of the hyperredundant manipulator that can be used in real applications was achieved, following a constant curvature model in real time with values RMSE of 2.30° and 2.63°, for pitch and yaw joint angle respectively.
# A Soft Fluidic Sensor-Actuator for Active Sensing of Force and Displacement in Biomedical Applications
## Keywords:
- Soft Sensors and Actuators
- Force and Tactile Sensing
- Hydraulic/Pneumatic Actuators
## Abstract:
Achieving compact and biocompatible actuators with sensing capabilities is a key challenge for the safety critical and highly patient-specific biomedical field. In this study, a compact and versatile soft fluidic sensor-actuator capable of measuring both force and displacement in static and dynamic conditions is presented. Pressure and resistance are shown to be interchangeable in predicting load and sensor-actuator height, and showed good repeatability and distinction between the loaded and constrained conditions tested. Furthermore the sensor-actuator is demonstrated in a probe application and showed comparable findings to a tensile test machine when tested on three objects of varying stiffness. Overall, this sensor-actuator has the potential to be a key building block for biomedical robots that require large expansion, as well as continuous monitoring of both displacement and force.
# GSG: A Granary-Shaped Soft Gripper with Mechanical Sensing Via Snap-Through Structure
## Keywords:
- Grasping
- Soft Sensors and Actuators
- Soft Robot Materials and Design
## Abstract:
Soft robotic grippers have attracted considerable attention in terms of the advantages of the high compliance and robustness to variance in object geometry; however, they are still limited by the corresponding sensing capabilities. We propose a novel soft gripper that looks like a granary in the geometrical shape with a snap-through bistable mechanism fabricated by an ordered mold technology, which consists of a palm chamber, shell, cap and three fingers. It can achieve sensing?mechanically and perform pinching, enveloping and caging grasps for objects with various profiles. In particular, the snap-through bistable mechanism in the proposed gripper allows us to reduce the complexity of the mechanism, control, sensing designs. The grasping behavior is activated once the gripper deformation or perceived pressure arrives at a certain value. First, after the theoretical model for snap-through behavior is constructed, the modularized design of the gripper is described in detail. Then, the ordered molding method is employed to fabricate the proposed gripper. Finally, the finite element (FE) simulations are conducted to verify the built theoretical model. Further, a series of grasping experiments are carried out to assess the performance of the proposed gripper on grasping and sensing. The experimental results illustrate that the proposed gripper can manipulate a variety of soft and rigid objects and remain stable even though it undergoes external disturbances. (YouTube video: https://youtu.be/74h9A-qlv28)
# FireFly: An Insect-Scale Aerial Robot Powered by Electroluminescent Soft Artificial Muscles
## Keywords:
- Micro/Nano Robots
- Soft Sensors and Actuators
- Biologically-Inspired Robots
## Abstract:
Light production in natural fireflies represents an effective and unique method for communication and mating. Inspired by bioluminescence, we develop a 650 mg aerial robot powered by four electroluminescent (EL) dielectric elastomer actuators (DEAs) that have distinct colors and patterns. To enable simultaneous actuation and light emission, we embed EL particles in a DEA that has highly transparent electrodes. During robot flight, a strong (>40 V/um) and high frequency (400 Hz) electric field is generated within the DEA, exciting the EL particles to emit light. Compared to a regular DEA, our new design and fabrication methods require small additional weight (2.4%) and actuation power (3.2%) without adversely impacting the DEA’s output power or lifetime. We further develop a position and attitude tracking method using vision-based color detection. We demonstrate a series of controlled hovering flights and compare camera-tracked results with that of the state-of-the-art Vicon motion tracking system. The root-mean-square (rms) position and attitude errors are 2.55 mm and 2.60 degrees, respectively. This work illustrates a novel and effective design for communication and motion tracking in extreme payload-constrained microscale aerial systems, and it further shows the potential of achieving coordinated swarm flights without using well-calibrated in door tracking systems.
# Sensor-Based Reconstruction of Slender Flexible Beams Undergoing Large-Scale Deflection
## Keywords:
- Flexible Robotics
- Force and Tactile Sensing
## Abstract:
This paper presents a model-based approach to reconstructing the large deformations of slender flexible beams through strain-gauge deflection sensors. Using the principal axes decomposition of structural compliance, a closed-form kinetostatics model can be obtained to characterize the non-linear force-deformation behavior of the flexible beams undergoing large-scale deflection. Owing to analytical derivation of the system Jacobian, the efficient Newton-Raphson method is employed to determine the equilibrium configuration of the flexible beams, as well as the corresponding reaction force. To verify the correctness and effectiveness of the proposed method, an experimental apparatus is built up, on which a variety of experiments are conducted. The results show that for a 300 mm long beam, the tip position can be predicted with an accuracy of 1.27 mm, 4.42 mm, and 1.17°, respectively, for the x, y directions and rotation. Accordingly, the estimation errors for the planar forces and torque are 0.075 N (3.33%), 0.155 N (14.23%), and 0.027 Nm (26.84%), respectively.
# Development of a 6 DOF Soft Robotic Manipulator with Integrated Sensing Skin
## Keywords:
- Soft Robot Materials and Design
- Hydraulic/Pneumatic Actuators
- Medical Robots and Systems
## Abstract:
This paper presents a new 6 DOF soft robotic manipulator intended for colorectal surgery. The manipulator, based on a novel design that employs an inextensible tube to limit axial extension, is shown to maximize the force exerted at its tip and the bending angle, the latter being measured with a soft sensing skin. Manufacturing of the prototype is achieved with a lost-wax silicone-casting technique. The kinematic model of the manipulator, its workspace, and its manipulability are discussed. The prototype is evaluated with extensive experiments, including pressure-deflection measurement with and without tip load, and lateral force measurements with and without the soft sensing skin to assess hysteresis. The experimental results indicate that the prototype fulfils the key design requirements for colorectal surgery: (i) it can generate sufficient force to perform a range of laparoscopic tasks; (ii) the workspace is commensurate with the dimensions of the large intestine; (iii) the soft sensing skin only results in a marginal reduction of the maximum tip rotation within the range of pressures and external loads relevant for the chosen application.
# Autonomous Intraluminal Navigation of a Soft Robot Using Deep-Learning-Based Visual Servoing
## Keywords:
- Medical Robots and Systems
- Visual Servoing
- Computer Vision for Medical Robotics
## Abstract:
Navigation inside luminal organs is an arduous task that requires non-intuitive coordination between the movement of the operator's hand and the information obtained from the endoscopic video. The development of tools to automate certain tasks could alleviate the physical and mental load of doctors during interventions, allowing them to focus on diagnosis and decision-making tasks. In this paper, we present a synergic solution for intraluminal navigation consisting of a 3D printed endoscopic soft robot that can move safely inside luminal structures. Visual servoing, based on Convolutional Neural Networks(CNNs) is used to achieve the autonomous navigation task. The CNN is trained with phantoms and in-vivo data to segment the lumen, and a model-less approach is presented to control the movement in constrained environments. The proposed robot is validated in anatomical phantoms in different path configurations. We analyze the movement of the robot using different metrics such as task completion time, smoothness, error in the steady-state, mean and maximum error. We show that our method is suitable to navigate safely in hollow environments and conditions which are different than the ones the network was originally trained on.
# Equilibrium Manipulation Planning for a Soft Elastic Rod Considering an External Distributed Force and Intrinsic Curvature
## Keywords:
- Manipulation Planning
## Abstract:
Previous work has shown that the set of equilibrium shapes of a rod is a smooth 6-dimensional manifold. We develop the Kirchhoff rod model in a differential equation form using Darboux vector that easily adds distributed force and intrinsic curvature. It can be seen that in this form, the manifold of the equilibrium set is the same. Furthermore, we address the rod manipulation planning problem which has the certain point on rod following a predefined spatial track. We propose a novel rod manipulation planning algorithm that considers the spatial configuration distance between the current and the goal, and follows its quickest descent direction in each planning step. The experiments show that it has a much higher successful rate than straight-line path planning in the Euclidean space of the gripper and significantly less planning time than the commonly used sampling method. The hardware experiments are also conducted on a platform that consists of a manipulator, an F/T sensor and two cameras. We choose soft rubber rods in the experiments, and the results validate the proposed model and methods.
# Localization 5
# FSM: Correspondenceless Scan-Matching of Panoramic 2D Range Scans
## Keywords:
- Localization
- Range Sensing
## Abstract:
Recent years have seen the introduction of more affordable but less accurate 2D range sensors whose field of view is **2π**. Scan-matching with these has been insufficiently researched, while being a challenge due to these sensors' increased measurement uncertainty. This paper proposes a real-time method for matching scans extracted from panoramic 2D LIDAR sensors. The method leverages properties of the Fourier transform which arise due to the periodicity of the range signal. Matching is performed in a correspondenceless manner. The proposed method outperforms established scan-matching methods in terms of pose accuracy and robustness in tests on public domain data, and over noise levels of commercially available sensors. The source code is available for download.
# VMVG-Loc: Visual Localization for Autonomous Driving Using Vector Map and Voxel Grid Map
## Keywords:
- Localization
- Autonomous Vehicle Navigation
- Computer Vision for Transportation
## Abstract:
This study proposes a visual localization method using a vector map and voxel grid map with a stereo camera. The two maps provide different modality advantages and are integrated using a particle filter.
In contrast to other vector map-based methods, our method does not use road markings because creating and maintaining vector maps that include high-accuracy road markings is laborious. Furthermore, it limits the regions where they are available. This method uses only lane center-lines from vector maps, which are easier to create than road markings.
The method performs ray casting and computes the reprojection error to evaluate the vehicle position for voxel grid maps. Although this makes the method environmentally sensitive, the constraints by lanes make the estimation stable.
Experiments confirmed that the method could perform localization stably and accurately without failure even over long distances. In addition, an ablation study showed the benefits of combining both maps.
# Learnable Spatio-Temporal Map Embeddings for Deep Inertial Localization
## Keywords:
- Localization
- Sensor Fusion
## Abstract:
Indoor localization systems often fuse inertial odometry with map information via hand-defined methods to reduce odometry drift, but such methods are sensitive to noise and struggle to generalize across odometry sources. To address the robustness problem in map utilization, we propose a data-driven prior on possible user locations in a map by combining learned spatial map embeddings and temporal odometry embeddings. Our prior learns to encode which map regions are feasible locations for a user more accurately than previous hand-defined methods. This prior leads to a 49% improvement in inertial-only localization accuracy when used in a particle filter. This result is significant, as it shows that our relative positioning method can match the performance of absolute positioning using bluetooth beacons. To show the generalizability of our method, we also show similar improvements using wheel encoder odometry.
# CGiS-Net: Aggregating Colour, Geometry and Implicit Semantic Features for Indoor Place Recognition
## Keywords:
- Localization
- Recognition
- Deep Learning for Visual Perception
## Abstract:
We describe a novel approach to indoor place recognition from RGB point clouds based on aggregating low-level colour and geometry features with high-level implicit semantic features. It uses a 2-stage deep learning framework, in which the first stage is trained for the auxiliary task of semantic segmentation and the second stage uses features from layers in the first stage to generate discriminate descriptors for place recognition. The auxiliary task encourages the features to be semantically meaningful, hence aggregating the geometry and colour in the RGB point cloud data with implicit semantic information. We use an indoor place recognition dataset derived from the ScanNet dataset for training and evaluation, with a test set comprising 3,608 point clouds generated from 100 different rooms. Comparison with a traditional feature-based method and four state-of-the-art deep learning methods demonstrate that our approach significantly outperforms all five methods, achieving, for example, a top-3 average recall rate of 75% compared with 41% for the closest rival method. Our code is available at: https://github.com/YuhangMing/ Semantic-Indoor-Place-Recognition
# A New Dense Hybrid Stereo Visual Odometry Approach
## Keywords:
- Localization
- Deep Learning Methods
- Vision-Based Navigation
## Abstract:
Visual odometry is an important part in the perception module of autonomous robots. Recent advances in deep learning approaches have given rise to hybrid visual odometry approaches that combine both deep networks and traditional pose estimation methods. One limitation of deep learning approaches is the availability of ground truth data needed to train the neural networks. For example, it is extremely difficult, if not impossible, to obtaining ground truth dense depth map of the environment to be used for stereo visual odometry. Even if unsupervised training of networks has been investigated, supervised training remains more reliable and robust. In this paper, we propose a new hybrid dense stereo visual odometry approach in which a dense depth map is obtained with a network that is supervised using ground truth poses that can be more easily obtained than ground truth depths maps. The depth map obtained from the neural network is used to warp the current image into the reference frame and the optimal pose is obtained by minimizing a cost function that encodes the similarity between the warped image and the reference image. The experimental results show that the proposed approach, not only improves state-of-the-art depth maps estimation networks on some of the standard benchmark datasets, but also outperforms the state-of-the-art visual odometry methods.
# BoxGraph: Semantic Place Recognition and Pose Estimation from 3D LiDAR
## Keywords:
- Localization
- Semantic Scene Understanding
- Range Sensing
## Abstract:
This paper is about extremely robust and lightweight localisation using LiDAR point clouds based on instance segmentation and graph matching. We model 3D point clouds as fully-connected graphs of semantically identified components where each vertex corresponds to an object instance and encodes its shape. Optimal vertex association across graphs allows for full 6-Degree-of-Freedom (DoF) pose estimation and place recognition by measuring similarity. This representation is very concise, condensing the size of maps by a factor of 25 against the state-of-the-art, requiring only 3kB to represent a 1.4MB laser scan. We verify the efficacy of our system on the SemanticKITTI dataset, where we achieve a new state-of-the-art in place recognition, with an average of 88.4 % recall at 100 % precision where the next closest competitor follows with 64.9 %. We also show accurate metric pose estimation performance – estimating 6-DoF pose with median errors of 10 cm and 0.33 deg.
# Towards Holistic Autonomous Obstacle Detection in Railways by Complementing of On-Board Vision with UAV-Based Object Localization
## Keywords:
- Localization
- Transfer Learning
- Intelligent Transportation Systems
## Abstract:
This paper presents the two sub-systems of the first holistic system for autonomous obstacle detection (OD) in railways, the on-board vision system and unmanned aerial vehicle (UAV) vision system for object localization (OL) on and near the rail tracks. The main goal of such a holistic system is to enable long-range detection of obstacles on the rail tracks ahead of the train where the UAV-based OL system complements on-board system in detecting obstacles in the areas that are not visible by on-board system such as curves. The deep learning (DL)-based object detection and distance estimation in thermal camera unit of the on-board system is presented, as well as the OL based on UAV camera image. The experimental results achieved in a real-world railway experimental scenario that includes obstacles visible only by the on-board thermal camera, only by UAV camera as well as obstacles in the Field of View (FoV) of both systems are presented. These preliminary results show the high potential of developing holistic system where the final decision on OD would be autonomously made and consequently possible actions for the train control would be suggested based on the OD outputs of individual systems having different rail tracks sections in their FoV.
# Visual-Inertial SLAM with Tightly-Coupled Dropout-Tolerant GPS Fusion
## Keywords:
- Localization
- Sensor Fusion
- Visual-Inertial SLAM
## Abstract:
Robotic applications are continuously striving towards higher levels of autonomy. To achieve that goal, a highly robust and accurate state estimation is indispensable. Combining visual and inertial sensor modalities has proven to yield accurate and locally consistent results in short-term applications. Unfortunately, visual-inertial state estimators suffer from the accumulation of drift for long-term trajectories. To eliminate this drift, global measurements can be fused into the state estimation pipeline. The most known and widely available source of global measurements is the Global Positioning System (GPS). In this paper, we propose a novel approach that fully combines stereo Visual-Inertial Simultaneous Localisation and Mapping (SLAM), including visual loop closures, with the fusion of global sensor modalities in a tightly-coupled and optimisation-based framework. Incorporating measurement uncertainties, we provide a robust criterion to solve the global reference frame initialisation problem. Furthermore, we propose a loop-closure-like optimisation scheme to compensate drift accumulated during outages in receiving GPS signals. Experimental validation on datasets and in a real-world experiment demonstrates the robustness of our approach to GPS dropouts as well as its capability to estimate highly accurate and globally consistent trajectories compared to existing state-of-the-art methods.
# Continuous Self-Localization on Aerial Images Using Visual and Lidar Sensors
## Keywords:
- Localization
- Vision-Based Navigation
- Deep Learning Methods
## Abstract:
This paper proposes a novel method for geo-tracking, i.e. continuous metric self-localization in outdoor environments by registering a vehicle's sensor information with aerial imagery of an unseen target region. Geo-tracking methods offer the potential to supplant noisy signals from global navigation satellite systems (GNSS) and expensive and hard to maintain prior maps that are typically used for this purpose. The proposed geo-tracking method aligns data from on-board cameras and lidar sensors with geo-registered orthophotos to continuously localize a vehicle. We train a model in a metric learning setting to extract visual features from ground and aerial images. The ground features are projected into a top-down perspective via the lidar points and are matched with the aerial features to determine the relative pose between vehicle and orthophoto.
Our method is the first to utilize on-board cameras in an end-to-end differentiable model for metric self-localization on unseen orthophotos. It exhibits strong generalization, is robust to changes in the environment and requires only geo-poses as ground truth. We evaluate our approach on the KITTI-360 dataset and achieve a mean absolute position error (APE) of 0.94m. We further compare with previous approaches on the KITTI odometry dataset and achieve state-of-the-art results on the geo-tracking task.
# Reinforcement Learning 4
# Autonomous Control of Redundant Hydraulic Manipulator Using Reinforcement Learning with Action Feedback
## Keywords:
- AI-Enabled Robotics
- Reinforcement Learning
- Industrial Robots
## Abstract:
This article presents an entirely data-driven approach for autonomous control of redundant manipulators with hydraulic actuation. The approach only requires minimal system information, which is inherited from a simulation model. The non-linear hydraulic actuation dynamics are modeled using actuator networks from the data gathered during the manual operation of the manipulator to effectively emulate the real system in a simulation environment. A neural network control policy for autonomous control, based on end-effector (EE) position tracking is then learnt using Reinforcement Learning (RL) with Ornstein–Uhlenbeck process noise (OUNoise) for efficient exploration. The RL agent also receive feedback based on supervised learning of the forward kinematics which facilitate selecting the best suitable action from exploration. The control policy directly provides the joint variables as outputs based on provided target EE position while taking into account the system dynamics. The joint variables are then mapped to the hydraulic valve commands, which are then fed to the system without further modifications. The proposed approach is implemented on a scaled hydraulic forwarder crane with three revolute and one prismatic joint to track the desired position of the EE in 3-Dimensional (3D) space. With the emulated dynamics and extensive learning in simulation, the results demonstrate the feasibility of deploying the learned controller directly on the real system.
# DRL-ISP: Multi-Objective Camera ISP with Deep Reinforcement Learning
## Keywords:
- Deep Learning for Visual Perception
- Reinforcement Learning
- Computer Vision for Automation
## Abstract:
In this paper, we propose a multi-objective camera ISP framework that utilizes Deep Reinforcement Learning (DRL) and camera ISP toolbox that consists of network-based and conventional ISP tools. The proposed DRL-based camera ISP framework iteratively selects a proper tool from the toolbox and applies it to the image to maximize a given vision task-specific reward function. For this purpose, we implement total 51 ISP tools that include exposure correction, color-and-tone correction, white balance, sharpening, denoising, and others. We also propose an efficient DRL network architecture that can extract the various aspects of an image and make a rigid mapping relationship between images and a large number of actions. Our proposed DRL-based ISP framework effectively improves the image quality according to each vision task such as RAW-to-RGB image restoration, 2D object detection, and monocular depth estimation.
# Renaissance Robot: Optimal Transport Policy Fusion for Learning Diverse Skills
## Keywords:
- Deep Learning Methods
- Reinforcement Learning
- AI-Based Methods
## Abstract:
Deep reinforcement learning (RL) is a promising approach to solving complex robotics problems. However, the process of learning through trial-and-error interactions is often highly time-consuming, despite recent advancements in RL algorithms. Additionally, the success of RL is critically dependent on how well the reward-shaping function suits the task, which is also time-consuming to design. As agents trained on a variety of robotics problems continue to proliferate, the ability to reuse their valuable learning for new domains becomes increasingly significant. In this paper, we propose a post-hoc technique for policy fusion using Optimal Transport theory as a robust means of consolidating the knowledge of multiple agents that have been trained on distinct scenarios. We further demonstrate that this provides an improved weights initialisation of the neural network policy for learning new tasks, requiring less time and computational resources than either retraining the parent policies or training a new policy from scratch. Ultimately, our results on diverse agents commonly used in deep RL show that specialised knowledge can be unified into a "Renaissance agent", allowing for quicker learning of new skills.
# SKILL-IL: Disentangling Skill and Knowledge in Multitask Imitation Learning
## Keywords:
- Imitation Learning
- Reinforcement Learning
- Transfer Learning
## Abstract:
In this work, we introduce a new perspective for learning transferable content in multi-task imitation learning. Humans are able to transfer skills and knowledge. If we can cycle to work and drive to the store, we can also cycle to the store and drive to work. We take inspiration from this and hypothesize the latent memory of a policy network can be disentangled into two partitions. These contain either the knowledge of the environmental context for the task or the generalizable skill needed to solve the task. This allows improved training efficiency and better generalization over previously unseen combinations of skills in the same environment, and the same task in unseen environments.
We used the proposed approach to train a disentangled agent for two different multi-task IL environments. In both cases we out-performed the SOTA by 30% in task success rate. We also demonstrated this for navigation on a real robot.
# Learning Perceptual Locomotion on Uneven Terrains Using Sparse Visual Observations
## Keywords:
- Machine Learning for Robot Control
- Reinforcement Learning
- Sensorimotor Learning
## Abstract:
To proactively navigate and traverse various terrains, active use of visual perception becomes indispensable. We aim to investigate the feasibility and performance of using sparse visual observations to achieve perceptual locomotion over a range of common terrains (bumps, ramps, gaps, and stairs) in human-centered environments. We formulate the selection of minimal visual input suitable for locomotion over the terrains of interest, and propose a learning framework to integrate exteroceptive and proprioceptive states. We specifically design the state observations and a training curriculum to learn feedback control policies effectively over a range of different terrains. We extensively validate and benchmark the learned policy in various tasks: omnidirectional walking on flat ground, and forward locomotion over various obstacles, showing high success rate of traversability. Furthermore, we study exteroceptive ablations and evaluate policy generalization by adding various levels of noise and testing on new unseen terrains. We demonstrate the capabilities of autonomous perceptual locomotion that can be achieved by only using sparse visual observations from direct depth measurements, which are easily available from a Lidar or RGB-D sensor, showing robust ascent and descent over high stairs of 20 cm height, i.e., 50% leg length, and robustness against noise and unseen terrains.
# Towards Adaptive Continuous Control of Soft Robotic Manipulator Using Reinforcement Learning
## Keywords:
- Reinforcement Learning
- Modeling, Control, and Learning for Soft Robots
- Soft Robot Applications
## Abstract:
Although the soft robot is gaining considerable popularity in dexterous and safe manipulation, accurate motion control is still an open problem to be explored. Recent investigations suggest that reinforcement learning (RL) is a promising solution but lacks efficient adaptability for Sim2Real transfer or environment variations. In this paper, we present a deep deterministic policy gradient (DDPG)-based control system for the continuous task-space manipulation of soft robots. Domain randomization is adopted in simulation for fast control-policy initialization, while an offline retraining strategy is utilized to update the controller parameters for incremental learning. The experiments demonstrate that the proposed RL controller can track a moving target accurately (with RMSE of 1.26 mm), and accommodate to external varying load effectively (with ~30% RMSE reduction after retraining). Comparisons among the proposed RL controller and other supervised-learning-based controllers in handling additional tip load were also conducted. The results support that our RL method is appropriate for automatic learning such that there is no need of manual interference for data processing, particularly in cases with external disturbances and actuation redundancy.
# Infusing Model Predictive Control into Meta-Reinforcement Learning for Mobile Robots in Dynamic Environments
## Keywords:
- Reinforcement Learning
- Motion Control
## Abstract:
The successful operation of mobile robots requires them to adapt rapidly to environmental changes. To develop an adaptive decision-making tool for mobile robots, we propose a novel algorithm that combines meta-reinforcement learning (meta-RL) with model predictive control (MPC). Our method employs an off-policy meta-RL algorithm as a baseline to train a policy using transition samples generated by MPC when the robot detects certain events that can be effectively handled by MPC, with its explicit use of robot dynamics. The key idea of our method is to switch between the meta-learned policy and the MPC controller in a randomized and event-triggered fashion to make up for suboptimal MPC actions caused by the limited prediction horizon. During meta-testing, the MPC module is deactivated to significantly reduce computation time in motion control. We further propose an online adaptation scheme that enables the robot to infer and adapt to a new task within a single trajectory. The performance of our method has been demonstrated through simulations using a nonlinear car-like vehicle model with (i) synthetic movements of obstacles, and (ii) real-world pedestrian motion data. The simulation results indicate that our method outperforms other algorithms in terms of learning efficiency and navigation quality.
# A New Robotic Knee Impedance Control Parameter Optimization Method Facilitated by Inverse Reinforcement Learning
## Keywords:
- Reinforcement Learning
- Imitation Learning
- Prosthetics and Exoskeletons
## Abstract:
Recent efforts in the design of intelligent controllers for configuring robotic prostheses have demonstrated new possibilities in improving mobility and restoring locomotion for individuals with lower-limb disabilities. In these efforts, personalizing the controller of the robotic device is a crucial step in order to meet individual user's needs and physical conditions. Reinforcement learning (RL) based control designs are among some of the most promising approaches to achieving real-time, optimal adaptive tuning capability. However, such designs to date rely on subjectively determining human-robot walking performance measures, commonly in a quadratic form. To further automate the RL design for robotic knee control parameter tuning and potentially improve human-robot locomotion performance, this study introduces a new bilevel optimization method to objectively specify such control design performance measures via inverse reinforcement learning (IRL), which in turn, will be used in low level (forward) RL design of the impedance control parameters. We demonstrate the effectiveness of the bilevel optimization approach with improved human-robot walking performance using systematic OpenSim simulation studies.
# UNICON: Uncertainty-Conditioned Policy for Robust Behavior in Unfamiliar Scenarios
## Keywords:
- Reinforcement Learning
- Machine Learning for Robot Control
- Robust/Adaptive Control
## Abstract:
Deep reinforcement learning has been used to solve complex tasks in various fields, particularly in robotics control. However, agents trained using deep reinforcement learning have a problem of taking overconfident actions, even when the input state is far from the learned state distribution. This restricts deep reinforcement learning from being applied to real-world environments as overconfident actions in unlearned situations can result in catastrophic events; such as the collision of an autonomous vehicle. To address this, the agents should know "what they do not know" and choose an action by considering not only the state but also its uncertainty. In this study, we propose a novel uncertainty-conditioned policy (UNICON) inspired by the human behavior of changing policies according to uncertainty, e.g., slowing a car on a narrow road that has never been visited before. Our experimental results demonstrate that the proposed method is robust to unfamiliar scenarios that are not seen during training.
# Field Robots
# P-AgBot: In-Row & Under-Canopy Agricultural Robot for Monitoring and Physical Sampling
## Keywords:
- Field Robots
- Agricultural Automation
## Abstract:
In this work, we present a novel agricultural robot called the PurduemAgBot or P-AgBot that has been designed for in-row and under canopy crop monitoring and physical sampling. We suggest approaches to autonomous navigation, crop monitoring, and crop sampling that can be applied in crop rows and under canopies for different agricultural environments. Each monitoring approach was designed to extract key morphological characteristics of the crops. The proposed approaches of P-AgBot have been experimentally verified not only in simulation but also with real corn and sorghum crops. Crop heights and stalk diameters are able to be estimated in real-time with less than 10% error. Vision-based detection of leaf samples was implemented and physical sampling is accomplished with a more than 80% success rate.
# Efficient Sampling-Based Planning for Subterranean Exploration
## Keywords:
- Field Robots
- Motion and Path Planning
- Search and Rescue Robots
## Abstract:
The paper proposes a path planning solution for autonomous robotic exploration of complex subterranean environments. The work contributes to the family of graph-based planners by bringing the following improvements. Firstly, an occupancy grid-based sample-and-project solution to terrain-assessment is proposed instead of building an explicit elevation map of the environment. Secondly, the solution-search method is formulated as a constraint-satisfaction problem to obtain a good-enough solution instead of optimizing for a single objective function parametrized by penalty gains. This method is shown to significantly improve the computational efficiency of the planner. Thirdly, a coordination solution is proposed that relies on the position histories of the robots instead of merged-maps or merged-graphs, therefore, making the planning solution resilient to inter-robot map misalignments, while also reducing the communication bandwidth required to carry out coordination. Finally, the planner also takes into account changes in the environment such as blocked passages that are initially open. The proposed planning solution is demonstrated at the DARPA Subterranean Challenge final event by team MARBLE, the third place finisher of the challenge.
# A Novel Robot with Rolling and Climbing Modes for Power Transmission Line Inspection
## Keywords:
- Field Robots
- Climbing Robots
## Abstract:
As a hard high-altitude work, power transmission line inspection increasingly demands robots to conduct in place of human being. A variety of robots have been developed to this end, with basic locomotion and inspection implemented on the lines. However, most of current line inspection robots (LIRs) are only mobile platforms with complex structure (usually multiple arms or legs) and large weights, lacking of sufficiently dexterous locomotion on lines, especially for obstacle overcoming and line transition. Also with sensors fixed on the platform, the inspection range is largely limited. For higher mobility and larger inspection range, a novel biped robot which can roll and climb on power transmission line for inspection, called Climbot-L, is proposed in this paper. While the rolling mode has the advantage of high locomotion efficiency, the biped climbing mode makes it possible to easily overcome obstacles on the lines. Built with the modular approach, Climbot-L consists of five 1-DoF joint modules connected in series and two specially designed wheel-gripper modules mounted at the ends, in the configuration of a special manipulator with the symmetry about its middle point. With simple structure and lightweight, held by the wheel-gripper module clamping the line, the robot can swing another end with sensors to inspect the line from different configuration so that the inspection range is largely increased. In this paper, the design of this novel robot is first introduced, the working principle of the wheel-gripper modules is then analyzed, and obstacle overcoming gaits stated. The effectiveness and high maneuverability of the presented robot is verified by a series of experiments.
# Autonomous Pipeline Tracking Using Bernoulli Filter for Unmanned Underwater Surveys
## Keywords:
- Field Robots
- Marine Robotics
- Sensor Fusion
## Abstract:
Inspection of subsea pipelines is crucial for avoiding any hazards and minimizing the risks to infrastructure and the environment. These inspections are achieved using Autonomous Underwater Vehicles (AUVs) in favour of reduced operational costs. This work presents a vehicle agnostic approach for tracking subsea pipelines at close-range for autonomous guidance along the pipeline using an AUV. A multibeam echosounder is used as the primary tracking sensor augmented by fluxgate magnetometers that can track buried pipelines over short ranges until they are exposed again. A Bernoulli filter is proposed to efficiently track pipelines in presence of environmental clutter. Field experiments were carried out in a dock and at sea to evaluate the proposed system and the benefits of using a Bernoulli filter over a Kalman filter-based solution.
# An Evaluation of Position Keeping Strategies under Disturbances for a Symmetrical Shape Autonomous on Water Surface Robot
## Keywords:
- Field Robots
- Marine Robotics
## Abstract:
Extensive research has been conducted on autonomous surface robots and underwater robots for various tasks in aquatic environments. The duration of the operation of autonomous field robots depends on the capacity of the mounted battery, as they are not typically connected to an external power supply. Therefore, smart strategies which are optimized for each task are required to extend the working time of autonomous field robots. We have developed a symmetrically-shaped autonomous surface robot for the long-term monitoring of water quality. In this study, we propose position-keeping strategies to prolong the duration of the symmetrically-shaped surface robot for textit{in-situ} monitoring. The proposed position-keeping strategies are evaluated in terms of the power consumption and mean error distance in both practical and simulation environments. The experimental results demonstrate that a robot placed on a water surface with disturbance determines the best course of action to maintain its position based on the environmental conditions and application.
# Capability-Aware Task Allocation and Team Formation Analysis for Cooperative Exploration of Complex Environments
## Keywords:
- Field Robots
- Multi-Robot Systems
- Task Planning
## Abstract:
To achieve autonomy in complex real-world exploration missions, we consider deployment strategies for a team of robots with heterogeneous capabilities. We formulate a multi-robot exploration mission and compute an operation policy to maintain robot team productivity and maximize mission success. The environment description, robot capability, and mission outcome are modeled as a Markov decision process (MDP). We also include constraints, such as sensor failures, limited communication coverage, and mobility-stressing elements. The proposed operation model is applied to the DARPA Subterranean (SubT) Challenge. The deployment policy is also compared against the human-based operation strategy in the final competition of the SubT Challenge.
# MIMOSA: A Multi-Modal SLAM Framework for Resilient Autonomy against Sensor Degradation
## Keywords:
- Field Robots
- SLAM
- Sensor Fusion
## Abstract:
This paper presents a framework for Multi-Modal SLAM (MIMOSA) that utilizes a nonlinear factor graph as the underlying representation to provide loosely-coupled fusion of any number of sensing modalities. Tailored to the goal of enabling resilient robotic autonomy in GPS-denied and perceptually-degraded environments, MIMOSA currently contains modules for pointcloud registration, fusion of multiple odometry estimates relying on visible-light and thermal vision, as well as inertial measurement propagation. A flexible backend utilizes the estimates from various modalities as relative transformation factors. The method is designed to be robust to degeneracy through the maintenance and tracking of modality-specific health metrics, while also being inherently tolerant to sensor failure. We detail this framework alongside our implementation for handling high-rate asynchronous sensor measurements and evaluate its performance on data from autonomous subterranean robotic exploration missions using legged and aerial robots.
# PUTN: A Plane-Fitting Based Uneven Terrain Navigation Framework
## Keywords:
- Field Robots
- Autonomous Vehicle Navigation
## Abstract:
Autonomous navigation of ground robots has been widely used in indoor structured 2D environments, but there are still many challenges in outdoor 3D unstructured environments, especially in rough, uneven terrains. This paper proposed a plane-fitting based uneven terrain navigation framework (PUTN) to solve this problem. The implementation of PUTN is divided into three steps. First, based on Rapidly-exploring Random Trees (RRT), an improved sample-based algorithm called Plane Fitting RRT* (PF-RRT*) is proposed to obtain a sparse trajectory. Each sampling point corresponds to a custom traversability index and a fitted plane on the point cloud. These planes are connected in series to form a traversable strip. Second, Gaussian Process Regression is used to generate traversability of the dense trajectory interpolated from the sparse trajectory, and the sampling tree is used as the training set. Finally, local planning is performed using nonlinear model predictive control (NMPC). By adding the traversability index and uncertainty to the cost function, and adding obstacles generated by the real-time point cloud to the constraint function, a safe motion planning algorithm with smooth speed and strong robustness is available. Experiments in real scenarios are conducted to verify the effectiveness of the method. The source code is released for the reference of the community.
# A Standards-Based Pipeline Route Drawing System Using a Towed Sensing Unit
## Keywords:
- Field Robots
- Mapping
- Sensor Fusion
## Abstract:
This paper presents a method of drawing pipeline routes using a sensing unit with a rotary encoder and IMU (Inertial Measurement Unit), which is towed by a self-propelled in-pipe inspection robot. However, the IMU information generally contains integration errors, making it difficult to draw accurate pipeline routes. In this study, we propose a method combining gradient descent using a gyroscopic sensor and an accelerometer, and the correction of the route based on the standard information of the pipe. First, the method of identifying the start point, end point, direction of straight pipes, and bending direction of curved pipes is explained. Then, an experiment is conducted using the developed robot system on a 11.6-meter-long pipeline course that includes nine curved pipes and horizontal and vertical straight pipes. Consequently, the mean absolute error of the route dimension was reduced to 2.74 %.
# Motion and Path Planning 5
# Speeding up POMDP Planning Via Simplification
## Keywords:
- Motion and Path Planning
- AI-Based Methods
- Autonomous Agents
## Abstract:
In this paper, we consider online planning in partially observable domains. Solving the corresponding POMDP problem is a very challenging task, particularly in an online setting. Our key contribution is a novel algorithmic approach, Simplified Information-Theoretic Belief Space Planning (SITH# BSP), which aims to speed up POMDP planning considering belief-dependent rewards, without compromising the solution’s accuracy. We do so by mathematically relating the simplified elements of the problem to the corresponding counterparts of the original problem. Specifically, we focus on belief simplification and use it to formulate bounds on the corresponding original belief-dependent rewards. These bounds in turn are used to perform branch pruning over the belief tree, in the process of extracting the optimal policy from this existing belief tree. We further introduce the notion of adaptive simplification, while re-using calculations between different simplification levels and exploiting it to prune, at each level in the belief tree, all branches but one. Therefore, our approach is guaranteed to find the optimal solution (policy) that corresponds to the given belief tree but with substantial speedup. As a second key contribution, we derive novel analytical bounds for differential entropy, considering a sampling-based belief representation, which we believe are of interest on their own. We validate our approach in simulation using these bounds and where simplification corresponds to reducing the number of samples, exhibiting a significant computational speedup while yielding the optimal solution for the given belief tree.
# Speeding up Optimization-Based Motion Planning through Deep Learning
## Keywords:
- Motion and Path Planning
- Deep Learning Methods
- Learning from Experience
## Abstract:
Planning collision-free motions for robots with many degrees of freedom is challenging in environments with complex obstacle geometries. Recent work introduced the idea of speeding up the planning by encoding prior experience of successful motion plans in a neural network. However, this ``neural motion planning" did not scale to complex robots in unseen 3D environments as needed for real-world applications. Here, we introduce ``basis point set", well-known in computer vision, to neural motion planning as a modern compact environment encoding enabling efficient supervised training networks that generalize well over diverse 3D worlds. Combined with a new elaborate training scheme, we reach a planning success rate of 100%. We use the network to predict an educated initial guess for an optimization-based planner (OMP), which quickly converges to a feasible solution, massively outperforming random multi-starts when tested on previously unseen environments. For the DLR humanoid Agile Justin with 19DoF and in challenging obstacle environments, optimal paths can be generated in 200ms using only a single CPU core. We also show a first successful real-world experiment based on a high-resolution world model from an integrated 3D sensor.
# Improved A-Search Guided Tree for Autonomous Trailer Planning
## Keywords:
- Motion and Path Planning
- Nonholonomic Motion Planning
- Reinforcement Learning
## Abstract:
This paper presents a motion planning strategy that utilizes the improved A-search guided tree to enable autonomous parking of a general 3-trailer with a car-like tractor. Different from the state-of-the-art state-lattice-based methods where numerous motion primitives are necessary to ensure successful planning, our work allows quick off-lattice exploration to find a solution. Our treatment brings at least three advantages: fewer and lower design complexity of motion primitives, improved success rate, and increased path quality. Unlike on-lattice exploration, where the cost-to-go is obtained by querying a heuristic look-up table, off-lattice exploration entails the heuristic function being well-defined at off-lattice nodes. We train a neural network through reinforcement learning to model the maneuver costs of the trailer and use it as the heuristic value to better approximate the cost-to-go. Simulations demonstrate the effectiveness of the proposed method in terms of planning speed and path length.
# TerraPN: Unstructured Terrain Navigation Using Online Self-Supervised Learning
## Keywords:
- Motion and Path Planning
- Vision-Based Navigation
- Collision Avoidance
## Abstract:
We present TerraPN, a novel method that learns the surface properties (traction, bumpiness, deformability, etc.) of complex outdoor terrains directly from robot-terrain interactions through self-supervised learning, and uses it for autonomous robot navigation. Our method uses RGB images of terrain surfaces and the robot's velocities as inputs, and the IMU vibrations and odometry errors experienced by the robot as labels for self-supervision. Our method computes a surface cost map that differentiates smooth, high-traction surfaces (low navigation costs) from bumpy, slippery, deformable surfaces (high navigation costs). We compute the cost map by non-uniformly sampling patches from the input RGB image by detecting boundaries between surfaces resulting in low inference times (47.27% lower) compared to uniform sampling and existing segmentation methods. We present a novel navigation algorithm that accounts for a surface's cost, computes cost-based acceleration limits for the robot, and dynamically feasible, collision-free trajectories. TerraPN's surface cost prediction can be trained in sim 25 minutes for five different surfaces, compared to several hours for previous learning-based segmentation methods. In terms of navigation, our method outperforms previous works in terms of success rates (up to 35.84% higher), vibration cost of the trajectories (up to 21.52% lower), and slowing the robot on bumpy, deformable surfaces (up to 46.76% slower) in different scenarios.
# Robust Counterexample-Guided Optimization for Planning from Differentiable Temporal Logic
## Keywords:
- Motion and Path Planning
- Formal Methods in Robotics and Automation
- Optimization and Optimal Control
## Abstract:
Signal temporal logic (STL) provides a powerful, flexible framework for specifying complex autonomy tasks; however, existing methods for planning based on STL specifications have difficulty scaling to long-horizon tasks and are not robust to external disturbances. In this paper, we present an algorithm for finding robust plans that satisfy STL specifications. Our method alternates between local optimization and local falsification, using automatically differentiable temporal logic to iteratively optimize its plan in response to counterexamples found during the falsification process. We benchmark our counterexample-guided planning method against state-of-the-art planning methods on two long-horizon satellite rendezvous missions, showing that our method finds high-quality plans that satisfy STL specifications despite adversarial disturbances. We find that our method consistently finds plans that are robust to adversarial disturbances and requires less than half the time of competing methods. We provide an implementation of our planner at https://github.com/MIT-REALM/architect.
# CGLR: Dense Multi-Agent Navigation Using Voronoi Cells and Congestion Metric-Based Replanning
## Keywords:
- Motion and Path Planning
- Computational Geometry
- Collision Avoidance
## Abstract:
We present a decentralized path-planning algorithm for navigating multiple differential-drive robots in dense environments. In contrast to prior decentralized methods, we propose a novel congestion metric-based replanning that couples local and global planning techniques to efficiently navigate in scenarios with multiple corridors. To handle dense scenes with narrow passages, our approach computes the initial path for each agent to its assigned goal using a lattice planner. Based on neighbors' information, each agent performs online replanning using a congestion metric that tends to reduce the collisions and improves the navigation performance. Furthermore, we use the Voronoi cells of each agent to plan the local motion as well as a corridor selection strategy to limit the congestion in narrow passages. We evaluate the performance of our approach in complex scenes with tens of agents and narrow passages. We show that our Coupled Global-Local approach and Replanning (CGLR) improves the performance and efficiency over prior decentralized methods. In addition, our approach results in a higher success rate in terms of collision-free navigation to the goals, showing improvement in the range of 3-70% over prior decentralized solutions in certain scenarios.
# Adaptive Experience Sampling for Motion Planning Using the Generator-Critic Framework
## Keywords:
- Motion and Path Planning
- Learning from Experience
## Abstract:
Sampling-based motion planners are widely used for motion planning with high-DOF robots. These planners rely on a uniform distribution to explore the search space. Recent work has explored learning biased sampling distributions to improve the time efficiency of these planners. However, learning such distributions is challenging, since there is no direct connection between the choice of distributions and the performance of the downstream planner (e.g., minimizing the number of the planner's internal planning iterations). To alleviate this challenge, this paper proposes APES, a framework that learns sampling distributions optimized directly for the planner's performance. This is done using a critic, which serves as a differentiable surrogate objective modeling the planner's performance -# thus allowing gradients to circumvent the non-differentiable planner. Leveraging the differentiability of the critic, we train a generator, which outputs sampling distributions optimized for the given problem instance. We evaluate APES on a series of realistic and challenging high-DOF manipulation problems in simulation. Our experimental results demonstrate that APES can learn high-quality distributions that improve planning performance more than other biased sampling baselines.
# This Is the Way: Differential Bayesian Filtering for Agile Trajectory Synthesis
## Keywords:
- Motion and Path Planning
- Probabilistic Inference
- Integrated Planning and Learning
## Abstract:
One of the main challenges in autonomous racing is to design algorithms for motion planning at high speed, and across complex racing courses. End-to-end trajectory synthesis has been previously proposed where the trajectory for the ego vehicle is computed based on camera images from the racecar. This is done in a supervised learning setting using behavioral cloning techniques. In this paper, we address the limitations of behavioral cloning methods for trajectory synthesis by introducing Differential Bayesian Filtering (DBF), which uses probabilistic Bezier curves as a basis for inferring optimal autonomous racing trajectories based on Bayesian inference. We introduce a trajectory sampling mechanism and combine it with a filtering process which is able to push the car to its physical driving limits. The performance of DBF is evaluated on the DeepRacing Formula One simulation environment and compared with several other trajectory synthesis approaches as well as human driving performance. DBF achieves the fastest lap time, and the fastest speed, by pushing the racing car closer to its limits of control while always remaining inside track bounds.
# Optimal Motion Planning in Unknown Workspaces Using Integral Reinforcement Learning
## Keywords:
- Motion and Path Planning
- Reinforcement Learning
- Optimization and Optimal Control
## Abstract:
A novel motion planning scheme for optimal navigation in unknown workspaces is proposed in this paper. Based upon the Artificial Harmonic Potential Fields (AHPFs) theory, a robust framework for provably correct (i.e., safe and globally convergent) navigation is enhanced through Integral Reinforcement Learning (IRL) to obtain a provably complete solution for optimal motion planning in unknown workspaces. Our method aims at bridging the gap between the control theoretic framework of mathematical rigor, with the data-driven Reinforcement Learning (RL) paradigm, while preserving the strong traits of each approach. Finally, it is compared against an RRT* method to asses the optimality of the final results in a multiply connected synthetic workspace.
# Swarm Robotics
# Collective Decision-Making with Bayesian Robots in Dynamic Environments
## Keywords:
- Swarm Robotics
- Multi-Robot Systems
- Distributed Robot Systems
## Abstract:
Collective decision-making enables self-organizing robot swarms to act autonomously on a swarm level and is essential to coordinate their actions as a whole. When Robots only share and communicate information locally a distributed and decentralized approach is required. In a previous paper, an efficient method based on a distributed Bayesian algorithm was created to distinguish a binary environment. We extended it to have the capability of dealing with dynamic environments, which requires to avoid global lock-in states. In many realistic applications the robot swarm needs to adapt to (collectively) measurable changes at runtime by revising previous collective decisions. The trade-off between decision-making speed and readiness to revise previous decisions is a seemingly unavoidable challenge. We present our extension of the former approach and study how this trade-off can efficiently be balanced.
# Decentralized Control of Minimalistic Robotic Swarms for Guaranteed Target Encapsulation
## Keywords:
- Swarm Robotics
- Formal Methods in Robotics and Automation
- Collision Avoidance
## Abstract:
We propose a decentralized control algorithm for a minimalistic robotic swarm with limited capabilities such that the desired global behavior emerges. We consider the problem of searching for and encapsulating various targets present in the environment while avoiding collisions with both static and dynamic obstacles. The novelty of this work is the guaranteed generation of desired complex swarm behavior with constrained individual robots which have no memory, no localization, and no knowledge of the exact relative locations of their neighbors. Moreover, we analyze how the emergent behavior changes with different parameters of the task, noise in the sensor reading, and asynchronous execution.
# A Dynamical System Approach to Decentralized Collision-Free Autonomous Coordination of a Mobile Assistive Furniture Swarm
## Keywords:
- Autonomous Agents
- Swarm Robotics
- Distributed Robot Systems
## Abstract:
In order to facilitate and assist the indoor mobility of people with special needs, the classically static objects in the environment, such as furniture, can be rendered mobile. The need for efficient and safe autonomous coordination of a mobile furniture swarm arises. We present a closed-form approach for mobile furniture obstacle avoidance and navigation within an indoor environment. The approach shows that each mobile furniture agent, defined by a polygonal surface, does not collide with any static or mobile obstacle (e.g., a person is moving around). All controllable mobile furniture converges towards a defined goal position and orientation. We showcase the application of this algorithm in simulation on mobile furniture for smart environments. Results demonstrate that the proposed method can coordinate a swarm of mobile furniture to get out of the way of a mobile agent representing a person with limited mobility passing through the room while avoiding obstacles and converging towards a predefined target pose.
# Collective Decision Making in Communication-Constrained Environments
## Keywords:
- Swarm Robotics
- Agent-Based Systems
## Abstract:
One of the main tasks for autonomous robot swarms is to collectively decide on the best available option. Achieving that requires a high quality communication between the agents that may not always be available in a real world environment. In this paper we introduce the communication-constrained collective decision-making problem where some areas of the environment limit the agents’ ability to communicate, either by reducing success rate or blocking the communication channels. We propose a decentralised algorithm for mapping environmental features for robot swarms as well as improving collective decision making in communication-limited environments without prior knowledge of the communication landscape. Our results show that making a collective aware of the communication environment can improve the speed of convergence in the presence of communication limitations, at least 3 times faster, without sacrificing accuracy.
# Chemistry-Inspired Pattern Formation with Robotic Swarms
## Keywords:
- Swarm Robotics
- Multi-Robot Systems
- Distributed Robot Systems
## Abstract:
Self-organized emergent patterns can be widely seen in particle interactions producing complex structures such as chemical elements and molecules. Inspired by these interactions, this work presents a novel stochastic approach that allows a swarm of heterogeneous robots to create emergent patterns in a completely decentralized fashion and relying only on local information. Our approach consists of modeling the swarm configuration as a dynamic Gibbs Random Field (GRF) and setting constraints on the neighborhood system inspired by chemistry rules that dictate binding polarity between particles. Using the GRF model, we determine velocities for each robot, resulting in behaviors that lead to the creation of patterns or shapes. Simulated experiments show the versatility of the approach in producing a variety of patterns, and experiments with a group of physical robots show the feasibility in potential applications.
# Enhanced Decentralized Autonomous Aerial Robot Teams with Group Planning
## Keywords:
- Swarm Robotics
- Path Planning for Multiple Mobile Robots or Agents
- Multi-Robot Systems
## Abstract:
Designing autonomous aerial robot team systems remains a grand challenge in robotics. Existing works in this field can be categorized as centralized and decentralized. Centralized methods suffer from scale dilemmas, while decentralized ones often lead to poor planning quality. In this paper, we propose an enhanced decentralized autonomous aerial robot team system with group planning. According to the spatial distribution of agents, the system dynamically divides the team into several groups and isolated agents. For conflicts within each group, we propose a novel coordination mechanism named group planning. The group planning consists of efficient multi-agent pathfinding (MAPF) and trajectory joint optimization, which can significantly improve planning quality and success rate. We demonstrate through simulations and real-world experiments that our method not only has applicability for a large-scale team but also has toplevel planning quality.
# A Data-Driven Method for Metric Extraction to Detect Faults in Robot Swarms
## Keywords:
- Swarm Robotics
- Failure Detection and Recovery
- Probability and Statistical Methods
## Abstract:
Robot swarms are increasingly deployed in real-world applications. Making swarms safe will be critical to improve adoption and trust. Fault detection is a useful component in systems which require a level of safety: a key element of which are metrics that allow us to differentiate between faulty and normal (non-faulty) robots # metrics which are measurable on-board the individual robots for self-detection of faults. In this paper, we develop a method for identifying and evaluating such metrics and discuss how these metrics may be used in building a model for fault detection. We demonstrate this method for real-time error detection in a realistic use-case: intralogistics using swarms. We show that we are able to identify metrics of large effect size for various faults, demonstrating the potency of metrics selected in this way with a simple fault detection model.
# Deliberative Democracy with Robot Swarms
## Keywords:
- Swarm Robotics
- Social HRI
- Human-Robot Collaboration
## Abstract:
Decision-making among groups of humans can benefit from open discussion and inclusion of a diversity of opinions, promoting deliberative democracy. In this work, we test whether a swarm of robots can help facilitate decision-making by visually representing the diversity of opinions. We used a swarm of robots we built, called MOSAIX, that consists of 4-inch touchscreens-on-wheels robots called Tiles. The robots acted as physical avatars for opinions, helping them travel and mix together. We recruited 46 participants split into groups of 7 and 8 to test whether the robot movement had an impact on the decision-making process versus using the robots stationary in the participants’ hands akin to smartphones. Furthermore, we wanted to test whether the participants felt comfortable expressing their opinion through the robots. Results show the participants indeed felt comfortable using the robots, and user engagement increased with the movement of the robots. The difference between the participants’ first and last opinions also increased with the movement of the robots. We believe that robot swarms have not been used before to facilitate decision-making among a group of people. Therefore, our contribution is in testing the possibility of how and whether using a moving robot swarm helps humans reach a decision.
# Particle Swarm Optimizer-Based Attack Strategy with Swarm Robots
## Keywords:
- Evolutionary Robotics
- Swarm Robotics
- Path Planning for Multiple Mobile Robots or Agents
## Abstract:
An environment where a robot swarm attacks a territory protected by another one leads to an attack-defense confrontation problem. Commonly-used deep reinforcement learning-based methods rely on pre-training and become intractable due to the curse of dimensionality. To develop effective attack strategies, inspired by a particle swarm optimizer (PSO), this work proposes a PSO-based strategy for a robot swarm for the first time. During the moving of a robot swarm, each robot obtains situation information through perceiving its nearby peers and enemies and uses such information to construct its fitness function. Then, each robot uses PSO to optimize its fitness function and searches for its optimal attack position, which guides it to move in the next time slot. A collision avoidance strategy is integrated into the algorithm. Hence, a robot swarm realizes collaboration and handles confrontation as long as each robot can sense its surroundings. The experimental analyses show that the PSO-based attack strategy has better scalability and more potential in solving large-scale confrontational problems than the deep reinforcement learning-based algorithm.
# Industrial and Parallel Robots
# Multi-Objective Geometric Optimization of a Multi-Link Manipulator Using Parameterized Design Method
## Keywords:
- Industrial Robots
- Methods and Tools for Robot System Design
- Mechanism Design
## Abstract:
The performance of a robot is closely related to its structure. From the initial design of link lengths to structural optimization, it is still the research hotspot in recent years. To make the manipulator lightweight and ensure its working range and flexibility, researchers have proposed many optimization methods, most of which are for specific working scenarios, requirements, and robot structures, therefore their generality is limited. The optimization of the manipulator should be a comprehensive method. That is, we should pay attention to the joint configuration and each link length at the beginning of the design. Particularly, the geometric parameters of each link, which not only affect the range of the workspace but also have a direct impact on the working space, working efficiency, and flexibility of the manipulator. In this paper, a generalized optimization framework is proposed for multi-link manipulators. Starting from the optimization of manipulator link lengths, firstly, the geometry of the manipulator and workspace is parameterized; then the performance indicators are established; lastly, the geometric size of the manipulator is optimized according to the workspace limits and task requirements. Besides, we verified its feasibility and generality by applying this method to different TBM scenarios.
# A Configurable Skill Oriented Architecture Based on OPC UA
## Keywords:
- Control Architectures and Programming
- Software, Middleware and Programming Environments
- Industrial Robots
## Abstract:
Over the last years, research done in automation and industrial robotics has established the foundations for skill-oriented systems based on the OPC UA standard. Nevertheless, utilizing these advances in other areas of robotics research can be challenging and time consuming. We present a framework aiming to reduce this entry threshold. Our solution is an open source, easy to configure tool based on OPC UA, that provides with a hardware agnostic, skill-oriented, event driven interface to systems. The framework allows integrating external hardware and software by means of plugins. It also provides a mechanism for endowing skills with hardware agnostic motion control. We demonstrate how our framework can be combined by state of the art approaches to control in a simulated assembly task with multiple robots, conveyors, actuators and sensors involved.
# Accurate Edge Detection for Robotic Welding through Tactile Exploration
## Keywords:
- Industrial Robots
- Computational Geometry
- Haptics and Haptic Interfaces
## Abstract:
Programming paths for robotic welding conventionally requires precise positioning of workpieces, detailed 3D models and/or tedious teach pendant programming. A new method is introduced in this paper that enables an operator to teach the weld path to the robot through a haptic-visual interface. The operator teaches the path by guiding the tool tip to contact on the workpiece surface with force feedback through the haptic device, and drawing exploratory paths that intersect the edge to be welded as well as adjoining surfaces. Tool-tip positions in contact with the workpiece are recorded. A RANSAC-type algorithm is used to automatically estimate a piecewise parametric curve along the edge as well as geometric parameters of the adjoining surfaces. The required tool trajectory for the robot to weld along the workpiece edge is automatically generated. Experiments performed in simulation and on a physical KUKA IIWA7 robot demonstrate that the developed method can successfully detect workpiece edges within a maximum deviation of 1mm. Furthermore, the method is intuitive, and requires no knowledge of robot programming for an operator to program multi-segment weld paths quickly.
# Vision-Based Safety System for Barrierless Human-Robot Collaboration
## Keywords:
- Industrial Robots
- Safety in HRI
- Computer Vision for Automation
## Abstract:
Human safety has always been the main priority when working near an industrial robot. With the rise of Human-Robot Collaborative environments, physical barriers to avoiding collisions have been disappearing, increasing the risk of accidents and the need for solutions that ensure a safe Human-Robot Collaboration. This paper proposes a safety system that implements Speed and Separation Monitoring (SSM) type of operation. For this, safety zones are defined in the robot’s workspace following current standards for industrial collaborative robots. A deep learning-based computer vision system detects, tracks, and estimates the 3D position of operators close to the robot. The robot control system receives the operator’s 3D position and generates 3D representations of them in a simulation environment. Depending on the zone where the closest operator was detected, the robot stops or changes its operating speed. Three different operation modes in which the human and robot interact are presented. Results show that the vision-based system can correctly detect and classify in which safety zone an operator is located and that the different proposed operation modes ensure that the robot’s reaction and stop time are within the required time limits to guarantee safety.
# Horizontal Insertion of a Ring Onto a Shaft Using a Gantry Crane with Minimal Sensors
## Keywords:
- Industrial Robots
- Factory Automation
- Tendon/Wire Mechanism
## Abstract:
While manufacturing heavy and large machinery, the insertion of crane-hung heavy parts into horizontal holes is often required. This paper presents a method outlining the horizontal insertion of a ring onto a shaft using a gantry crane with a single cable attachment. We exploit the underactuated nature of the single-cable crane system to prevent the hung object from being over-constrained, and allow it to gently interact with the shaft. Simply measuring the tilt angle of the ring with an IMU as it interacts with the shaft face allows a robotic crane to estimate the direction of misalignment of the ring relative to the shaft. A 3D kinematic analysis of this tilting process is performed to obtain the conditions under which the tilting angle can be measured stably. Based on the analysis, a recursive procedure for reducing the misalignment is obtained, and its convergence conditions are discussed.
Furthermore, the conditions for jamming-free horizontal insertion are obtained. The autonomous horizontal insertion method is implemented on an overhead crane robot to verify the algorithm and demonstrate the feasibility.
# An All-In-One Cable-Driven Parallel Robot with Flexible Workspace and Its Auto-Calibration Method
## Keywords:
- Parallel Robots
- Mechanism Design
- Calibration and Identification
## Abstract:
For traditional cable-driven parallel robots (CDPRs), changing the workspace is relatively difficult, which needs to reconfigure the anchor points and the external frame. The main reason is that the winch is separated from the moving platform, and a series of pulleys are applied to guide the driving cables. This paper proposes a novel all-in-one suspended CDPR that integrates all components in the moving platform to realize a flexible workspace. For the rapid construction of the CDPR, the ends of the cables only need to be connected to the existing anchor point. However, due to the flexible workspace, the position values of the anchor points should be recalibrated by appropriate calibration methods, especially by using a rapid auto-calibration method in application sites. Thus, based on the kinetostatic model considering sagging cable, an auto-calibration method with an inclinometer is proposed. Simulation and experiment are conducted respectively, and the experiment results indicate that 78.56% totally reduces the errors of the fixed anchor points. Moreover, experiments were carried out to validate the design and kinematics.
# Experimental Study on Impact Resistance of Multi-DOF Electro-Hydrostatic Robot Systems Using Hydracer, a 6DOF Arm
## Keywords:
- Industrial Robots
- Hydraulic/Pneumatic Actuators
- Actuation and Joint Mechanisms
## Abstract:
Industrial robots require force controllability and impact resistance to ensure safe physical interactions. An electro-hydrostaic actuator (EHA) is expected to be suitable for such applications because it has high backdrivability which improve both force controllability at contact and impact resistance. However, EHAs had been rarely used in multi-axes robotic systems. The previous works validated the force controllability of the EHA-driven robot Hydra. However, the impact resistance of an EHA-driven robot is still unclear. In order to evaluate the impact resistance of the high-power EHA-driven robot, we developed high-pressure EHAs employing ceramics as rigid material to reduce internal leakage, and developed the EHA-driven 6-DOF robot arm Hydracer as the platform for the evaluation. This paper describes the mechanism of Hydracer especially on the base 3-DOF mechanism, and conducts the backdrivability measurement and the impact resistance evaluation.
# On a Balanced Delta Robot for Precise Aerial Manipulation: Implementation, Testing, and Lessons for Future Designs
## Keywords:
- Parallel Robots
- Mechanism Design
- Aerial Systems: Applications
## Abstract:
Using a delta-manipulator for stabilisation of an end-effector to perform precise spatial positioning is a current area of interest in aerial manipulation. High speed precision movements of a manipulator can cause disturbances to the aerial platform, which hinders trajectory tracking and in some cases could be sufficient to cause a loss of control of the vehicle. In this paper, a statically balanced delta aerial manipulator is developed and evaluated. The system is balanced using three counter-masses to reduce the force imparted onto the base and thus reduce perturbations to the movement of the drone. The system is thoroughly tested following trajectories while mounted to a force sensor and while on-board an aerial vehicle. Results show that the forces transmitted to the base in all axes are reduced considerably, however improvements in overall flight accuracy are not observed in aerial settings. Design lessons to make a balanced delta-manipulator viable for practical implementation on an aerial vehicle are discussed in depth. A video summarising the flight testing results is available at https://youtu.be/fXKnosnVKCk.
# Locally Optimal Estimation and Control of Cable Driven Parallel Robots Using Time Varying Linear Quadratic Gaussian Control
## Keywords:
- Parallel Robots
- Optimization and Optimal Control
- Control Architectures and Programming
## Abstract:
We present a locally optimal tracking controller for Cable Driven Parallel Robot (CDPR) control based on a time-varying Linear Quadratic Gaussian (TV-LQG) controller. In contrast to many methods which use fixed feedback gains, our time-varying controller computes the optimal gains depending on the location in the workspace and the future trajectory. Meanwhile, we rely heavily on offline computation to reduce the burden of online implementation and feasibility checking. Following the growing popularity of probabilistic graphical models for optimal control, we use factor graphs as a tool to formulate our controller for their efficiency, intuitiveness, and modularity. The topology of a factor graph encodes the relevant structural properties of equations in a way that facilitates insight and efficient computation using sparse linear algebra solvers. We first use factor graph optimization to compute a nominal trajectory, then linearize the graph and apply variable elimination to compute the locally optimal, time varying linear feedback gains. Next, we leverage the factor graph formulation to compute the locally optimal, time-varying Kalman Filter gains, and finally combine the locally optimal linear control and estimation laws to form a TV-LQG controller. We compare the tracking accuracy of our TV-LQG controller to a state-of-the-art dual-space feed-forward controller on a 2.9m x 2.3m, 4-cable planar robot and demonstrate improved tracking accuracies of 0.8° and 11.6 mm root mean square error in rotation and translation respectively.
# Learning from Demonstration 1
# Learning Object Manipulation Skills from Video Via Approximate Differentiable Physics
## Keywords:
- Learning from Demonstration
- Optimization and Optimal Control
- Imitation Learning
## Abstract:
We aim to teach robots to perform simple object manipulation tasks by watching a single video demonstration. Towards this goal, we propose an optimization approach that outputs a coarse and temporally evolving 3D scene to mimic the action demonstrated in the input video. Similar to previous work, a differentiable renderer ensures perceptual fidelity between the 3D scene and the 2D video. Our key novelty lies in the inclusion of a differentiable approach to solve a set of Ordinary Differential Equations (ODEs) that allows us to approximately model laws of physics such as gravity, friction, and hand-object or object-object interactions. This not only enables us to dramatically improve the quality of estimated hand and object states, but also produces physically admissible trajectories that can be directly translated to a robot without the need for costly reinforcement learning. We evaluate our approach on a 3D reconstruction task that consists of 54 video demonstrations sourced from 9 actions such as pull something from right to left or put something in front of something. Our approach improves over previous state-of-the-art by almost 30%, demonstrating superior quality on especially challenging actions involving physical interactions of two objects such as put something onto something. Finally, we showcase the learned skills on a Franka Emika Panda robot.
# Quantifying Demonstration Quality for Robot Learning and Generalization
## Keywords:
- Learning from Demonstration
- Physical Human-Robot Interaction
- Design and Human Factors
## Abstract:
Learning from Demonstration (LfD) seeks to democratize robotics by enabling non-expert end-users to teach robots. However, most LfD techniques assume users provide optimal demonstrations, which may not be accurate. Demonstration quality plays a crucial role in robot learning and generalization. Hence, it is important to quantify the quality of the provided demonstrations before using them for robot learning. In this paper, we propose quantifying the generalizability of the demonstrations based on how well they perform in the learned task. The proposed approach is validated in a user study (N = 27). Participants with different robotics expertise levels were recruited to teach a PR2 robot a generic task (pressing a button) under different task constraints. They taught the robot in two sessions on two different days to capture their teaching behaviour across sessions. The task performance was utilized to classify the provided demonstrations into high-quality and low-quality sets. The results show a significant correlation between task performance and generalization performance across all participants. We also found that users clustered into two groups: Users who provided high-quality demonstrations from the first session (the fast-adapters), and users who provided low-quality demonstrations in the first session and then improved with practice (the slow-adapters). This approach for assessing demonstrations allows us to determine whether users require more training in order to provide high-quality demonstrations.
# Imitation of Manipulation Skills Using Multiple Geometries
## Keywords:
- Learning from Demonstration
- Imitation Learning
- Optimization and Optimal Control
## Abstract:
Daily manipulation tasks are characterized by geometric primitives related to actions and object shapes. Such geometric descriptors are poorly represented by only using Cartesian coordinate systems. In this paper, we propose a learning approach to extract the optimal representation from a dictionary of coordinate systems to encode an observed movement/behavior. This is achieved by using an extension of Gaussian distributions on Riemannian manifolds, which is used to analyse a set of user demonstrations statistically, by considering multiple geometries as candidate representations of the task. We formulate the reproduction problem as a general optimal control problem based on an iterative linear quadratic regulator (iLQR), where the Gaussian distribution in the extracted coordinate systems are used to define the cost function. We apply our approach to object grasping and box opening tasks in simulation and on a 7-axis Franka Emika robot. The results show that the robot can exploit several geometries to execute the manipulation task and generalize it to new situations, by maintaining the invariant characteristics of the task in the coordinate system(s) of interest.
# Learning Category-Level Generalizable Object Manipulation Policy Via Generative Adversarial Self-Imitation Learning from Demonstrations
## Keywords:
- Learning from Demonstration
- Learning Categories and Concepts
- Imitation Learning
## Abstract:
Generalizable object manipulation skills are critical for intelligent and multi-functional robots to work in real-world complex scenes. Despite the recent progress in reinforcement learning, it is still very challenging to learn a generalizable manipulation policy that can handle a category of geometrically diverse articulated objects. In this work, we tackle this category-level object manipulation policy learning problem via imitation learning in a task-agnostic manner, where we assume no handcrafted dense rewards but only a terminal reward. Given this novel and challenging problem setting, we identify several key issues that fail the previous imitation learning algorithms and hinder the generalization to unseen instances. We then propose several critical techniques, including generative adversarial self-imitation learning from demonstrations, progressive growing of discriminator, and instance-balancing for expert buffer, that pinpoints and tackles these issues and can benefit category-level manipulation policy learning regardless of the tasks. Our experiments on ManiSkill benchmarks demonstrate remarkable improvements on all tasks, compared to the popular imitation learning algorithm, GAIL. This work won first place of the "no external annotation" track of ManiSkill Challenge 2021.
# Robot Learning from Demonstration Using Elastic Maps
## Keywords:
- Learning from Demonstration
- Imitation Learning
## Abstract:
Learning from Demonstration (LfD) is a popular method of reproducing and generalizing robot skills from given human demonstrations. In this paper, we propose a novel optimization-based LfD method that encodes demonstrations as elastic maps. An elastic map is a graph of nodes connected through a mesh of springs. The formulated optimization problem in our approach includes three quadratic objectives with natural and physical interpretations. The main term rewards the mean square error in the Cartesian coordinate. The second term penalizes the non-equidistant distribution of points resulting in the optimum total length of the trajectory. The third term rewards smoothness while penalizing nonlinearity. Additionally, our proposed LfD representation forms a convex problem that can be solved efficiently with local optimizers. We examine methods for constructing and weighting the elastic maps and study their performance in robotic tasks. We also evaluate the proposed method in several simulated and real-world experiments using a UR5e manipulator arm, and compare it to other LfD approaches to demonstrate its benefits and flexibility across a variety of metrics.
# Robot Policy Learning from Demonstration Using Advantage Weighting and Early Termination
## Keywords:
- Reinforcement Learning
- Learning from Demonstration
- Imitation Learning
## Abstract:
Learning robotic tasks in the real world is still highly challenging and effective practical solutions remain to be found. Traditional methods used in this area are imitation learning and reinforcement learning, but they both have limitations when applied to real robots. Combining reinforcement learning with pre-collected demonstrations is a promising approach that can help in learning control policies to solve robotic tasks. In this paper, we propose an algorithm that uses novel techniques to leverage offline expert data using offline and online training to obtain faster convergence and improved performance. The proposed algorithm (AWET) weights the critic losses with a novel agent advantage weight to improve over the expert data. In addition, AWET makes use of an automatic early termination technique to stop and discard policy rollouts that are not similar to expert trajectories---to prevent drifting far from the expert data. In an ablation study, AWET showed improved and promising performance when compared to state-of-the-art baselines on four standard robotic tasks.
# Inverse Reinforcement Learning with Hybrid-Weight Trust-Region Optimization and Curriculum Learning for Autonomous Maneuvering
## Keywords:
- Reinforcement Learning
- Learning from Demonstration
- Autonomous Vehicle Navigation
## Abstract:
Despite significant advancements, collision-free navigation in autonomous driving is still challenging, considering inverse reinforcement learning with hybrid-weight trust-region optimization and curriculum learning (IRL-HC) for autonomous maneuver. Our method can incorporate both expert demonstration and domain knowledge (encoded in reward function) to learn an effective policy. The hybrid-weight trust-region optimization is used to determine the difficulty of the task curriculum, improving the efficiency of inverse reinforcement learning. IRL-HC is also compatible with domain-dependent techniques such as learn-from-accident, which can further boost performance. Overall, IRL-HC can reduce the number of collisions up to 48%, increase the training efficiency by 2.8x, and enable the vehicle to drive 10x further compared to other methods.
# WFA-IRL: Inverse Reinforcement Learning of Autonomous Behaviors Encoded As Weighted Finite Automata
## Keywords:
- Learning from Demonstration
- Imitation Learning
- Formal Methods in Robotics and Automation
## Abstract:
This paper presents a method for learning logical task specifications and cost functions from demonstrations. Constructing specifications by hand is challenging for complex objectives and constraints in autonomous systems. Instead, we consider demonstrated task executions, whose logic structure and transition costs need to be inferred by an autonomous agent. We employ a spectral learning approach to extract a weighted finite automaton (WFA), approximating the unknown task logic. Thereafter, we define a product between the WFA for high-level task guidance and a labeled Markov decision process for low-level control. An inverse reinforcement learning (IRL) problem is considered to learn a cost function by backpropagating the loss between agent and expert behaviors through the planning algorithm. Our proposed model, termed WFA-IRL, is capable of generalizing the execution of the inferred task specification in a suite of MiniGrid environments.
# Ergodic Exploration Using Tensor Train: Applications in Insertion Tasks (I)
## Keywords:
- Optimization and Optimal Control
- Learning from Demonstration
- Task and Motion Planning
## Abstract:
In robotics, ergodic control extends the tracking principle by specifying a probability distribution over an area to cover instead of a trajectory to track. The original problem is formulated as a spectral multiscale coverage problem, typically requiring the spatial distribution to be decomposed as Fourier series. This approach does not scale well to control problems requiring exploration in search space of more than two dimensions. To address this issue, we propose the use of tensor trains, a recent low-rank tensor decomposition technique from the field of multilinear algebra. The proposed solution is efficient, both computationally and storagewise, hence making it suitable for its online implementation in robotic systems. The approach is applied to a peg-in-hole insertion task requiring full 6-D end-effector poses, implemented with a seven-axis Franka Emika Panda robot. In this experiment, ergodic exploration allows the task to be achieved without requiring the use of force/torque sensors.
# Manipulation Systems 5
# SSP-Pose: Symmetry-Aware Shape Prior Deformation for Direct Category-Level Object Pose Estimation
## Keywords:
- Deep Learning in Grasping and Manipulation
- Perception for Grasping and Manipulation
- Semantic Scene Understanding
## Abstract:
Category-level pose estimation is a challenging problem due to intra-class shape variations. Recent methods deform pre-computed shape priors to map the observed point cloud into the normalized object coordinate space and then retrieve the pose via post-processing,	i.e., Umeyama's Algorithm. The shortcomings of this two-stage strategy lie in two aspects: 1) The surrogate supervision on the intermediate results can not directly guide the learning of pose, resulting in large pose error after post-processing. 2) The inference speed is limited by the post-processing step. In this paper, to handle these shortcomings, we propose an end-to-end trainable network SSP-Pose for category-level pose estimation, which integrates shape priors into a direct pose regression network. SSP-Pose stacks four individual branches on a shared feature extractor, where two branches are designed to deform and match the prior model with the observed instance, and the other two branches are applied for directly regressing the totally 9 degrees-of-freedom pose and performing symmetry reconstruction and point-wise inlier mask prediction respectively. Consistency loss terms are then naturally exploited to align the outputs of different branches and promote the performance. During inference, only the direct pose regression branch is needed. In this manner, SSP-Pose not only learns category-level pose-sensitive characteristics to boost performance but also keeps a real-time inference speed. Moreover, we utilize the symmetry information of each category to guide the shape prior deformation, and propose a novel symmetry-aware loss to mitigate the matching ambiguity. Extensive experiments on public datasets demonstrate that SSP-Pose produces superior performance compared with competitors with a real-time inference speed at about 25Hz.
# VGPN: 6-DoF Grasp Pose Detection Network Based on Hough Voting
## Keywords:
- Deep Learning in Grasping and Manipulation
- Perception for Grasping and Manipulation
- Grasping
## Abstract:
In this paper, we propose a novel Voting based Grasp Pose Network (VGPN) to detect 6-DoF grasps in cluttered scenes. The motivation of this paper is that local object geometry can provide useful clues about where the object can be grasped. Generated by the sampled seed points from raw point cloud, the votes allow seed points in different object regions to contribute to locations where the object can be grasped. Geometric features from various local regions are aggregated to generate grasps in a more confident and dense space, which enables grasp prediction utilizing more global context features. The search space of grasp pose detection is also greatly reduced. Experimental results on both simulation and real-world environments show that our proposed method outperforms state-of-the# art approaches in terms of both success rate and coverage of the ground truth grasps. The objects can be grasped with fewer attempts which is critical in real-world applications.
# TANDEM: Learning Joint Exploration and Decision Making with Tactile Sensors
## Keywords:
- Force and Tactile Sensing
- Reinforcement Learning
## Abstract:
Inspired by the human ability to perform complex manipulation in the complete absence of vision (like retrieving an object from a pocket), the robotic manipulation field is motivated to develop new methods for tactile-based object interaction. However, tactile sensing presents the challenge of being an active sensing modality: a touch sensor provides sparse, local data, and must be used in conjunction with effective exploration strategies in order to collect information. In this work, we focus on the process of guiding tactile exploration, and its interplay with task-related decision making. We propose TANDEM (TActile exploration aNd DEcision Making), an architecture to learn efficient exploration strategies in conjunction with decision making. Our approach is based on separate but co-trained modules for exploration and discrimination. We demonstrate this method on a tactile object recognition task, where a robot equipped with a touch sensor must explore and identify an object from a known set based on binary contact signals alone. TANDEM achieves higher accuracy with fewer actions than alternative methods and is also shown to be more robust to sensor noise.
# Leveraging Publicly Available Textual Object Descriptions for Anthropomorphic Robotic Grasp Predictions
## Keywords:
- Learning Categories and Concepts
- Data Sets for Robot Learning
- Multifingered Hands
## Abstract:
Robotic systems using anthropomorphic end-effectors face tremendous challenges choosing a suitable pose for grasping an object. The fact that the choice of a grasp is influenced by the physical properties of an object, the intended task, and the environment results in a considerable amount of variables. The majority of models targeted towards enabling such robots to determine a suitable grasping pose rely on computer vision techniques, sometimes complemented by textual data. This paper investigates the potential of publicly available textual descriptions to predict a suitable grasping pose for anthropomorphic end-effectors. To this end, we have retrieved textual descriptions from Wikipedia, Wiktionary, and WordNet as well as a number of well-known dictionaries for 100 everyday objects. We analyze and compare the prediction quality of multiple learning methods while showing that a support vector machine-based approach can utilize this data for achieving a prediction accuracy above 0.75. Finally, we make our collected data available to the research community.
# Learning Closed-Loop Dough Manipulation Using a Differentiable Reset Module
## Keywords:
- Deep Learning in Grasping and Manipulation
- Perception-Action Coupling
- Perception for Grasping and Manipulation
## Abstract:
Deformable object manipulation has many applications such as cooking and laundry folding in our daily lives. Manipulating elastoplastic objects such as dough is particularly challenging because dough lacks a compact state representation and requires contact-rich interactions. We consider the task of flattening a piece of dough into a specific shape from RGB-D images. While the task is seemingly intuitive for humans, there exist local optima for common approaches such as naive trajectory optimization. We propose a novel trajectory optimizer that optimizes through a differentiable "reset" module, transforming a single-stage, fixed-initialization trajectory into a multistage, multi-initialization trajectory where all stages are optimized jointly. We then train a closed-loop policy on the demonstrations generated by our trajectory optimizer. Our policy receives partial point clouds as input, allowing ease of transfer from simulation to the real world. We show that our policy can perform real-world dough manipulation, flattening a ball of dough into a target shape.
# When Transformer Meets Robotic Grasping: Exploits Context for Efficient Grasp Detection
## Keywords:
- Deep Learning in Grasping and Manipulation
- Deep Learning Methods
## Abstract:
In this paper, we present a transformer-based architecture, namely TF-Grasp, for robotic grasp detection. The developed TF-Grasp framework has two elaborate designs mak# ing it well suitable for visual grasping tasks. The first key design is that we adopt the local window attention to capture local contextual information and detailed features of graspable objects. Then, we apply the cross window attention to model the long# term dependencies between distant pixels. Object knowledge, environmental configuration, and relationships between different visual entities are aggregated for subsequent grasp detection. The second key design is that we build a hierarchical encoder# decoder architecture with skip-connections, delivering shallow features from encoder to decoder to enable a multi-scale feature fusion. Due to the powerful attention mechanism, the TF# Grasp can simultaneously obtain the local information (i.e., the contours of objects), and model long-term connections such as the relationships between distinct visual concepts in clutter. Extensive computational experiments demonstrate that the TF-Grasp achieves superior results versus state-of-art grasping convolutional models and attain a higher accuracy of 97.99% and 94.6% on Cornell and Jacquard grasping datasets, respectively. Real# world experiments using a 7DoF Franka Emika Panda robot also demonstrate its capability of grasping unseen objects in a variety of scenarios. The code and pre-trained models will be available at https://github.com/WangShaoSUN/grasp-transformer.
# Biologically-Inspired Robots 5
# Effects of Design and Hydrodynamic Parameters on Optimized Swimming for Simulated, Fish-Inspired Robots
## Keywords:
- Biologically-Inspired Robots
- Reinforcement Learning
- Biomimetics
## Abstract:
In this work, we developed a mathematical model and a simulation platform for a fish-inspired robotic template, namely Magnetic, Modular, Undulatory Robot (MUBot). Through this platform, we systematically explored the effects of robot design and fluid parameters on swimming performance via reinforcement learning. The mathematical model was composed of two interacting subsystems, the robotic dynamic model and the hydrodynamic model. The hydrodynamic model consisted of the reactive components (added-mass force and pressure forces) and the resistive components (drag and friction forces). These components were nondimensionalized for deriving key “control parameters” of the robot-fluid interaction. The MUBots were actuated via magnetic actuators controlled with harmonic voltage signals, which were optimized via EM-based Policy Hyper Parameter Exploration (EPHE) to maximize forward swimming speed. By varying the control parameters, a total of 36 cases with different robot template variations (Number of Actuators (NoAs) and stiffness) and hydrodynamic parameters were simulated and optimized via EPHE. Results showed that the wavelength of the optimized gaits (i.e., backward traveling wave along the body) was independent of template variations and hydrodynamic parameters. Higher NoAs yielded higher speed but lower speed per body length, suggesting a diminishing gain from added actuators. Body and caudal-fin dynamics were dominated by the interaction among fluid added-mass, spring, and actuation torque, with negligible contribution from fluid resistive drag. In contrast, thrust was dominated by the pressure force acting on the caudal fin, as steady swimming resulted from a balance between resistive force and pressure force, with minor contributions from added-mass force and body drag forces. Therefore, added-mass force only indirectly affected the thrust generation and forward swimming speed via the caudal fin dynamics.
# High-Performance Morphing Wing for Large-Scale Bio-Inspired Unmanned Aerial Vehicles
## Keywords:
- Biologically-Inspired Robots
- Aerial Systems: Applications
- Soft Robot Applications
## Abstract:
This paper proposes a novel bio-inspired wing design to improve some characteristics of Flapping Wing Unmanned Vehicles (FWUV) related to their potential applications such as payload capability, maneuverability, low injury risk, and energy improvement. The suggested solution takes advantage of a broadly based avian research, focusing on the integration of advanced bird-like features ranging from bird-like high-compliant airfoil to active morphing strategies to mimic the ways birds naturally manage flights. The proposed conceptual design is supported by Unsteady Vortex Latex Method simulations provided by a novel flapping-oriented open-source solver. Prototype validation relies on both test-bench and real-flights results. A motion capture system is used to validate the wing aero-elastic characteristics. The resulted improvements are highlighted by a comprehensive comparison with different similar-size prototypes.
# A Motion Generation Strategy of Robotic Rat Using Imitation Learning for Behavioral Interaction
## Keywords:
- Biologically-Inspired Robots
- Bioinspired Robot Learning
- Imitation Learning
## Abstract:
In this paper, we propose a motion generation strategy using imitation learning (IL) for biomimetic robots to interact with animals in a more natural manner. We previously developed a bioinspired spine mechanism allowing the robot to mimic rat motion closely. Thanks to the spine morphology, we established the corresponding relationship of motion vector (spatial location and positions of key movement joints) between the robot and rats. We denote the motion vectors of two agents (demo robot and policy robot) as the interaction motion features (IMFs), where the motion vector of demo robot is directly copied from the demo rat and that of policy robot is generated using IL. First, we trained multilayer perceptrons by inputting the IMFs from the rat-rat interaction to generate the predicted IMFs for robot-robot interaction. Secondly, robot-robot IMFs are used to train a policy net, whose cost is the mean squared errors between the predicated and current features. Finally, we evaluated the proposed method in a simulation environment for the interaction between demo robot and policy robot. The results show effective interaction duration between robots has an increment of 34% than that between rats. Moreover, it also has a better concentration span than that of rat-rat interaction.
# Shaping Impedances to Comply with Constrained Task Dynamics (I)
## Keywords:
- Compliance and Impedance Control
- Redundant Robots
- Biologically-Inspired Robots
## Abstract:
Humans are capable of managing multiple tasks simultaneously. It is widely assumed that human motor control can be emulated by impedance control. To achieve human-like behavior, however, the impedance parameters of multiple tasks may vary during task execution. We propose an algorithm that shapes task impedance as a function of the robot’s time-varying inertial properties. These properties involve virtually constrained masses and virtually constrained inertias that counteract a task in order to comply with a given constraint. In this work, we not only detect task conflicts, but also show how to handle them. Our method is able to control kinematically redundant robots. We developed a damping# design method that does not interfere with our desired Cartesian task-space behavior. The control approach was verified in experiments on a real robot. We compared our impedance shaping method with two alternative control approaches: simple impedance superposition and nullspace projection. Our method preserved the passivity while improving the Cartesian task performance of an impedance controller. The method has computational advantages, beneficial to control robots with many degrees of freedom.
# Development of a Small-Sized Quadruped Robotic Rat Capable of Multimodal Motions (I)
## Keywords:
- Biologically-Inspired Robots
- Biomimetics
- Motion Control
## Abstract:
Legged robots are very promising for use in real-world applications, but their operation in narrow spaces is still challenging. One solution for enhancing their environmental adaptability is to design a small-sized biomimetic robot capable of performing multiple motions. By capturing a decent representation of an actual rat (rattus norvegicus), we developed a small-sized quadruped robotic rat (SQuRo), which includes four limbs and one flexible spine. On the basis of the extracted key movement joints, SQuRo was subtly designed with a relatively elongated slim body (aspect ratio: 3.42) and smaller weight (220 g) compared with quadruped robots of the same scale. Accordingly, we propose a control framework for multi-modal motion planning, and the appropriate control parameters were tuned through optimization with consideration to the stability and actuation limits. The results obtained through a series of experimental tests reveal that SQuRo achieves superior motion performance compared with existing state-of-the-art small-sized quadruped robots. Remarkably, SQuRo has an extremely small turning radius (0.48 BL) and strong payload capacity (200 g), and it can recover from falls.
# Aerial Systems 4
# Hoverability Analysis and Development of a Quadrotor Only with Clockwise Rotors
## Keywords:
- Aerial Systems: Mechanics and Control
- Aerial Systems: Applications
## Abstract:
This paper presents novel quadrotor structures composed of only clockwise rotors. A multirotor unmanned aerial vehicle (UAV) generally has both clockwise and counterclockwise rotors to counteract the torques from the rotors. While the proposed structures have only clockwise rotors, those rotors are tilted to cancel the torques around the yaw angle of the body. This paper investigates the conditions for the proposed structures to achieve static hovering. More specifically, we provide a guideline to design the rotor tilt angles of the proposed structure. Then, this paper presents the design example of the rotor tilt angles and develops a prototype of the proposed quadrotor. The cascaded controller is also developed for the proposed structure. Finally, experimental validation is conducted with a developed prototype and controller.
# A Novel Quadrotor with a 3-Axis Deformable Frame Using Tilting Motions of Parallel Link Modules without Thrust Loss
## Keywords:
- Aerial Systems: Mechanics and Control
## Abstract:
We propose a novel quadrotor with a 3-axis deformable frame using parallel link modules. By adding three servo motors to the frame, it has two configurations, namely, roll-pitch deformation mode and yaw deformation mode. In the roll-pitch deformation mode, it can tilt and fold the frame in the roll and pitch directions independently, which gives it 6 controllable degrees of freedom (CDOF). In the yaw deformation mode, it can contract the whole frame in the yaw direction. We propose a design method without thrust loss at any deformed state in both modes. In experiments, we show that it can fly stably even when deformed in both modes by the extended conventional control method. Furthermore, its applications are presented to demonstrate its high versatility.
# Adaptive Tank-Based Control for Aerial Physical Interaction with Uncertain Dynamic Environments Using Energy-Task Estimation
## Keywords:
- Aerial Systems: Mechanics and Control
- Force Control
- Robust/Adaptive Control
## Abstract:
While aerial manipulation has witnessed noticeable growth as a field in the last decade, most works investigated forms of interaction with static and rigid environments only. Whenever dynamic environments were considered, the employed methods often relied on the knowledge of the model of the environment, which in most real applications cannot be obtained. In this work, we propose an adaptive controller for a fully actuated UAV performing stable and efficient physical interaction tasks with unmodeled and dynamic objects moving in unknown environments. We develop a passive time-varying impedance controller and wrench tracking controller, whose adaptable parameters allow us to minimize tracking error and instabilities during the execution of the interaction task. Robust stability is guaranteed by energy tanks, with the addition of a task-based formulation for adapting online the tank parameters in order to always provide the system with an adequate amount of energy. The control framework is validated both in simulations and experimentally by interacting with an unmodeled cart moving in passive time-varying environments, while subjected to unknown disturbances.
# A Robotic Aerial Platform with Functionally Anthropomorphic Arms Designed for Physical Interaction
## Keywords:
- Aerial Systems: Mechanics and Control
- Bimanual Manipulation
- Natural Machine Motion
## Abstract:
Frequently, ground robots are hampered by debris and objects on the ground, and safely surpassing them is not always trivial. On the contrary, a robot capable of flying is intrinsically immune to such obstacles and, therefore, greatly enhances the possibility of inspecting and intervening in adverse surroundings for humans.
This work introduces a novel teleoperated aerial platform for inspection and intervention in unstructured environments. The robot is composed of an aerial base, two arms, and a two-degrees-of-freedom head that consent the access of human operators in any workplace in total safety. The arms are designed with a joint structure of tendons and are held by elastic components. This composition considerably improves the robustness by inserting softness and redistributing the weights to lessen the actions on the drone. Moreover, the aerial platform employs two soft hands capable of adapting to the shape of the objects under grasp, increasing the manipulation performance.
We presented the mechanical and control design, a gazebo simulation employed to test the controllers, and a physical structure for the experimental validation of the system. The system is available as Open-Source material.
# Back-Transition Control with Large Deceleration for a Dual Propulsion VTOL UAV Based on Its Maneuverability
## Keywords:
- Aerial Systems: Mechanics and Control
- Motion and Path Planning
- Dynamics
## Abstract:
This paper analyzes the maneuverability of a fixed-wing hybrid Vertical Take-Off and Landing (VTOL) Unmanned Aerial Vehicle (UAV), and proposes a control strategy for back-transitions from fixed-wing mode to rotary-wing mode based on it. Longitudinal aerodynamic forces and moment are modeled to derive a dynamic model of the UAV, and the translational and rotational accelerations that can be generated for the UAV are examined based on the model. To achieve a back-transition with the largest deceleration while maintaining level flight, we search for the best choice of pitch angle and thrust forces for each forward speed by numerical optimization. Flight experiments demonstrate that it is possible to perform a horizontal back-transition while generating a large deceleration with the chosen pitch angles.
# Nonlinear Model Predictive Control for Human-Robot Handover with Application to the Aerial Case
## Keywords:
- Aerial Systems: Mechanics and Control
- Aerial Systems: Perception and Autonomy
- Aerial Systems: Applications
## Abstract:
In this article, we consider the problem of delivering an object to a human coworker by means of an aerial robot (AR). To this aim, we present an ergonomics-aware Nonlinear Model Predictive Control (NMPC) designed to autonomously perform the handover. The method is general enough to be applied to any multi-rotor aerial vehicle (MRAV) with a minimal adaptation of the robot model. The formulation of the optimal control problem steers the AR toward a handover location by optimizing the human coworker ergonomics, which includes the predicted arm joint torques of the human. The motion task is expressed in a frame relative to the human, whose motion model is included in the equations of the NMPC. This allows the controller to promptly adapt to the human movements by predicting her future poses over the horizon. The control framework also accounts for the problem of maintaining visibility on the human coworker, while respecting both the actuation and state limits of the robot. Additionally, a safety barrier is embedded in the controller to avoid any risk of collision with the human partner. Realistic simulations are performed to validate the feasibility of the approach and the source code of the implementation is released open-source.
# Design, Modeling and Control of a Two Flight Mode Capable Single Wing Rotorcraft with Mid-Air Transition Ability
## Keywords:
- Aerial Systems: Mechanics and Control
- Biologically-Inspired Robots
- Aerial Systems: Applications
## Abstract:
Monocopters are nature-inspired, single-wing, rotating aerial vehicles that fly by spinning their entire body. Meanwhile, bicopters are twin propeller-based aerial vehicles that control their attitude by changing the direction of thrust from the motors using two servos. In this paper, we present a novel single-wing aerial vehicle, which can fly in both the monocopter and bicopter modes. To enhance its maneuverability while still being in the air, the platform can perform a mid-air transition from one mode to another. To achieve this, we fused the attributes of monocopter and bicopter, while allowing the monocopter to maintain its natural shape for flight. Considering forces and torques experienced by both modes of flight, the dynamics are described, and a cascaded control strategy is developed. A novel approach is proposed to control the angular velocity of the monocopter. An innovative blending and transition method of controllers for both modes is developed to allow transition between the two modes. We constructed a prototype to demonstrate the flight of the aerial vehicle in both modes. The results verify the proposed concept for the design of the aerial vehicle, along with the control strategy implemented for the control over the states during the flight modes as well as the transition between the two modes.
# Stabilization of Tangent and Normal Contact Forces for a Quadrotor Subject to Disturbances
## Keywords:
- Aerial Systems: Mechanics and Control
- Force Control
- Contact Modeling
## Abstract:
The lightweight structure of an underactuated quadrotor vibrates due to the high natural frequency of rotating propellers, which amounts for over thousands of rpm, but damped by dissipative aerodynamic forces. This exacerbates the problem of maintaining contact and exerting force against a rigidly fixed object because it will transfer back kinetic energy to the quadrotor that may surpass its flying capabilities to end up in a crash finally. This paper studies the problem of aerial contact stabilization of a quadrotor equipped with a hemispherical deformable tip. The soft tip is aimed at accommodating contact forces at a lower frequency at the expense of inducing rolling motion and deformation at contact, two phenomena not studied in the literature. Therefore, a normal restoring force arises due to deformation, simultaneously with a (velocity) rolling constraint, introducing a tangent constrained force. Then, a novel model-free continuous attitude fractional controller is proposed to guarantee finite-time attitude stabilization. It is shown that the residual coupled nonlinear dynamics yield the desired attitude corresponding to a given contact force; thus, force stabilization is achieved. Finally, experimental results are presented to assess the performance of the proposed approach.
# Experimental Performance Comparison of Bidirectional Actuator Configurations for Suspended Aerial Platforms
## Keywords:
- Aerial Systems: Mechanics and Control
- Aerial Systems: Applications
- Dynamics
## Abstract:
Suspended payload requires bidirectional thrust actuation to control their motion. Such systems, like the small suspended aerial cliff sampling system considered in this paper, require strong bidirectional actuators capable of fine positioning and fast disturbance rejection to
fight wind gusts. This paper presents a detailed experimental comparison of three bidirectional thrust actuator configurations (i.e., reverse thrust, antagonist thrusters, and variable pitch propeller) to understand their characteristics at the scale of small aerial systems. Five tests highlight the strengths and weaknesses of each configuration regarding static thrust capabilities, large and small step response, and bandwidth capabilities. This information is then used to select the best configuration for the suspended aerial cliff sampling system described, which in turn was able to sample rare cliff plants in Kaua'i in winds gusts of up to 37~km/h. The results will also help aerial roboticists make better-informed design decisions.
# Learning from Demonstration 2
# Learning to Sequence and Blend Robot Skills Via Differentiable Optimization
## Keywords:
- Learning from Demonstration
- Manipulation Planning
- Humanoid Robot Systems
## Abstract:
In contrast to humans and animals who naturally execute seamless motions, learning and smoothly executing sequences of actions remains a challenge in robotics. This paper introduces a novel skill-agnostic framework that learns to sequence and blend skills based on differentiable optimization. Our approach encodes sequences of previously-defined skills as quadratic programs (QP), whose parameters determine the relative importance of skills along the task. Seamless skill sequences are then learned from demonstrations by exploiting differentiable optimization layers and a tailored loss formulated from the QP optimality conditions. Via the use of differentiable optimization, our work offers novel perspectives on multitask control. We validate our approach in a pick-and-place scenario with planar robots, a pouring experiment with a real humanoid robot, and a bimanual sweeping task with a human model.
# Risk-Sensitive MPCs with Deep Distributional Inverse RL for Autonomous Driving
## Keywords:
- Learning from Demonstration
- Autonomous Vehicle Navigation
- Integrated Planning and Learning
## Abstract:
In robot learning from demonstration (LfD), a visual representation of a cost function inferred from Inverse Reinforcement Learning (IRL) provides an intuitive tool for humans to quickly interpret the underlying objectives of the demonstration. The inferred cost function can be used by controllers, for example, Model Predictive Controllers (MPCs). In this work, we improve the recently developed IRL-MPC framework, by enhancing it in a risk-sensitive formulation to be more applicable for safety-critical applications like autonomous driving. Our risk-sensitive MPCs together with the distributional costmap demonstrate lower collision rates in the CARLA simulator for autonomous driving tasks compared to other learning-based baseline methods.
# Learning Turn-Taking Behavior from Human Demonstrations for Social Human-Robot Interactions
## Keywords:
- Learning from Demonstration
- Social HRI
## Abstract:
Turn-taking is a fundamental behavior during human interactions and robots must be capable of turn-taking to interact with humans. Current state-of-the-art approaches in turn-taking focus on developing general models to predict the end of turn (EoT) across all contexts. This demands an all-inclusive verbal and non-verbal behavioral dataset from all possible contexts of interaction. Before robot deployment, gathering such a dataset may be infeasible and/or impractical. More importantly, a robot needs to predict the EoT and decide on the best time to take a turn (i.e., start speaking). In this research, we present a learning from demonstration (LfD) system for a robot to learn from demonstrations, after it has been deployed, to make decisions on the appropriate time for taking a turn within specific social interaction contexts. The system captures demonstrations of turn-taking during social interactions and uses these demonstrations to train a LSTM RNN based model to replicate the turn-taking behavior of the demonstrator. We evaluate the system for teaching the turn-taking behavior of an interviewer during a job interview context. Furthermore, we investigate the efficacy of verbal, prosodic, and gestural cues for deciding when to begin a turn.
# A Framework for Transferring Surface Finishing Skills to New Surface Geometries
## Keywords:
- Learning from Demonstration
- Industrial Robots
- Task and Motion Planning
## Abstract:
This paper presents a framework for transferring surface finishing skills to new surface geometries while preserving the surface finish quality. The main idea is to estimate the contact area between the workpiece and the tool by using 3D point cloud approach and replicate a given material removal rate and the accumulated material removal, as these quantities are the main parameters for quality. The grinding motion trajectory is generated by solving a constrained optimization problem that minimizes the maximal point-wise deviation between actual and desired material removal and simultaneously minimizes the average deviation between actual and desired material removal rate. The proposed approach is verified in simulation to show the difference between direct replication of force/motion and the proposed replication of material removal. Finally, experimental results confirm that the quality of a surface finishing task can be transferred to new surface geometries with the proposed method.
# A Bimanual Manipulation Taxonomy
## Keywords:
- Learning from Demonstration
- Bimanual Manipulation
- Human and Humanoid Motion Analysis and Synthesis
## Abstract:
The ability of humans to bimanually manipulate objects is unprecedented and has not been matched by robots yet. The goal-oriented coordination requires the consideration of both temporal and spatial constraints between the hands. Within this work, we propose a taxonomy which differentiates between the different coordination patterns observed in human bimanual manipulation. The taxonomy rests on the key aspects of coordination and interaction of the hands, hand roles and symmetry in the execution of bimanual tasks. To validate the taxonomy, we propose a contact# and graph-based representation of the task, which combined with a rule-based classification provides the category of bimanual actions.
# Learning Temporal Task Models from Human Bimanual Demonstrations
## Keywords:
- Learning from Demonstration
- Bimanual Manipulation
## Abstract:
Learning temporal relations between actions in a bimanual manipulation task is important for capturing the constraints of actions required to achieve the task's goal. However, given several demonstrations of a bimanual manipulation task, the problem of identifying the true temporal dependencies between actions # if there are any # is very challenging due to contradictions. We propose a model-driven approach for learning temporal task models from multiple bimanual human demonstrations that represents temporal relations on two levels. First, temporal relations between sets of actions that exhibit a tight temporal coupling, and second, temporal relations between these sets of actions. We build on Allen's interval algebra as a representation to express relations between temporal intervals. Semantically defining these interval relations allows us to soften their formulation to deal with inaccuracies in real data obtained when observing humans demonstrating the task. Our temporal task models can be learned incrementally from multiple modalities, and allow us to reason about viable alternatives during task execution in case of unexpected events. We evaluated the approach quantitatively on two datasets and qualitatively on a humanoid robot. The evaluation shows how inherent properties of bimanual human manipulation tasks can be exploited to derive a model useful for the reproduction by humanoid robots.
# Learning Implicit Priors for Motion Optimization
## Keywords:
- Learning from Demonstration
- Machine Learning for Robot Control
- Deep Learning Methods
## Abstract:
Motion optimization is an effective framework for generating smooth and safe trajectories for robotic manipulation tasks. However, it suffers from local optima that hinder its applicability, especially for multi-objective tasks. In this paper, we study this problem in light of the integration of Energy-Based Models (EBM) as guiding priors in motion optimization. EBMs are probabilistic models with unnormalized energy functions that represent expressive multimodal distributions. Due to their implicit nature, EBMs can easily be integrated as data-driven factors or initial sampling distributions in the motion optimization problem. This work presents a set of necessary modeling and algorithmic choices to effectively learn and integrate EBMs into motion optimization. We present a set of EBM architectures for learning generalizable distributions over trajectories that are important for the subsequent deployment of EBMs. Moreover, we investigate the benefit of including smoothness regularization in the learning process to improve motion optimization. In addition to gradient-based solvers, we also propose a stochastic method for trajectory optimization with learned EBMs. We provide extensive empirical results in a set of representative tasks against competitive baselines that demonstrate the superiority of EBMs as priors in motion optimization scaling up to 7-dof robot pouring that can be easily transferred to the real robotic system.
# Learning from Demonstration Based on Environmental Constraints
## Keywords:
- Learning from Demonstration
- Bioinspired Robot Learning
- Perception-Action Coupling
## Abstract:
We present a novel learning from demonstration approach which uses environmental constraints as the underlying representation to interpret and reproduce demonstrations. This representation based on environmental constraints separates the information that facilitates generalization from the information specific to object instances. Combined with adaptive controllers which fill in the instance-specific details during execution through explorative interaction, our approach generalizes from a single demonstration on an articulated object to different instances of the same object type. We test our approach in real-world experiments on contact-rich manipulation, using a series of mechanical locks as well as drawers and doors. The high success rate of 95% across all of these experiments provides strong evidence that environmental constraints are a powerful inductive bias for general and robust learning from demonstration.
# Multi-Level Task Learning Based on Intention and Constraint Inference for Autonomous Robotic Manipulation
## Keywords:
- Learning from Demonstration
- Probabilistic Inference
- Control Architectures and Programming
## Abstract:
To perform tasks in unstructured environments, robots need to be able to apply learned skills to different contexts and to autonomously make decisions online. We therefore developed a novel data-driven task learning approach that segments a task demonstration into simpler skills and structures them in a high-level task graph. In contrast to other state-of-the-art methods, the presented approach can not only infer the low-level skills and their respective subgoals, but also multimodal feature constraints fitted individually to each skill. The inferred feature constraints allow to detect anomalies during autonomous task execution, which can be automatically resolved by a recovery behavior of the task graph. The subgoals encode each skill's intention and thereby enable to flexibly transition between skills and to generalize the behavior to new setups. By separating the subgoal and constraint inference, we achieve a reduced computational complexity and an increased performance compared to state-of-the-art task learning approaches. In a real-world manipulation task, we demonstrate the reusability of skills as well as the autonomous decision-making of our approach.
# Telerobotics and Teleoperation 2
# HI-DWA: Human-Influenced Dynamic Window Approach for Shared Control of a Telepresence Robot
## Keywords:
- Telerobotics and Teleoperation
- Human Factors and Human-in-the-Loop
## Abstract:
This paper considers the problem of enabling the user to modify the path of a telepresence robot. The robot is capable of autonomously navigating to a goal predefined by the user, but the user might still want to modify the path, for example, to go further away from other people, or to go closer to landmarks she wants to see on the way. We propose Human# Influenced Dynamic Window Approach (HI-DWA), a shared control method aimed for telepresence robots based on Dynamic Window Approach (DWA), that allows the user to influence the control input given to the robot. To verify the proposed method, we performed a user study (N=32) in Virtual Reality (VR) to compare HI-DWA with switching between autonomous navigation and manual control for controlling a simulated telepresence robot moving in a virtual environment. Results showed that users reached their goal faster using HI-DWA controller and found it easier to use. Preference between the two methods was split equally. Qualitative analysis revealed that a major reason for the participants that preferred switching between two modes was the feeling of control. We also analyzed the effect of different input methods, joystick, and gesture, on the preference and perceived workload.
# A Method for Automated Drone Viewpoints to Support Remote Robot Manipulation
## Keywords:
- Telerobotics and Teleoperation
- Aerial Systems: Applications
- Human-Centered Robotics
## Abstract:
Drones can provide a minimally-constrained adapting camera view to support robot telemanipulation. Furthermore, the drone view can be automated to reduce the burden on the operator during teleoperation. However, existing approaches do not focus on two important aspects of using a drone as an automated view provider. The first is how the drone should select from a range of quality viewpoints within the workspace (e.g., opposite sides of an object). The second is how to compensate for unavoidable drone pose uncertainty in determining the viewpoint. In this paper, we provide a nonlinear optimization method that yields effective and adaptive drone viewpoints for telemanipulation with an articulated manipulator. Our first key idea is to use sparse human-in-the-loop input to toggle between multiple automatically-generated drone viewpoints. Our second key idea is to introduce optimization objectives that maintain a view of the manipulator while considering drone uncertainty and the impact on viewpoint occlusion and environment collisions. We provide an instantiation of our drone viewpoint method within a drone-manipulator remote teleoperation system. Finally, we provide an initial validation of our method in tasks where we complete common household and industrial manipulations.
# On the Communication Channel in Bilateral Teleoperation: An Experimental Study for Ethernet, WiFi, LTE and 5G
## Keywords:
- Telerobotics and Teleoperation
- Force and Tactile Sensing
- Networked Robots
## Abstract:
Teleoperated robots are believed to play an important role for future applications in industry, medicine and other domains. Examples for this are remote assembly and maintenance, surgery, diagnosis or deep-sea and space exploration. Such applications are made possible by state-of-the-art tactile manipulators, well-researched control schemes and novel communication technologies such as the fifth generation of mobile communication (5G). The achievable performance is highly dependent on the communication delay and thus on the distance between leader and follower station, as well as the potentially used wireless protocol. Specially in this regard, 5G is a promising technology compared to the other communication protocols for transferring tactile information. In this paper, we introduce our telepresence reference platform, which can be used for empirical evaluation of different algorithms and communications. Comparative analysis are conducted to capture the influence of wireless communication protocols on telepresence systems consisting of complex robotic arms. The experiment compares the influence of 5G, LTE and WiFi communication protocols with regard to the motion and force tracking performance of the system.
# On Stabilizing Communication Law for Bilateral Force-Reflecting Teleoperation Systems
## Keywords:
- Telerobotics and Teleoperation
- Haptics and Haptic Interfaces
- Human-Centered Robotics
## Abstract:
This brief proposes a new stabilizing communication law to allow the wave transformation-based teleoperation architecture to accommodate direct environmental contact force feedback, potentially increasing the human operator's experience of telepresence. Simulation results are provided.
# Towards Robot Avatar: Systems and Methods for Teleinteraction at Avatar XPRIZE Semi-Final
## Keywords:
- Telerobotics and Teleoperation
- Force and Tactile Sensing
- Physical Human-Robot Interaction
## Abstract:
There has been a drastic shift to remote interaction for professional, industrial and personal interactions. Improving the overall quality of these interactions by removing any sense of distance between the users is the ultimate goal. Video conferencing has been widely adopted as an improvement to audio-only interactions. Having added visuals to audio communication, the next frontier is to add physical interaction to this remote communication. In this paper, we present an avatar system with the aim of tackling these necessities. The proposed system includes both hardware and software designs to ensure a real-time telemanipulation experience with tactile force feedback. We present a coupled hydrostatic actuated gripper and glove with high system bandwidth to reduce the inherent latency of the mechanical system. To account for latency over the network, the wave variable based method is adopted to maintain the stability of the closed-loop gripper control even under hundreds of milliseconds of delay. A bi-directional audiovisual communication system comprised of off-the-shelf hardware and software is incorporated to allow real-time conversation between the operator and the recipient for collaborative tasks. The proposed system has been validated in lab experiments and the global ANA Avatar XPRIZE challenge semifinal.
# Multi-Phase Multi-Modal Haptic Teleoperation
## Keywords:
- Telerobotics and Teleoperation
- Space Robotics and Automation
- Human Factors and Human-in-the-Loop
## Abstract:
Virtual Fixtures facilitate teleoperation, for instance by guiding the human operator. Developing these Virtual Fixtures in tasks with tight tolerances remains challenging. Fixtures with a high stiffness allow for more precise guidance, whereas a lower stiffness is required to allow for corrections. We observed that many assembly operations can be split into different phases # approaching, positioning, in-contact manipulation # each with different accuracy requirements. Therefore, we propose to use multi-modal fixtures, satisfying the different requirements of these phases: i.e. a position-based Trajectory Fixture for approaching and a more accurate Visual Servoing Fixture for the positioning phase. A state estimation and arbitration component ensures smooth transitions between the fixtures to provide optimal support for the operator and to achieve global availability paired with local precision at the same time. It also allows a high stiffness to be used throughout, thus achieving good guidance for all phases. The approach is validated in an application from a space scenario, consisting of the assembly of a CubeSat subsystem. The empirical results from a pilot study on this task show that our approach is faster and requires less interaction force from the operator than the baseline method.
# Optimal Joint TDPA Formulation for Kinematically Redundant Robot Manipulators
## Keywords:
- Telerobotics and Teleoperation
- Optimization and Optimal Control
- Haptics and Haptic Interfaces
## Abstract:
The accomplishment of a successful teleoperation task requires guaranteeing system stability and transparency. Communication delay (in particular variable time delay), quantization and discretization negatively affect system stability and might be overcome with Time Domain Passivity Approach (TDPA), a model-free and robust way to cope with energy injection due to communication delay. However, this method degrades the transparency of the teleoperation system and worsens tracking performance, introducing in particular position drift error at the slave side and high-frequency vibration (jittering) at the master side. In this work, we propose a new joint passivity controller formulation for kinematically redundant manipulators. Our approach stabilizes the system guaranteeing minimal performance loss by privileging the dissipation of the observed energy in the Jacobian null-space. The residual energy (if any) is dissipated in an orthogonal subspace. This is achieved by the solution of an optimization problem with appropriately defined cost functions and constrained to dissipate the energy observed by the passivity observer, guaranteeing the stability of the system. The effectiveness of our algorithm is tested in simulation with both constant and variable time delays.
# Enhanced Accuracy in Magnetic Actuation: Closed-Loop Control of a Magnetic Agent with Low-Error Numerical Magnetic Model Estimation
## Keywords:
- Telerobotics and Teleoperation
- Medical Robots and Systems
- Mobile Manipulation
## Abstract:
Magnetic actuation holds promise for wirelessly controlling small, magnetic surgical tools and may enable the next generation of ultra minimally invasive surgical robotic systems. Precise torque and force exertion are required for safe surgical operations and accurate state control. Dipole field estimation models perform well far from electromagnets but yield large errors near coils. Thus, manipulations near coils suffer from severe (10x) field modeling errors. We experimentally quantify closed-loop magnetic agent control performance by using both a highly erroneous dipole model and a more accurate numerical magnetic model to estimate magnetic forces and torques for any given robot pose in 2D. We compare experimental measurements with estimation errors for the dipole model and our finite element analysis (FEA) based model of fields near coils. With five different paths designed for this study, we demonstrate that FEA-based magnetic field modeling reduces positioning root-mean-square (RMS) errors by 48% to 79% as compared with dipole models. Models demonstrate close agreement for magnetic field direction estimation, showing similar accuracy for orientation control. Such improved magnetic modelling is crucial for systems requiring robust estimates of magnetic forces for positioning agents, particularly in force-sensitive environments like surgical manipulation.
# Enhancing Rover Teleoperation on the Moon with Proprioceptive Sensors and Machine Learning Techniques
## Keywords:
- Telerobotics and Teleoperation
- Space Robotics and Automation
## Abstract:
Geological formations, environmental conditions, and soil mechanics frequently generate undesired effects on rovers' mobility, such as slippage or sinkage. Underestimating these undesired effects may compromise the rovers' operation and lead to a premature end of the mission. Minimising mobility risks becomes a priority for colonising the Moon and Mars. However, addressing this challenge cannot be treated equally for every celestial body since the control strategies may differ; e.g. the low latency Earth-Moon communication allows constant monitoring and controls, something not feasible on Mars. This paper proposes a Hazard Information System (HIS) that estimates the rover's mobility risks (e.g. slippage) using proprioceptive sensors and Machine Learning (supervised and unsupervised). A Graphical User Interface was created to assist human-teleoperation tasks by presenting mobility risk indicators. The system has been developed and evaluated in the lunar analogue facility (LunaLab) at the University of Luxembourg. A real rover and eight participants were part of the experiments. Results demonstrate the benefits of the HIS in the decision-making processes of the operator's response to overcome hazardous situations.
# Manipulation Systems 6
# The Role of Tactile Sensing in Learning and Deploying Grasp Refinement Algorithms
## Keywords:
- Force and Tactile Sensing
- Grasping
- Multifingered Hands
## Abstract:
A long-standing question in robot hand design is how accurate tactile sensing must be. This paper uses simulated tactile signals and the reinforcement learning (RL) framework to study the sensing needs in grasping systems. Our first experiment investigates the need for rich tactile sensing in the rewards of RL-based grasp refinement algorithms for multi-fingered robotic hands. We systematically integrate different levels of tactile data into the rewards using analytic grasp stability metrics. We find that combining information on contact positions, normals, and forces in the reward yields the highest average success rates of 95.4% for cuboids, 93.1% for cylinders, and 62.3% for spheres across wrist position errors between 0 and 7 centimeters and rotational errors between 0 and 14 degrees. This contact-based reward outperforms a non-tactile binary-reward baseline by 42.9%. Our follow-up experiment shows that when training with tactile-enabled rewards, the use of tactile information in the control policy's state vector is drastically reducible at only a slight performance decrease of at most 6.6% for no tactile sensing in the state. Since policies do not require access to the reward signal at test time, our work implies that models trained on tactile-enabled hands are deployable to robotic hands with a smaller sensor suite, potentially reducing cost dramatically.
# Learning to Singulate Layers of Cloth Based on Tactile Feedback
## Keywords:
- Force and Tactile Sensing
- Machine Learning for Robot Control
- Grasping
## Abstract:
Robotic manipulation of cloth has applications ranging from fabrics manufacturing to handling blankets and laundry. Cloth manipulation is challenging for robots largely due to their high degrees of freedom, complex dynamics, and severe self-occlusions when in folded or crumpled configurations. Prior work on robotic manipulation of cloth relies primarily on vision sensors alone, which may pose challenges for fine-grained manipulation tasks such as grasping a desired number of cloth layers from a stack of cloth. In this paper, we propose to use tactile sensing for cloth manipulation; we attach a tactile sensor (ReSkin) to one of the two fingertips of a Franka robot and train a classifier to determine whether the robot is grasping a specific number of cloth layers. During test-time experiments, the robot uses this classifier as part of its policy to grasp one or two cloth layers using tactile feedback to determine suitable grasping points. Experimental results over 180 physical trials suggest that the proposed method outperforms baselines that do not use tactile feedback and has better generalization to unseen cloth compared to methods that use image classifiers. Code, data, and videos are available at url{https://sites.google.com/view/reskin-cloth}.
# Multi-Finger Tactile Servoing for Grasping Adjustment under Partial Observation
## Keywords:
- Force and Tactile Sensing
- Perception for Grasping and Manipulation
- Multifingered Hands
## Abstract:
Grasping of objects using multi-fingered robotic hands often fails due to small uncertainties in the hand motion control and the object's pose estimation. To tackle this problem, we propose a grasp adaptation strategy based on tactile seroving. Our technique employs feedback from a sensorized multi-fingered robotic hand to collaboratively servo the fingers and palm to achieve the desired grasp. We demonstrate the performance of our method through simulation and physical experiments by having a robot grasp different objects under conditions of variable uncertainty. The results show that our approach achieved a higher success rate and tolerated greater uncertainty than an open-looped grasp.
# Finger-STS: Combined Proximity and Tactile Sensing for Robotic Manipulation
## Keywords:
- Force and Tactile Sensing
- Perception for Grasping and Manipulation
- Grippers and Other End-Effectors
## Abstract:
This paper introduces and develops novel touch sensing technologies that enable robots to better sense and react to to intermittent contact interactions. We present Finger-STS, a robotic finger embodiment of the See-Through-your-Skin (STS) sensor that can capture 1) an “in the hand” visual perspective of an object that is being manipulated and 2) a high resolution tactile imprint of the contact geometry. We demonstrate the value of the sensor on a Bead Maze task. Here the multimodal feedback provided by the Finger-STS is leveraged by a robot to locate a bead visually and to guide it across a wire in response to tactile cues, with no additional sensing or planning required. To achieve this, we introduce a set of relevant visuotactile operations using computer vision-based algorithms. In particular, we sense the proximity of the object relative to the sensor as well as the nature of contact as a high resolution stick/slip vector field tracking the object motion in the finger.
# Soft Tactile Contour Following for Robot-Assisted Wiping and Bathing
## Keywords:
- Force and Tactile Sensing
- Physically Assistive Devices
- Contact Modeling
## Abstract:
The automated cleaning of surfaces such as furniture, bathroom sinks, and even human bodies is challenging due to the three-dimensional nature of their geometries. Yet, enabling robots to effectively and safely perform these tasks would not only reduce user efforts spent on household cleaning chores, but would also alleviate the strenuous workload of caretakers as the elderly population continues to grow at an unprecedented rate. In this work, we unify the applications of wiping objects and bathing humans as a general contour-following problem. To this end, we utilize a depth camera-based soft tactile sensor to extract the contact geometries and force-correlated measures during interaction between the robot and the target object or body part, and design a general contour-following controller that not only maintains contact with the target throughout the cleaning process, but also regulates the amount of force applied. Our system enables successful cleaning of pipes, shelving, and even human limbs and torsos without the need for data-driven methods such as deep learning, upon which the majority of existing works have relied.
# A Deep-Learning-Based System for Indoor Active Cleaning
## Keywords:
- Computer Vision for Automation
- Data Sets for Robotic Vision
- Object Detection, Segmentation and Categorization
## Abstract:
Cleaning public areas like commercial complexes is challenging due to their sophisticated surroundings and the vast kinds of real-life dirt. Robots are required to distinguish dirts and apply corresponding cleaning strategies. In this work, we proposed an active-cleaning framework by utilizing deep-learning methods for both solid wastes detection and liquid stains segmentation. Our system consists of 4 components: a Perception module integrated with deep-learning models, a Post-processing module for projection, a Tracking module for map localization, and a Planning and Control module for cleaning strategies. Compared with classic approaches, our vision-based system significantly improves cleaning efficiency. Besides, we released the largest real-world indoor hybrid dirt cleaning dataset (HD10K) containing 10K labeled images, together with a track-level evaluation metric for better cleaning performance measurement. The proposed deep-learning based system is verified with extensive experiments on our dataset, and deployed to Gaussian Robotics's robots operating globally.
# Grasp Stability Prediction with Sim-To-Real Transfer from Tactile Sensing
## Keywords:
- Force and Tactile Sensing
- Simulation and Animation
- Deep Learning in Grasping and Manipulation
## Abstract:
Robot simulation has been an essential tool for data-driven manipulation tasks. However, most existing simulation frameworks lack either efficient and accurate models of physical interactions with tactile sensors or realistic tactile simulation. This makes the sim-to-real transfer for tactile-based manipulation tasks still challenging. In this work, we integrate simulation of robot dynamics and vision-based tactile sensors by modeling the physics of contact. This contact model uses simulated contact forces at the robot's end-effector to inform the generation of realistic tactile outputs. To eliminate the sim-to-real transfer gap, we calibrate our physics simulator of robot dynamics, contact model, and tactile optical simulator with real-world data, and then we demonstrate the effectiveness of our system on a zero-shot sim-to-real grasp stability prediction task where we achieve an average accuracy of 90.7% on various objects. Experiments reveal the potential of applying our simulation framework to more complicated manipulation tasks. We open-source our simulation framework at https://github.com/CMURoboTouch/Taxim/tree/taxim-robot.
# Whisker-Inspired Tactile Sensing for Contact Localization on Robot Manipulators
## Keywords:
- Force and Tactile Sensing
- Soft Sensors and Actuators
- Biologically-Inspired Robots
## Abstract:
Perceiving the environment through touch is important for robots to reach in cluttered environments, but devising a way to sense without disturbing objects is challenging. This work presents the design and modelling of whisker-inspired sensors that attach to the surface of a robot manipulator to sense its surrounding through light contacts. We obtain a sensor model using a calibration process that applies to straight and curved whiskers. We then propose a sensing algorithm using Bayesian filtering to localize contact points. The algorithm combines the accurate proprioceptive sensing of the robot and sensor readings from the deflections of the whiskers. Our results show that our algorithm is able to track contact points with sub-millimeter accuracy, outperforming a baseline method. Finally, we demonstrate our sensor and perception method in a real-world system where a robot moves in between free-standing objects and uses the whisker sensors to track contacts tracing object contours.
# Comparing Human Haptic Perception and Robotic Force/Torque Sensing in a Simulated Surgical Palpation Task
## Keywords:
- Force and Tactile Sensing
- Haptics and Haptic Interfaces
- Surgical Robotics: Laparoscopy
## Abstract:
In minimally invasive surgery (MIS), the reliable detection of hard inclusions in soft tissue is crucial for the success of the intervention. In robot-assisted surgery (RAS) however, limited technologies are available for intracorporeal tissue stiffness assessment due to the lack of force and tactile feedback from the robot tool tip. This paper investigates both, human haptic perception and robotic F/T sensing in similar experimental setups to draw conclusions about the usage of a haptic sensor for teleoperation in RAS. We use a novel 6-axis F/T sensor compact enough to be moved through trocars during RAS interventions and experimentally analyze its performance in a simulated robotic palpation task. Furthermore, we carry out a comprehensive user study (n=30) and collect fingertip interaction data to investigate human haptic perception. Results show, that both approaches detect larger bead diameters of 19 mm and 15 mm with high precision and show similar accuracy rates. With regards to interaction forces, subjects on average apply more than 10 times the amount of normal force (Fz=28.8±4.9 N), which leads to higher accuracy particularly for smaller embedded nodules. The robotic sensing technique, on the contrary, offers distinct advantages by providing more gentle treatments and reducing the risk of tissue damage.
# Navigation Systems 5
# SwitchHit: A Probabilistic, Complementarity-Based Switching System for Improved Visual Place Recognition in Changing Environments
## Keywords:
- Autonomous Vehicle Navigation
- Localization
- SLAM
## Abstract:
Visual place recognition (VPR) # a fundamental task in computer vision and robotics # is the problem of identifying a place mainly based on visual information. Viewpoint and appearance changes, such as due to weather and seasonal variations, make this task challenging. Currently, there is no universal VPR technique that can work in all types of environments, on a variety of robotic platforms, and under a wide range of viewpoint and appearance changes. Recent work has shown the potential of combining different VPR methods intelligently by evaluating complementarity for some specific VPR datasets to achieve better performance. This, however, requires ground truth information (correct matches) which is not available when a robot is deployed in a real-world scenario. Moreover, running multiple VPR techniques in parallel may be prohibitive for resource-constrained embedded platforms. To overcome these limitations, this paper presents a probabilistic complementarity-based switching VPR system, SwitchHit. Our proposed system consists of multiple VPR techniques, however, it does not simply run all techniques at once, rather predicts the probability of correct match for an incoming query image and dynamically switches to another complementary technique if the probability of correctly matching the query is below a certain threshold. This innovative use of multiple VPR techniques allow our system to be more efficient and robust than other combined VPR approaches employing brute force and running multiple VPR techniques at once. Thus making it more suitable for resource constrained embedded systems and achieving an overall superior performance from what any individual VPR method in the system could have by achieved running independently.
# A Robust Sidewalk Navigation Method for Mobile Robots Based on Sparse Semantic Point Cloud
## Keywords:
- Autonomous Vehicle Navigation
## Abstract:
Last-mile delivery robots are usually required to navigate on the sidewalk through a fixed route. The current solutions heavily rely on the image-based perception and GPS localization to successfully complete delivery tasks.However, it is prone to fail and become unreliable when the robot runs in challenging conditions, such as operating in different illuminations, or under canopies of trees or buildings. To address these issues, this paper proposes a novel robust sidewalk navigation method for the last-mile delivery robots with an affordable sparse LiDAR, which consists of two main modules: Semantic Point Cloud Network (SegPCn) and Reactive Navigation Network (RNn). More specifically, SegPCn takes the raw 3D point cloud as input and predicts the point-wise segmentation labels, presenting a robust perception capability even in the night. Then, the semantic point clouds are fed to RNn to generate an angular velocity to navigate the robot along the sidewalk, where the localization of the robot is not required. Moreover, an autolabeling mechanism is developed to reduce the labor involved in data preparation as well. And the LSTM neural network is explored to effectively leverage the historical context and derive correct decisions. Extensive experiments have been carried out to verify the efficacy of this method, and the results show that this method enables the robot to navigate on the sidewalk robustly during day and night.
# RCA: Ride Comfort-Aware Visual Navigation Via Self-Supervised Learning
## Keywords:
- Autonomous Vehicle Navigation
- Vision-Based Navigation
- Acceptability and Trust
## Abstract:
Under shared autonomy, wheelchair users expect vehicles to provide safe and comfortable rides while following users’ high-level navigation plans. To find such a path, vehicles negotiate with different terrains and assess their traversal difficulty. Most prior works model surroundings either through geometric representations or semantic classifications, which do not reflect perceived motion intensity and ride comfort in downstream navigation tasks. We propose to model ride comfort explicitly in traversability analysis using proprioceptive sensing. We develop a self-supervised learning framework to predict traversability costmap from first-person-view images by leveraging vehicle states as training signals. Our approach estimates how the vehicle would “feel” if traversing over based on terrain appearances. We then show our navigation system provides human-preferred ride comfort through robot experiments together with a human evaluation study.
# Binary Neural Networks for Memory-Efficient and Effective Visual Place Recognition in Changing Environments (I)
## Keywords:
- Localization
- Vision-Based Navigation
## Abstract:
Visual place recognition (VPR) is a robot’s ability to determine whether a place was visited before using visual data. While conventional handcrafted methods for VPR fail under extreme environmental appearance changes, those based on convolutional neural networks (CNNs) achieve state-of-the-art performance but result in heavy runtime processes and model sizes that demand a large amount of memory. Hence, CNN-based approaches are unsuitable for resource-constrained platforms, such as small robots and drones. In this article, we take a multistep approach of decreasing the precision of model parameters, combining it with network depth reduction and fewer neurons in the classifier stage to propose a new class of highly compact models that drastically reduces the memory requirements and computational effort while maintaining state-of-the-art VPR performance. To the best of our knowledge, this is the first attempt to propose binary neural networks for solving the VPR problem effectively under changing conditions and with significantly reduced resource requirements. Our best-performing binary neural network, dubbed FloppyNet, achieves comparable VPR performance when considered against its full-precision and deeper counterparts while consuming 99% less memory and increasing the inference speed by seven times.
# Avoiding Dense and Dynamic Obstacles in Enclosed Spaces: Application to Moving in Crowds (I)
## Keywords:
- Autonomous Vehicle Navigation
- Collision Avoidance
- Path Planning for Multiple Mobile Robots or Agents
## Abstract:
This article presents a closed-form approach to con# straining a flow within a given volume and around objects. The flow is guaranteed to converge and to stop at a single fixed point. The obstacle avoidance problem is inverted to enforce that the flow remains enclosed within a volume defined by a polygonal surface. We formally guarantee that such a flow will never contact the boundaries of the enclosing volume or obstacles. It asymptotically converges toward an attractor. We further create smooth motion fields around obstacles with edges (e.g., tables). Both obstacles and enclosures may be time-varying, i.e., moving, expanding, and shrinking. The technique enables a robot to navigate within en# closed corridors while avoiding static and moving obstacles. It was applied on an autonomous robot (QOLO) in a static complex indoor environment and tested in simulations with dense crowds. The final proof of concept was performed in an outdoor environment in Lausanne. The QOLO-robot successfully traversed a marketplace in the center of town in the
# Optimal Hierarchical Planner for Object Search in Large Environments Via Mobile Manipulation
## Keywords:
- Manipulation Planning
## Abstract:
We propose a hierarchical planning algorithm that efficiently computes an optimal plan for finding a target object in large environments where a robot must simultaneously consider both navigation and manipulation. One key challenge that arises from large domains is the substantial increase in search space complexity that stems from considering mobile manipulation actions and the increase in number of objects. We offer a hierarchical planning solution that effectively handles such large problems by decomposing the problem into a set of low-level intra-container planning problems and a high-level key place planning problem that utilizes the low-level plans. To plan optimally, we propose a novel admissible heuristic function that, unlike previous methods, accounts for both navigation and manipulation costs. We propose two algorithms: one based on standard A* that returns the optimal solution, and the other based on Anytime Repairing A* (ARA*) which can trade-off computation time and solution quality, and prove they are optimal even when we use hierarchy. We show our method outperforms existing algorithms in simulated domains involving up to 6 times more number of objects than previously handled.
# CNS Flight Stack for Reproducible, Customizable, and Fully Autonomous Applications
## Keywords:
- Software Architecture for Robotic and Automation
- Autonomous Vehicle Navigation
- Aerial Systems: Perception and Autonomy
## Abstract:
While low-level auto pilot stacks for aerial vehicles focus on robust control, sensing, and estimation, the continuous advancement of higher-level autonomy for aerial vehicles requires much more complex higher-level flight stacks in order to enable safe, fully autonomous long-duration missions. Rather than focusing on the low-level control, high-level flight stacks are required to monitor the system's integrity continuously, initiate contingency plans, execute mission plans and adapt them in non-nominal situations, allow for proper data logging, and provide standardized interfaces and integrity verification for external mission planners and localization modules.
To that end, we present our freely available, high-level flight stack (dubbed CNS Flight Stack) that meets the above requirements and at the same time a) is platform-agnostic through a generalized (embedded) hardware abstraction layer, b) uses low compute complexity for online use on embedded hardware, and c) can be extended with other sensor modalities, integrity checks, and mission modules. These additional properties make it reproducible on a variety of different platforms for safe and fully autonomous applications.
We tested the proposed flight stack in over 450 real-world flights and report the failure modes our framework detected and also mitigated to avoid crashes of the aerial system.
# A Hybrid Primitive-Based Navigation Planner for the Wheeled-Legged Robot CENTAURO
## Keywords:
- Sensor-based Control
- Motion and Path Planning
- Legged Robots
## Abstract:
Wheeled-legged robots have the potential to navigate in cluttered and irregular scenarios by altering the locomotion modes to adapt to the terrain challenges and effectively reach targeted locations in unstructured spaces. To achieve this functionality, a hybrid locomotion planner is necessary. 
In this work we present a search-based planner, which explores a set of motion primitives and a 2.5D traversability map extracted from the environment to generate navigation plans for the hybrid mobility robot CENTAURO. The planner explores the map from the current robot position to the goal location requested by the user, considering the most appropriate composition and tuning of locomotion primitives to build up a feasible plan, which is then executed by the robot. The available primitives are prioritized and can be easily modified, added or removed through a configuration file. Our approach was evaluated both in simulation and on the real wheeled-legged robot CENTAURO, demonstrating traversing capabilities in cluttered environments with various obstacles.
# Stronger Together: Air-Ground Robotic Collaboration Using Semantics
## Keywords:
- Field Robots
- Multi-Robot Systems
- Cooperating Robots
## Abstract:
In this work, we present an end-to-end heterogeneous multi-robot system framework where ground robots are able to localize, plan, and navigate in a semantic map created in real time by a high-altitude quadrotor. The ground robots choose and deconflict their targets independently, without any external intervention. Moreover, they perform cross-view localization by matching their local maps with the overhead map using semantics. The communication backbone is opportunistic and distributed, allowing the entire system to operate with no external infrastructure aside from GPS for the quadrotor. We extensively tested our system by performing different missions on top of our framework over multiple experiments in different environments. Our ground robots travelled over 6 km autonomously with minimal intervention in the real world and over 96 km in simulation without interventions.
# SLAM 6
# LAMP 2.0: A Robust Multi-Robot SLAM System for Operation in Challenging Large-Scale Underground Environments
## Keywords:
- Multi-Robot SLAM
- Multi-Robot Systems
- Field Robots
## Abstract:
Search and rescue with a team of heterogeneous mobile robots in unknown and large-scale underground environments requires high-precision localization and mapping. This crucial requirement is faced with many challenges in complex and perceptually-degraded subterranean environments, as the onboard perception system is required to operate in off-nominal conditions (poor visibility due to darkness and dust, rugged and muddy terrain, and the presence of self-similar and ambiguous scenes). In a disaster response scenario and in the absence of prior information about the environment, robots must rely on noisy sensor data and perform Simultaneous Localization and Mapping (SLAM) to build a 3D map of the environment and localize themselves and potential survivors. To that end, this paper reports on a multi-robot SLAM system developed by team CoSTAR in the context of the DARPA Subterranean Challenge. We extend our previous work, LAMP, by incorporating a single-robot front-end interface that is adaptable to different odometry sources and lidar configurations, a scalable multi-robot front-end to support inter# and intra-robot loop closure detection for large scale environments and multi-robot teams, and a robust back-end equipped with an outlier-resilient pose graph optimization based on Graduated Non-Convexity. We provide a detailed ablation study on the multi-robot front-end and back-end, and assess the overall system performance in challenging real-world datasets collected across mines, power plants, and caves in the United States. We also release our multi-robot back-end datasets (and the corresponding ground truth), which can serve as challenging benchmarks for large-scale underground SLAM.
# Loop Closure Prioritization for Efficient and Scalable Multi-Robot SLAM
## Keywords:
- Multi-Robot SLAM
- Multi-Robot Systems
- Field Robots
## Abstract:
Multi-robot SLAM systems in GPS-denied environments require loop closures to maintain a drift-free centralized map. With an increasing number of robots and size of the environment, checking and computing the transformation for all the loop closure candidates becomes computationally infeasible. In this work, we describe a loop closure module that is able to prioritize which loop closures to compute based on the underlying pose graph, the proximity to known beacons, and the characteristics of the point clouds. We validate this system in the context of the DARPA Subterranean Challenge and on four challenging underground datasets where we demonstrate the ability of this system to generate and maintain a map with low error. We find that our proposed techniques are able to select effective loop closures which results in 51% mean reduction in median error when compared to an odometric solution and 75% mean reduction in median error when compared to a baseline version of this system with no prioritization. We also find our proposed system is able to achieve a lower error in the mission time of one hour when compared to a system that processes every possible loop closure in four and a half hours. The code and dataset for this work can be found at https://github.com/NeBula-Autonomy/LAMP.
# Keeping Less Is More: Point Sparsification for Visual SLAM
## Keywords:
- SLAM
- Visual Tracking
- Localization
## Abstract:
When adapting Simultaneous Mapping and Localization (SLAM) to real-world applications, such as autonomous vehicles, drones, and augmented reality devices, its memory footprint and computing cost are the two main factors limiting the performance and the range of applications. In sparse feature based SLAM algorithms, one efficient way for this problem is to limit the map point size by selecting the points potentially useful for local and global bundle adjustment (BA). This study proposes an efficient graph optimization for sparsifying map points in SLAM systems. Specifically, we formulate a maximum pose-visibility and maximum spatial diversity problem as a minimum-cost maximum-flow graph optimization problem. The proposed method works as an additional step in existing SLAM systems, so it can be used in both conventional or learning based SLAM systems. By extensive experimental evaluations we demonstrate the proposed method achieves even more accurate camera poses with approximately 1/3 of the map points and 1/2 of the computation.
# Online Extrinsic Correction of Multi-Camera Systems by Low-Dimensional Parameterization of Physical Deformation
## Keywords:
- SLAM
- Calibration and Identification
## Abstract:
 In this paper, we propose the online extrinsic correction method that effectively optimizes the extrinsic parameters of multi-camera systems used in visual SLAM. In the typical visual SLAM systems that use multi-camera settings, the intrinsic and extrinsic parameters of the cameras are calculated through offline calibration, which is used as the fixed constraints in online execution. However, the camera rig can be physically deformed by shock or vibration, and the deviation from the offline calibration parameters can adversely affect the accuracy of triangulation and pose estimation. Therefore, it is crucial to maintain the accurate calibration of the camera rigs continuously throughout the execution. The previous online calibration methods optimize the extrinsic camera parameters in a full degree of freedom(DoF) by minimizing the reprojection error, but the limited visual information available online may bias the resulting camera poses. From the observation that the cameras are mounted on a physical body and the patterns that the body can be deformed is restricted and not completely free, we propose to model the pattern of physical rig deformation by external forces in advance, and then use the pre-trained low-dimensional deformation model to robustly and accurately estimate the changed camera poses in real-time. The proposed method consists of two steps. First, the physical model of the camera system is constructed in a simulator and the actual deformations by various external disturbances are recorded, and the deformation patterns are modeled by a PCA algorithm to build a low-dimensional model. In online execution, the camera poses are updated by minimizing the reprojection errors of visual features within the pre-trained low-dimensional parameterization, instead of optimizing all camera poses independently. Through the experiments in synthetic environments, the proposed online extrinsic correction method shows that it produces more accurate and robust camera pose estimation results than the existing method even when inaccurate 3D-2D correspondences exist or 2D feature positions are noisy.
# Active SLAM in 3D Deformable Environments
## Keywords:
- SLAM
- Motion and Path Planning
## Abstract:
This paper considers active SLAM problem for 3D deformable environments where the trajectory of the robot is planned to optimize the SLAM results. A planning strategy combining an efficient global planner with an accurate local planner is proposed to solve the problem. Simulation results under different scenarios have shown that the proposed active SLAM algorithm provides a good balance between accuracy and efficiency as compared to the local planner and the global planner.
# Event-Based Line SLAM in Real-Time
## Keywords:
- SLAM
- Localization
- Mapping
## Abstract:
Event-based cameras generate asynchronous streams of events, triggered proportionally to the logarithmic change of brightness in the scene. These cameras have very low latency and high dynamic range suitable to address challenging motion	scenarios in robotics. In this work, we explore a new event-based line-SLAM approach following a parallel tracking and mapping philosophy. Our fast tracking algorithm, produces accurate camera pose estimates at a rate in the order of	kHz by minimizing the event-line reprojection error with an error-state Kalman filter formulated entirely with Lie theory. The mapping thread leverages the natural edge highlighting strength of events to recover and optimize straight lines in human-made scenarios. The proper manipulation of matrix sparsity as well as the information sharing between tracking and mapping nodes allow us to achieve real-time performance on a standard multi-core CPU. This system	was tested on several scenarios rich in straight edge objects, and compared against, ground truth and frame and event based state-of-the-art approaches.
# MR-TopoMap: Multi-Robot Exploration Based on Topological Map in Communication Restricted Environment
## Keywords:
- Multi-Robot SLAM
- Multi-Robot Systems
- Mapping
## Abstract:
Multi-robot exploration in unknown environments is a fundamental task for a multi-robot system, involving inter-robot communication through messages to calculate the relative pose among the robots and merge the maps built by each robot. However, in a restricted communication environment, the limited communication resources become the system's bottleneck due to a large amount of data in the occupancy grid map. Hence, to enhance multi-agent exploration in communication-constrained environments, this paper develops a method to build topological maps while the robot moves in the environment and an exploration strategy based on the created topological map. The latter map comprises a set of vertices and edges connecting the vertices, where each vertex represents a specific area embedded with a descriptor extracted by visually observing this area and recognizing it utilizing descriptors. Each robot has its local grid map stored for path planning, not shared between them. Considering the exploration task, a robot's ability to choose a proper direction depends on the other robot's locations and the unexplored areas. Our exploration framework is evaluated on the Gazebo simulator and real robots, increasing the exploration efficiency by 35%~47%. Compared with the occupancy grid map scheme, our method's data transfer is reduced by 84%~90%.
# LCDNet: Deep Loop Closure Detection and Point Cloud Registration for LiDAR SLAM (I)
## Keywords:
- SLAM
- Deep Learning Methods
- Localization
## Abstract:
Loop closure detection is an essential component of Simultaneous Localization and Mapping (SLAM) systems, which reduces the drift accumulated over time. Over the years, several deep learning approaches have been proposed to address this task, however their performance has been subpar compared to handcrafted techniques, especially while dealing with reverse loops. In this paper, we introduce the novel LCDNet that effectively detects loop closures in LiDAR point clouds by simultaneously identifying previously visited places and estimating the 6-DoF relative transformation between the current scan and the map. LCDNet is composed of a shared encoder, a place recognition head that extracts global descriptors, and a relative pose head that estimates the transformation between two point clouds. We introduce a novel relative pose head based on the unbalanced optimal transport theory that we implement in a differentiable manner to allow for end-to-end training. Extensive evaluations of LCDNet on multiple real-world autonomous driving datasets show that our approach outperforms state-of-the-art loop closure detection and point cloud registration techniques by a large margin, especially while dealing with reverse loops. Moreover, we integrate our proposed loop closure detection approach into a LiDAR SLAM library to provide a complete mapping system and demonstrate the generalization ability using different sensor setup in an unseen city.
# Anchor Selection for SLAM Based on Graph Topology and Sub-Modular Optimization (I)
## Keywords:
- SLAM
- Mapping
- Probability and Statistical Methods
## Abstract:
This article considers simultaneous localization and mapping (SLAM) problem for robots in situations where accurate estimates for some of the robot poses, termed anchors, are available. These may be acquired through external means, for example, by either stopping the robot at some previously known locations or pausing for a sufficient period of time to measure the robot poses with an external measurement system. The main contribution is an efficient algorithm for selecting a fixed number of anchors from a set of potential poses that minimizes estimated error in the SLAM solution. Based on a graph-topological connection between the D-optimality design metric and the tree-connectivity of the pose-graph, the anchor selection problem can be formulated approximately as a submatrix selection problem for reduced weighted Laplacian matrix, leading to a cardinality-constrained submodular maximization problem. Two greedy methods are presented to solve this submodular optimization problem with a performance guarantee. These methods are complemented by Cholesky decomposition, approximate minimum degree permutation, order reuse, and rank-1 update that exploit the sparseness of the weighted Laplacian matrix. We demonstrate the efficiency and effectiveness of the proposed techniques on public-domain datasets, Gazebo simulations, and real-world experiments.
# Medical Robots and Systems 6
# Recognition and Prediction of Surgical Gestures and Trajectories Using Transformer Models in Robot-Assisted Surgery
## Keywords:
- Surgical Robotics: Laparoscopy
- Deep Learning Methods
- Kinematics
## Abstract:
Surgical activity recognition and prediction can help provide important context in many Robot-Assisted Surgery (RAS) applications, for example, surgical progress monitoring and estimation, surgical skill evaluation, and shared control strategies during teleoperation. Transformer models were first developed for Natural Language Processing (NLP) to model word sequences and soon the method gained popularity for general sequence modeling tasks. In this paper, we propose the novel use of a Transformer model for three tasks: gesture recognition, gesture prediction, and trajectory prediction during RAS. We modify the original Transformer architecture to be able to generate the current gesture sequence, future gesture sequence, and future trajectory sequence estimations using only the current kinematic data of the surgical robot end-effectors. We evaluate our proposed models on the JHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS) and use Leave-One-User-Out (LOUO) cross validation to ensure generalizability of our results. Our models achieve up to 89.3% gesture recognition accuracy, 84.6% gesture prediction accuracy (1 second ahead) and 2.71mm trajectory prediction error (1 second ahead). Our models are comparable to and able to outperform state-of-the-art methods while using only the kinematic data channel. This approach can enabling near-real time surgical activity recognition and prediction.
# Autonomous Laparoscope Control for Minimally Invasive Surgery with Intuition and RCM Constraints
## Keywords:
- Surgical Robotics: Laparoscopy
- Medical Robots and Systems
## Abstract:
The automated laparoscope control is able to ensure the stability of the laparoscopic image and enhance the performance of the surgeon during the surgical operations. In this letter, we presented a method that autonomously adjust laparoscopic pose to obtain the optimal field of view (FOV). An optimization problem was constructed to generate the laparoscopic pose, which provides the optimal FOV, based on the domain knowledge extracted from expert surgeon's experience. Furthermore, an image based algorithm to perceive the position of the surgical instruments in real time was developed. The remote center of motion (RCM) constraint of the laparoscope may cause the image misorientation while moving around. We presented a new criterion to eliminate the misorientation of FOV by adding an intuition constraint to the laparoscope controller. Finally, a control framework that can accomplish the laparoscope moving and meet the RCM constraint and the intuition constraint was proposed. The simulation and experiment results demonstrate that the validity of our method for automated laparoscope control.
# Learning Laparoscope Actions Via Video Features for Proactive Robotic Field-Of-View Control
## Keywords:
- Surgical Robotics: Laparoscopy
- Medical Robots and Systems
- Computer Vision for Medical Robotics
## Abstract:
Smart laparoscope motion control for adjusting surgical field-of-view is an increasingly hot topic in robot-assisted surgery. Previous off-the-shelf methods have been conducted in reactive ways which heavily rely on human input signals, e.g., gaze or voice, thus cannot avoid cognitive burdens to surgeons. In this paper, we introduce a novel proactive framework that learns the motion strategy from clinical surgical videos to achieve autonomous laparoscope control in surgery. In specific, we first propose a robust estimation method to acquire laparoscope motion in dynamic surgical scenes, which provides the basis for later supervised learning process. To imitate operating manners in different surgical domains, we design consistent dynamic image-level motion features that consist of semantic segmentation and dense optical flow. A sequence-to-sequence recurrent network is proposed to learn the connection between previous and future motion features at multiple temporal scales within a time-dependent sliding window. Then a laparoscope action head is built to convert the motion features into three-dimensional actions, hence establishing an end-to-end laparoscope motion imitation network. We have extensively validated the proposed proactive field-of-view control framework on both our textit{ex-vivo} phantom-based robotic platform, as well as textit{in-vivo} videos collected from real clinical videos. Our promising results demonstrate the feasibility to directly learn laparoscope behavioral actions from collected video data of experienced surgical assistants.
# A Surgical Robot for Intracorporeal Additive Manufacturing of Tissue Engineering Constructs
## Keywords:
- Surgical Robotics: Laparoscopy
- Additive Manufacturing
## Abstract:
The confluence of additive manufacturing (AM) based tissue engineering (TE), termed bioprinting, and robotic-assisted surgery (RAS) has the potential to increase the clinical adoption of regenerative medicine therapies by bioprinting inside the body. However, existing in vivo bioprinting systems are lacking in achievable structural complexity, defect access, or procedure invasiveness as they do not leverage the form factors of commercial RAS systems. Translating AM to RAS increases fluid pressures considerably, in turn increasing cell damage and decreasing cellular proliferation in TE constructs. Here, we describe Endoscopic AM, an intracorporeal bioprinting system that mimics the designs of commercial RAS systems and that has a novel endoscopic material metering system that produces cell pressures comparable to benchtop AM bioprinters. We present Endoscopic AM’s design, kinematics, fluid dynamics, and compare printing in a human body model to benchtop printing. We demonstrate intracorporeal printing is approximately 5 times less accurate than benchtop printing at this current design iteration, but that structure fidelity is sufficient for TE requirements.
# Automatic Keyframe Detection for Critical Actions from the Experience of Expert Surgeons
## Keywords:
- Surgical Robotics: Laparoscopy
- Medical Robots and Systems
## Abstract:
Robot-Assisted Minimally Invasive Surgery (RAMIS), which introduced robot-actuated invasive tools to increase the dexterity and efficiency of traditional MIS, has become popular. Investigations on how to achieve autonomy in RAMIS have drawn vast intention recently, which urges further insights into the process of the surgical procedures. In this paper, the definition of critical actions, which discriminates the essential stages from regular surgical actions, is proposed to help decompose the complicated surgical processes. A critical intra-operative moment of the surgical workflow, which is called the keyframe, is introduced to indicate the beginning or ending moments of the critical actions. A keyframe detection method is proposed for critical action identification based on a new in-vivo dataset labeled by expert surgeons. Surgeons' criteria for critical actions are captured by the explainable features, which can be extracted from the raw laparoscopic images with a two-stage network. Motivated by the surgeon's decision process of keyframes, a hierarchical structure is designed for keyframe identification by checking the spatial-temporal characteristics of the explainable features. Experimental results show that the reliability of the proposed method for keyframe detection achieves unanimous agreement by expert surgeons.
# Localization of Interaction Using Fibre-Optic Shape Sensing in Soft-Robotic Surgery Tools
## Keywords:
- Surgical Robotics: Laparoscopy
- Soft Sensors and Actuators
- Soft Robot Applications
## Abstract:
Minimally invasive surgery requires real-time tool tracking to guide the surgeon where depth perception and visual occlusion present navigational challenges. Although vision-based and external sensor-based tracking methods exist, fibreoptic sensing can overcome their limitations as they can be integrated directly into the device, are biocompatible, small, robust and geometrically versatile. In this paper, we integrate a fibre Bragg grating-based shape sensor into a soft robotic device. The soft robot is the pneumatically attachable flexible (PAF) rail designed to act as a soft interface between manipulation tools and intra-operative imaging devices. We demonstrate that the shape sensing fibre can detect the location of the tools paired with the PAF rail, by exploiting the change in curvature sensed by the fibre when a strain is applied to it. We then validate this with a series of grasping tasks and continuous US swipes, using the system to detect in real-time the location of the tools interacting with the PAF rail. The overall location-sensing accuracy of the system is 64.6%, with a margin of error between predicted location and actual location of 3.75 mm.
# Accurate Pose Estimation for Comanipulation Robotic Surgery
## Keywords:
- Surgical Robotics: Laparoscopy
- Calibration and Identification
- Medical Robots and Systems
## Abstract:
Robotic comanipulation provides a cost-effective solution to telesurgery when remote operation is not strictly necessary. Within the field of laparoscopic surgery, the comanip# ulation scenario is only recently being exploited commercially in the form of lightweight backdrivable systems. A passive wrist backdrivable robot does not require preoperative alignment with the incision that acts as a fulcrum around which the laparoscopic instrument pivots. Moreover, backdrivable systems can be comanipulated by the user without the need for expen# sive force sensors. Unfortunately, most backdrivable systems only provide limited accuracy when measuring the end effector pose from their joint encoders. Accurate knowledge of the end effector pose is required to estimate the the instrument tip and fulcrum position. This work presents a robust method to improve localisation of the pose of the end effector of a backdrivable robot. The method fuses optical tracking with robot proprioception by means of an unscented Kalman filter and is robust against intermittent occlusions of the line of sight. The algorithm is experimentally validated by analyzing its initialization behavior and accuracy when estimating the instrument tip and fulcrum position. An accuracy of 1.58±0.157 mm and 0.699±0.389 mm is achieved when estimating the instrument tip and fulcrum position respectively, which makes the algorithm suitable for advanced guidance schemes in comanipulation robotic surgery.
# Distilled Visual and Robot Kinematics Embeddings for Metric Depth Estimation in Monocular Scene Reconstruction
## Keywords:
- Surgical Robotics: Laparoscopy
- Medical Robots and Systems
- Computer Vision for Medical Robotics
## Abstract:
Estimating precise metric depth and scene reconstruction from monocular endoscopy is a fundamental task for surgical navigation in robotic surgery. However, traditional stereo matching adopts binocular images to perceive the depth information, which is difficult to transfer to the soft robotics-based surgical systems due to the use of monocular endoscopy. In this paper, we present a novel framework that combines robot kinematics and monocular endoscope images with deep unsupervised learning into a single network for metric depth estimation and then achieve 3D reconstruction of anatomy. Specifically, we first obtain the un-scaled depth of surgical scenes by leveraging a brightness-aware monocular disparity estimation method. Then, the corresponding endoscope poses are computed based on optimization of geometric and photometric reprojection errors. Afterwards, we develop a Depth-driven Sliding Optimization algorithm to extract the scale from kinematics sequences and calculated poses. By coupling the metric scale factor and un-scaled depth, we form a robust ensemble that represents the metric and consistent depth. Next, we treat the ensemble as supervisory labels to train a metric depth estimation network for surgeries (i.e., MetricDepthS-Net) that distills the embeddings from the robot kinematics, endoscopic videos, poses and surgical scene geometry. With accurate metric depth estimation, we utilize a dense visual reconstruction method to recover the 3D structure of the whole surgical site. We have evaluated the proposed framework on the public SCARED dataset and achieve comparable performance with stereo-based depth estimation methods. Our results demonstrate the feasibility of the proposed approach to recover the metric depth and 3D structure with monocular inputs.
# A New Power Law Linking the Speed to the Geometry of Tool-Tip Orientation in Teleoperation of a Robot-Assisted Surgical System
## Keywords:
- Surgical Robotics: Laparoscopy
- Human-Centered Robotics
- Physical Human-Robot Interaction
## Abstract:
Fine manipulation is important in dexterous tasks executed via teleoperation, including in robot-assisted surgery. Discovering fundamental laws of human movement can benefit the design and control of teleoperated systems, and the training of their users. These laws are formulated as motor invariants, such as the well-studied speed-curvature power law. However, while the majority of these laws characterize translational movements, fine manipulation requires controlling the orientation of objects as well. This subject has received little attention in human motor control studies. Here, we report a new power law linking the speed to the geometry in orientation control -# humans rotate their hands with an angular speed that is exponentially related to the local change in the direction of rotation. We demonstrate this law in teleoperated tasks performed by surgeons using surgical robotics research platforms. Additionally, we show that the law's parameters change slowly with the surgeons' training, and are robust within participants across task segments and repetitions. The fact that this power law is a robust motor invariant suggests that it may be an outcome of sensorimotor control. It also opens questions about the nature of this control and how it can be harnessed for better control of human-teleoperated robotic systems.
# Collision Avoidance
# Differentiable Collision Avoidance Using Collision Primitives
## Keywords:
- Collision Avoidance
- Motion and Path Planning
## Abstract:
A central aspect of robotic motion planning is collision avoidance, where a multitude of different approaches are currently in use. Optimization-based motion planning is one method, that often heavily relies on distance computations between robots and obstacles. These computations can easily become a bottleneck, as they do not scale well with the complexity of the robots or the environment. To improve performance, many different methods suggested to use collision primitives, i.e. simple shapes that approximate the more complex rigid bodies, and that are simpler to compute distances to and from. However, each pair of primitives requires its own specialized code, and certain pairs are known to suffer from numerical issues. In this paper, we propose an easy-to-use, unified treatment of a wide variety of primitives. We formulate distance computation as a minimization problem, which we solve iteratively. We show how to take derivatives of this minimization problem, allowing it to be seamlessly integrated into a trajectory optimization method. We demonstrate that the resulting method can be used to plan smooth and collision-free paths based on a variety of single# and multi-robot scenarios with different obstacles.
# Informed Sampling-Based Collision Avoidance with Least Deviation from the Nominal Path
## Keywords:
- Collision Avoidance
- Motion and Path Planning
- Autonomous Vehicle Navigation
## Abstract:
This paper addresses local path re-planning for n-dimensional systems by introducing an informed sampling scheme and cost function to achieve collision avoidance with minimum deviation from an (optimal) nominal path. The proposed informed subset consists of the union of ellipsoids along the specified nominal path, such that the subset efficiently encapsulates all points along the nominal path. The cost function penalizes large deviations from the nominal path, thereby ensuring current safety in the face of potential collisions while retaining most of the overall efficiency of the nominal path. The proposed method is demonstrated on scenarios related to the navigation of autonomous marine crafts.
# Reactive Neural Path Planning with Dynamic Obstacle Avoidance in a Condensed Configuration Space
## Keywords:
- Collision Avoidance
- Motion and Path Planning
- Bioinspired Robot Learning
## Abstract:
We present a biologically inspired approach for path planning with dynamic obstacle avoidance. Path planning is performed in a condensed configuration space of a robot generated by self-organizing neural networks (SONN). The robot itself and static as well as dynamic obstacles are mapped from the Cartesian task to the configuration space by precomputed kinematics. The condensed space represents a cognitive map of the environment, which is inspired by place cells and the concept of cognitive maps in mammalian brains. Generation of training data as well as the evaluation are performed on a real industrial robot accompanied by simulations. To evaluate reactive collision-free online planning within a changing environment, a demonstrator was realized. Then, a comparative study regarding sample-based planners was carried out. The robot is able to operate in dynamically changing environments and re-plan its motion trajectories within impressing 0.02 seconds, which proofs the real-time capability of our concept.
# HIRO: Heuristics Informed Robot Online Path Planning Using Pre-Computed Deterministic Roadmaps
## Keywords:
- Collision Avoidance
- Motion and Path Planning
- Human-Robot Collaboration
## Abstract:
We propose an online path planning method called HIRO to enable articulated robots to adapt their motion to environmental changes quickly. Dividing the workspace into static and dynamic environments, we use the static environment to initialize a deterministic roadmap, which provides a lower bound of the final path cost as informed heuristics for fast path-finding. These heuristics guide a search tree to explore the roadmap. The search tree examines the edges using a fuzzy collision checking concerning the dynamic environment. Finally, the heuristics tree exploits the knowledge fed back from the fuzzy collision checking module and updates the lower bound for the path cost. The closed-loop formed by these three components significantly accelerates the procedure. %while the resulting path is still legible. An additional backtracking step ensures the feasibility of the resulting paths. Experiments in simulation and the real world show that HIRO can find collision-free paths considerably faster than baseline methods with and without prior knowledge of the environment.
# A Framework for the Systematic Evaluation of Obstacle Avoidance and Object-Aware Controllers
## Keywords:
- Collision Avoidance
- Safety in HRI
- Physical Human-Robot Interaction
## Abstract:
Real-time control is an essential aspect of safe robot operation in the real world with dynamic objects. We present a framework for the analysis of object-aware controllers, methods for altering a robot's motion to anticipate and avoid possible collisions. This framework is focused on three design considerations: kinematics, motion profiles, and virtual constraints. Additionally, the analysis in this work relies on verification of robot behaviors using fundamental robot-obstacle experimental scenarios. To showcase the effectiveness of our method we compare three representative object-aware controllers. The comparison uses metrics originating from the design considerations. From the analysis, we find that the design of object-aware controllers often lacks kinematic considerations, continuity of control points, and stability in movement profiles. We conclude that this framework can be used in the future to design, compare, and benchmark obstacle avoidance methods.
# GraphDistNet: A Graph-Based Collision-Distance Estimator for Gradient-Based Trajectory Optimization
## Keywords:
- Collision Avoidance
- Manipulation Planning
- Deep Learning in Grasping and Manipulation
## Abstract:
Trajectory optimization (TO) aims to find a sequence of valid states while minimizing costs. However, its fine validation process is often costly due to computationally expensive collision searches, otherwise coarse searches lower the safety of the system losing a precise solution. To resolve the issues, we introduce a new collision-distance estimator, GraphDistNet, that can precisely encode the structural information between two geometries by leveraging edge feature-based convolutional operations, and also efficiently predict a batch of collision distances and gradients through 25,000 random environments with a maximum of 20 unforeseen objects. Further, we show the adoption of attention mechanism enables our method to be easily generalized in unforeseen complex geometries toward TO. Our evaluation show GraphDistNet outperforms state-of-the-art baseline methods in both simulated and real world tasks.
# A Generalized Continuous Collision Detection Framework of Polynomial Trajectory for Mobile Robots in Cluttered Environments
## Keywords:
- Collision Avoidance
- Motion and Path Planning
- Robot Safety
## Abstract:
In this paper, we introduce a generalized continuous collision detection (CCD) framework for the mobile robot along the polynomial trajectory in cluttered environments including various static obstacle models. Specifically, we find that the collision conditions between robots and obstacles could be transformed into a set of polynomial inequalities, whose roots can be efficiently solved by the proposed solver. In addition, we test different types of mobile robots with various kinematic and dynamic constraints in our generalized CCD framework and validate that it allows the provable collision checking and can compute the exact time of impact. Furthermore, we combine our architecture with the path planner in the navigation system. Benefiting from our CCD method, the mobile robot is able to work safely in some challenging scenarios. Codes and videos of this work are available at https://sites.google.com/view/gccd-pt/site.
# Collaborative Teleoperation with Haptic Feedback for Collision-Free Navigation of Ground Robots
## Keywords:
- Collision Avoidance
- Telerobotics and Teleoperation
- Human-Robot Collaboration
## Abstract:
We propose a collaborative teleoperation algorithm which utilizes haptic force feedback to guide users around oncoming obstacles while accounting for non-holonomic constraints. The proposed algorithm predicts the user's goal, plans a path using a modified RRT* algorithm to the predicted goal, and provides haptic guidance to the path and away from obstacles when the user is in an unsafe pose. We show that the vehicle cannot collide with obstacles under the proposed algorithm following the haptic commands. We assess the performance of our algorithm with a virtual pilot in simulations and hardware experiments, demonstrating its ability to prevent collisions while reaching the goal location. Additionally, we demonstrate human-in-the-loop navigation with a Geomagic Touch haptic device providing force feedback to the user. These simulations and experiments show that the proposed haptic guidance system is a useful and effective tool for co-navigation of non-holonomic vehicles via teleoperation.
# Deep Reinforcement Learning for Robot Collision Avoidance with Self-State-Attention and Sensor Fusion
## Keywords:
- Collision Avoidance
- Deep Learning Methods
- Reinforcement Learning
## Abstract:
3D LiDAR sensors can provide 3D point clouds of the environment, and are widely used in automobile navigation; while 2D LiDAR sensors can only provide point cloud in a 2D sweeping plane, and then are only used for navigating robots of small height, e.g., floor mopping robots. In this paper, we propose a simple yet effective deep reinforcement learning (DRL) method with our self-state-attention unit and give a solution that can use low-cost devices (i.e., a 2D LiDAR sensor and a monocular camera) to navigate a tall mobile robot of one meter height. The overrall pipeline is that we (1) infer the dense depth information of RGB images with the aid of the 2D LiDAR sensor data (i.e., point clouds in a plane with fixed height), (2) further filter the dense depth map into a 2D minimal depth data and fuse with 2D LiDAR data, and (3) make use of DRL module with our self-state-attention unit to a partially observable sequential decision making problem that can deal with partially accurate data. We present a novel DRL training scheme for robot navigation, proposing a concise and effective self-state-attention unit and proving that applying this unit can replace multi-stage training, achieve better results and generalization capability. Experiments on both simulated data and a real robot show that our method can perform efficient collision avoidance only using low-cost 2D LiDAR sensor and monocular camera.
# Simulation and Animation
# Fidelity Evaluation of Virtual Traffic Based on Anomalous Trajectory Detection
## Keywords:
- Simulation and Animation
- Deep Learning Methods
## Abstract:
Measuring the fidelity of synthesized virtual traffic has become an important and fundamental concern for evaluating the performance of different traffic simulation techniques and applications of autonomous vehicle testing. In this work, we propose a novel method to evaluate the fidelity of any trajectory data from the perspective of anomalous trajectory detection. First, given the trajectory data to be evaluated as input, the method learns spatio-temporal traffic features and reconstructs the input trajectory through a Long Short-Term Memory (LSTM)-based autoencoder architecture. Then, the anomalous trajectories are detected by comparing the reconstructed trajectories and the input ones using the reconstruction error as the benchmark. Our method can detect eight different kinds of anomalous trajectory in terms of changes in velocity and moving direction. In order to evaluate the fidelity of the input trajectory, we design a perceptual evaluation on virtual traffic fidelity and derive a mapping from the reconstruction error to the evaluation score. We demonstrated the effectiveness and robustness of our metric through many experiments on real-world and synthetic trajectory data containing different types of motion anomalies.
# CapSense: A Real-Time Capacitive Sensor Simulation Framework for Physical Human-Robot Interaction
## Keywords:
- Simulation and Animation
- Physical Human-Robot Interaction
## Abstract:
This article presents CapSense, a real-time open-source capacitive sensor simulation framework for robotic applications. CapSense provides raw data of capacitive proximity sensors based on a fast and efficient 3D finite-element method (FEM) implementation. The proposed framework is interfaced to off-the-shelf robot and physics simulation environments to couple dynamic interaction of the environment with an electro-static solver for capacitance computation in real-time. The FEM method proposed in this article relies on a static tetrahedralmesh of the sensor surrounding without a-posteriori re-meshing and achieves high update rates by an adaptive update step. CapSense is flexible due to various configuration parameters (i.e. number, size, shape and location of electrodes) and serves as a platform for investigation of capacitive sensors in robotic applications. By using the proposed framework, researchers can simulate capacitive sensors in different scenarios and investigate these sensors and their configuration prior to installation and fabrication of real hardware. The proposed framework opens new research opportunities via sim-to-real transfer of capacitive sensing. The simulation approach is	validated by comparing real-world results of different scenarios with simulation results. In order to showcase the benefits of CapSense in physical Human-Robot Interaction (pHRI), the framework is evaluated in a robotic healthcare scenario.
# Learning to Simulate Realistic LiDARs
## Keywords:
- Simulation and Animation
- Representation Learning
- Object Detection, Segmentation and Categorization
## Abstract:
Simulating realistic sensors is a challenging part in data generation for autonomous systems, often involving carefully handcrafted sensor design, scene properties, and physics modeling. To alleviate this, we introduce a pipeline for data-driven simulation of a realistic LiDAR sensor. We propose a model that learns a mapping between RGB images and corresponding LiDAR features such as raydrop, per-point intensities directly from real datasets. We show that our model can learn to encode realistic effects such as dropped points on transparent surfaces or high intensity returns on reflective materials. When applied to naively raycasted point clouds provided by off-the-shelf simulator software, our model enhances the data by predicting intensities and removing points based on the scene's appearance to match a real LiDAR sensor. We use our technique to learn models of two distinct LiDAR sensors and use them to improve simulated LiDAR data accordingly. Through a sample task of vehicle segmentation, we show that enhancing simulated point clouds with our technique improves downstream task performance.
# Realistic Real-Time Simulation of RGB and Depth Sensors for Dynamic Scenarios Using Augmented Image Based Rendering
## Keywords:
- Simulation and Animation
- RGB-D Perception
- Computer Vision for Automation
## Abstract:
Simulation remains one of the key methods for testing and validation of robotic perception systems and it also becomes increasingly important for training visuomotor policies for autonomous driving or manipulation. Further, as perception pipelines tend to leverage increasing amounts of modalities, it appears vital to simulate additional cues such as depth maps aside from RGB images. To align simulation with real-world observations, it is key to achieve realistic renderings of these maps, which includes the capability of rendering other dynamic objects in the scene. In this work, we propose an approach to real-time simulation of photo-realistic RGB images and sensor-realistic depth maps, that can contain dynamic objects at user-defined locations. Our method employs a selection of static samples of a pre-recorded database and multimodal cues from CAD models that are fused and warped to synthesize new imagery for a target camera pose. We show the efficacy of our method on newly proposed datasets recorded in a variety of different setups.
# Understanding Physical Effects for Effective Tool-Use
## Keywords:
- Simulation and Animation
- Service Robotics
## Abstract:
We present a robot learning and planning framework that produces an effective tool-use strategy with the least joint efforts, capable of handling objects different from training. Leveraging a Finite Element Method (FEM)-based simulator that reproduces fine-grained, continuous visual and physical effects given observed tool-use events, the essential physical properties contributing to the effects are identified through the proposed Iterative Deepening Symbolic Regression (IDSR) algorithm. We further devise an optimal control-based motion planning scheme to integrate robot# and tool-specific kinematics and dynamics to produce an effective trajectory that enacts the learned properties. In simulation, we demonstrate that the proposed framework can produce more effective tool-use strategies, drastically different from the observed ones in two exemplar tasks.
# A High-Fidelity Simulation Platform for Industrial Manufacturing by Incorporating Robotic Dynamics into an Industrial Simulation Tool
## Keywords:
- Simulation and Animation
- Software-Hardware Integration for Robot Systems
- Industrial Robots
## Abstract:
Simulation provides an efficient and safe evaluation solution for industrial automation to pretest software before deploying it in real systems. However, only high-fidelity simulation environments that precisely reconstruct the behavioral patterns of real systems can guarantee a successful transfer from simulation to reality (sim-to-real). Many existing industrial simulation tools provide libraries for various industrial devices, which simplify the development efforts significantly, but they generally lack the ability to model the system dynamics and often fail to generate a realistic representation when the system is sensitive to the system. For example, cooperative robots equipped with intelligent algorithms, potentially lead to failure of the tasks if the software is sensitive to the variation of the system dynamics. In this paper, we design a novel simulation platform for industrial manufacturing use cases consisting of a cooperative robot and a modular manufacturing device. With the dynamic model of the robot integrated into a manufacturing digital-twining software, the platform achieves high simulation fidelity by incorporating the effect of the robot dynamics to the control logic of the industrial tasks. Also, the simulation can exchange data with the real robot via an open protocol, which enables the simultaneous test of the real and simulated systems. Two experiments are conducted on the simulation platform to validate its fidelity in terms of the consistent control logic with the real system. Also, a workpiece distribution use case is studied to show how the simulation platform is used to develop a task-planning algorithm for a manufacturing application.
# Sequential Manipulation Planning on Scene Graph
## Keywords:
- Simulation and Animation
## Abstract:
We devise a 3D scene graph representation, contact graph+ (cg+), for efficient sequential task planning. Augmented with predicate-like attributes, this contact graph-based representation abstracts scene layouts with succinct geometric information and valid robot-scene interactions. Goal configurations, naturally specified on contact graphs, can be produced by a genetic algorithm with a stochastic optimization method. A task plan is then initialized by computing the Graph Editing Distance (GED) between the initial contact graphs and the goal configurations, which generates graph edit operations corresponding to possible robot actions. We finalize the task plan by imposing constraints to regulate the temporal feasibility of graph edit operations, ensuring valid task and motion correspondences. In a series of simulations and experiments, robots successfully complete complex sequential object rearrangement tasks that are difficult to specify using conventional planning language like Planning Domain Definition Language (PDDL), demonstrating the high feasibility and potential of robot sequential task planning on contact graph.
# Competency Assessment for Autonomous Agents Using Deep Generative Models
## Keywords:
- Acceptability and Trust
- Reinforcement Learning
- Probabilistic Inference
## Abstract:
For autonomous agents to act as trustworthy partners to human users, they must be able to reliably communicate their competency for the tasks they are asked to perform. Towards this objective, we develop probabilistic world models based on deep generative modelling that allow for the simulation of agent trajectories and accurate calculation of tasking outcome probabilities. By combining the strengths of conditional variational autoencoders with recurrent neural networks, the deep generative world model can probabilistically forecast trajectories over long horizons to task completion. We show how these forecasted trajectories can be used to calculate outcome probability distributions, which enable the precise assessment of agent competency for specific tasks and initial settings.
# A Simulation Framework for Magnetic Continuum Robots
## Keywords:
- Surgical Robotics: Steerable Catheters/Needles
- Simulation and Animation
- Modeling, Control, and Learning for Soft Robots
## Abstract:
Remote magnetic navigation is a technology used to robotically steer magnetic medical instruments, such as magnetic catheters and guidewires, for minimally invasive surgery. The ability to model and simulate the behavior of these magnetic instruments in complex anatomies is important for their clinical use in many ways. Simulation frameworks can improve their design, characterization, and automatic control capabilities, as well as provide training simulators for physicians. In this work we introduce a new simulation framework that accounts for both magnetic actuation and in# teractions forces with meshed collision models. The simulations are validated experimentally in 2d rigid models using a state-of# the-art electromagnetic navigation system. We also demonstrate the use of our framework to build training simulators for two endovascular navigation tasks including the exploration of the aortic arch and the internal carotid artery.
# Social HRI
# HRI Framework for Continual Learning in Face Recognition
## Keywords:
- Social HRI
- Continual Learning
- Learning from Experience
## Abstract:
Recognizing human partners is an essential social skill for building personalized and long-term human-robot interactions. However, robots deployed in complex, real-world environments have to face several challenges, such as managing unstructured interactions with multiple users, limited computational resources, and intrinsic and continuous variability of their sensory evidence. To cope with these challenges, we propose a framework to perform autonomous incremental learning for open-set face recognition suitable for unconstrained HRI scenarios. We validated the proposed framework in a real-world experiment, demonstrating its suitability to let the robot autonomously interact with multiple people while creating a labeled database of their faces across various encounters. Furthermore, we evaluated how an off-the-shelf model performed with data gathered from the HRI setting and proposed a fine-tuned model obtained with a transfer learning technique. Analyses about automatic threshold determination and rehearsal methods for memory sampling were also proposed. Our preliminary results suggest that exploiting the first-hand robot’s experience could be crucial to ensure better models’ performance and, therefore, could be advantageous for the acceptance and effectiveness of social robots in the long run. With this work, we aim to provide insights on continual learning approaches in the HRI field to promote autonomous and personalized solutions meaningful for real-world applications.
# Should a Robot Follow Social Norms? Human-Robot Interaction Design for Social Relations in Mixed Age Group
## Keywords:
- Social HRI
- Design and Human Factors
- Acceptability and Trust
## Abstract:
Social relations within a group are one of the factors that build the social context. Less attention has been paid to social relations within a group for human-robot interaction design. In this study, we designed different types of service behaviors for social relations in a mixed age group and conducted an experiment to investigate the effect of service behavior types (serving the elderly first versus serving the young first versus serving without priority) on a user’s evaluation of a service robot. We only found that service evaluation and appropriateness of the robot were rated less positively under the condition of serving the young first than under other conditions. In addition, we found that the participants evaluated the robot serving the young first as impolite. The effect of the robot’s behaviors on service evaluation and appropriateness was mediated by politeness. The current study provides an initial basis for human-robot interaction design for social norms in group-robot interaction.
# A Personable Robot: A Meta-Analysis of Robot Personality and Human Acceptance
## Keywords:
- Social HRI
- Design and Human Factors
- Emotional Robotics
## Abstract:
For robots to be of use to humans, they first must be accepted. One important variable that may impact this acceptance is a robot’s personality. To date results of studies examining robot's personality have produced mixed results. One method of making sense of these results is meta analysis. Therefore, to examine the potential relationship between robot personality and human acceptance this study conducts a review of the human-robot interaction literature and leverages this review for use in a comprehensive meta-analysis. In doing so it contributes to the literature in three ways. First, this study finds that robot’s personality does appear to influence human’s acceptance of robots. Second, this paper provides an introduction to meta-analysis and detailed methodology which can be applied by other researchers. Third, gaps are identified within the existing literature, and opportunities for future research are presented.
# A Novel Wire-Driven 3D Eyebrow Design for Communication with Humanoid Robot ICub
## Keywords:
- Social HRI
- Emotional Robotics
- Design and Human Factors
## Abstract:
The purpose of this research is to contribute to social communication between humans and robots in scenes that have been considered difficult due to the limited facial expression capabilities of robots. In order to provide more detailed facial expressions, we designed a novel wire-driven 3D eyebrow using a soft material with a bending structure. We then demonstrated the mechanical properties of the eyebrow design and developed a prototype that could be implemented on the humanoid robot iCub to verify its operation. Lastly, we confirmed that the new design enables the production of more slight changes in facial expressions by allowing the eyebrows to change their shape at more delicate angles and continuity than the LED eyebrows on the conventional iCub.
# SonifyIt: Towards Transformative Sound for All Robots
## Keywords:
- Social HRI
- Methods and Tools for Robot System Design
- Software Tools for Robot Programming
## Abstract:
Transformative robot sound yields perceptual, functional, and social benefits in human-robot interactions, but broader research and implementation related to this topic is impeded by the lack of a common sound generation system for robots. Such a system could enable a wide array of situated robot sound studies, smoother collaborations with sound designers than current state of the art methods, and broader adoption of transformative robot sound. Based on other successful open-source projects in the robotics community, we integrated Robot Operating System, a popular robotics middleware, and Pure Data, a visual programming language for multimedia, to enable live sound synthesis and sample playback for robots. This sound generation system synthesized sound in an in-the-wild pilot study with positive qualitative results. Furthermore, an online within-subjects survey study with N = 96 showed that the proposed sound system made the robot seem warmer, happier, and more energetic. This work benefits robotics researchers by providing the current sound system as a validated artifact and demonstrating its potential impact on broader robotics applications. We plan to develop this software into an open-source package: SonifyIt.
# Playful Recommendation: Sales Promotion That Robots Stimulate Pleasant Feelings Instead of Product Explanation
## Keywords:
- Social HRI
- Physical Human-Robot Interaction
## Abstract:
Successful cases of robot sales promotions have been increasing. Users tend to make purchases when robots properly interact with users. Most robot interactions/recommendations are created using specific products and locations within the context. Therefore, developers have to prepare a new recommendation interaction each time with each new product, which creates difficulty in responding smoothly to store's requests.
In this study, we propose Playful Recommendation, which is a situation-independent sales promotion method. This method stimulates pleasant emotions instead of presenting product information to the user, and the proposed method is less product-and location-dependent than other methods. Playful Recommendation was effective in two fieldworks. In both cases, the Playful Recommendation by the robot resulted in higher sales than the normal condition. Furthermore we have shown that the proposed method can be applied to a variety of robots and has the possibility of promoting products even when the recommended products change.
# Android As a Receptionist in a Shopping Mall Using Inverse Reinforcement Learning
## Keywords:
- Social HRI
- Service Robotics
- Imitation Learning
## Abstract:
For human-robot interaction (HRI), it is difficult to hand-craft all the rules for robots owing to diverse situations. Therefore, inverse reinforcement learning (IRL) is a potential solution that helps transfer human knowledge about interactions to robots. However, the feasibility of practically using IRL for HRI remains unknown. Here, we demonstrate a practical HRI application of IRL. An android was trained using IRL and acted as a receptionist to encourage visitors to practice hand hygiene in a shopping mall. We found that android learning through IRL has a competitive ability to a well-trained human operator on the reception task. Furthermore, we found that the android maintained high performance regardless of customer traffic. Our results demonstrate the potential of IRL in advancing the social HRI field. We anticipate that our work will be a starting point for using IRL in future HRI applications.
# SanitizerBot: How Human-In-The-Loop Social Robots Can Playfully Support Humans
## Keywords:
- Social HRI
- Robot Companions
- Human Factors and Human-in-the-Loop
## Abstract:
This paper evaluates a robot that distributed hand-sanitizer over an eight month period (October 2020-June 2021) in public places on the Oregon State University campus. During COVID times, many robots have been deployed in public places as social distancing enforcers, food delivery robots, UV-sanitation robots and more, but few studies have assessed the social situation of these robots. Using the context of robot distributing hand sanitizer, this work explores the benefits that social robots may provide to encouraging healthy human activities, as well as ways in which street-performance inspired approaches and a bit of humor might improve the quality and experience of functional human-robot interactions. After gaining human-in-the-loop deployment experience with a customized interface to enable both planned and improvized responses to human bystanders, we run two sub-studies. In the first, we compare the performance of the robot (moving or still) relative to a traditional hand sanitizer dispenser stick (N=2048, 3 week data collection period). In the second, we evaluate how varied utterance strategies further impact the interaction results (N=185, 2 week data collection period). The robot dramatically outperforms the stick dispenser across all tracked behavioral variables, cuing high levels of positive social engagement. We find the utterance design is more complex socially, and offer insights to future robot designers about how to integrate helpful and playful speech into service robot interactions. Finally, across both sub-studies, we find people in groups are more likely to engage with the robot and each other, as well as sanitize their hands.
# Deep Gesture Generation for Social Robots Using Type-Specific Libraries
## Keywords:
- Gesture, Posture and Facial Expressions
- Human and Humanoid Motion Analysis and Synthesis
- Datasets for Human Motion
## Abstract:
Body language such as conversational gesture is a powerful way to ease communication. Conversational gestures do not only make a speech more lively but also contain semantic meaning that helps to stress important information in the discussion. In the field of robotics, giving conversational agents (humanoid robots or virtual avatars) the ability to properly use gestures is critical, yet remain a task of extraordinary difficulty. This is because given only a text as input, there are many possibilities and ambiguities to generate an appropriate gesture. Different to previous works we propose a new method that explicitly takes into account the gesture types to reduce these ambiguities and generate human-like conversational gestures. Key to our proposed system is a new gesture database built on the TED dataset that allows us to map a word to one of three types of gestures: "Imagistic" gestures, which express the content of the speech, "Beat" gestures, which emphasize words, and "No gestures." We propose a system that first maps the words in the input text to their corresponding gesture type, generate type-specific gestures and combine the generated gestures into one final smooth gesture. In our comparative experiments, the effectiveness of the proposed method was confirmed in user studies for both avatar and humanoid robot.
# Humanoid Robot Systems
# Experimental Demonstration of a General Balancing Controller on an Untethered Planar Inverted Double Pendulum
## Keywords:
- Body Balancing
- Underactuated Robots
- Legged Robots
## Abstract:
This paper demonstrates the practical performance of a new theory of balance control that has been shown in simulation to out-perform earlier balance control theories in the sense of allowing the robot to make larger and faster movements while still maintaining its balance. The case studied here is that of a general planar double inverted pendulum, which resembles a legged robot's behaviour when the polygon of support shrinks to a line. The results show the speed and accuracy of the controller, as well as its robustness to external disturbances and slipping during fast movements.
# Robust Humanoid Walking System Considering Recognized Terrain and Robots' Balance
## Keywords:
- Humanoid and Bipedal Locomotion
- Humanoid Robot Systems
- Recognition
## Abstract:
When robots walk on uneven terrain, trajectory planning should take into account both the whole-body dynamics and the ground geometry simultaneously. In uneven terrain environments, there are only a limited number of places where the robot is able to make stable contact with the ground without its feet wobbling or slipping because of the intricate round geometry. In such environments, the optional landing position and time to maintain the robot's balance and stable foot contact are not obvious and computationally expensive. In this study, we propose a robust walking system that integrates environment recognition using steppable regions and walking control for a humanoid robot to walk on uneven terrain. In this paper, a steppable region is defined as a two-dimensional convex hull that represents a region where a robot is capable of landing. We propose a method to compute the steppable region quickly by 2.5D projection of the environment points and spatial filtering. In this system, the walking controller integrates the steppable region with the Capture Region to modify the landing position from a two-dimensional geometric calculation. In addition, to cope with the environment recognition error, we have introduced a trajectory generation that allows the feet to penetrate the ground and hybrid control of position and torque. We verified the effectiveness of the proposed system through experiments in which a life-size humanoid robot walked on uneven terrain and recovered when pushed.
# Human-Humanoid Robot Cooperative Load Transportation: Model-Based Control Approach
## Keywords:
- Humanoid Robot Systems
- Humanoid and Bipedal Locomotion
## Abstract:
In order to properly integrate humanoid robots in real-life situations, they must be able to collaborate with humans in completing tasks. One of these tasks is the cooperative transportation of a heavy object, which has been widely studied in the humanoids literature. However, the proposed methods rely heavily on six-axis force/torque (F/T) sensors at the wrists, which medium-sized or even some full-sized humanoid robots do not have. This paper proposes an observer to overcome the lack of F/T sensors. The observer is then coupled with a simplified dynamic model of the transportation task allowing the humanoid robot to carry out the task in a stable way. The method is extensively tested in simulation using a humanoid robot that does not have F/T sensors, a NAO robot, to demonstrate its performance. These tests pointed out that the proposed method successfully estimated the interaction forces while generating stable walking patterns.
# Hands-Free Telelocomotion of a Wheeled Humanoid
## Keywords:
- Humanoid Robot Systems
- Telerobotics and Teleoperation
- Wheeled Robots
## Abstract:
Robotic systems capable of Dynamic Mobile Manipulation (DMM) tasks combine dynamic manipulation and locomotion and could facilitate dangerous or physically demanding labor. For instance, firefighter humanoid robots could leverage their body by leaning against collapsed building rubble to push it aside. Here we introduce a teleoperation system that targets the realization of these tasks using human's whole-body motor skills. We describe a new wheeled humanoid platform, SATYRR, and a novel hands-free teleoperation architecture using a whole-body Human Machine Interface (HMI). This system enables telelocomotion of the humanoid robot using the operator's body motion, freeing their arms for manipulation tasks. In this study we evaluate the efficacy of the proposed system on hardware, and explore the control of SATYRR using two teleoperation mappings that map the operators body pitch and yaw to the robot’s velocity or acceleration. Through experiments and user feedback we showcase our preliminary findings of the pilot-system response. Results suggest that the HMI is capable of effectively telelocomoting SATYRR, that pilot preferences should dictate the appropriate motion mapping and gains, and finally that the pilot can better learn to control the system over time. This study represents a fundamental step towards the realization of combined manipulation and locomotion via teleoperation.
# Improved Zero Step Push Recovery with a Unified Reduced Order Model of Standing Balance
## Keywords:
- Body Balancing
- Humanoid Robot Systems
- Legged Robots
## Abstract:
Standing balance for legged robots can be achieved through regulating the center of pressure (ankle strategy), the angular momentum about the center of mass (hip strategy), and the magnitude of ground reaction force (variable height strategy). Prevalent reduced order models used to model legged robots at most only capture two of these strategies, and the contribution of the three available strategies is unclear. We propose a unified reduced order model that includes all three standing balance strategies and compared push recovery simulations of the unified model against existing balancing models using a nonlinear model predictive controller. We also developed a full body controller for a simple one legged balancing robot that tracked control from the reduced order models. For both the reduced order model and robot simulations, we found that the unified model could recover successfully from the largest pushes and yielded the smallest center of mass excursions. Between the hip and variable height strategies, the hip had the greatest effect on improving performance. Our results suggest that successful implementation of a unified reduced order model on physical robots would enable a simplified controller that takes advantage of available balancing strategies as needed to recover from larger push disturbances than feasible before.
# Walking Control Framework on Uneven Terrain Using Variable Stiffness Sole
## Keywords:
- Humanoid Robot Systems
- Humanoid and Bipedal Locomotion
- Legged Robots
## Abstract:
Although many walking control frameworks have been developed to enable biped robots to walk stably on uneven terrain, the foot sole of the robot is also important. Inspired by that study, we have developed a Variable Stiffness Sole (VSS), which is able to adapt to the shape of the obstacles on the ground in Compliant Mode and provide robust support in Stiff Mode. Furthermore, we proposed a walking control framework on uneven terrain for a biped robot equipped with the developed VSS. The proposed walking control framework comprises a posture balance controller to stabilize the zero moment point from disturbances applied to the robot, an ankle torque/foot force controller for walking on uneven terrain, and a VSS controller to change the mode of the VSS. Finally, the proposed framework was verified through walking experiments of RoK-3 equipped with the VSS module on a single obstacle and uneven terrain with various obstacles.
# Tello Leg: The Study of Design Principles and Metrics for Dynamic Humanoid Robots
## Keywords:
- Humanoid Robot Systems
- Actuation and Joint Mechanisms
- Legged Robots
## Abstract:
To be useful tools in real scenarios, humanoid robots must realize tasks dynamically. This means that they must be capable of applying substantial forces, rapidly swinging their limbs, and also mitigating impacts that may occur during the motion. Towards creating capable humanoids, this letter presents the leg of the robot TELLO and demonstrates how it embodies two new fundamental design concepts for dynamic legged robots. The limbs follows the principles of: (i) Cooperative Actuation (CA), by combining motors in differential configurations to increase the force capability of the limb. We demonstrate that the CA configuration requires half the motor torque to perform a jump in comparison to conventional serial design configurations. And (ii) proximal actuation, by placing heavy motors near the body to reduce the inertia of the limb. To quantify the effect of motor placement on the robot's dynamics, we introduce a novel metric entitle Centroidal Inertia Isotropy (CII). We show that the design of state-of-the-art dynamic legged robots empirically increase the CII to improve agility and facilitate model-based control. We hope this metric will enable a quantifiable way to design these machines in the future.
# Watch Me Calibrate My Force-Sensing Shoes!
## Keywords:
- Humanoid Robot Systems
- Force and Tactile Sensing
- Whole-Body Motion Planning and Control
## Abstract:
This letter presents a novel method for smallersized humanoid robots to self-calibrate their foot force sensors. This method consists of two steps: 1. The robot is commanded to move along several planned whole-body trajectories. 2. A nonlinear least-squares technique is implemented to determine sensor parameters by minimizing the error between the measured and modeled center of pressure (CoP) and ground reaction force (GRF) in the robot’s movement. This is the first proposed autonomous calibration method for foot force sensors in humanoid robots. Additionally, a manual calibration method is developed to improve the CoP measurement accuracy, which establishes the ground truth for evaluating the self-calibration approach. The manual calibration and the self-calibration are implemented on our previously presented force-sensing shoes. The results show that the self-calibration method, without any manual intervention, can accurately estimate CoP and GRF.
# RGB-D Perception
# Unsupervised Confidence for LiDAR Depth Maps and Applications
## Keywords:
- RGB-D Perception
- Computer Vision for Transportation
- Computer Vision for Automation
## Abstract:
Depth perception is pivotal in many fields, such as robotics and autonomous driving, to name a few. Consequently, depth sensors such as LiDARs rapidly spread in many applications. The 3D point clouds generated by these sensors must often be coupled with an RGB camera to understand the framed scene semantically. Usually, the former is projected over the camera image plane, leading to a sparse depth map. Unfortunately, this process, coupled with the intrinsic issues affecting all the depth sensors, yields noise and gross outliers in the final output. Purposely, in this paper, we propose an effective unsupervised framework aimed at explicitly addressing this issue by learning to estimate the confidence of the LiDAR sparse depth map and thus allowing for filtering out the outliers. Experimental results on the KITTI dataset highlight that our framework excels for this purpose. Moreover, we demonstrate how this achievement can improve a wide range of tasks.
# Multi-Scaled and Densely Connected Locally Convolutional Layers for Depth Completion
## Keywords:
- RGB-D Perception
- Deep Learning for Visual Perception
- Sensor Fusion
## Abstract:
The depth completion task aims to predict a dense depth map from a sparse LiDAR point cloud and an RGB image. This task is critical because an accurate depth map can be used as prior information to solve many computer vision tasks, such as downstream tasks in autonomous vehicles and robot vision. Previous deep learning methods which focus on the local affinity have achieved impressive results. However, an architecture that is directly designed to extract local affinity has not been proposed yet. In this paper, we propose multi-scaled and densely connected locally convolutional layers to learn the affinity of the neighborhood. We set a different grid factor for each step of this module, and each step consists of several convolutional layers applied only to the local area assigned from the grid factor. In addition, each step is densely connected, sequentially, to take advantage of the multi-scale receptive fields. The proposed module effectively learns the neighborhood's affinity in a local area with multiple scales, while keeping the network size small. As a result, our architecture achieves state-of-the-art performance compared to published works on the KITTI depth completion benchmark. On the NYU Depth V2 completion benchmark our method achieves performance comparable to state-of-the-art approaches.
# From Local to Holistic: Self-Supervised Single Image 3D Face Reconstruction Via Multi-Level Constraints
## Keywords:
- RGB-D Perception
## Abstract:
Single image 3D face reconstruction with accurate geometric details is a critical and challenging task due to the similar appearance on the face surface and fine details in organs. In this work, we introduce a self-supervised 3D face reconstruction approach from a single image that can recover detailed textures under different camera settings. The proposed network learns high-quality disparity maps from stereo face images during the training stage, while just a single face image is required to generate the 3D model in real applications. To recover fine details of each organ and facial surface, the framework introduces facial landmark spatial consistency to constrain the face recovering learning process in local point level and segmentation scheme on facial organs to constrain the correspondences at the organ level. The face shape and textures will further be refined by establishing holistic constraints based on the varying light illumination and shading information. The proposed learning framework can recover more accurate 3D facial details both quantitatively and qualitatively compared with state-of-the-art 3DMM and geometry-based reconstruction algorithms based on a single image.
# Learning Feature Decomposition for Domain Adaptive Monocular Depth Estimation
## Keywords:
- RGB-D Perception
- Visual Learning
- Deep Learning Methods
## Abstract:
Monocular depth estimation (MDE) has attracted intense study due to its low cost and critical functions for robotic tasks such as localization, mapping and obstacle detection. Supervised approaches have led to great success with the advance of deep learning, but they rely on large quantities of ground-truth depth annotations that are expensive to acquire. Unsupervised domain adaptation (UDA) transfers knowledge from labeled source data to unlabeled target data, so as to relax the constraint of supervised learning. However, existing UDA approaches may not completely align the domain gap across different datasets because of the domain shift problem. We believe better domain alignment can be achieved via well-designed feature decomposition. In this paper, we propose a novel UDA method for MDE, referred to as Learning Feature Decomposition for Adaptation (LFDA), which learns to decompose the feature space into content and style components. LFDA only attempts to align the content component since it has a smaller domain gap. Meanwhile, it excludes the style component which is specific to the source domain from training the primary task. Furthermore, LFDA uses separate feature distribution estimations to further bridge the domain gap. Extensive experiments on three domain adaptative MDE scenarios show that the proposed method achieves superior accuracy and lower computational cost compared to the state-of-the-art approaches.
# Inferring Articulated Rigid Body Dynamics from RGBD Video
## Keywords:
- RGB-D Perception
- Simulation and Animation
- Representation Learning
## Abstract:
Being able to reproduce physical phenomena ranging from light interaction to contact mechanics, simulators are becoming increasingly useful in more and more application domains where real-world interaction or labeled data are difficult to obtain. Despite recent progress, significant human effort is needed to configure simulators to accurately reproduce real-world behavior. We introduce a pipeline that combines inverse rendering with differentiable simulation to create digital twins of real-world articulated mechanisms from depth or RGB videos. Our approach automatically discovers joint types and estimates their kinematic parameters, while the dynamic properties of the overall mechanism are tuned to attain physically accurate simulations. Control policies optimized in our derived simulation transfer successfully back to the original system, as we demonstrate on a simulated system. Further, our approach accurately reconstructs the kinematic tree of an articulated mechanism being manipulated by a robot, as well as highly nonlinear dynamics of a real-world coupled pendulum mechanism.
# Multi-View Guided Multi-View Stereo
## Keywords:
- RGB-D Perception
- Sensor Fusion
- Computer Vision for Automation
## Abstract:
This paper introduces a novel deep framework for dense 3D reconstruction from multiple image frames, leveraging a sparse set of depth measurements gathered jointly with image acquisition. Given a deep multi-view stereo network, our framework uses sparse depth hints to guide the neural network by modulating the plane-sweep cost volume built during the forward step, enabling us to infer constantly much more accurate depth maps. Moreover, since multiple viewpoints can provide additional depth measurements, we propose a multi-view guidance strategy that increases the density of the sparse points used to guide the network, thus leading to even more accurate results. We evaluate our Multi-View Guided framework within a variety of state-of-the-art deep multi-view stereo networks, demonstrating its effectiveness at improving the results achieved by each of them on BlendedMVG and DTU datasets.
# Semantic Scene Completion through Multi-Level Feature Fusion
## Keywords:
- RGB-D Perception
- Semantic Scene Understanding
- Deep Learning for Visual Perception
## Abstract:
Abstract— Partial observation of indoor scenes (single-viewed RGB-D) carries insufficient spatial information for complex tasks such as autonomous navigation and virtual reality, thus many learning-based methods are proposed to realize semantic scene completion (SSC) from single-viewed input. However, most of them only extract scene-level features of input to generate output, which might lose details. In this paper, a new method that fully utilizes both instance-level and scene-level features is proposed. Firstly, an object detection module is pre-trained to localize indoor objects. Secondly, coarse completion result is obtained from scene-level feature using an encoder-decoder structure. Finally, based on the pre-trained bounding boxes, coarse completion result is refined using a geometric refinement module. Our network’s performance is evaluated on both real and synthetic datasets. The results demonstrate that our network is able to reconstruct indoor scenes with more geometric details, get clearer boundaries between instances and outperform most existing SSC methods both intuitively and quantitatively.
# RGB-D Inertial Odometry for a Resource-Restricted Robot in Dynamic Environments
## Keywords:
- Visual-Inertial SLAM
- RGB-D Perception
- AI-Based Methods
## Abstract:
Current simultaneous localization and mapping (SLAM) algorithms perform well in static environments but easily fail in dynamic environments. Recent works introduce deep learning-based semantic information to SLAM systems to reduce the influence of dynamic objects. However, it is still challenging to apply a robust localization in dynamic environments for resource-restricted robots. This paper proposes a real-time RGB-D inertial odometry system for resource-restricted robots in dynamic environments named Dynamic-VINS. Three main threads run in parallel: object detection, feature tracking, and state optimization. The proposed Dynamic-VINS combines object detection and depth information for dynamic feature recognition and achieves performance comparable to semantic segmentation. Dynamic-VINS adopts grid-based feature detection and proposes a fast and efficient method to extract high-quality FAST feature points. IMU is applied to predict motion for feature tracking and moving consistency check. The proposed method is evaluated on both public datasets and real-world applications and shows competitive localization accuracy and robustness in dynamic environments. Yet, to the best of our knowledge, it is the best-performance real-time RGB-D inertial odometry for resource-restricted platforms in dynamic environments for now. The proposed system is open source at: url{https://github.com/HITSZ-NRSL/Dynamic-VINS.git}
# SDFEst: Categorical Pose and Shape Estimation of Objects from RGB-D Using Signed Distance Fields
## Keywords:
- RGB-D Perception
- Deep Learning for Visual Perception
- Semantic Scene Understanding
## Abstract:
Rich geometric understanding of the world is an important component of many robotic applications such as planning and manipulation. In this paper, we present a modular pipeline for pose and shape estimation of objects from RGB-D images given their category. The core of our method is a generative shape model, which we integrate with a novel initialization network and a differentiable renderer to enable 6D pose and shape estimation from a single or multiple views. We investigate the use of discretized signed distance fields as an efficient shape representation for fast analysis-by-synthesis optimization. Our modular framework enables multi-view optimization and extensibility. We demonstrate the benefits of our approach over state-of-the-art methods in several experiments on both synthetic and real data. We open-source our approach at https://github.com/roym899/sdfest.
# Marine Robotics 2
# Evaluating the Benefit of Using Multiple Low-Cost Forward-Looking Sonar Beams for Collision Avoidance in Small AUVs
## Keywords:
- Marine Robotics
- Collision Avoidance
- Reactive and Sensor-Based Planning
## Abstract:
We seek to rigorously evaluate the benefit of using a few beams rather than a single beam for a low-cost obstacle avoidance sonar for small AUVs. For a small low-cost AUV, the complexity, cost, and volume required for a multi-beam forward looking sonar are prohibitive. In contrast, a single-beam system is relatively easy to integrate into a small AUV, but does not provide the performance of a multi-beam solution. To better understand this trade-off, we seek to rigorously quantify the improvement with respect to obstacle avoidance performance of adding just a few beams to a single-beam forward looking sonar relative to the performance of the single-beam system. Our work fundamentally supports the goal of using small low-cost AUV systems in cluttered and unstructured environments. Specifically, we investigate the benefit of incorporating a port and starboard beam to a single-beam sonar system for collision avoidance. A methodology for collision avoidance is developed to obtain a fair comparison between a single-beam and multi-beam system, explicitly incorporating the geometry of the beam patterns from forward-looking sonars with large beam angles, and simulated using a high-fidelity representation of acoustic signal propagation.
# Analysis of Hybrid Cable-Thruster Actuated ROV in Heavy Lifting Interventions
## Keywords:
- Marine Robotics
- Robotics in Hazardous Fields
- Control Architectures and Programming
## Abstract:
Many operations performed by work class Remotely Operated Vehicles (ROVs) require the manipulation of heavy loads. An example is the manipulation and grouting of armour stones. A way to increase the working capabilities of the ROV is to introduce cables among the set of actuators. The cable lengths and tensions are controlled by winches placed on the vehicle. Being similar to a cable-driven parallel robot (CDPR), the resultant system inherits some advantages such as the possibility to generate large forces over a large workspace and the possibility to use CDPR techniques to estimate the pose of the ROV. This paper proposes a complete control architecture for the Hybrid Cable-Thruster actuated ROV (HCT-ROV) and analyzes, in computer simulations, the performances of such a system while it performs real world operations, such as heavy lifting and hovering in presence of water current.
# Improving Marine Radar Odometry by Modeling Radar Resolution and Exploiting Additional Temporal Information
## Keywords:
- Marine Robotics
- SLAM
- Kinematics
## Abstract:
Radar odometry may provide valuable input for surface vessels in several marine applications. The vulnerability of global positioning satellite systems to jamming and spoofing motivates the search for alternatives. In this work, we investigate the feasibility of W-band frequency modulated continuous wave radars in marine settings for odometry. A method to model radar resolution is presented and is further extend to include multiple radar frames. Numerical implementation relies on concepts from Lie theory. The proposed methods were evaluated on datasets collected from a ferry in a harbour area, where the average relative translation error was reduced to 3.07% compared to 14.2% of a baseline method.
# UWRange: An Open ROS Framework for Simulating Acoustic Ranging and Localization for Underwater Robots under Realistic Conditions
## Keywords:
- Marine Robotics
- Localization
- Software Tools for Benchmarking and Reproducibility
## Abstract:
Considering realistic characteristics of acoustic localization methods is crucial for roboticists when developing guidance and control algorithms for small and agile underwater robots. Current simulators either rely purely on geometric distancing, i.e. do not consider dynamic effects such as robot motion during acoustic signal propagation, or they are too complex for usage by non-communication experts and, thus, vulnerable to misconfiguration. We propose an open ROS-based framework that extends existing robot simulators (e. g. Gazebo) by simulating the effects of realistic acoustic ranging for underwater robot localization. Thus, our simulator enables realistic real-time analysis and evaluation of guidance, navigation, and control algorithms in software in-the-loop systems. For this purpose, we incorporate and encapsulate the non-trivial characteristics of acoustic communication and ranging such as robot motion during signal propagation, packet reception failure, and modem timings. This ensures the applicability of the tool by roboticists who are typically non-experts in acoustic communication and guarantees accurate and realistic simulation results. We demonstrate the functionality and performance of our framework and validate it on real-world experimental data on the example of a two-way ranging method. Our open-source release includes well-defined interfaces and parameters as well as a tutorial. This targets other roboticists who can either use our framework directly or easily adapt it to their individual setup, e.g., by adding further acoustic-ranging protocols.
# HoloOcean: Realistic Sonar Simulation
## Keywords:
- Marine Robotics
- Simulation and Animation
- Field Robots
## Abstract:
Sonar sensors play an integral part in underwater robotic perception by providing imagery at long distances where standard optical cameras cannot. They have proven to be an important part in various robotic algorithms including localization, mapping, and structure from motion. Unfortunately, generating realistic sonar imagery for algorithm development is difficult due to the high cost of field trials and lack of simulation methods. To remove these obstacles, we present various upgrades to the sonar simulation method in HoloOcean, our open-source marine robotics simulator. In particular, we improve the noise modeling using a novel cluster-based multi-path ray-tracing algorithm, various probabilistic noise models, and material dependence. We also develop and integrate simulated models for side-scan, single-beam, and multibeam profiling sonars.
# DRACo-SLAM: Distributed Robust Acoustic Communication-Efficient SLAM for Imaging Sonar Equipped Underwater Robot Teams
## Keywords:
- Marine Robotics
- Multi-Robot SLAM
- Distributed Robot Systems
## Abstract:
An essential task for a multi-robot system is generating a common understanding of the environment and relative poses between robots. Cooperative tasks can be executed only when a vehicle has knowledge of its own state and the states of the team members. However, this has primarily been achieved with direct rendezvous between underwater robots, via inter-robot ranging. We propose a novel distributed multi-robot simultaneous localization and mapping (SLAM) framework for underwater robots using imaging sonar-based perception. By passing only scene descriptors between robots, we do not need to pass raw sensor data unless there is a likelihood of inter robot loop closure. We utilize pairwise consistent measurement set maximization (PCM), making our system robust to erroneous loop closures. The functionality of our system is demonstrated using two real-world datasets, one with three robots and another with two robots. We show that our system effectively estimates the trajectories of the multi-robot system and keeps the bandwidth requirements of inter-robot communication low. To our knowledge, this paper describes the first instance of multi-robot SLAM using real imaging sonar data (which we implement offline, using simulated communication).
# Confined Water Body Coverage under Resource Constraints
## Keywords:
- Marine Robotics
- Field Robots
- Motion and Path Planning
## Abstract:
This paper presents a novel algorithm for monitoring marine environments utilizing a resource-constrained robot. Collecting water quality data from large bodies of water is paramount for monitoring the ecosystem’s health, particularly for predicting harmful cyanobacteria blooms. The large spatial dimensions of such bodies of water and the slow varying of water quality parameters make exhaustive, complete coverage impractical and unnecessary. This work explores a new strategy for efficiently measuring water quality quantities with an autonomous surface vehicle (ASV). The method utilizes the medial axis of the water body producing a guideline for the ASV trajectory that visits representative areas of the environment. The proposed method ensures data collection in the narrower parts of the lake, where researchers have historically observed harmful blooms while also visiting open water areas. It also presents an analysis of the Spatio-temporal sensitivity of the target sensor. A comparison with the traditional lawnmower algorithm demonstrates that the conventional BCD-based complete coverage method cannot sample the small coves of a lake. As such, we show that the proposed method captures more diverse regions of the area with a partial coverage technique. Offline analysis of several lakes and reservoirs and results from field deployments at Lake Murray, SC, USA, demonstrate the proposed method’s effectiveness.
# Self-Management of ROV Umbilical Using Sliding Buoys and Stop
## Keywords:
- Marine Robotics
## Abstract:
The umbilical of Remote Operated Vehicle (ROV) has two main problems: it is subject to entanglement with obstacles or itself, and its shape is difficult to predict for the navigation. To address these issues, this article proposes a passive self-management of an ROV's umbilical, suitable for underwater and seafloor exploration. By adding two buoys moving freely on the umbilical, the described method avoids self-entanglement of the cable by stretching it, and gives it a predictable shape. A fast time computational model of the cable is proposed to provide feedback to the operator. The buoys move on their own to keep the cable taut without a motorized system, making this method easy to adapt to existing ROVs with few constraints on their navigation. Simulations and experimentation in pool show the effectiveness of the method.
# AUV-Assisted Diver Navigation
## Keywords:
- Marine Robotics
- Localization
## Abstract:
This paper presents the development of a new technique that enables precise navigation for a scuba diver using an autonomous underwater vehicle (AUV) as a positioning aid. We develop and evaluate the state estimation algorithms and communication architecture required for a diver navigation method based on subsurface human-AUV teaming with no requirement for ocean current data or exact diver speeds. By depending on acoustic communication and commercial AUV navigation capabilities, our method has increased accessibility, applicability, and robustness over other techniques. We utilize the Woods Hole Oceanographic Institution Micromodem 2 to enable range-only single-beacon navigation between two kayaks serving as proxies for the diver and REMUS 100 AUV. Range and odometry measurements are fused in a factor graph architecture using incremental smoothing and mapping 2 (iSAM2) with appropriate motion and measurement models to provide real-time diver position estimates given unknown ocean currents. Field experiments demonstrate an average online endpoint error of 4.53 meters after 400-meter transits.
# Soft Robot Applications
# Design of a Soft Wearable Passive Fitness Device for Upper Limb Resistance Exercise
## Keywords:
- Soft Robot Applications
- Wearable Robotics
- Human Performance Augmentation
## Abstract:
An increase in health awareness has fueled the development of fitness equipment or devices nowadays. Most conventional fitness devices have had some issues in space limitation and the high cost of equipment. With the advance in wearable robotics, we proposed a soft passive fitness wearable device for upper limb resistance exercises such as chest press, frontal raise, and chest fly. Users can customize the exercise intensity by adjusting the length of the elastic bands embedded in the wearable device. Moreover, the exer-tainment (Exercise-entertainment) user display interface was designed to motivate the user. Movements of users were estimated using inertial measurement units (IMUs), and haptic feedback was provided through the vibro-stimulation. Furthermore, the effectiveness of the proposed device was evaluated with the Borg scales representing the rating of perceived exertion (RPE) and measuring the surface electromyography (sEMG) of the three muscles located one on the shoulder and two on the chest. Both the Borg 6-20 and CR 10 scales were increased, and the normalized sEMG activities of the upper limb muscles with the activated device had more than double in magnitude compared to that with a bare condition; therefore, the proposed device has a potential effectiveness as for resistance exercise. Overall, this research devotes preliminary evidence on the benefits of the device in promoting the user to work out and contributing to the exercise effects.
# Multi-DoF Soft Robotic Actuators Based on Spring Reinforce and Particle Jamming
## Keywords:
- Soft Robot Applications
- Soft Robot Materials and Design
## Abstract:
Soft robots have a wide rang of applications due to their compliance, flexibility and low fabrication cost. Compare to rigid robots, soft robots are more safe for human. In this work,we design various multi-DoF actuators with spring reinforce and particle jamming, and two fabrication methods are proposed to make them. Each type of actuator is tested to evaluate the mechanical properties by experiments. Experimental results show that both spring and particle jamming have effect on the stiffness. Besides, Spring reinforced actuator(SRA) increase the maximum allowable inflation pressure, output bending force and give a good linear relationship of bending. We also integrate spring and particles to fabricate a hybrid actuator whose behaviors are explored by experiments. Finally, we create a snake-like robotic manipulator assembled with two actuators and show its bending motion. Results show that the manipulator is able to achieve several bending shapes steadily and large range of motion.
# Automated Fruit Quality Testing Using an Electrical Impedance Tomography-Enabled Soft Robotic Gripper
## Keywords:
- Soft Robot Applications
- Agricultural Automation
- AI-Enabled Robotics
## Abstract:
Soft robotic grippers are becoming increasingly popular for agricultural and logistics automation. Their passive conformability enables them to adapt to varying product shapes and sizes, providing stable large-area grasps. This work presents a novel methodology for combining soft robotic grippers with electrical impedance tomography-based sensors to infer intrinsic properties of grasped fruits. We use a Fin Ray soft robotic finger with embedded microspines to grab and obtain rich multi-direction electrical properties of the object. Learning-based techniques are then used to infer the desired fruit properties. The framework is extensively tested and validated on multiple fruit groups. Our results show that ripeness parameters and even weight of the grasped fruit can be estimated with reasonable accuracy autonomously using the proposed system.
# Jammkle: Fibre Jamming 3D Printed Multi-Material Tendons and Their Application in a Robotic Ankle
## Keywords:
- Soft Robot Materials and Design
- Flexible Robotics
## Abstract:
Fibre jamming is a new and understudied soft robotic mechanism that has previously found success in stiffness-tunable arms and fingers. However, to date researchers have not fully taken advantage of the freedom offered by contemporary fabrication techniques including multi-material 3D printing in the creation of fibre jamming structures. In this research, we present a novel, modular, multi-material, 3D printed, fibre jamming tendon unit for use in a stiffness-tunable compliant robotic ankle, or emph{Jammkle}. Its multimaterial printed design offers unparalleled design freedom, enabling application specific tendon design. We develop analytical and finite element models of the tendon unit, showing good agreement with experimental data and numerically explore the design space. Finally, we demonstrate a practical application by integrating multiple tendon units into a robotic ankle and perform extensive testing and characterisation. We show that the Jammkle outperforms comparative leg structures in terms of compliance, damping, and slip prevention.
# Grasping State Analysis of Soft Manipulator Based on Flexible Tactile Sensor Array
## Keywords:
- Soft Robot Applications
- Force and Tactile Sensing
- Soft Robot Materials and Design
## Abstract:
Although the grasping state analysis is vital in the study of manipulators, the grasping state analysis of soft manipulators as an independent research topic is not much so far. This paper proposes a novel pneumatic soft manipulator with a flexible tactile sensor array (SM-FTSA). The flexible tactile sensor array comprises piezoresistive materials with a porous structure. An equal potential approach is adopted to realize the collection of tactile signals of the SM-FTSA. Inspired by the grasping analysis of rigid manipulators, we propose 4 grasping states for the SM-FTSA, including inflating, shaking, stable, and slipping. Based on the experimental data, we conduct grasping experiments on 12 objects with SMFTSA, and we propose 10 features that reflect the grasping state. Several machine learning methods are utilized to classify the grasping state. Among them, the Random Forest method presents the best performance, and the average classification accuracy reaches 99%.
# RoboHeart: A Bi-Directional Zipping Actuator
## Keywords:
- Soft Robot Applications
- Soft Robot Materials and Design
- Soft Sensors and Actuators
## Abstract:
Widespread adoption of soft robotic technologies is held back by the limitations of existing soft robotic actuators. One cause of the limited performance of soft actuators is their uni-polar stroke, which means only part of the work-cycle is powered. In this work, we introduce RoboHeart, a bi-directional compliant smart actuator. RoboHeart consists of two spring-steel strips covered with PVC insulation, pre-bent into a heart shape and is driven by dielectrophoretic zipping. Here, we perform isotonic and isometric characterisation of RoboHeart performance, demonstrating work output of 17 mJ (expansion) and 18 mJ (contraction) and power of 1.5 mW (expansion) and 2 mW (contraction). We then confirm the practical application of RoboHeart by demonstrating a 10-RoboHeart ring configuration capable of gripping a range of objects as they are lifted. We also demonstrate bidirectional control of actuation using three separate control channels. We believe that RoboHeart represents a step towards high-performance soft actuators and technologies.
# Physics-Informed Recurrent Neural Networks for Soft Pneumatic Actuators
## Keywords:
- Soft Robot Applications
- Soft Sensors and Actuators
- Modeling, Control, and Learning for Soft Robots
## Abstract:
Replacing sensors with indirect sensing techniques contributes to retaining the flexibility of soft robots. By combining physical models with recurrent neural networks (which we term a physics informed recurrent neural network [PIRNN] approach), we implemented a hybrid prediction scheme on two typical soft pneumatic actuators: a McKibben pneumatic artificial muscle and a pneumatic-based soft finger made of silicone. The results showed that this hybrid scheme robustly enhanced the prediction accuracy to a great extent, even when combined with an inaccurate physical model. We also present the broad applicability of the PIRNN approach, showing its effectiveness for diverse types of RNNs and soft robotics platforms. Our work fills the gaps in the literature by applying a physics-informed machine-learning approach to practical engineering problems in soft robotics.
# Design and Experimental Characterization of a Push-Pull Flexible Rod-Driven Soft-Bodied Robot
## Keywords:
- Soft Robot Applications
- Soft Robot Materials and Design
## Abstract:
Soft robots with a well-balanced performance in terms of dexterity, accuracy, and payload have a great potential for application. Balancing safe human-robot interaction with operation performance enables the use of soft robot in biomedical fields, among others, such as surgery, rehabilitation and elder care. In this letter, we present a rod-driven soft robot (RDSR) where the flexible rods embedded in the silicone-based body provide a double push-pull actuation, to satisfy the needs of balanced performance. The RDSR can realize multi DOFs movement with elongation, contraction and bending. For trajectory tracking, Gaussian process model enables RDSR to achieve more accurate motion control with an RMSE within 2.8mm compared to the constant curvature model with that within 10.8mm. Comparative experiments demonstrate that the workspace, vertical and lateral stiffness of the RDSR are up to 5, 2.6 and 5.2 times that of an analogous tendon-driven soft robot (TDSR), respectively. Additionally, the RDSR possesses the ability, that the TDSR does not have, to actively apply pushing perpendicular to an inclined plane. Based on numerical Jacobian matrix, the maximum force along target direction is greater than 4N for a 30° plane. Furthermore, pick-and-place tests validate that our soft robot, with large workspace, precise and steady motion, is capable of conducting object manipulation tasks.
# Localization 6
# Centralized-Equivalent Pairwise Estimation with Asynchronous Communication Constraints for Two Robots
## Keywords:
- Localization
- Sensor Fusion
- Distributed Robot Systems
## Abstract:
Collaboratively estimating the state of two robots under communication constraints is challenging regarding computational complexity and statistical optimality. Previous work only achieves practical solutions by either disregarding parts of the measurements or imposing a communication overhead, being non-optimal or not entirely distributed, respectively.
In this work, we present a centralized-equivalent but distributed approach for pairwise state estimation where two agents only communicate when they meet. Our approach utilizes elements from wave scattering theory to efficiently and consistently summarize (pre-compute) past estimator information (i.e., state evolution and uncertainty) between encounters of two agents. This summarized information is then used in a joint correction step taking into account all past information of each agent in a statistically correct way. 
This novel approach enables us to distribute the pre-computations of both state evolution and uncertainties on the agents and reconstruct the centralized-equivalent system estimate with very few computations once the agents meet again while still applying all measurements from both agents on both estimates upon encounter. We compare our approach on a real-world dataset against a state of the art collaborative state estimation approach.
# Cooperative Localization Using Learning-Based Constrained Optimization
## Keywords:
- Localization
- Cooperating Robots
- Sensor Networks
## Abstract:
Loosely coupled multi-agent estimation algorithms such as covariance intersection (CI) for track-to-track fusion, and discorrelated minimum variance (DMV) and practical estimated cross-covariance minimum variance (PECMV) for cooperative localization (CL), which account for inter-agent correlations in an implicit manner, are favored from the less frequent communication aspect. However, they can be computationally too expensive to be online implementable due to the costly optimization process involved. To reduce the computational cost while maintaining the estimation accuracy, in this paper, we report the application of Machine learning (ML) techniques to substitute the optimization processes by learning their optimal solutions to reduce the computational complexity. We focus on the CL problems and propose two data-driven approaches, namely LDMV and LPECMV to generate the solutions of two different constrained optimization procedures contained in implicit CL algorithms. For LDMV, the artificial neural network (NN) technique is used to predict the scalar solution of the problem with a single inequality constraint while in LPECMV the NN works as a matrix predictor to learn the solution of a matrix optimization containing linear matrix inequality (LMI) constraints. We discuss the design of the NNs in detail to respect the constraints. The effectiveness and the generosity of the two methods are demonstrated via CL experiments. And the experimental results show that both our approaches reduce the computational cost significantly without sacrificing the localization accuracy and the estimation consistency.
# InCloud: Incremental Learning for Point Cloud Place Recognition
## Keywords:
- Localization
- Continual Learning
- Recognition
## Abstract:
Abstract— Place recognition is a fundamental component of robotics, and has seen tremendous improvements through the use of deep learning models in recent years. Networks can experience significant drops in performance when deployed in unseen or highly dynamic environments, and require additional training on the collected data. However naively fine-tuning on new training distributions can cause severe degradation of performance on previously visited domains, a phenomenon known as catastrophic forgetting. In this paper we address the problem of incremental learning for point cloud place recogni tion and introduce InCloud, a structure-aware distillation-based approach which preserves the higher-order structure of the network’s embedding space. We introduce several challenging new benchmarks on four popular and large-scale LiDAR datasets (Oxford, MulRan, In-house and KITTI) showing broad improvements in point cloud place recognition performance over a variety of network architectures. To the best of our knowledge, this work is the first to effectively apply incremental learning for point cloud place recognition. Data pre-processing, training and evaluation code for this paper can be found at https://github.com/csiro-robotics/InCloud.
# LNC Assisted Localization and Mapping in Pipe Environment
## Keywords:
- Localization
- Mapping
- Robotics and Automation in Construction
## Abstract:
Regular maintenance of pipelines is an important task to ensure oil transportation and other operation (sewers, nature gas). Precise localization of pipeline damage can greatly improve the efficiency of maintenance work. Since the texture similarity and illumination change of pipe, traditional local descriptors for image matching like SIFT, SURF and ORB are easy to suffer from false correspondences. As to remove the false matches, the local neighborhood constraints (LNC) that contain spatial constructs around feature points are proposed. Good correspondences are essential for the high-accuracy localization and mapping solution given the limited textures and illumination in the pipes. The LNC method is also integrated into the state-ofthe-art visual SLAM system. The proposed LNC image matching method and the SLAM system are evaluated on datasets gathered from the pipe environment. Compared with other state-of-the-art methods, our LNC image matching method achieves similar or better performance in precision, recall and runtime. The SLAM system provides state estimation and map reconstruction of the pipe in real-time, and the localization error is within 1%.
# Unsupervised Appearance Map Abstraction for Indoor Visual Place Recognition with Mobile Robots
## Keywords:
- Localization
- Mapping
- Recognition
## Abstract:
Visual Place Recognition (VPR), the task of identifying the place where an image has been taken from, is at the core of important robotic problems as relocalization, loop-closure detection or topological navigation. Even for indoors, the focus of this work, VPR is challenging for a number of reasons, including real-time performance when dealing with large image databases (~10^4) (probably captured by different robots), or the avoidance of Perceptual Aliasing in environments with repetitive structures and scenes. 
In this paper, we tackle these issues by proposing an off-line mapping technique that abstracts a dense database of georeferenced images without particular order into a Multivariate Gaussian Mixture Model, by creating soft clusters in terms of their similarity in both pose and appearance. This abstract representation is obtained through an Expectation-Maximization algorithm and plays the role of a simplified map. Since querying this map yields a probability of being in a cluster, we exploit this "belief" within a Bayesian filter that regards previous query images and a topological map between clusters to perform more robust VPR.
We evaluate our proposal in two different indoor datasets, demonstrating comparable VPR precision to querying the full database while incurring in shorter query times and handling Perceptual Aliasing for sequential navigation.
# Predicting to Improve: Integrity Measures for Assessing Visual Localization Performance
## Keywords:
- Localization
- Performance Evaluation and Benchmarking
## Abstract:
Visual Place Recognition (VPR) is a key component of many robot localization and mapping system processing pipelines, providing loop closure and coarse topological localization priors for pose refinement stages. When deploying these systems in the real-world, system self-characterization of when it is performing well or poorly can be more important than absolute performance. In this research, we demonstrate a new supervised learning approach to predicting localization integrity on a frame-by-frame basis along a route, using artefacts from the localization technique itself. Our method involves a lightweight post-processing step that is VPR technique-agnostic; it can be calibrated for any given place recognition technique, such that inaccurate localization points along a route can be identified and discarded. Unlike the normal parameter sweeping evaluation of a VPR system, which directly trades precision for recall, when deployed on a baseline VPR system our approach improves the precision without significantly reducing recall, resulting in improved average localization performance. Over twelve combinations of varied datasets and VPR techniques, we demonstrate our approach is able to predict localization errors with an average precision of 74%, resulting in an improvement in mean localization accuracy.
# What Goes Around: Leveraging a Constant-Curvature Motion Constraint in Radar Odometry
## Keywords:
- Localization
- Range Sensing
- Wheeled Robots
## Abstract:
This paper presents a method that leverages vehicle motion constraints to refine data associations in a point-based radar odometry system. By using the strong prior on how a non-holonomic robot is constrained to move smoothly through its environment, we develop the necessary framework to estimate ego-motion from a single landmark association rather than considering all of these correspondences at once. This allows for informed outlier detection of poor matches that are a dominant source of pose estimate error. By refining the subset of matched landmarks, we see an absolute decrease of 2.15% (from 4.68% to 2.53%) in translational error, approximately halving the error in odometry (reducing by 45.94%) than when using the full set of correspondences. This contribution is relevant to other point-based odometry implementations that rely on a range sensor and provides a lightweight and interpretable means of incorporating vehicle dynamics for ego-motion estimation.
# Learning-Enhanced Adaptive Robust GNSS Navigation in Challenging Environments
## Keywords:
- Localization
- Probability and Statistical Methods
- Machine Learning for Robot Control
## Abstract:
Global Navigation Satellite System (GNSS) is the widely used technology when it comes to outdoor positioning. But it has severe limitations with regard to safety-critical applications involving unmanned autonomous systems. Namely, the position# ing performance degrades in harsh propagation environment such as urban canyons. In this paper we propose a new algorithm for GNSS navigation in challenging environments based on robust statistics. M-estimators showed promising results in this context, but are limited by some fixed hyper-parameters. Our main idea is to adapt this parameter, for the Huber cost function, to the current environment in a data-driven manner. Doing so, we also present a simple yet efficient way of learning with satellite data, whose number may vary over time. Focusing the learning problem on a single parameter enables to efficiently learn with a lightweight neural network. The generalization capability and the positioning performance of the proposed method are evaluated in multiple contexts scenarios (open-sky, trees, urban and urban canyon), with two distinct GNSS receivers, and in an airplane ground inspection scenario. The maximum positioning error is reduced by up to 68% with respect to M-estimators.
# Optimization Strategies for Bayesian Source Localization Algorithms (I)
## Keywords:
- Robotics in Hazardous Fields
- Localization
- Reactive and Sensor-Based Planning
## Abstract:
Target search via Bayesian estimation is a commonly studied problem in which the goal is to locate and possibly characterize a lost "target" within a given space using noisy sensors. Example applications include locating gas leaks, radio sources, ships at sea, etc, using appropriate sensors for the specific phenomena. The motivating application for this effort is detecting and locating nearby radioactive material in nuclear facilities. Past work has produced several implementations for addressing this problem, with varying levels of accuracy and sophistication. Here we present both new and previously developed solution methods to the radioactive source localization problem. The solutions have diverse strategies for selecting advantageous positions at which to collect measurements. The objective is to minimize the number of measurements needed to complete the target localization. We empirically compare the effectiveness of various strategies, three of which are novel and prove superior over prior methods of measurement selection. The relative advantages of the novel strategies are discussed as well as their broader applicability to a general class of target search problems where measurement intensity correlates with target proximity.
# Imitation Learning
# Demonstrate Once, Imitate Immediately (DOME): Learning Visual Servoing for One-Shot Imitation Learning
## Keywords:
- Imitation Learning
- Machine Learning for Robot Control
- Computer Vision for Automation
## Abstract:
We present DOME, a novel method for one-shot imitation learning, where a task can be learned from just a single demonstration and then be deployed immediately, without any further data collection or training. DOME does not require prior task or object knowledge, and can perform the task in novel object configurations and with distractors. At its core, DOME uses an image-conditioned object segmentation network followed by a learned visual servoing network, to move the robot's end-effector to the same relative pose to the object as during the demonstration, after which the task can be completed by replaying the demonstration's end-effector velocities. We show that DOME achieves near 100% success rate on 7 real-world everyday tasks, and we perform several studies to thoroughly understand each individual component of DOME. Videos and supplementary material are available at: https://www.robot-learning.uk/dome .
# Using Human Gaze in Few-Shot Imitation Learning for Robot Manipulation
## Keywords:
- Imitation Learning
- Deep Learning in Grasping and Manipulation
- Telerobotics and Teleoperation
## Abstract:
Imitation learning has attracted attention as a method for realizing complex robot control without programmed robot behavior. Meta-imitation learning has been proposed to solve the high cost of data collection and low generalizability to new tasks that imitation learning suffers from. Meta-imitation can learn new tasks involving unknown objects from a small amount of data by learning multiple tasks during training. However, meta-imitation learning, especially using images, is still vulnerable to changes in the background, which occupies a large portion of the input image. This study introduces a human gaze into meta-imitation learning-based robot control. We created a model with model-agnostic meta-learning to predict the gaze position from the image by measuring the gaze with an eye tracker in the head-mounted display. Using images around the predicted gaze position as an input makes the model robust to changes in visual information. We experimentally verified the performance of the proposed method through picking tasks using a simulated robot. The results indicate that our proposed method has a greater ability than the conventional method to learn a new task from only 9 demonstrations even if the object's color or the background pattern changes between the training and test.
# Divide & Conquer Imitation Learning
## Keywords:
- Imitation Learning
- Reinforcement Learning
- Learning from Demonstration
## Abstract:
When cast into the Deep Reinforcement Learning framework, many robotics tasks require solving a long horizon and sparse reward problem, where learning algorithms struggle. In such contexts, Imitation Learning (IL) can be a powerful approach to bootstrap the learning process. However, most IL methods require several expert demonstrations which can be prohibitively difficult to acquire. Only a handful of IL algorithms have shown efficiency in the context of an extreme low expert data regime where a single expert demonstration is available. In this paper, we present a novel algorithm designed to imitate complex robotic tasks from the states of an expert trajectory. Based on a sequential inductive bias, our method divides the complex task into smaller skills. The skills are learned into a goal-conditioned policy that is able to solve each skill individually and chain skills to solve the entire task. We show that our method imitates a non-holonomic navigation task and scales to a complex simulated robotic manipulation task with very high sample efficiency.
# MMFN: Multi-Modal-Fusion-Net for End-To-End Driving
## Keywords:
- Imitation Learning
- Sensor Fusion
## Abstract:
Inspired by the fact that humans use diverse sensory organs to perceive the world, sensors with different modalities are deployed in end-to-end driving to obtain the global context of the 3D scene. In previous works, camera and LiDAR inputs are fused through transformers for better driving performance. These inputs are normally further interpreted as high-level map information to assist navigation tasks. Nevertheless, extracting useful information from the complex map input is challenging, for redundant information may mislead the agent and negatively affect driving performance. We propose a novel approach to efficiently extract features from vectorized High-Definition (HD) maps and utilize them in end-to-end driving tasks. In addition, we design a new expert to enhance the model performance by considering multi-road rules. Experimental results prove that both proposed improvements enable our agent to achieve superior performance compared with other methods.
# Output Feedback Tube MPC-Guided Data Augmentation for Robust, Efficient Sensorimotor Policy Learning
## Keywords:
- Imitation Learning
- Robust/Adaptive Control
- Visual Learning
## Abstract:
Imitation learning (IL) can generate computationally efficient sensorimotor policies from demonstrations provided by computationally expensive model-based sensing and control algorithms. However, commonly employed IL methods are often data-inefficient, requiring the collection of a large number of demonstrations and producing policies with limited robustness to uncertainties. In this work, we combine IL with an output feedback robust tube model predictive controller (RTMPC) to co-generate demonstrations and a data augmentation strategy to efficiently learn neural network-based sensorimotor policies. Thanks to the augmented data, we reduce the computation time and the number of demonstrations needed by IL, while providing robustness to sensing and process uncertainty. We tailor our approach to the task of learning a trajectory tracking visuomotor policy for an aerial robot, leveraging a 3D mesh of the environment as part of the data augmentation process. We numerically demonstrate that our method can learn a robust visuomotor policy from a single demonstration---a two-orders of magnitude improvement in demonstration efficiency compared to existing IL methods.
# Hierarchical Model-Based Imitation Learning for Planning in Autonomous Driving
## Keywords:
- Imitation Learning
- Learning from Demonstration
- Autonomous Vehicle Navigation
## Abstract:
We demonstrate the first large-scale application of model-based generative adversarial imitation learning (MGAIL) to the task of dense urban self-driving. We augment standard MGAIL using a hierarchical model to enable generalization to arbitrary goal routes, and measure performance using a closed-loop evaluation framework with simulated interactive agents. We train policies from expert trajectories collected from real vehicles driving over 100,000 miles in San Francisco, and demonstrate a steerable policy that can navigate robustly even in a zero-shot setting, generalizing to synthetic scenarios with novel goals that never occurred in real-world driving. We also demonstrate the importance of mixing closed-loop MGAIL losses with open-loop behavior cloning losses, and show our best policy approaches the performance of the expert. We evaluate our imitative model in both average and challenging scenarios, and show how it can serve as a useful prior to plan successful trajectories.
# Back to the Manifold: Recovering from Out-Of-Distribution States
## Keywords:
- Imitation Learning
- Learning from Demonstration
- Representation Learning
## Abstract:
Learning from previously collected datasets of expert data offers the promise of acquiring robotic policies without unsafe and costly online explorations. However, a major challenge is a distributional shift between the states in the training dataset and the ones visited by the learned policy at the test time. While prior works mainly studied the distribution shift caused by the policy during the offline training, the problem of recovering from out-of-distribution states at the deployment time is not very well studied yet. We alleviate the distributional shift at the deployment time by introducing a recovery policy that brings the agent back to the training manifold whenever it steps out of the in-distribution states, e.g., due to an external perturbation. The recovery policy relies on an approximation of the training data density and a learned equivariant mapping that maps visual observations into a latent space in which translations correspond to the robot actions. We demonstrate the effectiveness of the proposed method through several manipulation experiments on a real robotic platform. Our results show that the recovery policy enables the agent to complete tasks while the behavioral cloning alone fails because of the distributional shift problem.
# From One Hand to Multiple Hands: Imitation Learning for Dexterous Manipulation from Single-Camera Teleoperation
## Keywords:
- Imitation Learning
- Dexterous Manipulation
- Telerobotics and Teleoperation
## Abstract:
We propose to perform imitation learning for dexterous manipulation with multi-finger robot hand from human demonstrations, and transfer the policy to the real robot hand. We introduce a novel single-camera teleoperation system to collect the 3D demonstrations efficiently with only an iPad and a computer. One key contribution of our system is that we construct a customized robot hand for each user in the simulator, which is a manipulator resembling the operator's hand. It provides an intuitive interface for data collection, leading to large-scale and high quality data. Once the data is collected, the customized robot hand trajectories can be converted to different specified robot hands (models that are manufactured) to generate training demonstrations. With imitation learning using our data, we show large improvement over baselines with multiple complex manipulation tasks. Importantly, we show our learned policy is significantly more robust when transferring to the real robot. More videos can be found in https://yzqin.github.io/dex-teleop-imitation.
# DPMP-Deep Probabilistic Motion Planning: A Use Case in Strawberry Picking Robot
## Keywords:
- Imitation Learning
- Manipulation Planning
- Robotics and Automation in Agriculture and Forestry
## Abstract:
This paper presents a novel probabilistic approach to deep robot learning from demonstrations (LfD). Deep movement primitives (DMPs) are deterministic LfD model that maps visual information directly into a robot trajectory. This paper extends DMPs and presents a deep probabilistic model that maps the visual information into a distribution of effective robot trajectories. The architecture that leads to the highest level of trajectory accuracy is presented and compared with the existing methods. Moreover, this paper introduces a novel training method for learning domain-specific latent features. We show the superiority of the proposed probabilistic approach and novel latent space learning in the real-robot task of strawberry harvesting in the lab. The experimental results demonstrate that latent space learning can significantly improve model prediction performances. The proposed approach allows to sample trajectories from distribution and optimises the robot trajectory to meet a secondary objective, e.g. collision avoidance.
# Field and Marine Robotics
# Polytopic Planar Region Characterization of Rough Terrains for Legged Locomotion
## Keywords:
- RGB-D Perception
- Legged Robots
- Object Detection, Segmentation and Categorization
## Abstract:
This paper studies the problem of constructing polytopic representations for planar regions from depth camera readings. This problem is of great importance for terrain mapping in complicated environment and has great potentials in legged locomotion applications. To address the polytopic planar region characterization problem, we propose a two-stage solution scheme. At the first stage, the planar regions embedded within a sequence of depth images are extracted individually and then merged to establish a terrain map containing only planar regions in a selected frame. To simplify the representations of the planar regions that are applicable to foothold planning for legged robots, we further approximate the extracted planar regions via convex polytopes at the second stage. With the polytopic representation, the proposed approach achieves a great balance between accuracy and simplicity. Experimental validations with RGB-D cameras are conducted to demonstrate the performance of the proposed scheme. The proposed scheme successfully characterizes the planar regions via polytopes with acceptable accuracy. More importantly, the run time of the overall scheme is less than 10ms (i.e., > 100Hz) throughout the tests, which strongly illustrates the advantages of our approach developed in this paper.
# Online Localisation and Colored Mesh Reconstruction Architecture for 3D Visual Feedback in Robotic Exploration Missions
## Keywords:
- Field Robots
- Mapping
- SLAM
## Abstract:
This paper introduces an Online Localisation and Colored Mesh Reconstruction (OLCMR) ROS perception architecture for terrestrial exploration robots aiming to perform robust Simultaneous Localisation And Mapping (SLAM) in challenging unknown environments and provide an associated colored 3D mesh representation in real time. It is intended to be used by a remote human operator to easily visualise the mapped environment during or after the mission or as a development base for further researches in the field of exploration robotics. The architecture is mainly composed of carefully-selected open-source ROS implementations of a LiDAR-based SLAM algorithm alongside a colored surface reconstruction procedure using a point cloud and RGB camera images projected into the 3D space. The overall performances are evaluated on the Newer College handheld LiDAR-Vision reference dataset and on two experimental trajectories gathered on board of representative wheeled robots in respectively urban and countryside outdoor environments.
# Speed up of Wave-Driven Unmanned Surface Vehicle Using Passively Transformable Two-Segment Foils
## Keywords:
- Marine Robotics
## Abstract:
For wave-driven unmanned surface vehicles (WUSVs), utilizing oscillating foils is the most straightforward and common wave energy conversion mechanism. Improving the thrust of the oscillating foil to increase its speed can help WUSVs improve their maneuverability and shorten the completion of ocean missions. This paper proposes a novel transformable two-segment foil, improving the wave energy-converting efficiency to provide more average thrust in every wave cycle. We estimate their working effectiveness numerically with a simple model to verify that the design enhances foils’ thrust force. The thrust enhancement was further confirmed by computational fluid dynamic (CFD) simulations, and we estimate the suitable values of parameters of the foils in several different common sea conditions in coastal waters by CFD simulations. We design and make two wave gliders with traditional foils and transformable two-segment foils and finish the speed enhancement experiments. The speed enhancement is verified and transformable two-segment foils can increase the speed of WUSVs by 10% in similar sea conditions in experiments.
# Simultaneous Localization of Rail Vehicles and Mapping of Environment with Multiple LiDARs
## Keywords:
- Field Robots
- Intelligent Transportation Systems
- SLAM
## Abstract:
Precise and real-time rail vehicle localization as well as railway environment monitoring is crucial for railroad safety. In this letter, we propose a multi-LiDAR based simultaneous localization and mapping (SLAM) system for railway applications. Our approach starts with measurements preprocessing to denoise and synchronize multiple LiDAR inputs. Different frame-to-frame registration methods are used according to the LiDAR placement. In addition, we leverage the plane constraints from extracted rail tracks to improve the system accuracy. The local map is further aligned with global map utilizing absolute position measurements. Considering the unavoidable metal abrasion and screw loosening, online extrinsic refinement is awakened for long-during operation. The proposed method is extensively verified on datasets gathered over 3000 km. The results demonstrate that the proposed system achieves accurate and robust localization together with effective mapping for large-scale environments. Our system has already been applied to a freight traffic railroad for monitoring tasks.
# Forest Traversability Mapping (FTM): Traversability Estimation Using 3D Voxel-Based Normal Distributed Transform to Enable Forest Navigation
## Keywords:
- Field Robots
- Autonomous Vehicle Navigation
- Robotics and Automation in Agriculture and Forestry
## Abstract:
Autonomous navigation in dense vegetation remains an open challenge and is an area of major interest for the research community. In this paper we propose a novel traversability estimation method, the Forest Traversability Map, that gives autonomous ground vehicles the ability to navigate in harsh forests or densely vegetated environments. The method estimates traversability in unstructured environments dominated by vegetation, void of any dominant human structures, gravel or dirt roads, with higher accuracy than the state of the art: we demonstrate an improvement of over 20% F1 score (from 0.71 to 0.91) on challenging real-world data. Our method is based on 3D voxel representation and introduces a robust colour fusion method to overcome occlusion and frequent changes of lighting conditions in these environments. We also introduce and fuse multi-return lidar measurements into our probabilistic map representation in a recursive manner. Finally, we include information of neighboring voxels to increase our ability to assess the terrain traversability correctly. These measures improve the state-of-the-art results and allow for effective traversability estimation in very challenging, densely vegetated environments.
# WayFAST: Navigation with Predictive Traversability in the Field
## Keywords:
- Field Robots
- Deep Learning for Visual Perception
- Vision-Based Navigation
## Abstract:
We present a self-supervised approach for learning to predict traversable paths for wheeled mobile robots that require good traction to navigate. Our algorithm, termed WayFAST (Waypoint Free Autonomous Systems for Traversability), uses RGB and depth data, along with navigation experience, to autonomously generate traversable paths in outdoor unstructured environments. Our key inspiration is that traction can be estimated for rolling robots using kinodynamic models. Using traction estimates provided by an online receding horizon estimator, we are able to train a traversability prediction neural network in a self-supervised manner, without requiring heuristics utilized by previous methods. We demonstrate the effectiveness of WayFAST through extensive field testing in varying environments, ranging from sandy dry beaches to forest canopies and snow covered grass fields. Our results clearly demonstrate that WayFAST can learn to avoid geometric obstacles as well as untraversable terrain, such as snow, which would be difficult to avoid with sensors that provide only geometric data, such as LiDAR. Furthermore, we show that our training pipeline based on online traction estimates is more data-efficient than other heuristic-based methods.
# Learning Pseudo Front Depth for 2D Forward-Looking Sonar-Based Multi-View Stereo
## Keywords:
- Marine Robotics
- Deep Learning for Visual Perception
## Abstract:
Retrieving the missing dimension information in acoustic images from 2D forward-looking sonar is a well-known problem in the field of underwater robotics. There are works attempting to retrieve 3D information from a single image which allows the robot to generate 3D maps with fly-through motion. However, owing to the unique image formulation principle, estimating 3D information from a single image faces severe ambiguity problems. Classical methods of multi-view stereo can avoid the ambiguity problems, but may require a large number of viewpoints to generate an accurate model. In this work, we propose a novel learning-based multi-view stereo method to estimate 3D information. To better utilize the information from multiple frames, an elevation plane sweeping method is proposed to generate the depth-azimuth-elevation cost volume. The volume after regularization can be considered as a probabilistic volumetric representation of the target. Instead of performing regression on the elevation angles, we use pseudo front depth from the cost volume to represent the 3D information which can avoid the 2D-3D problem in acoustic imaging. High-accuracy results can be generated with only two or three images. Synthetic datasets were generated to simulate various underwater targets. We also built the first real dataset with accurate ground truth in a large scale water tank. Experimental results demonstrate the superiority of our method, compared to other state-of-the-art methods.
# Obstacle-Aided Locomotion of a Snake Robot Using Piecewise Helixes
## Keywords:
- Field Robots
- Search and Rescue Robots
- Biologically-Inspired Robots
## Abstract:
A non-wheeled snake robot can propel itself by pushing against obstacles. This is called obstacle-aided locomotion. To expand the exploration range of a snake robot using this method, it is preferable to utilize obstacles that are both on the ground and by the side or above. To achieve these goals, we propose an obstacle-aided locomotion using piecewise helixes. This target shape comprises grounding and obstacle-contacting parts. The length and shape of the grounding part can be changed from a straight line to a circular arc. The height of the obstacle-contacting part can be changed or its direction can be reversed. The robot can adapt to various obstacles by appropriately changing its body shape. In addition, we propose a snake robot locomotion in a flat ground using the same shape as that used for obstacle-aided locomotion. This involves a combination of shift control and rolling motion. The robot can move in a straight line in the forward or lateral direction or can turn in a circular arc using the proposed method. Finally, experiments that confirm the effectiveness of the proposed method are presented.
# Informative Path Planning to Estimate Quantiles for Environmental Analysis
## Keywords:
- Field Robots
- Planning under Uncertainty
- Environment Monitoring and Management
## Abstract:
Scientists interested in studying natural phenomena often take physical specimens from locations in the environment for later analysis. These analysis locations are typically specified by expert heuristics. Instead, we propose to choose locations for scientific analysis by using a robot to perform an informative path planning survey. The survey results in a list of locations that correspond to the quantile values of the phenomenon of interest. We develop a robot planner using novel objective functions to improve the estimates of the quantile values over time and an approach to find locations which correspond to the quantile values. We test our approach in four different environments using previously collected aquatic data and validate it in a field trial. Our proposed approach to estimate quantiles has a 10.2% mean reduction in median error when compared to a baseline approach which attempts to maximize spatial coverage. Additionally, when localizing these values in the environment, we see a 15.7% mean reduction in median error when using cross-entropy with our loss function compared to a baseline.
# Motion and Path Planning 6
# FIG-OP: Exploring Large-Scale Unknown Environments on a Fixed Time Budget
## Keywords:
- Motion and Path Planning
- Planning under Uncertainty
- Robotics in Hazardous Fields
## Abstract:
We present a method for autonomous exploration of large-scale unknown environments under mission time constraints. We start by proposing the Frontloaded Information Gain Orienteering Problem (FIG-OP) – a generalization of the traditional orienteering problem where the assumption of a reliable environmental model no longer holds. The FIG-OP addresses model uncertainty by frontloading expected information gain through the addition of a greedy incentive, effectively expediting the moment in which new area is uncovered. In order to reason across multi-kilometer environments, we solve FIG-OP over an information-efficient world representation, constructed through the aggregation of information from a topological and metric map. Our method was extensively tested and field-hardened across various complex environments, ranging from subway systems to mines. In comparative simulations, we observe that the FIG-OP solution exhibits improved coverage efficiency over solutions generated by greedy and traditional orienteering-based approaches (i.e. severe and minimal model uncertainty assumptions, respectively).
# Adaptive Sampling of Latent Phenomena Using Heterogeneous Robot Teams (ASLaP-HR)
## Keywords:
- Motion and Path Planning
- Environment Monitoring and Management
- Path Planning for Multiple Mobile Robots or Agents
## Abstract:
In this paper, we present an online adaptive planning strategy for a team of robots with heterogeneous sensors to sample from a latent spatial field using a learned model for decision making. Current robotic sampling methods seek to gather information about an observable spatial field. However, many applications, such as environmental monitoring and precision agriculture, involve phenomena that are not directly observable or are costly to measure, called latent phenomena. In our approach, we seek to reason about the latent phenomenon in real-time by effectively sampling the observable spatial fields using a team of robots with heterogeneous sensors, where each robot has a distinct sensor to measure a different observable field. The information gain is estimated using a learned model that maps from the observable spatial fields to the latent phenomenon. This model captures aleatoric uncertainty in the relationship to allow for information theoretic measures. Additionally, we explicitly consider the correlations among the observable spatial fields, capturing the relationship between sensor types whose observations are not independent. We show it is possible to learn these correlations, and investigate the impact of the learned correlation models on the performance of our sampling approach. Through our qualitative and quantitative results, we illustrate that empirically learned correlations improve the overall sampling efficiency of the team. We simulate our approach using a data set of sensor measurements collected on Lac Hertel, in Quebec, which we make publicly available.
# Online Planning for Interactive-POMDPs Using Nested Monte Carlo Tree Search
## Keywords:
- Motion and Path Planning
- Planning, Scheduling and Coordination
## Abstract:
The ability to make good decisions in partially observed non-cooperative multi-agent scenarios is important for robots to interact effectively in human environments. A robust framework for such decision-making problems is the Interactive Partially Observable Markov Decision Processes (I-POMDPs), which explicitly models the other agents' beliefs up to a finite reasoning level in order to more accurately predict their actions. This paper proposes a new online approximate solver for I-POMDPs, called Interactive Nested Tree Monte-Carlo Planning (I-NTMCP), that combines Monte Carlo Tree Search with the finite nested-reasoning construction of I-POMDPs. Unlike existing full-width I-POMDP planners, I-NTMCP focuses planning on the set of beliefs at each nesting level which are reachable under an optimal policy and uses sampling to construct and update policies at each nesting level, online. This strategy enables I-NTMCP to plan effectively in significantly larger I-POMDP problems and to deeper reasoning levels than has previously been possible. We demonstrate I-NTMCP's effectiveness on two competitive environments. The results indicate that I-NTMCP can generate substantially better policies up to more than 50X faster than I-POMDP Lite # one of the fastest I-POMDP solvers today. In the pursuit-evasion domain, we demonstrate I-NTMCP can plan effectively in a large, complex problem with over 88K states, which is two orders of magnitude larger than existing I-POMDP planning benchmark problems.
# Lazy Lifelong Planning for Efficient Replanning in Graphs with Expensive Edge Evaluation
## Keywords:
- Motion and Path Planning
## Abstract:
We present an incremental search algorithm, called Lifelong-GLS, which combines the vertex efficiency of Lifelong Planning A* (LPA*) and the edge efficiency of Generalized Lazy Search (GLS) for efficient replanning on dynamic graphs where edge evaluation is expensive. We use a lazily evaluated LPA* to repair the cost-to-come inconsistencies of the relevant region of the current search tree based on the previous search results, and then we restrict the expensive edge evaluations only to the current shortest subpath as in the GLS framework. The proposed algorithm is complete and correct in finding the optimal solution in the current graph, if one exists. We also show the efficiency of the proposed algorithm compared to the standard LPA* and the GLS algorithms over consecutive search episodes in a dynamic environment.
# LTR*: Rapid Replanning in Executing Consecutive Tasks with Lazy Experience Graph
## Keywords:
- Motion and Path Planning
- Task and Motion Planning
## Abstract:
In an environment where a manipulator needs to execute multiple consecutive tasks, the act of object manoeuvre will change the underlying configuration space, affecting all subsequent tasks. Previously free configurations might now be occupied by the manoeuvred objects, and previously occupied space might now open up new paths. We propose Lazy Tree-based Replanner (LTR*) # a novel hybrid planner that inherits the rapid planning nature of existing anytime incremental sampling-based planners. At the same time, it allows subsequent tasks to leverage prior experience via a lazy experience graph. Previous experience is summarised in a lazy graph structure, and LTR* is formulated to be robust and beneficial regardless of the extent of changes in the workspace. Our hybrid approach attains a faster speed in obtaining an initial solution than existing roadmap-based planners and often with a lower cost in trajectory length. Subsequent tasks can utilise the lazy experience graph to speed up finding a solution and take advantage of the optimised graph to minimise the cost objective. We provide proofs of probabilistic completeness and almost-surely asymptotic optimal guarantees. Experimentally, we show that in repeated pick-and-place tasks, LTR* attains a high gain in performance when planning for subsequent tasks.
# RRT*-Based Path Planning for Continuum Arms
## Keywords:
- Motion and Path Planning
- Task and Motion Planning
- Flexible Robotics
## Abstract:
Continuum arms are bio-inspired devices that exhibit continuous, smooth bending and generate motion through structural deformation. Rapidly-exploring random trees (RRT) is a traditional approach for performing efficient path planning. RRT approaches are usually based on exploring the configuration space (C-Space) of the robot to find a desirable work space (W-Space) path. Due to the complex kinematics and the highly non-linear mapping between the C-Space and W-Space of continuum arms, a high-quality path in the C-Space (e.g., a linear path) may not correspond to a desirable path/movement in the W-Space. Consequently, the C-Space RRT approaches that are based on C-Space cost functions do not lead to reliable and effective path planning when applied to continuum arms. In this paper, we propose a RRT* path planning approach for continuum arms that is based on exploring the W-Space of the robot as opposed to its C-Space. We show the successful applications of the proposed W-Space RRT* path planner in performing path planning with obstacle avoidance and in performing trajectory tracking. In all the aforementioned tasks, the quality of the paths generated by the proposed planner is superior to that of previous approaches and to its counterpart C-Space based RRT* approach, while the paths are generated in substantially less time.
# FlowBot: Flow-Based Modeling for Robot Navigation
## Keywords:
- Human-Aware Motion Planning
- Motion and Path Planning
## Abstract:
Autonomous navigation among people is a complex problem that also exhibits considerable variation depending on the type of environment and people involved. Here we consider navigation among crowds that exhibit flow-like behavior like people moving through a train station. We propose a novel pseudo-fluid model of crowd flow for such problems. These have an intuitive physical interpretation and do not require much tuning. We further formalize an observation model to infer flow properties from discrete sensor observations, including support for partial observability, and pair it with a flow-aware planner. We demonstrate the potential of the approach in simulated navigation scenarios. We achieve state of the art results on the CrowdBot navigation benchmark, and also compare favorably against a standard ROS planner on a partially observable environment, demonstrating that the flow-aware planner successfully estimates and plans around counter-flows in the crowd in real time. We conclude that flow-based planning shows great promise for crowded environments that may exhibit such flow-like behavior.
# The RATTLE Motion Planning Algorithm for Robust Online Parametric Model Improvement with On-Orbit Validation
## Keywords:
- Motion and Path Planning
- Planning under Uncertainty
- Space Robotics and Automation
## Abstract:
Certain forms of uncertainty that robotic systems encounter can be explicitly learned within the context of a known model, like parametric model uncertainties such as mass and moments of inertia. Quantifying such parametric uncertainty is important for more accurate prediction of the system behavior, leading to safe and precise task execution. In tandem, providing a form of robustness guarantee against prevailing uncertainty levels like environmental disturbances and current model knowledge is also desirable. To that end, the authors' previously proposed RATTLE algorithm, a framework for online information-aware motion planning, is outlined and extended to enhance its applicability to real robotic systems. RATTLE provides a clear tradeoff between information-seeking motion and traditional goal-achieving motion and features online-adjustable models. Additionally, online-adjustable low level control robustness guarantees and a new method for automatic adjustment of information content down to a specified estimation precision is proposed. Results of extensive experimentation in microgravity using the Astrobee robots aboard the International Space Station and practical implementation details are presented, demonstrating RATTLE's capabilities for real-time, robust, online-adjustable, and model information-seeking motion planning capabilities under parametric uncertainty.
# Transferring Multi-Agent Reinforcement Learning Policies for Autonomous Driving Using Sim-To-Real
## Keywords:
- Autonomous Vehicle Navigation
- Agent-Based Systems
- Reinforcement Learning
## Abstract:
Autonomous Driving requires high levels of coordination and collaboration between agents. Achieving effective coordination in multi-agent systems is a difficult task that remains largely unresolved. Multi-Agent Reinforcement Learning has arisen as a powerful method to accomplish this task because it considers the interaction between agents and also allows for decentralized training---which makes it highly scalable. However, transferring policies from simulation to the real world is a big challenge, even for single-agent applications. Multi-agent systems add additional complexities to the Sim-to-Real gap due to agent collaboration and environment synchronization. In this paper, we propose a method to transfer multi-agent autonomous driving policies to the real world. For this, we create a multi-agent environment that imitates the dynamics of the Duckietown multi-robot testbed, and train multi-agent policies using the MAPPO algorithm with different levels of domain randomization. We then transfer the trained policies to the Duckietown testbed and show that when using our method, domain randomization can reduce the reality gap by 90%. Moreover, we show that different levels of parameter randomization have a substantial impact on the Sim-to-Real gap. Finally, our approach achieves significantly better results than a rule-based benchmark.
# Control for Legged Robot
# The Uncertainty Aware Salted Kalman Filter: State Estimation for Hybrid Systems with Uncertain Guards
## Keywords:
- Contact Modeling
- Legged Robots
- Probability and Statistical Methods
## Abstract:
In this paper, we present a method for updating robotic state belief through contact with uncertain surfaces and apply this update to a Kalman filter for more accurate state estimation. Examining how guard surface uncertainty affects the time spent in each mode, we derive a novel guard saltation matrix # which maps perturbations prior to hybrid events to perturbations after # accounting for additional variation in the resulting state. Additionally, we propose the use of parameterized reset functions # capturing how unknown parameters change how states are mapped from one mode to the next # the Jacobian of which accounts for additional uncertainty in the resulting state. The accuracy of these mappings is shown by simulating sampled distributions through uncertain transition events and comparing the resulting covariances. Finally, we integrate these additional terms into the "uncertainty aware Salted Kalman Filter", uaSKF, and show a peak reduction in average estimation error by 24-60% on a variety of test conditions and systems.
# Contact-Implicit Trajectory Optimization with Hydroelastic Contact and ILQR
## Keywords:
- Optimization and Optimal Control
- Contact Modeling
- Multi-Contact Whole-Body Motion Planning and Control
## Abstract:
Contact-implicit trajectory optimization offers an appealing method of automatically generating complex and contact-rich behaviors for robot manipulation and locomotion. The scalability of such techniques has been limited, however, by the challenge of ensuring both numerical reliability and physical realism. In this paper, we present preliminary results suggesting that the Iterative Linear Quadratic Regulator (iLQR) algorithm together with the recently proposed pressure-field-based hydroelastic contact model enables reliable and physically realistic trajectory optimization through contact. We use this approach to synthesize contact-rich behaviors like quadruped locomotion and whole-arm manipulation. Furthermore, open-loop playback on a Kinova Gen3 robot arm demonstrates the physical accuracy of the whole-arm manipulation trajectories. Code is available at https://bit.ly/ilqr_hc and videos can be found at https://youtu.be/IqxJKbM8_ms.
# Balancing Control and Pose Optimization for Wheel-Legged Robots Navigating High Obstacles
## Keywords:
- Optimization and Optimal Control
- Force Control
- Legged Robots
## Abstract:
This paper proposes a novel approach to controlling wheel-legged quadrupedal robots using pose optimization and force-based control via quadratic programming (QP). Our method allows the robot to leverage the whole-body motion and the wheel actuation to roll over high obstacles while keeping wheel traction with the terrain. In detail, we first present linear rigid body dynamics with wheels that can be used for real-time balancing control of wheel-legged robots. We then introduce an effective pose optimization method for wheel-legged robot’s locomotion over steep ramp and stair terrains. The pose optimization solves for optimal poses to enhance stability and enforce collision-free constraints at critical pose locations for rolling over high obstacles. Experimental validation of the real robot demonstrated the capability of rolling up on a 0.36 m obstacle. The robot can also successfully roll up and down multiple stairs without lifting its legs or colliding with the terrain.
# Large-Scale ADMM-Based Co-Design of Legged Robots
## Keywords:
- Optimization and Optimal Control
- Legged Robots
- Mechanism Design
## Abstract:
This paper considers the problem of designing legged robots for traversing uneven terrain, wherein terrain characteristics represent uncertainty for the design process. When this process encompasses a wider variety of terrains, the likelihood of the designed robot falling in the real world should decrease. However, computational scalability limits the number of terrains that can be taken into account during design. The proposed framework uses the Alternating Direction Method of Multipliers (ADMM) to solve large-scale concurrent design (co-design) problems. The ADMM coordinates the solution of small-size sub-problems and enforces constraints to reach a consensus on the best design. The framework uses stochastic programming (SP) to account for terrain uncertainty and trajectory optimization (TO) to co-optimize a nominal trajectory alongside hardware parameters and a feedback controller. Case studies demonstrate application for a monopod and a quadruped. For the monopod, ADMM facilitated an increase in the number of terrains considered within co-design by 400% compared to SP alone, which contributed to robustifying the design and decreasing its failure probability to under 1% in an anticipated operating space. A multi-scenario co-design implementation for the quadruped had previously been intractable due to scalability limitations. The ADMM framework, by contrast, shows tractability running with 30 terrain types, opening the horizon for designing more complex systems.
# An Error-State Model Predictive Control on Connected Matrix Lie Groups for Legged Robot Control
## Keywords:
- Optimization and Optimal Control
- Legged Robots
## Abstract:
This paper reports on a new error-state Model Predictive Control (MPC) approach to connected matrix Lie groups for robot control. The linearized tracking error dynamics and the linearized equations of motion are derived in the Lie algebra. Moreover, given an initial condition, the linearized tracking error dynamics and equations of motion are globally valid and evolve independently of the system trajectory. By exploiting the symmetry of the problem, the proposed approach shows faster convergence of rotation and position simultaneously than the state-of-the-art geometric variational MPC based on variational-based linearization. Numerical simulation on tracking control of a fully-actuated 3D rigid body dynamics confirms the benefits of the proposed approach compared to the baselines. Furthermore, the proposed MPC is also verified in pose control and locomotion experiments on a quadrupedal robot MIT Mini Cheetah.
# Whole-Body Model Predictive Control with Rigid Contacts Via Online Switching Time Optimization
## Keywords:
- Optimization and Optimal Control
- Multi-Contact Whole-Body Motion Planning and Control
- Legged Robots
## Abstract:
This study presents a whole-body model predictive control (MPC) of robotic systems with rigid contacts, under a given contact sequence using online switching time optimization (STO). We treat robot dynamics with rigid contacts as a switched system and formulate an optimal control problem of switched systems to implement the MPC. We utilize an efficient solution algorithm for the MPC problem that optimizes the switching times and trajectory simultaneously. The present efficient algorithm, unlike inefficient existing methods, enables online optimization as well as switching times. The proposed MPC with online STO is compared over the conventional MPC with fixed switching times, through numerical simulations of dynamic jumping motions of a quadruped robot. In the simulation comparison, the proposed MPC successfully controls the dynamic jumping motions in twice as many cases as the conventional MPC, which indicates that the proposed method extends the ability of the whole-body MPC. We further conduct hardware experiments on the quadrupedal robot Unitree A1 and prove that the proposed method achieves dynamic motions on the real robot.
# Generating Families of Optimally Actuated Gaits from a Legged System’s Energetically Conservative Dynamics
## Keywords:
- Optimization and Optimal Control
- Passive Walking
- Legged Robots
## Abstract:
We present a homotopic approach to generating energetically optimal gaits for legged robots that maps passive (i.e., unactuated) gaits of an energetically conservative model of the robot to a model with user-defined target dynamics with dissipation and actuation (i.e., the more ``realistic'' legged model).	Our core contribution is advancing the state-of-the-art towards a turn-key approach where the seed values are known by design and do not rely on domain-specific knowledge to generate or randomly guess across a range of energetic cost functions and desired gait properties (e.g., walking speed, hopping height, etc.), which can limit the usefulness of the typical optimization-based approach. We demonstrate this methodology on a parallel elastic actuated planar monoped with five degrees of freedom.
Our work also demonstrates an explicit connection between passive gaits and optimally actuated motions, which has long been an area of interest in the fields of robotics and biomechanics.
# Optimal Gait Families Using Lagrange Multiplier Method
## Keywords:
- Optimization and Optimal Control
- Underactuated Robots
- Task and Motion Planning
## Abstract:
The Robotic locomotion community is interested in optimal gaits for control. Based on the optimization criterion, however, there could be a number of possible optimal gaits. For example, the optimal gait for maximizing displacement with respect to cost is quite different from the maximum displacement optimal gait. Beyond these two general optimal gaits, we believe that the optimal gait should deal with various situations for high-resolution of motion planning, e.g., steering the robot or moving in "baby steps.'' As the step size or steering ratio increases or decreases, the optimal gaits will slightly vary by the geometric relationship and they will form the families of gaits. In this paper, we explored the geometrical framework across these optimal gaits having different step sizes in the family via the Lagrange multiplier method. Based on the structure, we suggest an optimal locus generator that solves all related optimal gaits in the family instead of optimizing each gait respectively. By applying the optimal locus generator to two simplified swimmers in drag-dominated environments, we verify the behavior of the optimal locus generator.
# Lifted Contact Dynamics for Efficient Optimal Control of Rigid Body Systems with Contacts
## Keywords:
- Optimization and Optimal Control
- Multi-Contact Whole-Body Motion Planning and Control
- Legged Robots
## Abstract:
We propose a novel and efficient lifting approach for the optimal control of rigid-body systems with contacts to improve the convergence properties of Newton-type methods. To relax the high nonlinearity, we consider the state, acceleration, contact forces, and control input torques, as optimization variables and the inverse dynamics and acceleration constraints on the contact frames as equality constraints. We eliminate the update of the acceleration, contact forces, and their dual variables from the linear equation to be solved in each Newton-type iteration in an efficient manner. As a result, the computational cost per Newton-type iteration is almost identical to that of the conventional non-lifted Newton-type iteration that embeds contact dynamics in the state equation. We conducted numerical experiments on the whole-body optimal control of various quadrupedal gaits subject to the friction cone constraints considered in interior-point methods and demonstrated that the proposed method can significantly increase the convergence speed to more than twice that of the conventional non-lifted approach.
# Intelligent and Flexible Manufacturing
# Heuristic-Free Optimization of Force-Controlled Robot Search Strategies in Stochastic Environments
## Keywords:
- Intelligent and Flexible Manufacturing
- Industrial Robots
- Deep Learning in Grasping and Manipulation
## Abstract:
In both industrial and service domains, a central benefit of the use of robots is their ability to quickly and reliably execute repetitive tasks. However, even relatively simple peg-in-hole tasks are typically subject to stochastic variations, requiring search motions to find environment features such as holes. While search improves robustness, it comes at the cost of increased runtime: More exhaustive search will maximize the probability of successfully executing a given task, but will significantly delay any downstream tasks. This trade-off is typically resolved by human experts according to simple heuristics, which are rarely optimal. This paper introduces an automatic, data-driven and heuristic-free approach to optimize robot search strategies. By training a neural model of the search strategy on a large set of simulated stochastic environments, conditioning it on few real-world examples and inverting the model, we can infer search strategies which adapt to the time-variant characteristics of the underlying probability distributions, while requiring very few real-world measurements. We evaluate our approach on two different industrial robots in the context of spiral and probe search for THT electronics assembly.
# A Composable Framework for Policy Design, Learning, and Transfer Toward Safe and Efficient Industrial Insertion
## Keywords:
- Intelligent and Flexible Manufacturing
- Software-Hardware Integration for Robot Systems
- Industrial Robots
## Abstract:
Delicate industrial insertion tasks (e.g., PC board assembly) remain challenging for industrial robots. The challenges include low error tolerance, delicacy of the components, and large task variations with respect to the components to be inserted. To deliver a feasible robotic solution for these insertion tasks, we also need to account for hardware limits of existing robotic systems and minimize the integration effort. This paper proposes a composable framework for efficient integration of a safe insertion policy on existing robotic platforms to accomplish these insertion tasks. The policy has an interpretable modularized design and can be learned efficiently on hardware and transferred to new tasks easily. In particular, the policy includes a safe insertion agent as a baseline policy for insertion, an optimal configurable Cartesian tracker as an interface to robot hardware, a probabilistic inference module to handle component variety and insertion errors, and a safe learning module to optimize the parameters in the aforementioned modules to achieve the best performance on designated hardware. The experiment results on a UR10 robot show that the proposed framework achieves safety (for the delicacy of components), accuracy (for low tolerance), robustness (against perception error and component defection), adaptability and transferability (for task variations), as well as task efficiency during execution plus data and time efficiency during learning.
# Online 3D Bin Packing Reinforcement Learning Solution with Buffer
## Keywords:
- Factory Automation
- Reinforcement Learning
- AI-Enabled Robotics
## Abstract:
The 3D Bin Packing Problem (3D-BPP) is one of the most demanded yet challenging problems in industry, where an agent must pack variable size items delivered in sequence into a finite bin with the aim to maximize the space utilization. It represents a strongly NP-Hard optimization problem such that no solution has been offered to date with high performance in space utilization. In this paper, we present a new reinforcement learning (RL) framework for a 3D-BPP solution for improving performance. First, a buffer is introduced to allow multi-item action selection. By increasing the degree of freedom in action selection, a more complex policy that results in better packing performance can be derived. Second, we propose an agnostic data augmentation strategy that exploits both bin item symmetries for improving sample efficiency. Third, we implement a model-based RL method adapted from the popular algorithm AlphaGo, which has shown superhuman performance in zero-sum games. Our adaptation is capable of working in single-player and score based environments. In spite of the fact that AlphaGo versions are known to be computationally heavy, we manage to train the proposed framework with a single thread and GPU, while obtaining a solution that outperforms the state-of-the-art results in space utilization.
# GoferBot: A Visual Guided Human-Robot Collaborative Assembly System
## Keywords:
- Computer Vision for Manufacturing
- Human-Robot Collaboration
- Deep Learning for Visual Perception
## Abstract:
The current transformation towards smart manufacturing has led to a growing demand for human-robot collaboration (HRC) in the manufacturing process. Perceiving and understanding the human co-worker's behaviour introduces challenges for collaborative robots to efficiently and effectively perform tasks in unstructured and dynamic environments. Integrating recent data-driven machine vision capabilities into HRC systems is a logical next step in addressing these challenges. However, in these cases, off-the-shelf components struggle due to generalisation limitations. Furthermore, understanding the pure-vision aspects is a crucial first step before combining multiple modalities in order to understand the limitations. In this paper, we propose GoferBot, a novel vision-based semantic HRC system for a real-world assembly task. It is composed of a visual servoing module that reaches and grasps assembly parts in an unstructured multi-instance and dynamic environment, an action recognition module that performs human action prediction for implicit communication, and a visual handover module that uses the perceptual understanding of human behaviour to produce an intuitive and efficient collaborative assembly experience. GoferBot is a novel assembly system that seamlessly integrates all sub-modules by utilising implicit semantic information purely from visual perception.
# Robot Companion, an Intelligent Interactive Robot Coworker for the Industry 5.0
## Keywords:
- Intelligent and Flexible Manufacturing
- Software Architecture for Robotic and Automation
- Computer Vision for Manufacturing
## Abstract:
To overcome the limitations of the so-called Industry 4.0 focusing on mass production and full automation, a novel paradigm was recently introduced, namely Industry 5.0, which aims at an increased collaboration between humans and machines, and particularly robots, instead of replacing the former with the latter. This challenge requires novel interactive intelligent robots able to perform complex tasks easily and efficiently and to collaborate on the fly with humans whenever required, be it for training or working. In this work, the Robot Companion, a novel demonstrator of this paradigm, is introduced. It combines robotics, Artificial Intelligence, software engineering and embedded systems technologies, and targets industrial assembly tasks. First tests show that this robot can efficiently assemble a representative gear system autonomously or in collaboration with human operators.
# Metal Wire Manipulation Planning for 3D Curving a Low Payload Robot That Uses a Bending Machine to Bend High-Stiffness Wire
## Keywords:
- Intelligent and Flexible Manufacturing
- Task and Motion Planning
- Manipulation Planning
## Abstract:
This paper presents a combined task and motion planner for a robot arm to carry out 3D metal wire curving tasks by collaborating with a bending machine. We assume a collaborative robot that is safe to work in a human environment but has a weak payload to bend objects with large stiffness, and developed a combined planner for the robot to use a bending machine. Our method converts a 3D curve to a bending set and generates the feasible bending sequence, machine usage, robotic grasp poses, and pick-and-place arm motion considering the combined task and motion level constraints. Compared with previous deformable linear object shaping work that relied on forces provided by robotic arms, the proposed method is suitable for the material with high stiffness. We evaluate the system using different tasks. The results show that the proposed system is flexible and robust to generate robotic motion to corporate with the designed bending machine.
# SurfMan: Generating Smooth Robotic Surface Manipulation Trajectories for Human-Demonstrated Pattern Sequence
## Keywords:
- Intelligent and Flexible Manufacturing
- Learning from Demonstration
## Abstract:
Specifying robot tasks for low-volume manufacturing scenarios is an open problem. The state-of-the-art robotic systems enable the application of smooth 2D paths to a 3D surface but assume that the product engineer provides these paths. We extend this approach with a novel tool-path specification method, which produces smooth paths from noisy demonstrations. The user demonstrates only short patterns and selects a base path relative to an object in front of the robot, along which these patterns should be applied. The representation based on polynomials allows controlling the grade of the smoothness of the resulting tool path. We generate parametrized robot trajectories to meet the use-case-specific constraints and adhere to the robot’s kinodynamic limits. We propose a set of measures to evaluate the quality of the generated curves and corresponding trajectories with respect to executability by a robot. The evaluation in simulation and real-robot experiments showed that the robot could reach up to 15.9% higher constant speed on tool paths generated by our system compared to unprocessed paths.
# Development and Control of Robot Hand with Finger Camera for Garment Handling Tasks
## Keywords:
- Factory Automation
- Computer Vision for Automation
- Dual Arm Manipulation
## Abstract:
Robotic automation is steadily growing in different industries around the world. However, in some industries, such as garment manufacturing, most tasks are still predominantly manual, due to the flexible nature of clothes. Garment and clothes are easily deformed when some force is applied, so it is difficult for robots to handle them while predicting their deformation. Our general research goal is to realize flexible cloth handling using robots to automate different tasks in the garment manufacturing industry. We draw inspiration from the actions that humans perform when manipulating clothes and emulate them using a robotic system. In this paper, we developed a robot hand with a camera at the finger, to obtain local information of the contact between the garment and the robot hand, in order to achieve garment handling tasks. Specifically, we focus on the pinch and slide motion that humans perform when straightening a piece of cloth. We selected a specific task to be automated and proposed control methods using visual information from the finger camera that enabled the system to perform the task consistently. We carried out two validation experiments to demonstrate the effectiveness of the proposed methods, and an application experiment where we evaluate their applicability to a specific task.
# Robotics and Automation in Agriculture and Construction 2
# EPAR: An Efficient and Privacy-Aware Augmented Reality Framework for Indoor Location-Based Services
## Keywords:
- Robotics and Automation in Construction
- Acceptability and Trust
- Building Automation
## Abstract:
Augmented reality (AR) defines a new information-delivery paradigm by overlaying computer-generated information on the perception of the real world. AR-integrated robot has become an appealing concept in terms of enhanced human-robot interaction. Despite intensive research on AR, existing indoor location-based AR systems are vulnerable to attacks and can hardly meet the security and privacy requirements in practice. The problem of designing a secure AR framework to ensure the efficiency and privacy of location-based AR has not been sufficiently studied. In this paper, we holistically study this problem and propose EPAR, an efficient and privacy-aware AR framework for indoor location-based services. EPAR distinguishes itself from the existing work by being the first to address the issues of AR delivery in terms of system scalability, accuracy, privacy, and efficiency. First, an effective indoor location cloaking scheme is presented to safeguard user's privacy while improving system scalability and accuracy. Then, a novel privacy-aware localization scheme is proposed to hierarchically localize the user with privacy concerns. Finally, for the AR content delivery, a new authenticated data structure is tailored to save the data transmission cost and improve system efficiency. We implement EPAR and conduct extensive experiments in real-world scenarios. Evaluation results demonstrate the effectiveness of our EPAR system.
# Compact Strawberry Harvesting Tube Employing Laser Cutter
## Keywords:
- Robotics and Automation in Agriculture and Forestry
- Service Robotics
- Engineering for Robotic Systems
## Abstract:
In this paper, a novel prototype for hanging produce harvesting is presented, that is productive, versatile, and robust. In our methodology, the robot-mounted tube approaches, and eventually surrounds the produce of interest at the entry side, that can be as small as the produce diameter, plus a small margin. The stem is then cut by a laser beam, with the optics set up for a distant focal point. Such arrangement allows for minimal hardware at the produce-entry side and in turn, the interaction, and possible disturbance to the local environment. This is essential for fruit reachability and avoiding it dislocation. Experiments has been conducted to drive the laser power to time of cut relation, as well as successful demonstration to sample harvest strawberry.
# Reconstructing a Spatial Field with an Autonomous Robot under a Budget Constraint
## Keywords:
- Robotics and Automation in Agriculture and Forestry
- Planning, Scheduling and Coordination
## Abstract:
In this paper we consider the information path-planning problem for a single robot in a stochastic environment with static obstacles subject to a preassigned constraint on the distance it can travel. Given a set of candidate sampling locations, the objective is to determine a path for the robot that allows to visit as many sampling locations as possible to accurately reconstruct an unknown underlying scalar field while not exceeding the assigned travel budget. Starting from the assumption that the phenomenon being measured can be modeled by a Gaussian Process, our algorithm balances exploration and exploitation to determine a sequence of locations ensuring that a preassigned final site is reached before the budget is consumed. Using mutual information as a reward criterion, as well as a generative model to predict consumed energy, the algorithm iteratively determines where to sample next, and when to end the mission. Our findings are validated in simulation in various scenarios and lead to a better reconstruction with less failures when compared with other methods.
# Hybrid Discrete-Continuous Path Planning for Lattice Traversal
## Keywords:
- Robotics and Automation in Construction
- Motion and Path Planning
- Building Automation
## Abstract:
Lattice structures allow robotic systems to operate in complex and hazardous environments, e.g. construction, mining and nuclear plants, reliably and effectively. However, current navigation systems for these structures are neither realistic, as they assume simplistic motion primitives and obstacle-free workspaces, nor efficient as they rely solely on global discrete search in an attempt to leverage the modularity of lattices. This paper tackles this gap and studies how robots can navigate lattice structures efficiently. We present a realistic application environment where robots have to avoid obstacles and the structure itself to reach target locations. Our solution couples discrete optimal search, using a domain-dependent heuristic, and sampling-based motion planning to find feasible trajectories in the discrete search space and the continuous joint space at the same time. We provide two search graph formulations and a path planning approach. Simulation experiments, based on structures and robots created for the Innovate UK Connect-R project, examine scalability to large grid spaces while maintaining performances close to optimal.
# RECCraft System: Towards Reliable and Efficient Collective Robotic Construction
## Keywords:
- Robotics and Automation in Construction
- Multi-Robot Systems
- Mobile Manipulation
## Abstract:
This research presents a novel Collective Robotic Construction (CRC) system named RECCraft. The RECCraft hardware system is composed of the mobile manipulation vehicles, the cubic blocks, and the folding ramp blocks. Solid connection and easy removal of the blocks are achieved by an electropermanent magnet and silicon steel sheets. With one degree of freedom (DOF) lifting manipulator, the robot can carry a block 3.7 times its volume. An active folding ramp block can provide a robust passage to the upper level for the robot. Our study focuses on systemic improvement of the construction speed and reliability of the robotic construction system. Visual perception system realized by Apritag is adopted, featured by convenient deployment and high precision, to provide a reliable guarantee for robotic construction. RL-based planner provides end-to-end solution for planning tasks of building multi-layer constructions, which is validated by simulation plat# form and real prototype. Compared with construction speed of existing robotic construction systems, our proposed RECCraft system achieves state-of-the-art level. The robot builds a 2# layer construction by RL-based planner in 4 minutes and 16 seconds, which achieves construction volumetric throughput of 6.7 × 10^5 mm3 /s.
# Reinforcement Learning 5
# Improved Robustness and Safety for Pre-Adaptation of Meta Reinforcement Learning with Prior Regularization
## Keywords:
- Reinforcement Learning
- Autonomous Agents
## Abstract:
Meta Reinforcement Learning (Meta-RL) has seen substantial advancements recently. In particular, off-policy methods were developed to improve the data efficiency of Meta-RL techniques. Probabilistic embeddings for actor-critic RL (PEARL) is a leading approach for multi-MDP adaptation problems. A major drawback of many existing Meta-RL methods, including PEARL, is that they do not explicitly consider the safety of the prior policy when it is exposed to a new task for the first time. Safety is essential for many real world applications, including field robots and Autonomous Vehicles (AVs). In this paper, we develop the PEARL PLUS (PEARL+) algorithm, which optimizes the policy for both prior (pre-adaptation) safety and posterior (after-adaptation) performance. Building on top of PEARL, our proposed PEARL+ algorithm introduces a prior regularization term in the reward function and a new Q-network for recovering the state-action value under prior context assumptions, to improve the robustness to task distribution shift and safety of the trained network exposed to a new task for the first time. The performance of PEARL+ is validated by solving three safety-critical problems related to robots and AVs, including two MuJoCo benchmark problems. From the simulation experiments, we show that safety of the prior policy is significantly improved and more robust to task distribution shift compared to PEARL
# Active Tactile Exploration Using Shape Dependent Reinforcement Learning
## Keywords:
- Reinforcement Learning
- Force and Tactile Sensing
- Motion and Path Planning
## Abstract:
Tactile signals provide rich information about objects via touch and are essential for a robot to perform dexterous manipulation. Exploring actively via tactile perception collects important information about the workspace. However, designing an effective tactile exploration policy is challenging in unstructured environments. Typically, the geometric information is incomplete, and need to be completed by actively and repeatedly interacting with the environment. In this paper, we address the tactile exploration problem by proposing a shape-information-dependent exploration strategy, which consists of two components: (1) a Shape-Belief Encoder that encodes the explored area by learning effective 3-D reconstruction and predicts the complete object shape; (2) a shape-dependent exploration policy which incorporates the encoding in (1) to plan an exploration trajectory. The policy actively acquires new information about object surface by executing exploration actions. The Shape-Belief Encoder leverages the newly collected contact points to update the surface model and guides future exploration. We validate the proposed algorithm on simulated and real robots.
# DARL1N: Distributed Multi-Agent Reinforcement Learning with One-Hop Neighbors
## Keywords:
- Reinforcement Learning
- Distributed Robot Systems
- Multi-Robot Systems
## Abstract:
Multi-agent reinforcement learning (MARL) methods face a curse of dimensionality in the policy and value function representations as the number of agents increases. The development of distributed or parallel training techniques is also hindered by the global coupling among the agent dynamics, requiring simultaneous state transitions. This paper introduces Distributed multi-Agent Reinforcement Learning with One-hop Neighbors (DARL1N). DARL1N is an off-policy actor-critic MARL method that breaks the curse of dimensionality and achieves distributed training by restricting the agent interactions to one-hop neighborhoods. Each agent optimizes its value and policy functions over a one-hop neighborhood, reducing the representation complexity, yet maintaining expressiveness by training with varying numbers and states of neighbors. This structure enables the key contribution of DARL1N: a distributed training procedure in which each compute node simulates the state transitions of only a small subset of the agents, greatly accelerating the training of large-scale MARL policies. Comparisons with state-of-the-art MARL methods show that DARL1N significantly reduces training time without sacrificing policy quality as the number of agents increases.
# Adaptive Environment Modeling Based Reinforcement Learning for Collision Avoidance in Complex Scenes
## Keywords:
- Reinforcement Learning
- Collision Avoidance
## Abstract:
The major challenges of collision avoidance for robot navigation in crowded scenes lie inaccurate environment modeling, fast perceptions, and trustworthy motion planning policies. This paper presents a novel adaptive environment model-based collision avoidance reinforcement learning (i.e., AEMCARL) framework for an unmanned robot to achieve collision-free motions in challenging navigation scenarios. The novelty of this work is threefold: (1) developing a hierarchical network of gated-recurrent-unit (GRU) for environment modeling; (2) developing an adaptive perception mechanism with an attention module; (3) developing an adaptive reward function for the reinforcement learning (RL) framework to jointly train the environment model, perception function and motion planning policy. The proposed method is tested with the Gym-Gazebo simulator and a group of robots (Husky and Turtlebot) under various crowded scenes. Both simulation and experimental results have demonstrated the superior performance of the proposed method over baseline methods.
# Scalable Model-Based Policy Optimization for Decentralized Networked Systems
## Keywords:
- Reinforcement Learning
- Networked Robots
- Model Learning for Control
## Abstract:
Reinforcement learning algorithms require a large amount of samples; this often limits their real-world applica# tions on even simple tasks. Such a challenge is more outstanding in multi-agent tasks, as each step of operation is more costly, requiring communications or shifting or resources. This work aims to improve data efficiency of multi-agent control by model-based learning. We consider networked systems where agents are cooperative and communicate only locally with their neighbors, and propose the decentralized model-based policy optimization framework (DMPO). In our method, each agent learns a dynamic model to predict future states and broadcast their predictions by communication, and then the policies are trained under the model rollouts. To alleviate the bias of model# generated data, we restrain the model usage for generating myopic rollouts, thus reducing the compounding error of model generation. To pertain the independence of policy update, we introduce extended value function and theoretically prove that the resulting policy gradient is a close approximation to true policy gradients. We evaluate our algorithm on several benchmarks for intelligent transportation systems, which are connected autonomous vehicle control tasks (Flow and CACC) and adaptive traffic signal control (ATSC). Empirical results show that our method achieves superior data efficiency and matches the performance of model-free methods using true models.
# Safety Correction from Baseline: Towards the Risk-Aware Policy in Robotics Via Dual-Agent Reinforcement Learning
## Keywords:
- Reinforcement Learning
- Machine Learning for Robot Control
- Robot Safety
## Abstract:
Learning a risk-aware policy is essential but rather challenging in unstructured robotic tasks. Safe reinforcement learning methods open up new possibilities to tackle this problem. However, the conservative policy updates make it intractable to achieve sufficient exploration and desirable performance in complex, sample-expensive environments. In this paper, we propose a dual-agent safe reinforcement learning strategy consisting of a baseline and a safe agent. Such a decoupled framework enables high flexibility, data efficiency and risk-awareness for RL-based control. Concretely, the baseline agent is responsible for maximizing rewards under standard RL settings. Thus, it is compatible with off-the-shelf training techniques of unconstrained optimization, exploration and exploitation. On the other hand, the safe agent mimics the baseline agent for policy improvement and learns to fulfill safety constraints via off-policy RL tuning. In contrast to training from scratch, safe policy correction requires significantly fewer interactions to obtain a near-optimal policy. The dual policies can be optimized synchronously via a shared replay buffer, or leveraging the pre-trained model or the non-learning-based controller as a fixed baseline agent. Experimental results show that our approach can learn feasible skills without prior knowledge as well as deriving risk-averse counterparts from pre-trained unsafe policies. The proposed method outperforms the state-of-the-art safe RL algorithms on difficult robot locomotion and manipulation tasks with respect to both safety constraint satisfaction and sample efficiency.
# Multi-Objective Policy Gradients with Topological Constraints
## Keywords:
- Reinforcement Learning
- Deep Learning Methods
## Abstract:
Multi-objective optimization models that encode ordered sequential constraints provide a solution to model various challenging problems including encoding preferences, modeling a curriculum, and enforcing measures of safety. A recently developed theory of topological Markov decision processes (TMDPs) captures this range of problems for the case of discrete states and actions. In this work, we extend TMDP towards continuous spaces and unknown transition dynamics by formulating, proving, and implementing the policy gradient theorem for TMDPs. This theoretical result enables the creation of TMDP learning algorithms that use function approximators, and can generalize existing deep reinforcement learning (DRL) approaches. Specifically, we present a new algorithm for a policy gradient in TMDPs by a simple extension of the proximal policy optimization (PPO) algorithm. We demonstrate this on a real world multiple objective navigation problem with an arbitrary ordering of objectives both in simulation and on a real robot.
# Backward Imitation and Forward Reinforcement Learning Via Bi-Directional Model Rollouts
## Keywords:
- Reinforcement Learning
- Imitation Learning
- Agent-Based Systems
## Abstract:
Traditional model-based reinforcement learning (RL) methods generate forward rollout traces using the learnt dynamics model to reduce interactions with the real environment. The recent model-based RL method considers the way to learn a backward model that specifies the conditional probability of the previous state given the previous action and the current state to additionally generate backward rollout trajectories. However, in this type of model-based method, the samples derived from backward rollouts and those from forward rollouts are simply aggregated together to optimize the policy via the model-free RL algorithm, which may decrease both the sample efficiency and the convergence rate. This is because such an approach ignores the fact that backward rollout traces are often generated starting from some high-value states and are certainly more instructive for the agent to improve the behavior. In this paper, we propose the backward imitation and forward reinforcement learning (BIFRL) framework where the agent treats backward rollout traces as expert demonstrations for the imitation of excellent behaviors, and then collects forward rollout transitions for policy reinforcement. Consequently, BIFRL empowers the agent to both reach to and explore from high-value states in a more efficient manner, and further reduces the real interactions, making it potentially more suitable for real-robot learning. Moreover, a value-regularized generative adversarial network is introduced to augment the valuable states which are infrequently received by the agent. Theoretically, we provide the condition where BIFRL is superior to the baseline methods. Experimentally, we demonstrate that BIFRL acquires the better sample efficiency and produces the competitive asymptotic performance on various MuJoCo locomotion tasks compared against state-of-the-art model-based methods.
# BIMRL: Brain Inspired Meta Reinforcement Learning
## Keywords:
- Reinforcement Learning
- Cognitive Modeling
- Deep Learning Methods
## Abstract:
 Sample efficiency has been a key issue in reinforcement learning (RL). An efficient agent must be able to leverage its prior experiences to quickly adapt to similar, but new tasks and situations. Meta-RL is one attempt at formalizing and addressing this issue. Inspired by recent progress in meta-RL, we introduce BIMRL, a novel multi-layer architecture along with a novel brain-inspired memory module that will help agents quickly adapt to new tasks within a few episodes. We also utilize this memory module to design a novel intrinsic reward that will guide the agent’s exploration. Our architecture is inspired by findings in cognitive neuroscience and is compatible with the knowledge on connectivity and functionality of different regions in the brain. We empirically validate the effectiveness of our proposed method by competing with or surpassing the performance of some strong baselines on multiple MiniGrid environments.
# Late Breaking Results Poster 2
# Design and Control of a Modular Robotic Wheel for Shape Transformation
## Keywords:
- Mechanism Design
- Motion Control
- Kinematics
## Abstract:
Abstract This study proposes a wheel design and mathematical design for the control of a modular transformable wheel for various stair climbing. Through kinematic analysis of the wheel's 7 bar 2-DOF mechanism, we designed a formula to follow the appropriate control target value to transform the wheel's transformation workspace and various forms.
1. Introduction Numerous mechanisms have been developed and commercialized for robot driving. Among them, the most common wheel is an ideal type of mechanism in terms of speed, stability and efficiency. However, the terrain that can be driven with a simple wheel is limited. Therefore, a lot of research has been done on the mechanism of climbing rough terrain or stairs. Using a variety of environments, we devised a 2-DOF transformable wheel that applies a stair climbing mechanism to the wheel itself and is like running with regular wheels on flat ground. In this paper, we reinterpret this mechanism to manufacture a modular wheel, analyze the working space of the corresponding mechanism, and design a control variable to transform it into a desired shape.
2. Wheel design and Workspace analysis Each wheel is equipped with two motors, including an inner link structure and an outer lobe. The motor is chosen by calculating the required torque through the dynamics analysis. In order to transform into a desired shape, kinematic analysis of the wheel is essential. However, among phi and y on the p5 that determines the overall shape, y consists of a sixth-order equation for q1 and q2, so there is no general solution. Therefore, an algorithm to find an appropriate value among six solutions was applied and interpreted as a functional variable in the kinematic analysis. Through this, the workspace was analyzed and q1 and q2 can be calculated to make the desired shape.
3. Experiment With the above workspace analysis, we experimented with climbing by transforming the wheels to fit the stairs.
4. Conclusions In this study, a kinematic and dynamics analysis for the design and manufacture of a wheel that transform into various shapes based on a 7-bar link and shape control was conducted. As a future study, we plan to apply the impact force damping impedance control when descending stairs.
# Novel Design of a Reconfigurable Omnidirectional AMR Chassis
## Keywords:
- Mobile Manipulation
- Autonomous Agents
- Wheeled Robots
## Abstract:
The omnidirectional reconfigurable chassis is intended to increase the AMR's adaptability to fluctuating environmental circumstances. AMRs often function in a stationary environment, such as a warehouse, where shelving, machinery, containers, and even people might act as obstacles. Rather than having to wait for the situation, a reconfigurable chassis would be able to adjust its specifications to actively avoid obstacles. As such, this research mainly focuses on the following aspects: Affordable omnidirectional steering concepts; Reconfigurable chassis design for cost-efficient AMR.
# MPC-Based Force Control of a 2-Dof Parallel Grinding Manipulator
## Keywords:
- Mobile Manipulation
- Compliance and Impedance Control
## Abstract:
— This paper presents the application of force control based on Model Predictive Control(MPC) to 2-degreeof# freedom(dof) parallel grinding manipulator.The goal is to improve control performance in uncertain environments through the application of MPC to force control on grinding robots.The results of the experiment are shown through an experiment with a designed 2-dof parallel grinding robot. I. INTRODUCTION Grinding is a very dangerous task for workers, so it needs to be replaced by robots. Various grinding robots have been presented by researchers, and methods of controlling them have also been studied [1]. A special environment with a lot of uncertainty and disturbance in grinding work presented limitations in the existing force control method. This research introduce the application of control techniques that incorporate MPC into impedance force control on grinding robots. MPC was grafted to overcome the limitations of impedance force control in grinding work. An experiment was conducted with a 2-dof grinding robot designed to confirm the improved performance of MPCbased force control. II. MODELING OF GRINDING ROBOT Fig. 1 shows the modeling of 2-dof parallel grinding manipulator robot. Fig.1 (a) and (b) represent the appearance of 3d modeling and kinematic modeling, respectively. With the control of the changes in the length of q1 and q2, the desired values of x1 and x2 are created to take the target posture. Figure 2 shows a block diagram of an MPC-based force control. Equation 1 shows a conventional impedance control equation. The MPC method is applied to obtain the optimal M, B, K value. Mxdc + Bxdc + Kxdc = -Ef (1) It improves the existing force control by adding an optimal loop using MPC [2]. III. CONCLUSION The purpose of this study is to solve the problem by using MPC through general force control in a special environment called grinding. Experiments with the designed 2-dof grinding robot will show that the proposed MPC-based force control is effective in special environments with many uncertain disturbances such as grinding work.
# Modeling the Fabric-Type Actuator by Deep Learning on Point Clouds
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Deep Learning Methods
## Abstract:
Flexible actuators are often difficult to model due to viscoelasticity and non-linearity. This letter proposes a method to correct the deformation of the simulated flexible robots approaching the real robot by deep learning on the point cloud. The Long Short-Term Memory (LSTM) can simulate the next frame of actuator deformation from the previous frames of the deformation. It was found that using the encode-LSTM-decoder network can improve the similarity of the deformation of the learned muscle structure with the real deformation, and also worked in correcting the deformation of the unlearned structure. This research can provide a new solution for future flexible robot modeling by the point cloud.
# Machine Learning Techniques for the Identification of a Soft Robotic Neck
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Flexible Robotics
- Soft Robot Applications
## Abstract:
The kinematics problem is specially difficult to face when it comes to soft robots, where the elasticity of the soft links introduces new model uncertainties, among other effects. This paper addresses the identification of the kinematic model of a soft robotic neck using a multilayer perceptron to obtain the relationship between the neck pose and the angular configuration of the three motors that command it.
# Mobile Coverage Planning for Large-Scale Robotic Pen Drawing
## Keywords:
- Motion and Path Planning
- Art and Entertainment Robotics
- Mobile Manipulation
## Abstract:
We present a semi-autonomous robotic pen-drawing system that is capable of creating pen art on a large canvas. Our robotic system relies on a seven-degree-of-freedom impedance-controlled manipulator with a three-degree-of-freedom holonomic mobile platform. Given a 3D drawing path mapped on a 3D target surface, we propose a planning method that finds a set of minimal, discrete configurations for the mobile platform to cover the entire canvas surface while considering the reachability of the manipulator. The drawing is split into multiple sub-drawings according to the found configurations. Our system replicates the spline drawing on the target surface using impedance control, which enables us to compensate for the uncertainty and incompleteness inherent to canvas-surface representations and various robotic and sensor noises. We demonstrate that our system can create visually pleasing and complicated pen art on large surfaces.
# Active Lane Keeping System for Four-Wheel Independent Driving Electric Vehicles
## Keywords:
- Motion and Path Planning
- Collision Avoidance
- Autonomous Agents
## Abstract:
Lane detection plays an important role in building autonomous vehicle systems. This study proposes an active lane keeping system based on a four-wheel independent drive electric vehicle. The proposed electric vehicle is built on a microcontroller that uses a camera to recognize images to control the four-wheel steering. Based on the prototype car, the lane keeping function determines the steering path through the Hough transform. The experimental vehicle adopts the electronic differential algorithm to complete the steering action for any driving requirement. The main contribution of this research is the use of cameras to detect the steering direction of the vehicle, combined with an electronic differential system to make it run properly and autonomously.
# Combinational Objective Function for RRT*-Based Path Replanning in Dynamic Corridor Environments
## Keywords:
- Motion and Path Planning
- Collision Avoidance
- Service Robotics
## Abstract:
This paper addresses the problem of path replanning of a robot which moves along the path generated using the RRT*(Rapidly-exploring Random Tree*) in dynamic corridor environments. If moving obstacles may invade the path, the robot needs to replan its own path to reach the goal point without collisions. This paper proposes a combinational objective function which can be used for the RRT*-based path replanning. In simulations, the proposed objective function was successfully conducted with the RRT*-based path replanning.
# A Learning-Enhanced Parameter Tuner Improves Motion Planner Deployment Scalability in Autonomous Driving
## Keywords:
- Motion and Path Planning
- Deep Learning Methods
- Learning from Demonstration
## Abstract:
The rule-based motion planner is an optimization finding valid future configurations of moving objects, which is popular in the deployment of commercial level autonomous driving systems. Parameters of a rule-based planner provide flexibility in driving behavior generation. But tuning parameters require experience and tremendous time. We present an inverse reinforcement learning inspired critic, extracting the underlying driving common senses by learning from human demonstrations. The critic is integrated into a high efficiency automatic parameter tuning framework, generating an optimal parameter set, reducing 90% of the time cost compared to manual tuning. The proposed method is validated on urban road scenarios with complex traffic environments, including traffic signals, curved roads and interactive obstacles. The effectiveness of the framework is evaluated in speed plan distribution, comfort and robustness. Compared to manually tuning, the automatically tuned planner reaches a better balance between comfort and travel efficiency with significant improvements, where the vehicle comfort score is improved by 117.27% and the robustness of the speed planner is improved from 94.2% to 100%.
# Error Compensation of a Facade Cleaning Manipulator on a Gondola
## Keywords:
- Motion and Path Planning
- Dynamics
- Compliance and Impedance Control
## Abstract:
In modern times, the demand for cleaning and managing the exterior of buildings is increasing. In this study, it is possible to overcome obstacles, remove obstacles, and minimize uncleaned areas through z-axis manipulation and H∞ control based on obstacle position detection. In addition, differences in robot cleaning performance according to Z-axis manipulation and sensor-based control devices are confirmed. In general, fac¸ade-cleaning is done manually on a rope or gondola. This method puts workers at risk. Therefore, the fac¸ade cleaning robot is designed to minimize this risk. However, these have the disadvantage of creating uncleaned areas around obstacles[1]. The purpose is to compensate for the failure that occurs in the gondola-equipped original robot and minimize the filthy area under the obstacle. The types and locations of sensors attached to the z-axis manipulator are shown in Fig.1. Dynamic modeling was performed for the control mechanism and simulation of the z-axis manipulator. H∞ has been applied to the ZAM to create a robust system for disturbance by swaying gondolas. The parameters of the weight function are designed to minimize disturbance based on the input value and the measured output value through simulation based on the dynamic modeling system. Actual cleaning experiments were performed by applying each controller. A comparison of the unwashed area under the obstacle is shown in Fig.2. Cleaning was performed with the original manipulator without ZAM, which left an average of 31 mm of uncleaned area(Fig.2 (a)). A ZAM with an H∞ controller was applied to minimize the unswept area at the bottom of the obstacle. ZAM reduced the existing uncleaned area to 6.5 mm on average (Fig.2 (b)). PID control and H∞ control reduced the uncleaned area to 10.7 mm and 7.5 mm in average the disturbance applied condition. In this study, the ZAM and H∞ controller were applied to a gondola-mounted fac¸ade-cleaning robot to minimize the uncleaned area near the obstacle and disturbance by the gondola swing. In the future, the fac¸ade-cleaning robot with ZAM and H∞ controller will be tested in a real building to verify its actual performance, and more compensation for disturbance through additional controller design will be provided.
# A Preliminary Research on an Angled Spoked Based Robot Running on a Granular Media
## Keywords:
- Motion and Path Planning
- Search and Rescue Robots
- Wheeled Robots
## Abstract:
This paper presents locomotion planning algorithm for angled spoke-based wheel robot called DODO in a seashore environment. Cost function is defined as required revolution of angled spoke-based wheel to travel adjacent nodes. Mathematical model for cost function is estimated by interpolating motor input velocity, roll and pitch angles, and characteristic of terrain. Path planning will be done by applying A* algorithm. Fast access to disastrous site while navigating multiple terrains including rough terrain is necessary in field of search and rescue(SAR). Precedent research had been proven that DODO is capable of locomoting multiple terrains and overcoming obstacles. SAR mission in seashore environment is challenging for mobile robot. Seashore environment includes solid ground, granular media, and ground covered with granular media. Mobile robot experience slippage, and even sinkage in gran# ular media. Slippage slows the speed of mobile robot, and sinkage fails the mission. The mobile robot for SAR in seashore environment should be able to locomote solid ground and granular media and search for the optimal path to the goal. Precedent study proved that angled spoke-based wheels(ASWs) and the mobile robot with ASWs called DODO has ability to locomote both solid ground and granular media[2]. Hardware design of DODO is modified. Two Herkulex DRS-0601 motors are used for steering. Indeed, in order to increase friction at the tip of ASWs Silicone material is used to compose feet. A* algorithm finds the optimal path while minimizing cost function and heuristic function. This study defines cost function as revolution of ASWs to travel adjacent node based on slip ratio. Mathematical model for cost function is estimated by interpolating motor input velocity, roll and pitch angles, slope of terrain, and characteristic of terrain. Each nodes contains elevation and characteristic. Robot orientations and slope of terrain are determined based on the elevation height of adjacent nodes. revolution of angled spoke-based wheel to travel adjacent nodes is estimated based on slip ratio.
# Overcoming Method for a Wheel Legged Robot Using a Rope against Various Terrain in 3D Space
## Keywords:
- Motion and Path Planning
- Wheeled Robots
## Abstract:
This paper introduces the overcoming way of a new wheel legged robot using a rope system against various terrains in 3D space by gait planning. We used a B-spline curve for a stable gait trajectory and a modified ZMP theory for a stable control of center of gravity, respectively.
# Optimized Grasping and Transport Positions for Multi-Robot Systems Using Genetic Algorithm
## Keywords:
- Multi-Robot Systems
- Mobile Manipulation
## Abstract:
Robot formations often extend a single robot’s capabilities or break down complex tasks into simpler subtasks. Thereby, formations consisting of multiple mobile robots can transport objects that would otherwise be too heavy, big, or delicate for a single mobile robot. The initialization of a multi-robot object transport can be achieved by either externally loading the object on the mobile robots or by lifting the object using the mobile robots themselves. We decided to mount a robotic arm onto each mobile platform providing an independent object transport solution. This requires the mobile robots to position themselves around an arbitrary object without any predefined grasping points. Multiple factors have to be considered when determining the grasping points and mobile platform positions for any multirobot object transport. Firstly, the grasping points must be reachable, the stability of the lifted object guaranteed and the weight equally distributed across each robot arm. Without considering these requirements, the object could be damaged due to it falling when a robot arm is overloaded or the balance is lost. Secondly, the mobile platform positions must be close to the grasping positions and the facing orientation should be equal. This reduces the leverage arm and supports an immediate movement. While complying with these requirements, the number of degrees of freedom (DOF) is high as we allow the grasping positions and mobile platform positions to be anywhere on and around the object. To limit the solution space we choose flat objects for our experiments, resulting in a constant z-height for all grasping positions. but still, each grasping and mobile platform position is defined by two translation DOF in the x# and y-plane and one rotation DOF around the z-axis. This results in 6n DOF for the multi-robot system, where n is the number of mobile robots participating in the object transport.
# Multi-Task Scheduling with the A* Algorithm for Antarctic Development and Exploration
## Keywords:
- Multi-Robot Systems
- Planning, Scheduling and Coordination
- Robotics in Hazardous Fields
## Abstract:
In Antarctic areas, multi-robot systems can be used to avoid the risks of human-centered development and exploration. A multi-robot system consists of a lot of technical components such as multi-path planning and multi-task scheduling. This paper proposes a multi-task scheduling method with the A* algorithm on a given map, which can perform efficient multi-task scheduling on multiple destinations. In experimental result, the proposed method was better than other methods in the context of computational time and path length.
# Adaptive Multi-Robot Coordination from Task Specifications
## Keywords:
- Multi-Robot Systems
- Reactive and Sensor-Based Planning
- Planning, Scheduling and Coordination
## Abstract:
Efficiently coordinating different types of robots is an important enabler for many commercial and industrial automation tasks. Here, we present a distributed framework that enables a team of heterogeneous robots to dynamically generate actions from a common, user-defined goal specification. In particular, this allows for the integration of various robotic capabilities into a common task allocation and planning formalism, as well as the specification of expressive, temporally-extended goals by non-expert users. Models for task allocation and execution both consider non-deterministic outcomes of actions and thus, are suitable for a wide range of real-world tasks including formally specified reactions to online observations.
# Monitoring Object Detectors with Depth and Flow Estimates Via a Fuzzy Inference System
## Keywords:
- Object Detection, Segmentation and Categorization
- Robot Safety
- AI-Based Methods
## Abstract:
In this article, we describe an ongoing work on using depth and flow estimates as runtime monitoring signals for object detectors via predefined fuzzy rules and adjustable membership functions built from design time.
# HM-DDP: A Hybrid Multiple-Shooting Differential Dynamic Programming Method for Constrained Trajectory Optimization
## Keywords:
- Optimization and Optimal Control
- Task and Motion Planning
- Motion and Path Planning
## Abstract:
Differential Dynamic Programming (DDP) has been used as an efficient trajectory optimization (TO) solver, with lower computational cost compared with general-purpose nonlinear programming solvers. However, standard DDP cannot handle constraints nor perform reasonable initialization of state trajectory. In this poster, we propose a hybrid DDP variant with a multiple-shooting framework to incorporate inequality constraints and infeasible states initialization. The main technical points are: 1) With inheriting the simplicity of initialization in multiple-shooting settings, a two-stage framework is developed to deal with state and/or control constraints robustly without loss of the linear feedback term. 2) An improved globalization strategy is proposed to exploit the coupled effects between line-searching and regularization, which is able to enhance the numerical robustness. Our approach is tested on constrained tasks and compared with commonly-used TO methods
# Robust Design of a Rope Ascender for High Repeatability
## Keywords:
- Optimization and Optimal Control
- Tendon/Wire Mechanism
- Design and Human Factors
## Abstract:
ABSTRACT In this study, the optimized traction pulley was designed to achieve the high repeatability of winches using flexible ropes, where the traction pulley was evaluated and optimized through two experiments using the Taguchi method.
INTRODUCTION Façade-Cleaning Robots (FCRs) have been developed to perform the cleaning process of exterior walls. Most FCRs use an external winch and steel cable for movement. However, installing a winch on the roof of a building requires a gantry. And steel cables have a large mass. If FCR use ascender(free-end-type winch) and flexible rope it can be installed quickly and easily on any building. However, a slip occurs between the ascender and rope, which could be fatal during position estimation. If the amount of slip is constant, it is possible to improve control through a feed-forward controller. Therefore, high repeatability should be considered to improve the control performance of the FCR using ascender. ROPE SLIP FACTOR FOR WINCHES When t The capstan equation proposed by Euler is applied to a pulley, both slip and nonslip zones are present on the pulley surface. In the slip zone, slip can be determined using Hooke’s law and tension formula. dδslip = εrdθ = 1/(EA) integral T(θ)dθ, where, A denotes the area of the rope, E denotes Young’s modulus, and it can be seen that slip is caused by rope deformation due to the tension difference in the slip zone. ROBUST EXPERIMENT DESIGN PLANNING A.Objective Function and Design Parameters The winch has several design parameters that affect repeatability. In this experiment, three design parameters(pulley diameter, number of grooves, and force of the pressure roller) were selected, B.EXPERIMENTAL METHOD In this experiment, the position error was defined as the slip of the weight module (10kg) when the pulley was rotated by the motor. The performance of the pulley was determined based on the slip, and an experiment was conducted by measuring the position change of the weight module with a linear encoder. the position error was measured at the designated position. The ISO specifications were used to measure the position repeatability of the weight module. Experimental Results: CONCLUSIONS In this study, a pulley was optimized using the Taguchi method to maximize the position repeatability of a winch using synthetic fiber ropes. The optimized pulley demonstrated improved performance by reducing the standard deviation in the position error compared to other pulleys. The results indicate that position repeatability can be achieved and that position error prediction is possible.
# Smooth Spline-Based Trajectory Planning for Semi-Rigid Multi-Robot Formations
## Keywords:
- Path Planning for Multiple Mobile Robots or Agents
- Multi-Robot Systems
- Nonholonomic Mechanisms and Systems
## Abstract:
We present an approach for smooth trajectory planning in semi-rigid nonholonomic mobile robot formations using Bezier-splines. Unlike most existing approaches, the focus is on maintaining a semi-rigid formation, as required in many scenarios such as object transport, handling or assem# bly. We use a Relaxed A* planner to create an optimal collision-free global path and then smooth this path using splines. The smoothed global path serves to create target paths for every robot in the formation. From these paths, we then calculate the trajectories for each robot. In an iterative process, we match the velocities of the robots so that all trajectories are synchronized, and the dynamic limits of all robots are maintained. We provide experimental validation, which confirms no violation of the dynamic limits and shows an excellent control performance for a system of three robots moving at 0.1 m/s to 0.7 m/s.
# Measuring Prediction Reliability on 6D Object Pose Estimation
## Keywords:
- Perception for Grasping and Manipulation
- Deep Learning in Grasping and Manipulation
## Abstract:
Estimating the uncertainty of 6D object pose estimation is essential for the field of robotics; Since sensor fusion with heterogeneous sensor data is commonly required, measuring the prediction reliability becomes crucial. In this paper, we introduce the uncertainty estimation approach based on the primitive associated 6D object pose estimation method. This approach predicts the uncertainty of the estimated 6D object pose on all object types; asymmetrical and symmetrical objects. We validate that the 6D object pose and the associated uncertainty correlate positively.
# TeRF: Thermal Radiance Field for Rendering Depth in Transparent Objects
## Keywords:
- Perception for Grasping and Manipulation
- Visual Learning
- Recognition
## Abstract:
Research on object manipulation using robots has been steadily progressing. Transparent objects hardly appear clearly in RGB images due to reflection and refraction; therefore, most of studies have targeted opaque objects. In particular, the depth sensor has a limitation on recovering depth of transparent objects due to noise. In this paper, we propose Thermal Radiance Field (TeRF) to obtain depth on transparent objects using a powerful thermal imaging camera.
# A Variable Impedance Scheme for Flexible-Joint Robot Interaction and Tracking Control Based on Power-Shaping Signals and Minimal Modelling
## Keywords:
- Physical Human-Robot Interaction
- Flexible Robotics
- Compliance and Impedance Control
## Abstract:
This work proposes a novel scheme, based on power-shaping control (PSC), that can endow flexible-joint robots with both tracking, and interactional, capabilities. In virtue of relying upon the PSC method, this approach entails minimal modelling requirements restricted to computation of the gravitational torque vector, and motor dynamics terms (available in manufacturer datasheets). Hence, it distinguishes itself by obviating the need for calculation of the more cumbersome link dynamics elements, such as the Coriolis and link inertia matrices. In contrast to analogous schemes, the highest-order term required by the proposed design is the third derivative of the motor position vector. Moreover, the propounded framework enables utilisation of non-collocated feedback for enhanced tracking accuracy, as well as variable impedance control (VIC) for interactional performance augmentation. The aforesaid features are effectuated without any reliance on coordinate transformations, thereby leaving the original dynamical model intact. Experimental results involving a flexible-joint robot (Baxter) corroborate the theoretical analyses, while demonstrating that interactional and tracking performance improvements can be achieved via the proposed scheme.
# A Portable Upper-Limb Home Fitness Device Based on Twisted String Actuation and Elastic Bands for Effective Exercise
## Keywords:
- Physical Human-Robot Interaction
- Mechanism Design
- Tendon/Wire Mechanism
## Abstract:
This paper introduces a portable chair-shaped upper-limb home fitness device that allows inducing various resistance profiles. A compact and light actuation module design was achieved while covering resistance up to 100 N for each left and right arm by adopting twisted-string-actuation (TSA) with elastic bands. The resistance is controlled by the length of the elastic band adjusted by the TSA. The proposed controller variates the resistance across the joint range-of-motion (ROM) to make the workout more challenging through the full ROM.
# 2-DOF Power Assist Suit for Lower Back Twisting Motion: Tornade
## Keywords:
- Physically Assistive Devices
- Wearable Robotics
- Physical Human-Robot Interaction
## Abstract:
This paper presents our developed 2-DOF power-assisted suit (PAS).	This PAS not only assists with a power in conventional lifting and lowering motions, but also supports a twisting motion to prevent a wearer from a lower-back injury based on a mechanism of a differential gear box. Therefore, an implemented prototype of the 2-DOF PAS was named Tornado. Experiments were conducted to detect the wearer’s force applied to the PAS using the disturbance observer (DOB). In these experiments, the PAS was tested to support his/her twisting motion using positional tracking control. The results of the DOB estimate were evaluated and discussed for assisting power in the twisting motion effectively.
# Novel Online Terrain Classification Algorithm for Mobile Robots
## Keywords:
- Recognition
- AI-Based Methods
- Wheeled Robots
## Abstract:
Terrain classification plays an important role in reliable mobile robot navigation problems, since it enables the establishment of algorithms that adaptively vary their parameters based on the identified environment. Methods based on LiDAR and camera are widely used for terrain classification, but these systems have high computational requirements for embedded systems. Accelerometers, which offer a low-cost alternative for the problem, are also widely used in relevant methods. However, the evaluation of gyroscopes and magnetometers in such applications were not performed yet. During previous research, frequency-domain (FD) analysis was tested for terrain classification using accelerometer and gyro data [1]. Existing algorithms mostly rely on FD analysis. The development of a proper online algorithm with both low computational and memory requirements can enable the usage of a low-cost embedded system to run the entire navigation algorithm. The proposed online algorithm applies time-domain (TD) analysis-based features extracted from the raw sensor data separately for all sensor axes in fixed size segments, which are forwarded to a multi-layer perceptron classifier. The feature set consists of nine features, which do not require transformation from TD to FD and the storage of the measurements in the window, thus, they are well suitable for an online algorithm [2]. The algorithm was tested on real measurement data, which were collected using a prototype measurement system. The constructed robot is equipped with three three-axis sensors, an accelerometer, a gyroscope, and a magnetometer. Data acquisition was performed using two different speeds for six different terrain types, which can be seen in Fig. 1. The applied sampling frequency was 400 Hz for the inertial sensors and 100 Hz for the magnetometer. To explore the capabilities of the sensors, 21 datasets were constructed based on three processing window sizes (0.32 s, 0.64 s, and 1.28 s) and used sensor types (separately, in pairs, and fused together). Measurements using both speeds were incorporated in the datasets. The achieved results using the proposed algorithm are compared with the FD feature set proposed in [1]. The obtained classification efficiencies on validation data can be seen in Fig. 2. The obtained results show that the TD feature set outperforms the FD features in most datasets, except when accelerometer and magnetometer data are used alone, but for these sensors not all TD features are applicable due to the varying offsets. The gyroscope provides significantly higher results (97.57% using the largest segment) than the other two sensors. The efficiencies can be slightly increased by fusing the data of different sensors (up to 98.61%), but this also increases the number of inputs of the classifier, which leads to increased memory consumption and computation time. The proposed method provides reliable data for adaptive navigation algorithms of robots operated in varying terrains.
# 1 Billion Redundant Manipulator Solutions for Systematic Goal Selection During Path Planning Tasks in Confined Spaces
## Keywords:
- Redundant Robots
- Motion and Path Planning
- Robotics in Hazardous Fields
## Abstract:
A manipulator with redundancy presents a challenge to a controller: any required end-effector pose has a continuum of manipulator configurations from which a singular solution must be chosen. Often, this is achieved by incorporating some element of randomness to perform the inverse kinematics (IK). In confined or cluttered environments, however, the informed selection of a manipulator goal configuration is critical to planning success. We use a database to systematically select a goal during redundant manipulator path planning in a confined glovebox space.
# Data Augmentation in Prioritized Subset to Improve the Performance of Offline Reinforcement Learning
## Keywords:
- Reinforcement Learning
- AI-Enabled Robotics
- Machine Learning for Robot Control
## Abstract:
In this study, we propose a new data augmentation methodology for offline reinforcement learning (RL). Our proposed method performs data augmentation by selectively choosing data points from sparse subsets of the original dataset to specifically target the data region that is insufficient in the original dataset. For such a process, variational autoencoder (VAE) is used to represent the subsets of the original dataset in the latent space from which the data is sampled and decoded to generate newly augmented data. As the latent space of VAE captures the data distribution of the original data, the augmented data is highly likely to follow the original distribution, which prevents severe out-of-distribution data that could degrade learning performance. The evaluation results show that our method successfully improves the performance of the baseline offline RL algorithm.
# Ensemble Inverse Model Network Based Disturbance Observer for Reinforcement Learning
## Keywords:
- Reinforcement Learning
- Machine Learning for Robot Control
- AI-Based Methods
## Abstract:
Ensemble inverse model network based disturbance observer (EIMN-DOB) are proposed to improve the robustness of the policy network (PN) as a result of reinforcement learning (RL) without physics based model. EIMN-DOB uses the ensemble model of the inverse model network (IMN), which acts as a nominal inverse model, and can estimate and cancel model uncertainty and disturbance like DOB without physical model. Because EIMN is trained from the data used for RL training, additional training data is not required to represent the inverse model. Experiments have confirmed that PN of Soft Actor Critic (SAC) combined with EIMN-DOB maintains control performance even in the presence of disturbances in halfcheetah task in the Mujoco physics engine. So, minimizing the sim-to-real gap of RL is expected, when the PN is used with EIMN-DOB in the real system.
# Safe Reinforcement Learning for Robot Control Using Control Lyapunov Barrier Functions
## Keywords:
- Reinforcement Learning
- Robot Safety
- Machine Learning for Robot Control
## Abstract:
强化学习（RL）对于复杂的机器人控制任务具有令人印象深刻的性能。限制RL在物理机器人中应用的主要挑战是缺乏安全保障。在安全RL中，流行的策略涉及修改标准RL的策略优化过程，以使用信任区域等方法同时推理任务奖励和约束，优化拉格朗日松弛或构造Lyapunov函数。上述方法必须训练额外的批评者来估计未来违反约束的概率，这需要更多的数据来近似。本文首先探讨了控制Lyapunov屏障函数（CLBF），这是一个统一的证书，仅基于数据分析闭环可达性和安全性，而无需显式使用动态模型。然后，我们提出了一种无模型的演员-评论家RL算法，通过构建CLBF证书来找到一个控制器。所学控制器满足基于数据的随机非线性系统可达性和安全条件近似，特征为约束马尔可夫决策过程。即使对于具有非凸约束的非线性系统，该方法也能提供可达性和安全性保证，而使用模型预测控制等最优控制方法很难实现。我们通过直接将模拟器中学习的控制器部署到物理机器人来...
# Robotic Bricklayer: A Multi-Robot System for Building Activity
## Keywords:
- Robotics and Automation in Construction
- Multi-Robot Systems
- Cooperating Robots
## Abstract:
In recent years robotic solutions for masonry are attracting the attention of various researchers and of the market. Several bricklaying platforms have been proposed. Most of the solutions proposed so far adopt the classical assumption of 'rigid robot' which results in a large weight of the robots w.r.t. the loads that it is able to manipulate and therefore most of them did not pass the prototype status. In this work, we propose and analyze an innovative bricklaying concept to lay large and heavy sand-lime blocks which overcomes this problem. The core idea behind the proposed solution is the use of two cooperating robotic sub-units: a 'non-rigid' crane in charge of the macro-movement and of holding most of the weight of the block, and a rigid robot for the fine placement of the block. We demonstrate the feasibility and the effectiveness of this concept on a full-scale demonstrator based on an overhead crane and a KUKA LBR IIWA14R820.
# Volumetric Change Assessment Using Multi Session SLAM Toward Construction Monitoring Automation
## Keywords:
- Robotics and Automation in Construction
- Range Sensing
- SLAM
## Abstract:
Volumetric change calculation is necessary for quantitative evaluation of construction progress. Existing volume change evaluation methods generate a topographical mesh with dense aerial images obtained by unmanned aerial vehicles (UAVs). Complementary to UAVs, unmanned ground vehicles (UGVs) with Light Detection and Ranging (LiDAR) systems are widely used for their ability to navigate obscured areas. However, the point cloud UGVs achieve poses challenges such as sparsity, occlusion, and viewpoint limitation. In this paper, we propose a method to calculate the volumetric changes of two sparse point cloud maps with the time difference in an analytical way. This is achieved by first detecting surface point changes between two maps, and then selecting a specific region of interest (ROI) to fit planes and perform double integration over the range of the ROI.
# How to Increase Safety and Performance of Emergency Departments with AI-Guided Robots and IoT? Lessons Provided to European Hospitals by Polish Pilot of Flagship Horizon 2020 ODIN Project
## Keywords:
- Robotics and Automation in Life Sciences
- AI-Enabled Robotics
- Intelligent Transportation Systems
## Abstract:
I.	MOTIVATION Hospitals are critical for community safety, particularly under the unfavourable conditions of various disasters (e.g. COVID-19 pandemic). Unfortunately, the load of work that their Emergency Departments (EDs) are exposed to is rising rapidly, reflecting global problems of ageing, and related multimorbidity [1]. This reduces EDs’ performance and jeopardises their safety. In order to help this, there is a need to introduce new solutions, such as artificial intelligence (AI), robots and internet of things (IoT). Such cutting-edge technologies are tested within ODIN Project [2], a research programme, which aims at leveraging AI-based technology to transform the future of health care delivery in Europe. Within this framework a specialized AI-guided robot will be used in ED of one of teaching hospitals in Lodz, Poland to deliver samples of biological material from patients suspected for Clostridium difficile infection. The use of robotic system may not only save precious time of ED staff, yet also to increase their safety. 
II.	PROBLEM STATEMENT Identified requirements of this Use Case define the top-line architecture of the system. However, there is a need to design the system in more details, in order to optimise its performance, and adjust it to the needs of its final end-users. Therefore, a process of co-creation has been employed, with major stakeholders involved.
III.	MAIN RESULTS In designing the final architecture of the robotic system we followed the Quadruple Helix Innovation Model [3], inviting scientists, healthcare professionals, patients and administration of the hospital to co-create the final solution. We have employed a set of cohesive methods for optimizing and configuring the healthcare technology. A communication and legal strategy was established together with the set of questionnaires and workshops for interdisciplinary teams to introduce the solution into the hospital environment. Measurements of stakeholders’ attitude toward robotic system were taken twice, before and after the co-creation session. In consequence, the final design of the system was detailed, being informed by the preferences of its future end-users. We have proven that this approach contributed to better acceptance of the new intervention and increased the chances of adoption of this novel technology in ED settings. These results bring an important lesson for policymakers and healthcare managers. In order to smoothly introduce novel technology such as AI, robots and IoT into hospitals, it is highly advisable to take into consideration the perspective of target users, and particularly, the healthcare professionals and patients. Doing so before the procurement process is initiated allows also to avoid unnecessary costs and get the best value for money.
IV.	REFERENCES
1.	Morley C. et al. PloS One, 2018; 13(8), e0203316. 2.	ODIN Project. https://odin-smarthospitals.eu 3.	Kotter E. et al. Eur Radiol 2021; 31, 5–7.
# Ultra-Wide-Angle Stereo Vision System for Snake Robot: Sidewinder for Forward and Panoramic Vision Tasks
## Keywords:
- Search and Rescue Robots
- SLAM
- Omnidirectional Vision
## Abstract:
This study presents a unique stereo vision system, namely Sidewinder, for a snake-type rescue robot. Sidewinder is characterized by multi-functional use of ultra-wide-angle and high-definition input images. Two types of image mapping methods are proposed for forward and panoramic vision tasks. Experiments were conducted for a stereo visual SLAM and for detection of persons in need of rescue. Both tasks performed well in verification experiments.
# Multiple LIDAR-Based SLAM System for an Air-Purifying Robot in Dynamic Environments
## Keywords:
- SLAM
- Sensor Fusion
- Service Robotics
## Abstract:
Simultaneous Localization and Mapping (SLAM) in dynamic environments is a challenging problem and yet has not been thoroughly studied. This paper proposes a multiple LiDAR (Light Detection And Ranging)-based SLAM system for an air-purifying mobile robot to overcome mapping and localization problem in dynamic scenarios. Our system executes transformation and merging of laser scans from multiple LiDARs according to the geometry of real robots and SLAM in real-time. The proposed method was implemented with Robot Operating System (ROS) and Point Cloud Library (PCL).
# Comparison and Analysis of SLAM Algorithms for Low-Cost LiDAR-Based Small Robot Systems
## Keywords:
- SLAM
- Swarm Robotics
- Mapping
## Abstract:
In small robot systems with a low-cost LiDAR (light detection and ranging), it is difficult to perform SLAM (simultaneous localization and mapping) due to the lack of scan data generated from limited detection distances and angles. Despite the limitations, it is necessary to evaluate the SLAM performance to use the small robot systems appropriately. This paper presents the comparison and analysis of SLAM algorithms for low-cost LiDAR-based small robot systems. Experimental results showed that most SLAM algorithms were conducted without divergence, but inevitable errors due to the lack of scan data have occurred.
# An Autonomous Mobile Robot Generating Context-Aware Description Using Its Observation and Memory
## Keywords:
- Social HRI
- Natural Dialog for HRI
- Long term Interaction
## Abstract:
We propose an autonomous mobile robot that generates context-aware description. Our system generates necessary and sufficient language description to transmit the robot's observation ans internal states using observation changes.
# Active Suction Cup with Detecting Softness
## Keywords:
- Soft Robot Applications
- Grippers and Other End-Effectors
- Object Detection, Segmentation and Categorization
## Abstract:
This study proposes a technology to expand the range of applications of suction cup without disturbing the external environment. We have developed a suction cup operated by an electro-chemical dual-transducer (ECDT) that has two functions: silent pumping and sensing of flow rate. This suction cup is capable of sensing contact with the object and its own softness, as in addition to grasping, holding, and releasing the object.
# Fractional Order Control of a Kresling Pattern Origami Soft Link
## Keywords:
- Soft Robot Applications
- Robust/Adaptive Control
- Modeling, Control, and Learning for Soft Robots
## Abstract:
This paper presents a robust control approach for an origami-based self-scaling soft robot following a low-cost approach. Despite the limitations of low-cost devices, a very competitive performance has been obtained thanks to the origami structure and the robust control developed specifically for this system. For the robust control of the robot, a fractional order controller is proposed, where integral and derivative actions are generalized to fractional order. This type of controller provides superior flexibility, allowing the control scheme to outperform its integral order counterparts and meet robustness specifications. Simulation and experimental results are provided to show the robustness achieved by this type of control solution, which validates the two contributions proposed in the paper: the robot model and the control strategy.
# Design of the Inflatable Robotic Arm Deployed by Rolling
## Keywords:
- Soft Robot Applications
- Soft Robot Materials and Design
- Soft Sensors and Actuators
## Abstract:
 Robots are gradually entering our lives in various forms, from robotic vacuum cleaners to service robots. Accordingly, safety, portability, and cost-efficiency are emerging as requirements of robots, especially for in-home mobile robots. Soft robots have been proposed as in-home mobile robots due to their capabilities such as softness, compliance, and reversible shape deformation [1]. So, research on the integration of soft robots and hard robots, especially hard mobile robots, has been developed [2]. Inflatable robots are promising approaches due to their lightweight, flexibility, deformability, and easy fabrication. Then, many kinds of inflatable robotic arms were developed, but it was difficult to maximize these advantages since rigid parts were included in. We propose an inflatable robotic arm that is entirely made of compliant material and can be rolled and packaged in a small volume. The prototype is capable of pick-and-place objects with a simple inflatable gripper.
# Salp-Inspired, Modular, Soft-Bodied Design for Underwater Robotics
## Keywords:
- Soft Robot Materials and Design
- Biologically-Inspired Robots
- Multi-Robot Systems
## Abstract:
We present the design of a modular soft robot for underwater applications. The robot is inspired by salps, oceanic sea creatures which can swim alone or in long chain-like colonies. The RoboSalp can connect into 1D and 2D colonies and shows potential for sophisticated locomotion and applications including environmental remediation.
# Structure-Based Solution for Securing Inner Channels of Soft Growing Robots
## Keywords:
- Soft Robot Materials and Design
- Soft Robot Applications
- Soft Sensors and Actuators
## Abstract:
Securing the inner channels of soft growing robots so that the robot can attach wired sensors to the tip and transport fluids through the interior is considered one of the main problems in the field of soft growing robots. However, since the pressure inside the robot tightens the inner channel, it is impossible to secure the inner channel without additional hardware and control methods. In this study, a structure-based solution for securing the inner channels is proposed. We investigated the self-restoring behavior of the axially attached inflated tubes. In addition, we proposed a mechanism to secure the inner channel using the self-restoring behavior of the structure. An experimental study was conducted to measure the force enduring capability of the inner channel of the proposed mechanism.
# Design of Dielectric Elastomer Robot Powered by Triboelectric Nanogenerator
## Keywords:
- Soft Robot Materials and Design
- Soft Sensors and Actuators
- Soft Robot Applications
## Abstract:
Dielectric elastomer actuators (DEAs), which are actively used as soft robots, require high voltage when operating. On the other hand, a triboelectric nanogenerator (TENG), an energy harvester that converts mechanical energy into electrical energy, generates high voltage output. Therefore, TENG has the potential to directly operate DEA and it is possible to design a self-powered robot system that is operated by mechanical energy. In this study, we propose a flapping/crawling DEA robot powered by TENG.
# Wearable Tactile Sensor for Soft Robot
## Keywords:
- Soft Sensors and Actuators
## Abstract:
This study proposes a wearable tactile sensor for a soft robot using a photoreflector. The tactile sensor is attached to a part of a soft robot such as a finger and detects force by measuring the deformation of the soft body induced by force. We prototyped the tactile sensor and attached it to a soft finger. The experimental result revealed that the output of the tactile sensor linearly increased to the applied force.
# A Skill Programming Environment for Industrial Robots
## Keywords:
- Software, Middleware and Programming Environments
- Control Architectures and Programming
- Intelligent and Flexible Manufacturing
## Abstract:
I) Motivation Robotic manufacturing has been an increasingly active field for years but remains a major challenge in industry 4.0. While current technologies fulfill the requirements of large-scale manufacturing, smaller batches with frequent process revisions are significantly harder to automatize. Reasons for this slower adoption arise from the limitations of Programmable Logic Controllers (both in terms of development time and limited capabilities), which are accentuated by its lack of reusability across tasks and hardware. This observation led to the paradigm of robotic skills, which designates high-level robot tasks [1] [2]. Our approach investigates a skills framework named SPEIR (Skill Programming Environment for Industrial Robots), focusing on intuitive programming and task reuse. 
II) Problem statement The main requirement of robotic skills is reusability. For this, a standard robotic API was designed in order to enable robot interoperability with a set of pre-defined low-level functions. It is incrementally built, which is especially relevant for adding modern force-position control patterns. Skills, as implemented in SPEIR, can be composed to any level of hierarchy in order to build new complex skills from existing, simpler ones. Composition structures include sequencing, parallelization, conditional branching, and error recovery. This last structure proved to be critical to implement autonomous learning and optimization tasks. Skills require a teaching phase, where the user provides the skill with parameters. Geometric parameters (poses and trajectories) can be tedious to measure and input, therefore motion-capture programming by demonstration was integrated, with an offline variant and a teleoperation variant. An off-the-shelf HTC Vive setup was used. An autonomous optimization feature was developed in order to overcome transfer issues and demonstration inaccuracies, without requiring the user to finetune parameters by oneself. Sample-efficiency, among other criteria, favored Tree-structured Parzen Estimators and Covariance Matrix Adaption – Evolutionnary Strategy as algorithms of choice. A comprehensive graphical user interface provides an intuitive workflow for operators.
III) Main results SPEIR was successfully used to quickly and intuitively implement multi-robot, high level skills for the following applications : # Bimanual fabric manipulation taught with motion capture teleoperation. # High precision gear assembly (10 µm clearance) with autonomous optimization. # E-waste disassembly, as part of the Robothon® Grand Challenge. # Food packaging tasks. 
[1] C. Lesire, D. Doose et C. Grand, «Formalization of Robot Skills with Descriptive and Operational Models,» at 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2020. [2] M. R. Pedersen and al, «Robot skills for manufacturing: From concept to industrial deployment,» Robotics and Computer-Integrated Manufacturing, vol. 37
# Onboard Scheduling and Execution to Address Uncertainty for a Planetary Lander
## Keywords:
- Space Robotics and Automation
- AI-Based Methods
- Autonomous Agents
## Abstract:
The Europa Lander Mission Concept presents a number of challenges. The current mission concept would land with a fixed amount of energy, an expected mission lifetime of approximately 30 days, and would be able to communicate with the Earth in less than 42 out of every 84 hours due to the Europa-Jupiter orbit. Additionally, planned activities such as trenching and sampling, will interact significantly with a largely unknown environment and therefore may encounter failure or highly variable duration or energy consumption when executing. All of these factors present challenges for a conventional ground operations paradigm. We describe advanced prototyping of onboard autonomy soft# ware to address such challenges. Onboard event driven execution and rescheduling offer promise to enable the lander to adjust to execution feedback without incurring costly ground interaction. We describe prototyping with the TRACE execution system and the Mexec scheduling and execution system. We show how these autonomy systems can address: uncertainty in domain modeling, stochasticity at execution time, and the presence of exogenous events.
# Dynamic Targeting to Improve Earth Science Missions
## Keywords:
- Space Robotics and Automation
- Reactive and Sensor-Based Planning
- Planning, Scheduling and Coordination
## Abstract:
Fundamental physics of remote sensing dictates that high spatial resolution at reduced size (and therefore power, cost) forces reduced swath. This places a premium on measurement on acquiring the highest science value data enabled by pointable instruments in Earth science missions. Dynamic targeting (DT) can improve the efficiency of conventional expensive narrow swath instruments. DT is a decision-making approach that leverages information from a lookahead sensor to identify targets for the primary instrument, which can then be pointed or reconfigured to improve science yield. Most related works have focused on screening cloud cover and other poor observing conditions from airborne and spaceborne missions. This work is an extension of a NASA study for the Smart Ice Cloud Sensing (SMICES) satellite concept, whose objective is to employ Artificial Intelligence (AI) to make better decisions while collecting dynamic measurements of ice clouds.In this work we show that DT is applicable across a wide range of missions and can enable far better coverage of transient phenomena. 
We formulate DT as a pointing planning problem. The goal is to observe scientific phenomena of interest more often while screening poor observing conditions and respecting the mission's energy constraints. We have developed several DT algorithms that draw from a rich heritage of decision-making methods involving AI, operations research, and heuristic search. We compare them against: a) a baseline (i.e., lower bound) that is representative of most Earth observing missions, and b) an optimal method (i.e., upper bound) that is generally not deployable on missions as it requires unrealistic instrument and computational resources. 
The algorithms are evaluated in a simulation study that consists of an Earth-observing satellite with two onboard instruments: a primary radar with a narrow swath (245 km), and a secondary radiometer with a wider field of view (680 km) that can only be used for lookahead. General Mission Analysis Tool (GMAT) was used to simulate and generate realistic satellite trajectories. The simulation study consists of the following mission scenarios and datasets: 1) the objective is to observe ice storm clouds and data comes from the Global Weather and Research Forecasting (GWRF) model covering two different regions, the Caribbean (tropical) and the Eastern coast of the United States (non tropical); 2) the goal is to observe storm clouds and global data comes from the Global Precipitation Measurement (GPM) mission; and 3) the purpose is to acquire clear-sky measurements and data comes from global cloud fraction products from the Moderate Resolution Imaging Spectroradiometer (MODIS).
The main results from the four experiments indicate that DT collects substantially more observations of interest than the baseline, while consistently achieving a performance that is relatively close to optimal.
# Experimental Study on Strategies of Multi-Quadrotor Persistent Coverage with Environmental Hotspots
## Keywords:
- Swarm Robotics
- Cooperating Robots
- Distributed Robot Systems
## Abstract:
Persistent coverage is a recursive problem of acquiring the latest information over a decaying environment. This study introduces strategies for persistent coverage with hotspots and numerous experimental comparisons as empirical analysis. The hot spots assimilate the requirement of information quality in certain regions of the environment. The desired quality of information is achieved by varying the altitude of quadrotors accordingly. Communication protocols and trajectories with cost functions are designed to maintain expected coverage quality in these different strategies. The presented approaches are validated by thorough simulations and extensive experimental studies with various cases of parameters considering quadrotor dynamics.
# Simultaneous Use of Autonomy Guidance Haptic Feedback and Obstacle Avoiding Force Feedback for Mobile Robot Teleoperation
## Keywords:
- Telerobotics and Teleoperation
- Autonomous Vehicle Navigation
- Haptics and Haptic Interfaces
## Abstract:
Even though force feedback of the distance to obstacles and guidance force from autonomy can improve the performance of mobile robot teleoperation, it is difficult to use both force feedback simultaneously. This is because not only the force feedback of distance to obstacles and the autonomy guidance force cancel out each other when those forces have different directions, but also the interaction force and the virtual guidance force cannot be distinguished, making it difficult for the operator to be aware of the situation. In this paper, we propose a method to solve this problem by assigning different force magnitudes through the different stiffness for each method and for the simultaneous use of both methods. The proposed method is verified through mobile robot teleoperation experiments on the simulation environment, and the experiment result shows that the proposed method performed better than when only one type of force feedback is used.
# Haptic Rendering Architecture for Wheeled Vehicle Shared Teleoperation on Unstructured Environments
## Keywords:
- Telerobotics and Teleoperation
- Haptics and Haptic Interfaces
- Task and Motion Planning
## Abstract:
Improving the operator's senses is vital for teleoperation to suggest an appropriate path to the rover, but intuitively representing remote data is challenging. We propose a novel haptic feedback strategy using the distribution of LiDAR point clouds. Rover uses LiDAR to generate haptic fields with compressed obstacle and ground information, from which remote operators receive haptic feedback. Experiments on reaching the target point of the mobile robot confirmed that the similarity between the suggested path and the ideal path is higher when the proposed haptic feedback is provided.
# Comparison of Remote and Local Virtual Fixture and Method to Improve Performance of Them
## Keywords:
- Telerobotics and Teleoperation
- Haptics and Haptic Interfaces
- Virtual Reality and Interfaces
## Abstract:
Virtual Fixture is one of the efficient methods to improve task performance during Teleoperation. There is remote and local virtual fixture depending on their generation method. Since each type has different haptic feedback characteristics, the operator can select differently depending on the task purpose to obtain optimal results. However, there has been no research about usage references. Therefore, in this paper, we find which virtual fixture is better to use for each task by comparing it. Furthermore, there are cases to use non-optimal virtual fixtures due to existing problems of each type even if the operator wants to use an optimal one. Therefore, we also present a method to solve their problems.
# Keyframe Selection, Communication, and Prediction for Teleoperated Driving Systems
## Keywords:
- Telerobotics and Teleoperation
- Intelligent Transportation Systems
- Networked Robots
## Abstract:
Autonomous driving systems face significant challenges, where human intervention is still needed when the situation becomes so complicated and beyond the autonomous vehicle's (AV) capability. Thus, teleoperated driving is important to free the AVs -# human operators remotely control AVs via wireless networks.
However, good communication performance cannot always be guaranteed in all situations. Limited radio bandwidth and dynamic time delay are two major challenges in teleoperated driving. In [1], a novel rate-quality model has been proposed to dynamically change the bitrates and resolution of the video streaming according to the dynamic bandwidth. In [2], a latency visualization method was developed to mitigate the effect of dynamic time delay on teleoperated driving. %However, they can only address one communication challenge at a time.
In this poster, we propose a new framework to mitigate the effects of both limited bandwidth and dynamic time delay using a keyframe selector, based on AV designed by [3], and a video predictor. We evaluate our methodology in simulated scenarios using CARLA [4].
# User Evaluation of 5 DOF Manipulator for Teleoperation Tasks
## Keywords:
- Telerobotics and Teleoperation
- Performance Evaluation and Benchmarking
- Human-Centered Robotics
## Abstract:
Majewicz [1] and Wang [2], worked on the best teleoperation approach for non-holonomic systems. From the case of steering needles used in clinical procedures, they conducted a study to analyze users’ most preferred space of operation using a simulated clinical environment. Teleoperators draw the attention between people and robots in scenarios where service tasks can be performed remotely. In this paper, we empirically evaluate users’ comfort level and preference in teleoperating a robotic manipulator to perform operations such as pick and place, and stacking. The performance of a person controlling a remote manipulator is hugely affected by factors such as interface types, task types, and interface-task combinations [5]. In our work, users control the manipulator using Cartesian control, Joint control and view from various cameras for visibility. We validate our results by conducting studies with 21-63 years aged users across multiple countries. Experiment-1 consisted of 8 users and Experiment-2 consisted of 7 users. We observe that 73% of the users prefer using Cartesian space as the reference control, 57% needed additional viewpoints for better visibility in experiment-1 that reduced to 29% in experiment-2 with different positioning of the same cameras. In addition to time analysis, we collected the feedback provided by the users.
# Spatial Reorientation Control of an Underactuated Hybrid Tail-Wheel Robot Using Quadratic Programming
## Keywords:
- Underactuated Robots
- Biologically-Inspired Robots
- Motion Control
## Abstract:
Inertial appendages (e.g., tails and wheels) have shown their reorientation capability to enhance robots' mobility while airborne. The tail, especially with two Degrees of Freedom (DoFs), is normally subject to its limited Range of Motion (RoM). Although the reaction wheel circumvents this limitation, its efficiency has been shown lower than the tail in terms of inducing Moment of Inertia (MoI). In literature, to our knowledge, only one type of inertial appendages has been used on terrestrial robots in the air, e.g., either using a tail on the hexapedal robot RHex or using a reaction wheel on the jumping quadruped robot SpaceBok. In this abstract, to benefit from both unlimited RoM and efficient MoI inducing, we propose to combine a 1-DoF tail and a reaction wheel together for spatial reorientation (regulating robot body's 3D orientation). Motivated by this, a hybrid tail-wheel robot is built, i.e., the tail creating the roll motion is attached to a wheel-equipped robot whose wheels act like a reaction wheel generating the pitch rotation; however, the robot is underactuated on the yaw rotation. In order to achieve its real-time spatial reorientation, we propose a novel Quadratic Programming (QP) algorithm based on a geometric metric for the underactuated hybrid tail-wheel robot. Within the proposed algorithm, the physical limitations on tail and wheel velocities are automatically accommodated. Simulation results show that the hybrid tail-wheel appendage can exploit efficient Moment of Inertia (MoI) inducing capability of the tail and unlimited Range of Motion (RoM) feature of the wheel. Experimental results demonstrate the capability of real-time spatial reorientation with underactuation and velocity constraints using the hybrid tail-wheel inertial appendage. Although the proposed controller in this abstract starts from a specific prototype, it can be applicable to many different robot structures, for example, attaching a simple extra tail along the roll DoF to those legged robots (leg swing for pitching) has the potential of enabling spatial reorientation.
# Sampling, Communication, and Prediction Co-Design for Synchronizing the Real-Robot and Digital-Robot in Metaverse
## Keywords:
- Virtual Reality and Interfaces
- Telerobotics and Teleoperation
- Reinforcement Learning
## Abstract:
An immersive and highly interactive metaverse requires an accurate and reliable synchronisation of the real-world device and its digital model. However, it is very challenging to have good and uniform communication performances in wireless and long-distance communication networks due to the dynamic features of wireless channel and networks. Poor synchronization can lead to chaotic interactions, dizziness, and even serious consequences in mission-critical applications. In this work, we develop a sampling, communication, and prediction co-design framework for synchronizing the trajectories of a real-world robotic arm and its digital model in the metaverse. This allows the system to dynamically adjust the sampling rate and the prediction horizon to minimize the communication load while enjoying good synchronization performances.
# Intra-Operative Anatomical 3D SLAM
## Keywords:
- Vision-Based Navigation
- Object Detection, Segmentation and Categorization
## Abstract:
In recent years, several studies have analysed the feasibility of autonomy in the field of Robot-Assisted Minimally-Invasive Surgery (RAMIS). One of the most important requisites for such a system is the capability of reconstructing patient’s 3D anatomy in real-time. In this paper, we propose a semantic based monocular SLAM where we remove the a priori knowledge of dynamic objects during an intervention to increase the accuracy of the reconstruction and the pose estimation. Validation is carried out by performing one of the phases of the radical prostatectomy procedure: the bladder pushing.
# Optimization-Based Trajectory Prediction Using a Monocular Camera
## Keywords:
- Vision-Based Navigation
- RGB-D Perception
## Abstract:
This paper presents a state estimation and trajectory prediction method for a dynamic object using monocular depth estimation and optimization algorithm. A simulation is conducted to validate the performance of the proposed method.
# Pixel-Wise and Uncertainty Based Prediction for Visual Odometry
## Keywords:
- Vision-Based Navigation
- Visual Learning
- Deep Learning Methods
## Abstract:
This paper introduces pixel-wise and uncertainty based prediction for visual odometry (PUVO), which is a dense prediction task that evaluates the values of translation and rotation for every pixel in its input observations. PUVO employs uncertainty estimation to identify the noisy regions in the input observations, and adopts a selection mechanism to integrate pixel-wise predictions based on the estimated uncertainty maps to derive the final translation and rotation. The experimental results show that PUVO is able to deliver favorable results. In addition, our analyses validate the effectiveness of the designs adopted in PUVO, and demonstrate that the uncertainty maps estimated by PUVO is capable of capturing the noises in its input observations.
# Visual-Inertial Odometry Priors for Bundle-Adjusting Neural Radiance Fields
## Keywords:
- Visual Learning
- Data Sets for Robotic Vision
- Vision-Based Navigation
## Abstract:
We present bundle-adjusting Neural Radiance Fields (BARF) with visual-inertial odometry (VIO) priors. We utilize suitable motion priors and BARF to provide higher accuracy and more stable motion estimates in view synthesis. The proposed method achieves results that outperform the original BARF, demonstrating the effectiveness of motion priors to knowledge use.
# Vision-Based Hand Tracking to Reduce Latency of Tele-Operation System for Therapeutic Devices
## Keywords:
- Visual Servoing
- Computer Vision for Automation
- Telerobotics and Teleoperation
## Abstract:
Our previous work introduced a telerobotic system to assist medical staff. The system was developed to meet the requirements of the medical staff and evaluated through a field demonstration. One of the major improvements was the reduction of the time taken for task completion. Therefore, we scheme to let the XY-positioner follow the movement of the user’s hand when determining which manipulation the user will perform by implementing the function for hand tracking. We utilize the MediaPipe hand tracking library and the direct linear transformation to calculate a transformation matrix between a pixel coordinate and a world coordinate. We expect this function might be effective to reduce the undesired latency by synchronizing the motion of user's hand and the motion of XY-positioner.
# Towards Robotic Ultrasound Catheter Tracking Based on Intermediate Ultrasound Representations for Endovascular Procedures
## Keywords:
- Visual Servoing
- Vision-Based Navigation
- Computer Vision for Medical Robotics
## Abstract:
During endovascular procedures the location of inserted catheter needs to be shown in real-time to the interventionist. Currently, this is accomplished through X-ray fluoroscopy, which emits harmful radiation. In this study, we present an alternative approach using a robotic ultrasound system for catheter tracking and navigation. Instead of relying on the registration of pre-operative images for tracking, we employ a novel method for generating intermediate ultrasound images to simplify catheter detection in B-modes. Our approach enables real-time visual feedback for catheter tip tracking and is validated on a phantom with a realistic vessel structure.
# Mobile Human-In-The-Loop Approach for Metabolic Reduction Using Exosuits with Hip Extension Assistance
## Keywords:
- Wearable Robotics
- Human Factors and Human-in-the-Loop
- Modeling, Control, and Learning for Soft Robots
## Abstract:
It is crucial to optimize the control parameters of wearable robots for a possible reduction in the metabolic cost of the wearer. However, the limitation of the existing Human-in-the-Loop approaches is that the optimization can only be conducted inside the laboratory as it takes a long time to measure the human response (i.e., metabolic cost). Consequently, it demands high computational time and power, which restricts the application of wearable robots in daily life. Therefore, it is necessary to develop a mobile Human-in-the-Loop approach that can optimize the control parameters in real-time outside the laboratory. This paper presents the portable Human-in-the-Loop (HIL) optimization for autonomous exosuit with hip extension assistance. The optimization is conducted via the Bayesian optimization with maximizing the positive delivered mechanical power from the exosuit to the wearer, instead of the metabolic costs requiring a time-consuming process. The preliminary result considering a single participant show an increase in mechanical power by as much as 210.9%, and a reduction in the metabolic cost by as much as 12.41% is achieved.
# Design of a Wire-Driven Actuator with Quasi-Direct Drive for a Compact, High-Bandwidth Exosuit
## Keywords:
- Wearable Robotics
- Physically Assistive Devices
- Tendon/Wire Mechanism
## Abstract:
A compact actuator for wire driven exosuits, the Pulley Embedded Quasi-Direct Drive actuator (PEQDD), is designed and evaluated. Based on the quasi-direct drive actuation, the PEQDD has a design that places the motor inside the embedded pulley, that makes it compact, lightweight, and highly responsive. Using a dynamometer, the efficiency map of the fabricated PEQDD was drawn. The PEQDD was compared with the original actuator used in Harvard Exosuit in a control bandwidth test, and showed higher control bandwidth of 20 Hz,compared to 6.25 Hz.
# Coordination with Humans Via Strategy Matching
## Keywords:
- Human-Robot Collaboration
- Human-Robot Teaming
## Abstract:
Human and robot partners increasingly need to work together to perform tasks as a team. Robots designed for such collaboration must reason about how their task-completion strategies interplay with the behavior and skills of their human team members as they coordinate on achieving joint goals. Our goal in this work is to develop a computational framework for robot adaptation to human partners in human-robot team collaborations. We first present an algorithm for autonomously recognizing available task-completion strategies by observing human-human teams performing a collaborative task. By transforming team actions into low dimensional representations using hidden Markov models, we can identify strategies without prior knowledge. Robot policies are learned on each of the identified strategies to construct a Mixture-of-Experts model that adapts to the task strategies of unseen human partners. We evaluate our model on a collaborative cooking task using an Overcooked simulator. Results of an online user study with 125 participants demonstrate that our framework improves the task performance and collaborative fluency of human-agent teams, as compared to state of the art reinforcement learning methods.
# DULA and DEBA: Differentiable Ergonomic Risk Models for Postural Assessment and Optimization in Ergonomically Intelligent PHRI
## Keywords:
- Physical Human-Robot Interaction
- Safety in HRI
- Human-Aware Motion Planning
## Abstract:
Ergonomics and human comfort are essential concerns in physical human-robot interaction applications. Defining an accurate and easy-to-use ergonomic assessment model stands as an important step in providing feedback for postural correction to improve operator health and comfort. Common practical methods in the area suffer from inaccurate ergonomics models in performing postural optimization. In order to retain assessment quality, while improving computational considerations, we propose a novel framework for postural assessment and optimization for ergonomically intelligent physical human-robot interaction. We introduce DULA and DEBA, differentiable and continuous ergonomics models learned to replicate the popular and scientifically validated RULA and REBA assessments with more than 99% accuracy. We show that DULA and DEBA provide assessment comparable to RULA and REBA while providing computational benefits when being used in postural optimization. We evaluate our framework through human and simulation experiments. We highlight DULA and DEBA's strength in a demonstration of postural optimization for a simulated pHRI task.
# Towards Inclusive HRI: Using Sim2Real to Address Underrepresentation in Emotion Expression Recognition
## Keywords:
- Gesture, Posture and Facial Expressions
- Social HRI
- Simulation and Animation
## Abstract:
Robots and artificial agents that interact with humans should be able to do so without bias and inequity, but facial perception systems have notoriously been found to work more poorly for certain groups of people than others. In our work, we aim to build a system that can perceive humans in a more transparent and inclusive manner. Specifically, we focus on dynamic expressions on the human face, which are difficult to collect for a broad set of people due to privacy concerns and the fact that faces are inherently identifiable. Furthermore, datasets collected from the Internet are not necessarily representative of the general population. We address this problem by offering a Sim2Real approach in which we use a suite of 3D simulated human models that enables us to create an auditable synthetic dataset covering 1) underrepresented facial expressions, outside of the six basic emotions, such as confusion; 2) ethnic or gender minority groups; and 3) a wide range of viewing angles that a robot may encounter a human in the real world. By augmenting a small dynamic emotional expression dataset containing 123 samples with a synthetic dataset containing 4536 samples, we achieved an improvement in accuracy of 15% on our own dataset and 11% on an external benchmark dataset, compared to the performance of the same model architecture without synthetic training data. We also show that this additional step improves accuracy specifically for racial minorities when the architecture's feature extraction weights are trained from scratch.
# Reasoning about Counterfactuals to Improve Human Inverse Reinforcement Learning
## Keywords:
- Human-Robot Collaboration
## Abstract:
To collaborate well with robots, we must be able to understand their decision making. Humans naturally infer other agents' beliefs and desires by reasoning about their observable behavior in a way that resembles inverse reinforcement learning (IRL). Thus, robots can convey their beliefs and desires by providing demonstrations that are informative for a human learner's IRL. An informative demonstration is one that differs strongly from the learner's expectations of what the robot will do given their current understanding of the robot's decision making. However, standard IRL does not model the learner's existing expectations, and thus cannot do this counterfactual reasoning. We propose to incorporate the learner's current understanding of the robot's decision making into our model of human IRL, so that a robot can select demonstrations that maximize the human's understanding. We also propose a novel measure for estimating the difficulty for a human to predict instances of a robot's behavior in unseen environments. A user study finds that our test difficulty measure correlates well with human performance and confidence. Interestingly, considering human beliefs and counterfactuals when selecting demonstrations decreases human performance on easy tests, but increases performance on difficult tests, providing insight on how to best utilize such models.
# Proactive Robotic Assistance Via Theory of Mind
## Keywords:
- AI-Based Methods
- AI-Enabled Robotics
- Human-Centered Robotics
## Abstract:
Advanced social cognitive skills enhance the effectiveness of human-robot interactions. Research shows that an important precursor to the development of these abilities in humans is Theory of Mind (ToM) -# the ability to attribute mental states to oneself and to others. In this work, we endow robots with ToM abilities and propose a ToM-based approach to proactive robotic assistance by appealing to epistemic planning techniques. Our evaluation shows that robots implementing our approach and demonstrating ToM are measurably more helpful and perceived by humans as more socially intelligent compared to robots with a deficit in ToM.
# A Novel Perceptive Robotic Cane with Haptic Navigation for Enabling Vision-Independent Participation in the Social Dynamics of Seat Choice
## Keywords:
- Multi-Modal Perception for HRI
- Vision-Based Navigation
## Abstract:
Goal-based navigation in public places is critical for independent mobility and for breaking the boundaries that exist for blind or visually impaired (BVI) people in our sight-centric society. Through this work, we present a proof-of-concept system that can autonomously find socially preferred seats and safely guide its user towards them in unknown indoor environments. The robotic system includes a camera, an IMU, vibrational motors, and a white cane, powered via a backpack-mounted laptop. The system combines techniques from computer vision, robotics, and motion planning with insights from psychology to perform 1) SLAM and object detection, 2) goal disambiguation and scoring, and 3) path planning and guidance. We introduce a novel 2-motor haptic feedback system on the cane’s grip for navigation assistance. Through a pilot user study, we show that the system is successful in autonomously classifying and providing haptic navigation guidance to socially preferred seats, while optimizing for users’ convenience, privacy, and intimacy in addition to increasing their confidence in independent navigation. The implications are encouraging as this technology, with careful design guided by the BVI community, can be adopted and further developed to be used with medical devices enabling the BVI population to better independently engage in socially dynamic situations like seat choice.
# SESNO: Sample Efficient Social Navigation from Observation
## Keywords:
- Imitation Learning
- Human-Aware Motion Planning
- Learning from Experience
## Abstract:
In this paper, we present the Sample Efficient Social Navigation from Observation (SESNO) algorithm that efficiently learns socially-compliant navigation policies from observations of human trajectories. SESNO is an inverse reinforcement learning (IRL)-based algorithm that learns from human trajectory observations without knowledge of their actions. We improve the sample-efficiency over previous IRL-based methods by introducing a shared experience replay buffer that allows reuse of past trajectory experiences to estimate the policy and the reward. We evaluate SESNO using publicly available pedestrian motion data sets and compare its performance to related baseline methods in the literature. We show that SESNO yields performance superior to existing baselines while dramatically improving the sample complexity by using as few as a hundredth of the samples required by existing baselines.
# Understanding Acoustic Patterns of Human Teachers Demonstrating Manipulation Tasks to Robots
## Keywords:
- Human-Centered Robotics
- Learning from Demonstration
## Abstract:
Humans use audio signals in the form of spoken language or verbal reactions effectively when teaching new skills or tasks to other humans. While demonstrations allow humans to teach robots in a natural way, learning from trajectories alone does not leverage other available modalities including audio from human teachers. To effectively utilize audio cues accompanying human demonstrations, first it is important to understand what kind of information is present and conveyed by such cues. This work characterizes audio from human teachers demonstrating multi-step manipulation tasks to a situated Sawyer robot along three dimensions: (1) duration of speech used, (2) expressiveness in speech or prosody, and (3) semantic content of speech. We analyze these features for four different independent variables and find that teachers convey similar semantic content via spoken words for different conditions of (1) demonstration types, (2) audio usage instructions, (3) subtasks, and (4) errors during demonstrations. However, differentiating properties of speech in terms of duration and expressiveness are present for the four independent variables, highlighting that human audio carries rich information, potentially beneficial for technological advancement of robot learning from demonstration methods.
# Gesture2Vec: Clustering Gestures Using Representation Learning Methods for Co-Speech Gesture Generation
(Finalist for IROS Best Paper Award on Cognitive Robotics Sponsored by KROS)
## Keywords:
- Gesture, Posture and Facial Expressions
- Social HRI
- Representation Learning
## Abstract:
Co-speech gestures are a principal component in conveying messages and enhancing interaction experiences between humans and critical ingredients in human-agent interaction, including virtual agents and robots. Existing machine learning approaches have yielded only marginal success in learning speech-to-motion at the frame level. Current methods generate repetitive gesture sequences that lack appropriateness with respect to the speech context. To tackle this challenge, we take inspiration from successes in natural language processing on context and long-term dependencies, and propose a new framework that views text-to-gesture as machine translation, where gestures are words in another (non-verbal) language. We propose a vector-quantized variational autoencoder structure as well as training techniques to learn a rigorous representation of gesture sequences. We then translate input text into a discrete sequence of associated gesture chunks in the learned gesture space. Ultimately, we use translated gesture tokens from the input text as an input to the autoencoder’s decoder to produce gesture sequences. Subjective and objective evaluations confirm the success of our approach in terms of appropriateness, human-likeness, and diversity. We also introduce new objective metrics using the quantized gesture representation.
# Optical Flow-Based Branch Segmentation for Complex Orchard Environments
## Keywords:
- Robotics and Automation in Agriculture and Forestry
- Object Detection, Segmentation and Categorization
## Abstract:
Machine vision is a critical subsystem for enabling robots to be able to perform a variety of tasks in orchard environments. However, orchards are highly visually complex environments, and computer vision algorithms operating in them must be able to contend with variable lighting conditions and background noise. Past work on enabling deep learning algorithms to operate in these environments has typically required large amounts of hand-labeled data to train a deep neural network or physically controlling the conditions under which the environment is perceived. In this paper, we train a neural network system in simulation only using simulated RGB data and optical flow. This resulting neural network is able to perform foreground segmentation of branches in a busy orchard environment without additional real-world training or using any special setup or equipment beyond a standard camera. Our results show that our system is highly accurate and, when compared to a network using manually labeled RGBD data, achieves significantly more consistent and robust performance across environments that differ from the training set.
# Near Real-Time Vineyard Downy Mildew Detection and Severity Estimation
## Keywords:
- Robotics and Automation in Agriculture and Forestry
- Environment Monitoring and Management
- Agricultural Automation
## Abstract:
The global grape and wine industry has been considerably impacted by diseases such as downy mildew (DM). Agricultural robots have demonstrated great potential to accurately and rapidly map DM infection for precision applications. Although the robots can autonomously acquire high-resolution images in the vineyard, data processing is mostly performed offline because of network infrastructure and onboard computing power constraints, limiting the use of agricultural robots for field operations. To address this issue, we developed a semantic segmentation model based on the modified DeepLabv3 network for near real time DM segmentation in high resolution images. Compared with state-of-the-art real time semantic segmentation models, the developed one achieved the best efficiency-accuracy balance on the DM dataset using embedded computing devices that can be easily integrated with commercial robotic platforms. DM severity estimation pipeline based on the model also showed a comparable measurement accuracy and statistical power in differentiation of fungicide treatments as the one based on offline semantic segmentation models. This enables the use of robotic perception systems for field operations.
# View Planning Using Discrete Optimization for 3D Reconstruction of Row Crops
## Keywords:
- Robotics and Automation in Agriculture and Forestry
- Agricultural Automation
- Computer Vision for Automation
## Abstract:
In view planning, the position and orientation of the cameras have been a major contributing factor to the quality of the resulting 3D model. In applications such as precision agriculture, a dense and accurate reconstruction must be obtained quickly while the data is still actionable. Instead of using an arbitrarily large number of images taken from every possible position and orientation in order to cover the desired area of study, a more optimal approach is required. We present an efficient and realistic pipeline, which aims to optimize the positioning of cameras and hence the quality of the 3D reconstruction of a field of row crops. This is achieved with four steps; an initial flight to obtain a sparse point cloud, the fitting of a simple mesh model, the planning of images via a discrete optimization process, and a second flight to obtain the final reconstruction. We demonstrate the effectiveness of our method by comparing it with baseline methods commonly used for agricultural data collection and processing.
# BonnBot-I: A Precise Weed Management and Crop Monitoring Platform
## Keywords:
- Robotics and Automation in Agriculture and Forestry
- Agricultural Automation
- Field Robots
## Abstract:
Cultivation and weeding are two of the primary tasks performed by farmers today. A recent challenge for weed# ing is the desire to reduce herbicide and pesticide treatments while maintaining crop quality and quantity. In this paper we introduce BonnBot-I a precise weed management platform which can also performs field monitoring. Driven by crop monitoring approaches which can accurately locate and classify plants (weed and crop) we further improve their performance by fusing the platform available GNSS and wheel odometry. This improves tracking accuracy of our crop monitoring approach from a normalized average error of 8.3% to 3.5%, evaluated on a new publicly available corn dataset. We also present a novel arrangement of weeding tools mounted on linear actuators evaluated in simulated environments. We replicate weed distributions from a real field, using the results from our monitoring approach, and show the validity of our work-space division techniques which require significantly less movement (a 50% reduction) to achieve similar results. Overall, BonnBot-I is a significant step forward in precise weed management with a novel method of selectively spraying and controlling weeds in an arable field. Keywords — Robotics and Automation in Agriculture and Forestry; Agricultural Automation; Field Robotics.
# An Integrated Actuation-Perception Framework for Robotic Leaf Retrieval: Detection, Localization, and Cutting
## Keywords:
- Agricultural Automation
- Software-Hardware Integration for Robot Systems
- Robotics and Automation in Agriculture and Forestry
## Abstract:
Contemporary robots in precision agriculture focus primarily on automated harvesting or remote sensing to monitor crop health. Comparatively less work has been performed with respect to collecting physical leaf samples in the field and retaining them for further analysis. Typically, orchard growers manually collect sample leaves and utilize them for stem water potential measurements to analyze tree health and determine irrigation routines. While this technique benefits orchard management, the process of collecting, assessing, and interpreting measurements requires significant human labor and often leads to infrequent sampling. Automated sampling can provide highly accurate and timely information to growers. The first step in such automated in-situ leaf analysis is identifying and cutting a leaf from a tree. This retrieval process requires new methods for actuation and perception. We present a technique for detecting and localizing candidate leaves using point cloud data from a depth camera. This technique is tested on both indoor and outdoor point clouds from avocado trees. We then use a custom-built leaf-cutting end-effector on a 6-DOF robotic arm to test the proposed detection and localization technique by cutting leaves from an avocado tree. Experimental testing with a real avocado tree demonstrates our proposed approach can enable our mobile manipulator and custom end-effector system to successfully detect, localize, and cut leaves.
# Algorithm Design and Integration for a Robotic Apple Harvesting System
## Keywords:
- Robotics and Automation in Agriculture and Forestry
- Agricultural Automation
- Software-Hardware Integration for Robot Systems
## Abstract:
Due to labor shortage and rising labor cost for the apple industry, there is an urgent need for the development of robotic systems to efficiently and autonomously harvest apples. In this paper, we present a system overview and algorithm design of our recently developed robotic apple harvester prototype. Our robotic system is enabled by the close integration of several core modules, including visual perception, planning, and control. This paper covers the main methods and advancements in deep learning-based multi-view fruit detection and localization, unified picking and dropping planning, and dexterous manipulation control. Indoor and field experiments were conducted to evaluate the performance of the developed system, which achieved an average picking rate of 3.6 seconds per apple. This is a significant improvement over other reported apple harvesting robots with a picking rate in the range of 7-10 seconds per apple. The current prototype shows promising performance towards further development of efficient and automated apple harvesting technology. Finally, limitations of the current system and future work are discussed.
# Predicting Fruit-Pick Success Using a Grasp Classifier Trained on a Physical Proxy
## Keywords:
- Robotics and Automation in Agriculture and Forestry
- Grasping
- Data Sets for Robot Learning
## Abstract:
Apple picking is a challenging manipulation task, but it is difficult to test solutions due to the limited window of time that apples are in season. Previous methods have built simulations of apple trees, but simulations rarely capture soft contact and deformation well, both of which are common in fruit picking. In this paper we present and validate a physical proxy that replicates the mechanics of a real world apple pick. This proxy, in conjunction with a novel hand with multiple sensors, enables large-scale capture of sensor data for data collection and testing. To validate our approach, we train a Long Short-Term Memory network to classify a pick as successful or failed based on sensor feedback from the robot hand. We show that a network trained on the proxy performs as well or even better than a network trained solely on real apple trees, with accuracies up to 90 %. We determine which sensors are most important for pick classification and also demonstrate that our proxy preserves the most important sensor feature data for pick classification. Specifically for the implemented hand, the most informative feature group was the finger's servomotor effort.
# Contrastive 3D Shape Completion and Reconstruction for Agricultural Robots Using RGB-D Frames
(Finalist for IROS Best Paper Award on Agri-Robotics Sponsored by YANMAR)
## Keywords:
- Robotics and Automation in Agriculture and Forestry
- Deep Learning for Visual Perception
- RGB-D Perception
# Beyond mAP: Towards Practical Object Detection for Weed Spraying in Precision Agriculture
## Keywords:
- Agricultural Automation
- Computer Vision for Automation
- Object Detection, Segmentation and Categorization
## Abstract:
The evolution of smaller and more powerful GPUs over the last 2 decades has vastly increased the opportunity to apply robust deep learning-based machine vision approaches to real-time use cases in practical environments. One ex# citing application domain for such technologies is precision agriculture, where the ability to integrate on-board machine vision with data-driven actuation means that farmers can make decisions about crop care and harvesting at the level of the individual plant rather than the whole field. This makes sense both economically and environmentally. This paper assesses the feasibility of precision spraying weeds via a comprehensive evaluation of weed detection accuracy and speed using two separate datasets, two types of GPU, and several state-of-the# art object detection algorithms. A simplified model of precision spraying is used to determine whether the weed detection accuracy achieved could result in a sufficiently high weed hit rate combined with a significant reduction in herbicide usage. The paper introduces two metrics to capture these aspects of the real-world deployment of precision weeding and demonstrates their utility through experimental results.
# Audio-Visual Depth and Material Estimation for Robot Navigation
## Keywords:
- Semantic Scene Understanding
- Vision-Based Navigation
- Audio-Visual SLAM
## Abstract:
Reflective and textureless surfaces such as windows, mirrors, and walls can be a challenge for scene reconstruction, due to depth discontinuities and holes. We propose an audio-visual method that uses the reflections of sound to aid in depth estimation and material classification for 3D scene reconstruction in robot navigation and AR/VR applications. The mobile phone prototype emits pulsed audio, while recording video for audio-visual classification for 3D scene reconstruction. Reflected sound and images from the video are input into our audio (EchoCNN-A) and audio-visual (EchoCNN-AV) convolutional neural networks for surface and sound source detection, depth estimation, and material classification. The inferences from these classifications enhance 3D scene reconstructions containing open spaces and reflective surfaces by depth filtering, inpainting, and placement of unmixed sound sources in the scene. Our prototype, demos, and experimental results from real-world with challenging surfaces and sound, also validated with virtual scenes, indicate high success rates on classification of material, depth estimation, and closed/open surfaces, leading to considerable improvement in 3D scene reconstruction for robot navigation.
# Design of a Low-Cost Passive Acoustic Monitoring System for Animal Localisation from Calls
## Keywords:
- Robot Audition
## Abstract:
The field of bioacoustics is concerned with monitoring wild animals based on their vocalisations. Passive acoustic recorders are now commonly used to collect data of the soundscapes of our wild places. While the data they collect is extremely useful, the majority of the recorders use a single omnidirectional microphone, and thus cannot independently perform localisation of a calling animal. Localisation can be useful to differentiate between multiple calling animals, to improve statistical estimates of abundance, and to locate calling posts, which may be close to nests. In this paper, we consider the design of a low-cost, practical, passive directional acoustic recorder that will facilitate animal localisation, and present and evaluate a prototype system for this purpose.
# Spotforming by NMF Using Multiple Microphone Arrays
## Keywords:
- Robot Audition
## Abstract:
Sound source separation is a method to extract a target sound source from a mixture of various sound sources and noises. One of the typical sound source separation methods is beamforming, which can separate sound sources by direction based on the phase difference between channels from the recorded signal of a microphone array, a multi-channel recording system. However, beamforming is a direction-based method and cannot separate multiple sources in the same direction. In this paper, we propose a method for separating sources in the same direction using multiple microphone arrays. The proposed method performs beamforming using multiple microphone arrays and extracts only the target sound source from the separated sound by the Non-negative Matrix Factorization (NMF), thus reducing the influence of other sources in the same direction. In this paper, to investigate the effectiveness of the proposed method, experiments were conducted assuming the presence of another sound source in the same direction from an arbitrary microphone array. The results show that the proposed method outperforms the delay-sum method in a simulation environment. In addition, experiments were conducted in a real environment to verify the effect of reverberation.
# Noisy Agents: Self-Supervised Exploration by Predicting Auditory Events
## Keywords:
- Reinforcement Learning
- Robot Audition
## Abstract:
Humans integrate multiple sensory modalities e.g., visual and audio) to build a causal understanding of the physical world. In this work, we propose a novel type of intrinsic motivation for Reinforcement Learning (RL) that encourages the agent to understand the causal effect of its actions through auditory event prediction. First, we allow the agent to collect a small amount of acoustic data and use K-means to discover underlying auditory event clusters. We then train a neural network to predict the auditory events and use the prediction errors as intrinsic rewards to guide RL exploration. We first conduct proof-of-concept experiments using a set of Atari games for an in-depth analysis of our module. We then apply our model to embodied audio-visual exploration using the Habitat simulator and active exploration with a rolling robot using the ThreeDWorld (TDW) simulator. Experimental results demonstrate the advantages of using audio signals over vision-based models as intrinsic rewards to guide RL explorations.
# Direction-Aware Adaptive Online Neural Speech Enhancement with an Augmented Reality Headset in Real Noisy Conversational Environments
## Keywords:
- Robot Audition
- Deep Learning Methods
- Human Performance Augmentation
## Abstract:
This paper describes the practical response# and performance-aware development of online speech enhancement for an augmented reality (AR) headset that helps a user understand conversations made in real noisy echoic environments (e.g., cocktail party). One may use a state-of-the-art blind source separation method called fast multichannel nonnegative matrix factorization (FastMNMF) that works well in various environments thanks to its unsupervised nature. Its heavy computational cost, however, prevents its application to real-time processing. In contrast, a supervised beamforming method that uses a deep neural network (DNN) for estimating spatial information of speech and noise readily fits real-time processing, but suffers from drastic performance degradation in mismatched conditions. Given such complementary characteristics, we propose a dual-layer robust online speech enhancement method based on DNN-based beamforming with FastMNMF-guided adaptation. FastMNMF (back end) is performed in a mini-batch style and the noisy and enhanced speech pairs are used together with the original parallel training data for updating the direction-aware DNN (front end) with backpropagation at a computationally-allowable interval. This method is used with a blind dereverberation method called weighted prediction error (WPE) for transcribing the noisy reverberant speech of a speaker, which can be detected from video or selected by a user's hand gesture or eye gaze, in a streaming manner and spatially showing the transcriptions with an AR technique. Our experiment showed that the word error rate was improved by more than 10 points with the run-time adaptation using only twelve minutes observation.
# Object Surface Recognition Using Microphone Array by Acoustic Standing Wave
## Keywords:
- Robot Audition
- Range Sensing
- Object Detection, Segmentation and Categorization
## Abstract:
This paper proposes a microphone array with a speaker to recognize the shape of the surface of the target object by using the standing wave between the transmitted and the reflected acoustic signals. Because the profile of the distance spectrum encodes both the distance to the target and the distance to the edges of the target’s surface, this paper proposes to fuse distance spectra using a microphone array to estimate the three-dimensional structure of the target surface. The proposed approach was verified through numerical simulations and outdoor field experiments. Results showed the effectiveness of the method as it could extract the shape of the board located 2m in front of the microphone array by using a chirp tone with 20kHz bandwidth.
# Recognizing Object Surface Material from Impact Sounds for Robot Manipulation
## Keywords:
- Perception for Grasping and Manipulation
- Recognition
- Robot Audition
## Abstract:
We investigated the use of impact sounds generated during exploratory behaviors in a robotic manipulation setup as cues for predicting object surface material and for recognizing individual objects. We collected and make available the YCB-impact sounds dataset which includes over 3,500 impact sounds for the YCB set of everyday objects lying on a table. Impact sounds were generated in three modes: (i) human holding a gripper and hitting, scratching, or dropping the object; (ii) gripper attached to a teleoperated robot hitting the object from the top; (iii) autonomously operated robot hitting the objects from the side with two different speeds. A convolutional neural network (ResNet34) is trained from scratch to recognize the object material (steel, aluminium, hard plastic, soft plastic, other plastic, ceramic, wood, paper/cardboard, foam, glass, rubber) from a single impact sound. On the manually collected dataset with more variability in the action, nearly 60% accuracy for the test set (unseen objects) was achieved. On a robot setup and a stereotypical poking action from top, accuracy of 85% was achieved. This performance drops to 79% if multiple exploratory actions are combined. Individual objects from the set of 75 objects can be recognized with a 79% accuracy. This work demonstrates promising results regarding the possibility of using sound for recognition in tasks like single-stream recycling where objects have to be sorted based on their material composition.
# Controlling the Impression of Robots Via GAN-Based Gesture Generation
## Keywords:
- Gesture, Posture and Facial Expressions
- Social HRI
- Emotional Robotics
## Abstract:
As a type of body language, gestures can largely affect the impressions of human-like robots perceived by users. Recent data-driven approaches to the generation of co-speech gestures have successfully promoted the naturalness of produced gestures. These approaches also possess greater generalizability to work under various contexts than rule-based methods. However, most have no direct control over the human impressions of robots. The main obstacle is that creating a dataset that covers various impression labels is not trivial. In this study, based on previous findings in cognitive science on robot impressions, we present a heuristic method to control them without manual labeling, and demonstrate its effectiveness on a virtual agent and partially on a humanoid robot through subjective experiments with 50 participants.
# Outdoor Evaluation of Sound Source Localization for Drone Groups Using Microphone Arrays
## Keywords:
- Localization
- Search and Rescue Robots
- Aerial Systems: Applications
## Abstract:
For robot and drone auditions, microphone arrays have been used for estimating sound source directions and sound source locations. By using sound source localization techniques, for example, drones can detect people calling for help even if the target person is not visible. Most sound source localization methods are based on estimated sound source directions and triangulation. However, when it comes to situations using drones, severe drone noise distorts direction estimation results which could worsen the localization results badly due to the discreteness of direction estimation. In this perspective, the authors have proposed a sound source localization method that can omit outlying triangulation points, which could improve its localization performance. In this paper, an outdoor experiment has been held, and the proposed method is evaluated whether it can localize a sound source even if real drone noise is added to the recordings. Experiment results show that the proposed method can localize with 4.15 m of estimation error for a sound source up to 50 m away, suppress the impact of outliers, and use only plausible triangulation points.
# Machine Learning for Robot Control 1
# Reactive Stepping for Humanoid Robots Using Reinforcement Learning: Application to Standing Push Recovery on the Exoskeleton Atalante
## Keywords:
- Machine Learning for Robot Control
- Reinforcement Learning
- Humanoid Robot Systems
## Abstract:
State-of-the-art reinforcement learning is now able to learn versatile locomotion, balancing and push-recovery capabilities for bipedal robots in simulation. Yet, the reality gap has mostly been overlooked and the simulated results hardly transfer to real hardware. Either it is unsuccessful in practice because the physics is over-simplified and hardware limitations are ignored, or regularity is not guaranteed, and unexpected hazardous motions can occur. This paper presents a reinforcement learning framework capable of learning robust standing push recovery for bipedal robots that smoothly transfer to reality, providing only instantaneous proprioceptive observations. By combining original termination conditions and policy smoothness conditioning, we achieve stable learning, sim-to-real transfer and safety using a policy without memory nor explicit history. Reward engineering is then used to give insights into how to keep balance. We demonstrate its performance in reality on the lower-limb medical exoskeleton Atalante.
# Hybrid Approach for Stabilizing Large Time Delays in Cooperative Adaptive Cruise Control with Reduced Performance Penalties
## Keywords:
- Machine Learning for Robot Control
## Abstract:
cooperative adaptive cruise control (CACC) is a smart transportation solution that can mitigate traffic jams and improve road safety. CACC performance is heavily impacted by communication time delay; moreover, control theory solutions generally compromise control performance by tuning control gains in order to maintain plant stability. We propose a control-machine learning hybrid approach called deep time delay filter (DTDF). DTDF predicts the present (un-delayed) car states given time delayed versions. We successfully train a neural network for the DTDF method and use a physical testbed to show that DTDF can mitigate the effects of constant time delays as large as 5s while maintaining superior control performance compared to that of a baseline control algorithm.
# Leveraging Multi-Level Modelling to Automatically Design Behavioral Arbitrators in Robotic Controllers
## Keywords:
- Machine Learning for Robot Control
- Behavior-Based Systems
- Swarm Robotics
## Abstract:
Automatic control design for robotic systems is becoming more and more popular. However, this usually involves a significant computational cost, due to the expensive and noisy evaluation of candidate solutions through high-fidelity simulation or even real hardware. This work aims at reducing the computational cost of automatic design of behavioral arbitrators through the introduction of a two-step approach. In the first step, the structure of the finite state machine governing the behavioral arbitrator is optimized. To this purpose, a more abstracted model of the robotic system is leveraged in order to significantly reduce the computational cost. In the second step, the close-to-hardware, behavioral parameters are fine-tuned using a high-fidelity model. We show that, for a scenario involving a single robot and multiple tasks to be solved sequentially, using the proposed method results in a significant decrease of the computational cost while reaching the same controller performance both in simulation and reality.
# Federated Learning from Demonstration for Active Assistance to Smart Wheelchair Users
## Keywords:
- Machine Learning for Robot Control
- Service Robotics
- AI-Based Methods
## Abstract:
Learning from Demonstration (LfD) is a very appealing approach to empower robots with autonomy. Given some demonstrations provided by a human teacher, the robot can learn a policy to solve the task without explicit programming. A promising use case is to endow smart robotic wheelchairs with active assistance to navigation. By using LfD, it is possible to learn to infer short-term destinations anywhere, without the need of building a map of the environment beforehand. Nevertheless, it is difficult to generalize robot behaviors to environments other than those used for training. We believe that one possible solution is learning from crowds, involving a broad number of teachers (the end users themselves) who perform demonstrations in diverse and real environments. To this end, in this work we consider Federated Learning from Demonstration (FLfD), a distributed approach based on a Federated Learning architecture. Our proposal allows the training of a global deep neural network using sensitive local data (images and laser readings) with privacy guarantees. In our experiments we pose a scenario involving different clients working in heterogeneous domains. We show that the federated model is able to generalize and deal with non Independent and Identically Distributed (non-IID) data.
# PourNet: Robust Robotic Pouring through Curriculum and Curiosity-Based Reinforcement Learning
## Keywords:
- Machine Learning for Robot Control
- AI-Enabled Robotics
- Manipulation Planning
## Abstract:
Pouring liquids accurately into containers is one of the most challenging tasks for robots as they are unaware of the complex fluid dynamics and the behavior of liquids when pouring. Therefore, it is not possible to formulate a generic pouring policy for real-time applications. In this paper, we propose PourNet, as a generalized solution to pouring different liquids into containers. PourNet is a hybrid planner that uses deep reinforcement learning, for end-effector planning, and Nonlinear Model Predictive Control, for joint planning. In this work, we introduce a novel simulation environment using Unity3D and NVIDIA-Flex to train our agents. By effective choice of the state space, action space, and the reward functions, we allow for a direct sim-to-real transfer of the learned skills without additional training. In the simulation, PourNet outperforms state-of-the-art by an average of 4.9g deviation for water-like, and 9.2g deviation for honey-like liquids. In the real-world scenario using Kinova Movo Platform, PourNet achieves an average pouring deviation of 2.3g for dish soap when using a novel pouring container. The average pouring deviation measured for water was 5.5g.
# Simulation-Based Learning of the Peg-In-Hole Process Using Robot-Skills
## Keywords:
- Machine Learning for Robot Control
- Industrial Robots
- Reinforcement Learning
## Abstract:
Increasingly volatile markets challenge companies and demand flexible production systems that can be quickly adapted to new conditions. Machine Learning has proven to show significant potential in supporting the human operator during the time-consuming and complex task of robot programming by identifying relevant parameters of the underlying robot control program. We present a solution to learn these parameters for contact-rich, force-controlled assembly tasks from a simulation using hardware-independent robot skills. We show that successful learning and real-world execution are possible even under process deviation and tolerances utilizing the designed learning system. We present learning skill parameters as high-level robot control, evaluation and comparison of extensive simulations, and preliminary experiments on a physical robot test-bed. The developed solution approach is evaluated and discussed using the Peg-in-Hole process, a typical benchmark process in force-controlled assembly.
# Hybrid LMC: Hybrid Learning and Model-Based Control for Wheeled Humanoid Robot Via Ensemble Deep Reinforcement Learning
## Keywords:
- Machine Learning for Robot Control
- Reinforcement Learning
- Humanoid Robot Systems
## Abstract:
Control of wheeled humanoid locomotion is a challenging problem due to the nonlinear dynamics and underactuated characteristics of these robots. Traditionally, feedback controllers have been utilized for stabilization and locomotion. However, these methods are often limited by the fidelity of the underlying model used, choice of controller, and environmental variables considered (surface type, ground inclination, etc). Recent advances in reinforcement learning (RL) offer promising methods to tackle some of these conventional feedback controller issues but require large amounts of interaction data to learn. Here, we propose a hybrid learning and modelbased controller Hybrid LMC that combines the strengths of a classical linear quadratic regulator (LQR) and ensemble deep reinforcement learning. Ensemble deep reinforcement learning is composed of multiple Soft Actor-Critic (SAC) and is utilized in reducing the variance of RL networks. By using a feedback controller in tandem the network exhibits stable performance in the early stages of training. As a preliminary step, we explore the viability of Hybrid LMC in controlling wheeled locomotion of a humanoid robot over a set of different physical parameters in MuJoCo simulator. Our results show that Hybrid LMC achieves better performance compared to other existing techniques and has increased sample efficiency.
# Active Exploration for Robotic Manipulation
## Keywords:
- Machine Learning for Robot Control
- Reinforcement Learning
- Probabilistic Inference
## Abstract:
Robotic manipulation stands as a largely unsolved problem despite significant advances in robotics and machine learning in recent years. One of the key challenges in manipulation is the exploration of the dynamics of the environment when there is continuous contact between the objects being manipulated. This paper proposes a model-based active exploration approach that enables efficient learning in sparse-reward robotic manipulation tasks. The proposed method estimates an information gain objective using an ensemble of probabilistic models and deploys model predictive control (MPC) to plan actions online that maximize the expected reward while also performing directed exploration. We evaluate our proposed algorithm in simulation and on a real robot, trained from scratch with our method, on a challenging ball pushing task on tilted tables, where the target ball position is not known to the agent a-priori. Our real-world robot experiment serves as a fundamental application of active exploration in model-based reinforcement learning of complex robotic manipulation tasks. Project page https://sites.google.com/view/aerm.
# Cloud-Edge Training Architecture for Sim-To-Real Deep Reinforcement Learning
## Keywords:
- Control Architectures and Programming
- Reinforcement Learning
- Transfer Learning
## Abstract:
Deep reinforcement learning (DRL) is a promising approach to solve complex control tasks by learning policies through interactions with the environment. However, the training of DRL policies requires large amounts of training experiences, making it impractical to learn the policy directly on physical systems. Sim-to-real approaches leverage simulations to pretrain DRL policies and then deploy them in the real world. Unfortunately, the direct real-world deployment of pretrained policies usually suffers from performance deterioration due to the different dynamics, known as the reality gap. Recent sim-to-real methods, such as domain randomization and domain adaptation, focus on improving the robustness of the pretrained agents. Nevertheless, the simulation-trained policies often need to be tuned with real-world data to reach optimal performance, which is challenging due to the high cost of real-world samples. 
This work proposes a distributed cloud-edge architecture to train DRL agents in the real world in real-time. In the architecture, the inference and training are assigned to the edge and cloud, separating the real-time control loop from the computationally expensive training loop. To overcome the reality gap, our architecture exploits sim-to-real transfer strategies to continue the training of simulation-pretrained agents on a physical system. We demonstrate its applicability on a physical inverted-pendulum control system, analyzing critical parameters. The real-world experiments show that our architecture can adapt the pretrained DRL agents to unseen dynamics consistently and efficiently.
# Soft Robot Modeling and Control 1
# Towards Accurate Modeling of Modular Soft Pneumatic Robots: From Volume FEM to Cosserat Rod
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Hydraulic/Pneumatic Actuators
- Soft Sensors and Actuators
## Abstract:
Compared to their rigid counterparts, soft material robotic systems offer great advantages when it comes to flexibility and adaptability. Despite their advantages, modeling of soft systems is still a challenging task, due to the continuous and often highly nonlinear nature of deformation these systems exhibit. Tasks like motion planning or design optimization of soft robots require computationally cheap models of the system’s behavior. In this paper we address this need by deriving operational point dependent Cosserat rod models from detailed volume finite element models (FEM). While the latter offer detailed simulations, they generally come with high computational burden that hinders them from being used in time critical model-based methods like motion planning or control. Basic Cosserat rod models promise to provide computationally efficient mechanical models of soft continuum robots. By using a detailed FE model in an offline stage to identify operational point dependent Cosserat rod models, we bring together the accuracy of volumetric FEM with the efficiency of Cosserat rod models. We apply the approach to a fiber reinforced soft pneumatic bending actuator module (SPA module) and evaluate the model’s predictive capabilities for a single module as well as a two-module robot.
# A Proprioceptive Method for Soft Robots Using Inertial Measurement Units
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Kinematics
- Sensor Fusion
## Abstract:
Proprioception, or the perception of the configuration of one's body, is challenging to achieve with soft robots due to their infinite degrees of freedom and incompatibility with most off-the-shelf sensors. This work explores the use of inertial measurement units (IMUs), sensors that output orientation with respect to the direction of gravity, to achieve soft robot proprioception. A simple method for estimating the shape of a soft continuum robot arm from IMUs mounted along the arm is presented. The approach approximates a soft arm as a serial chain of rigid links, where the orientation of each link is given by the output of an IMU or by spherical linear interpolation of the output of adjacent IMUs. In experiments conducted on a 660mm long real-world soft arm, this approach provided estimates of its end effector position with a median error of less than 10% of the arm's length. This demonstrates the potential of IMUs to serve as inexpensive off-the-shelf sensors for soft robot proprioception.
# Model-Based Contact Detection and Accommodation for Soft Bending Actuators: An Integrated Direct/Indirect Adaptive Robust Approach
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Motion Control
## Abstract:
Soft robots have intrinsic advantages in interaction with humans or complex environments for actual applications, during which various external disturbances (e.g., external contact or collision) are inevitable. They show remarkable abilities in complicated tasks due to their easily deformable bodies and compliance characteristic, while also bringing challenges to the modeling, control, and trajectory planning in precise tasks. Thereby, perception and reaction to external disturbances are quite critical. In this paper, we focus on the slowly varying external contact and propose a contact detection method for the fiber-reinforced soft bending actuator (FRSBA), which is based on the system dynamical behavior. When contact is detected, a parameter extension method is introduced to modify the dynamic model. Then, a backstepping-based integrated direct/indirect adaptive robust controller with contact detection and accommodation strategy (CDA-DIARC) is designed to deal with system nonlinearities, uncertainties, and parametric variations caused by the external contact. Theoretical proof and physical experiments validate the convergence and high trajectory tracking performance of the proposed methods under different contact environments.
# A Unified and Modular Model Predictive Control Framework for Soft Continuum Manipulators under Internal and External Constraints
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Optimization and Optimal Control
- Robust/Adaptive Control
## Abstract:
Fluidically actuated soft robots have promising capabilities such as inherent compliance and user safety. The control of soft robots needs to properly handle nonlinear actuation dynamics, motion constraints, workspace limitations, and variable shape stiffness, so having a unique algorithm for all these issues would be extremely beneficial. In this work, we adapt Model Predictive Control (MPC), popular for rigid robots, to a soft robotic arm called SoPrA. We address the challenges that current control methods are facing, by proposing a framework that handles these in a modular manner. While previous work focused on Joint-Space formulations, we show through simulation and experimental results that Task-Space MPC can be successfully implemented for dynamic soft robotic control. We provide a way to couple the Piece-wise Constant Curvature and Augmented Rigid Body Model assumptions with internal and external constraints and actuation dynamics, delivering an algorithm that unites these aspects and optimizes over them. We believe that a MPC implementation based on our approach could be the way to address most of model-based soft robotics control issues within a unified and modular framework, while allowing to include improvements that usually belong to other control domains such as machine learning techniques.
# Contact-Implicit Trajectory and Grasp Planning for Soft Continuum Manipulators
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Soft Robot Applications
## Abstract:
As robots begin to move from structured industrial environments to the real world, they must be equipped to not only safely interact with the environment, but also reason about how to leverage contact to perform tasks. In this work, we develop a modeling and motion planning framework for continuum robots that accounts for contact anywhere along the robot. We first present an analytical model for continuum manipulators under contact and discuss the ideal choice of generalized coordinates given properties of the manipulator and task specifications. We then demonstrate the utility of our model by developing a motion planning framework that can solve a diverse set of tasks. We apply our framework to end effector path planning for a soft arm in an obstacle-rich environment, and grasp planning for soft robotic grippers, where contact can happen anywhere on the arm or gripper. Finally, we verify the utility of our model and planning framework by planning a grasp with a desired contact force for a soft antipodal gripper and testing this grasp in a hardware demonstration. Overall, our model and planning approach further enhance soft and continuum robots where they already excel: utilizing contact with the world to achieve their goals with a gentle touch.
# Analytical Modeling of a Membrane-Based Pneumatic Soft Gripper
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Soft Robot Applications
- Contact Modeling
## Abstract:
Finite deformation is the principal actuation basis of elastomer-based pneumatic soft actuators. Desired deformation behavior is the key design requirement for such actuators. The objective of current study is to optimize the design of a flat shell gripper and to investigate its interaction with a cylindrical object. Herein, we propose an analytical model for a membrane-based flat shell gripper. The model is based on finite strain membrane theory and neo-Hookean material. The proposed model considers the contact interaction of the actuator with flat and cylindrical rigid substrates. The model is developed for three different states of the actuator: (a) free-space; (b) contact with a flat substrate; and (c) contact with a cylindrical substrate. In application, the model was used to predict the relative position and air pressure required to grasp a cylindrical object by a parallel two-fingered shell gripper. Additionally, the frictional behavior of the actuator in contact with a cylindrical substrate is investigated. The model involves only solving nonlinear algebraic equations and is computationally efficient. The theoretically predicted deformation behavior of the actuator is experimentally validated via free-space deformation, force measurement, and grasping tests.
# Planar Modeling and Sim-To-Real of a Tethered Multimaterial Soft Swimmer Driven by Peano-HASELs
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Soft Robot Materials and Design
- Soft Robot Applications
## Abstract:
Soft robotics has the potential to revolutionize robotic locomotion, in particular, soft robotic swimmers offer a minimally invasive and adaptive solution to explore and preserve our oceans. Unfortunately, current soft robotic swimmers are vastly inferior to evolved biological swimmers, especially in terms of controllability, efficiency, maneuverability, and longevity. Additionally, the tedious iterative fabrication and empirical testing required to design soft robots has hindered their optimization. In this work, we tackle this challenge by providing an efficient and straightforward pipeline for designing and fabricating soft robotic swimmers equipped with electrostatic actuation. We streamline the process to allow for rapid additive manufacturing, and show how a differentiable simulation can be used to match a simplified model to the real deformation of a robotic swimmer. We perform several experiments with the fabricated swimmer by varying the voltage and actuation frequency of the swimmer's antagonistic muscles. We show how the voltage and frequency vary the locomotion speed of the swimmer while moving in liquid oil and observe a clear optimum in forward swimming speed. The differentiable simulation model we propose has various downstream applications, such as control and shape optimization of the swimmer; optimization results can be directly mapped back to the real robot through our sim-to-real matching.
# Model-Based Disturbance Estimation for a Fiber-Reinforced Soft Manipulator Using Orientation Sensing
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Soft Sensors and Actuators
## Abstract:
A soft robotic arm should ideally be working efficiently, robustly, and safely in human-centered environments to provide assistance in real-world situations. For this goal, soft robots need to be able to estimate their state and external interactions based on (proprioceptive) sensors. Estimating disturbances allows a soft robot to perform desirable force control. Even in the case of rigid manipulators, force estimation at the end-effector is seen as a non-trivial problem. And indeed, other current approaches to address this challenge have shortcomings that prevent their general application. They are often based on simplified soft dynamic models, such as the ones relying on a piece-wise constant curvature approximation or matched rigid-body models that do not represent enough details of the problem. Thus, the applications needed for complex human-robot interaction can not be built. Finite element method (FEM) based modelings allow for predictions of soft robot dynamics in a more generic fashion. Here, using the soft robot modeling capabilities of the framework SOFA, we build a detailed FEM model of a multi-segment soft continuum robotic arm composed of compliant deformable materials and fiber-reinforced pressurized actuation chambers. In addition, a model for sensors that provide orientation output is presented. This model is used to establish a state observer for the manipulator. The sensor model is adequate for representing the output of flexible bend sensors as well as orientations provided by IMUs or coming from tracking systems, all of which are popular choices in soft robotics. Model parameters were calibrated to match imperfections of the manual fabrication process using physical experiments. We then solve a quadratic programming inverse dynamics problem to compute the components of external force that explain the pose error. Our experiments show an average force estimation error of around 1.2%. As the methods proposed are generic, these results are encouraging for the task of building soft robots exhibiting complex, reactive, sensor-based behavior that can be deployed in human-centered environments.
# Variable Stiffness Object Recognition with Bayesian Convolutional Neural Network on a Soft Gripper
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Deep Learning Methods
## Abstract:
From a medical standpoint, detecting the size and shape of hard inclusions hidden in soft three-dimensional objects is of great significance for early detection of cancer through palpation. Soft robots, especially soft grippers, substantially broaden robots' palpation capabilities from soft to hard materials without the assistance of a camera. We have recently introduced a CNN-Bayes approach which added a Naive Bayes classifier to a convolutional neural network (CNN) architecture called SoftTactNet for variable stiffness object recognition on a three-finger FinRay soft gripper. SoftTactNet itself lacks uncertainty estimations though it can reach a certain level of recognition accuracy. In this paper, We further improve the framework by merging Bayes method directly into CNN architectures and build a new Bayes-SoftTactNet for object recognition. The new approach, using a prior distribution instead of point estimation, allows the network to present results with uncertainty estimates. We conduct new experiments using the same soft gripper with tactile sensor arrays to grasp different variable stiffness objects surrounded by non-different soft material and generate tactile images as dataset. The results show that our new algorithm is more efficient than the previous approach and still able to achieve higher recognition accuracy than general deterministic CNNs.
# SLAM 7
# Simultaneous Localization and Mapping through the Lens of Nonlinear Optimization
## Keywords:
- Visual-Inertial SLAM
- Localization
- Mapping
## Abstract:
Simultaneous Localization and Mapping (SLAM) algorithms perform visual-inertial estimation via filtering or batch optimization methods. Empirical evidence suggests that filtering algorithms are computationally faster, while optimization methods are more accurate. This work presents an optimization-based framework that unifies these approaches, and allows users to flexibly implement different design choices, e.g., the number and types of variables maintained in the algorithm at each time. We prove that filtering methods correspond to specific design choices in our generalized framework. We then reformulate the Multi-State Constrained Kalman Filter (MSCKF) and contrast its performance with that of sliding-window based filters. Our approach modularizes state-of-the-art SLAM algorithms to allow for adaptation to various scenarios. Experiments on the EuRoC MAV dataset verify that our implementations of these algorithms are competitive with the performance of off-the-shelf implementations in the literature. Using these results, we explain the relative performance characteristics of filtering and batch-optimization based algorithms in the context of our framework. We illustrate that under different design choices, our empirical performance interpolates between those of state-of-the-art approaches.
# Fast and Safe Exploration Via Adaptive Semantic Perception in Outdoor Environments
## Keywords:
- Perception-Action Coupling
- Motion and Path Planning
- Field Robots
## Abstract:
 Autonomous exploration in unknown environments is a fundamental task for robots. Existing approaches mostly were concentrated on the efficiency of the exploration with the assumption of perfect state estimation, but the drift of pose estimation in visual SLAM occurs frequently and is detrimental to robot's localization safety and exploration performance. In this paper, a perception-aware exploration(PAE) method is proposed for rapidly and safely autonomous exploration in outdoor environments. The adaptive semantic perception is proposed to improve the robustness of perceptual ability, and based on the perception module, both the selection of exploration goal on a novel weighted information gain and the path planning can avoid the areas with high localization uncertainty. In addition, thanks to the proposed pipeline, including the scan-based frontier detection, kd-tree based map prediction and suboptimal frontier buffer strategy, the PAE planner can explore the environment with high success rate and high efficiency. Several simulations are performed to verify the effectiveness of our methods.
# Towards Robust Visual-Inertial Odometry with Multiple Non-Overlapped Monocular Cameras
## Keywords:
- Visual-Inertial SLAM
- Omnidirectional Vision
## Abstract:
We present a Visual-Inertial Odometry (VIO) algorithm with multiple non-overlapping monocular cameras aiming at improving the robustness of the VIO algorithm. An initialization scheme and tightly-coupled bundle adjustment for multiple non-overlapping monocular cameras are proposed. With more stable features captured by multiple cameras, VIO can maintain stable state estimation, especially when one of the cameras tracked unstable or limited features. We also address the high CPU usage rate brought by multiple cameras by proposing a GPU-accelerated frontend. Finally, we use our pedestrian carried system to evaluate the robustness of the VIO algorithm in several challenging environments. The results show that the multi-camera setup yields significantly higher estimation robustness than a monocular system while not increasing the CPU usage rate (reducing the CPU resource usage rate and computational latency by 40.4% and 50.6% on each camera). A demo video can be found at https://youtu.be/r7QvPth1m10.
# Scalable Probabilistic Gas Distribution Mapping Using Gaussian Belief Propagation
## Keywords:
- Robotics in Hazardous Fields
- Environment Monitoring and Management
- Probabilistic Inference
## Abstract:
This paper advocates the Gaussian belief propagation solver for factor graphs in the case of gas distribution mapping to support an olfactory sensing robot. The local message passing of belief propagation moves away from the standard Cholesky decomposition technique, which avoids solving the entire factor graph at once and allows for only areas of interest to be updated more effectively. Implementing a local solver means that iterative updates to the distribution map can be achieved orders of magnitude quicker than conventional direct solvers which scale computationally to the size of the map. After defining the belief propagation algorithm for gas mapping, several state of the art message scheduling algorithms are tested in simulation against the standard Cholesky solver for their ability to converge to the exact solution. Testing shows that under the wildfire scheduling method for a large urban scenario, that distribution maps can be iterated at least 10 times faster whilst still maintaining exact solutions. This move to an efficient local framework allows future works to consider 3D mapping, predictive utility and multi-robot distributed mapping.
# WiSARD: A Labeled Visual and Thermal Image Dataset for Wilderness Search and Rescue
## Keywords:
- Search and Rescue Robots
- Data Sets for Robotic Vision
- Object Detection, Segmentation and Categorization
## Abstract:
Sensor-equipped unoccupied aerial vehicles (UAVs) have the potential to help reduce search times and alleviate safety risks for first responders carrying out Wilderness Search and Rescue (WiSAR) operations, the process of finding and rescuing person(s) lost in wilderness areas. Unfortunately, visual sensors alone do not address the need for robustness across all the possible terrains, weather, and lighting conditions that WiSAR operations can be conducted in. The use of multi-modal sensors, specifically visual-thermal cameras, is critical in enabling WiSAR UAVs to perform in diverse operating conditions. However, due to the unique challenges posed by the wilderness context, existing dataset benchmarks are inadequate for developing vision-based algorithms for autonomous WiSAR UAVs. To this end, we present WiSARD, a dataset with roughly 56,000 labeled visual and thermal images collected from UAV flights in various terrains, seasons, weather, and lighting conditions. To the best of our knowledge, WiSARD is the first large-scale dataset collected with multi-modal sensors for autonomous WiSAR operations. We envision that our dataset will provide researchers with a diverse and challenging benchmark that can test the robustness of their algorithms when applied to real-world (life-saving) applications.
Link to dataset: https://sites.google.com/uw.edu/wisard/
# A Tightly-Coupled Event-Inertial Odometry Using Exponential Decay and Linear Preintegrated Measurements
## Keywords:
- Visual-Inertial SLAM
- Vision-Based Navigation
## Abstract:
In this paper, we introduce an event-based visual odometry and mapping framework that relies on decaying event-based corners. Event cameras, unlike conventional cameras, can provide sensor data during high-speed motions or in scenes with high dynamic ranges. Rather than providing intensity information at a global shutter rate, events are triggered asynchronously depending on whether there is a change in brightness at the pixel location. This novel sensing paradigm calls for unconventional ego-motion estimation techniques to address these new challenges. The key aspect of our framework is the use of a continuous representation of inertial measurements to characterise the system's motion which accommodates the asynchronous nature of the event data while estimating a discrete state in an optimisation-based approach. The proposed method relies on corners extracted from events-only data and associates them with a spatio-temporal locality scheme based on exponential decay. Event tracks are then tightly coupled with temporally accurate preintegrated inertial measurements, allowing for the estimation of ego-motion and a sparse map. The proposed method is evaluated on the Event Camera Dataset showing performance against the state-of-art in event-based visual-inertial odometry.
# Photometric Visual-Inertial Navigation with Uncertainty-Aware Ensembles (I)
## Keywords:
- Visual-Inertial SLAM
- Vision-Based Navigation
- Sensor Fusion
## Abstract:
In this article, we propose a visual-inertial navigation system that directly minimizes a photometric error without an explicit data-association. We focus on the photometric error parametrized by pose and structure parameters that is highly nonconvex due to the nonlinearity of image intensity. The key idea is to introduce an optimal intensity gradient that accounts for a projective uncertainty of a pixel. Ensembles sampled from the state uncertainty contribute to the proposed gradient and yield a correct update direction even in a bad initialization point. We present two sets of experiments to demonstrate the strengths of our framework. First, a thorough Monte Carlo simulation in a virtual trajectory is designed to reveal robustness to large initial uncertainty. Second, we show that the proposed framework can achieve superior estimation accuracy with efficient computation time over state-of-the-art visual-inertial fusion methods in a real-world UAV flight test, where most scenes are composed of a featureless floor.
# FAST-LIO2: Fast Direct LiDAR-Inertial Odometry (I)
## Keywords:
- SLAM
- Mapping
- Autonomous Vehicle Navigation
## Abstract:
This article presents FAST-LIO2: a fast, robust, and versatile LiDAR-inertial odometry framework. Building on a highly efficient tightly coupled iterated Kalman filter, FAST-LIO2 has two key novelties that allow fast, robust, and accurate LiDAR navigation (and mapping). The first one is directly registering raw points to the map (and subsequently update the map, i.e., mapping) without extracting features. This enables the exploitation of subtle features in the environment and, hence, increases the accuracy. The elimination of a hand-engineered feature extraction module also makes it naturally adaptable to emerging LiDARs of different scanning patterns; the second main novelty is maintaining a map by an incremental k-dimensional (k-d) tree data structure, incremental k-d tree ( ikd-Tree ), that enables incremental updates (i.e., point insertion and delete) and dynamic rebalancing. Compared with existing dynamic data structures (octree, R -tree, and nanoflann k-d tree), ikd-Tree achieves superior overall performance while naturally supports downsampling on the tree. We conduct an exhaustive benchmark comparison in 19 sequences from a variety of open LiDAR datasets. FAST-LIO2 achieves consistently higher accuracy at a much lower computation load than other state-of-the-art LiDAR-inertial navigation systems. Various real-world experiments on solid-state LiDARs with small field of view are also conducted. Overall, FAST-LIO2 is computationally efficient (e.g., up to 100 Hz odometry and mapping in large outdoor environments), robust (e.g., reliable pose estimation in cluttered indoor environments with rotation up to 1000 deg/s), versatile (i.e., applicable to both multiline spinning and solid-state LiDARs, unmanned aerial vehicle (UAV) and handheld platforms, and Intel# and ARM-based processors), while still achieving a higher accuracy than existing methods. Our implementation of the system FAST-LIO2 and the data structure ikd-Tree are both open-sourced on Github.
# Rail Vehicle Localization and Mapping with LiDAR-Vision-Inertial-GNSS Fusion
## Keywords:
- Field Robots
- Intelligent Transportation Systems
- SLAM
## Abstract:
In this paper, we present a global navigation satellite system (GNSS) aided LiDAR-visual-inertial scheme, RailLoMer-V, for accurate and robust rail vehicle localization and mapping. RailLoMer-V is formulated atop a factor graph and consists of two subsystems: an odometer assisted LiDAR-inertial system (OLIS) and an odometer integrated Visual-inertial system (OVIS). Both the subsystem exploits the typical geometry structure on the railroads. The plane constraints from extracted rail tracks are used to complement the rotation and vertical errors in OLIS. Besides, the line features and vanishing points are leveraged to constrain rotation drifts in OVIS. The proposed framework is extensively evaluated on datasets over 800 km, gathered for more than a year on both general-speed and high-speed railways, day and night. Taking advantage of the tightly-coupled integration of all measurements from individual sensors, our framework is accurate to long-during tasks and robust enough to grievously degenerated scenarios (railway tunnels). In addition, the real-time performance can be achieved with an onboard computer.
# Medical Robots and Systems 7
# A Metric for Finding Robust Start Positions for Medical Steerable Needle Automation
## Keywords:
- Surgical Robotics: Steerable Catheters/Needles
- Surgical Robotics: Planning
- Medical Robots and Systems
## Abstract:
Steerable needles are medical devices with the ability to follow curvilinear paths to reach targets while circumventing obstacles. In the deployment process, a human operator typically places the steerable needle at its start position on a tissue surface and then hands off control to the automation that steers the needle to the target. Due to uncertainty in the placement of the needle by the human operator, choosing a start position that is robust to deviations is crucial since some start positions may make it impossible for the steerable needle to safely reach the target. We introduce a method to efficiently evaluate steerable needle motion plans such that they are safe to variation in the start position. This method can be applied to many steerable needle planners and requires that the needle’s orientation angle at insertion can be robotically controlled. Specifically, we introduce a method that builds a funnel around a given plan to determine a safe insertion surface corresponding to insertion points from which it is guaranteed that a collision-free motion plan to the goal can be computed. We use this technique to evaluate multiple feasible plans and select the one that maximizes the size of the safe insertion surface. We evaluate our method through simulation in a lung biopsy scenario and show that the method is able to quickly find needle plans with a large safe insertion surface.
# Design and Development of a Lorentz Force-Based MRI-Driven Neuroendoscope
## Keywords:
- Surgical Robotics: Steerable Catheters/Needles
## Abstract:
The introduction of neuroendoscopy, microneurosurgery, neuronavigation, and intraoperative imaging for surgical operations has made significant improvements over other traditionally invasive surgical techniques. The integration of magnetic resonance imaging (MRI)-driven surgical devices with intraoperative imaging and endoscopy can enable further advancements in surgical treatments and outcomes. This work proposes the design and development of an MRI-driven endoscope leveraging the high (3-7 T), external magnetic field of an MR scanner for heat-mitigated steering within the ventricular system of the brain. It also demonstrates the effectiveness of a Lorentz force-based grasper for diseased tissue manipulation and ablation. Feasibility studies show the neuroendoscope can be steered precisely within the lateral ventricle to locate a tumor using both MRI and endoscopic guidance. Results also indicate grasping forces as high as 31 mN are possible and power inputs as low as 0.69 mW can cause cancerous tissue ablation. These findings enable further developments of steerable devices using MR imaging integrated with endoscopic guidance for improved outcomes.
# GESRsim: Gastrointestinal Endoscopic Surgical Robot Simulator
## Keywords:
- Medical Robots and Systems
- Simulation and Animation
- Visual Servoing
## Abstract:
Robot-assisted gastrointestinal endoscopic surgery (GES) as a kind of natural orifice transluminal endoscopic surgery (NOTES) is the next-generation minimally invasive surgery (MIS). Besides, rendering certain autonomy to a Gastrointestinal Endoscopic Surgical Robot (GESR) is currently promising but highly challenging. Therefore, to accelerate the development and augment the autonomy of GESR, we use CoppeliaSim to develop the first robotic simulator for the GESR system (GESRsim) based on our previous design. The GESRsim provides several 3D models and kinematics of our designed manipulators and endoscopic snake bone. Additionally, we build several scenes for robotic GES training and then utilize different programming interfaces to perform teleoperation. Furthermore, several advanced control algorithms, including visual servoing (VS) and deep reinforcement learning (DRL), are implemented to verify the performance of the GESRsim.
# A Dataset and Benchmark for Learning the Kinematics of Concentric Tube Continuum Robots
## Keywords:
- Surgical Robotics: Steerable Catheters/Needles
- Data Sets for Robot Learning
- Flexible Robotics
## Abstract:
Establishing a physics-based model capturing the kinetostatic behavior of concentric tube continuum robots is challenging as elastic interactions between the flexible tubes constituting the robot result in a highly non-linear problem. The Goldstandard physics-based model using the Cosserat theory of elastic rods achieves reasonable approximations with 1.5-3% with respect to the robot's length, if well-calibrated. Learning-based models of concentric tube continuum robots have been shown to outperform the Goldstandard model with approximation errors below 1%. Yet, the merits of learning-based models remain largely unexplored as no common dataset and benchmark exist.
In this paper, we present a dataset captured from a three-tube concentric tube continuum robot for use in learning-based kinematics research. The dataset consists of 100,000 joint configurations and the corresponding four 6 dof sensors in SE(3) measured with an electromagnetic tracking system (github.com/ContinuumRoboticsLab/CRL-Dataset-CTCR-Pose). With our dataset, we empower the continuum robotics and machine learning community to advance the field. We share our insights and lessons learned on joint space representation, shape representation in task space, and sampling strategies. Furthermore, we provide benchmark results for learning the forward kinematics using a simple, shallow feedforward neural network. The benchmark results for the tip error are 0.74 mm w.r.t. position (0.4 % of total robot length) and 6.49 grad w.r.t. orientation.
# Intrinsic Force Sensing for Motion Estimation in a Parallel, Fluidic Soft Robot for Endoluminal Interventions
## Keywords:
- Soft Robot Applications
- Medical Robots and Systems
- Soft Sensors and Actuators
## Abstract:
Determining the externally-induced motion of a soft robot in minimally-invasive procedures is highly challenging and commonly demands specific tools and dedicated sensors. Intrinsic force sensing paired with a model describing the robot's compliance offers an alternative pathway which relies heavily on knowledge of the characteristic mechanical behaviour of the investigated system. In this work, we apply quasi-static intrinsic force sensing to a miniature, parallel soft robot designed for endoluminal ear interventions. We characterize the soft robot's nonlinear mechanical behaviour and devise methods for inferring forces applied to the actuators of the robot from fluid pressure and volume information of the working fluid. We demonstrate that it is possible to detect the presence of an external contact acting on the soft robot's actuators, infer the applied reaction force with an accuracy of 28.1mN and extrapolate from individual actuator force sensing to determining forces acting on the combined parallel soft robot when it is deployed in a lumen, which can be achieved with an accuracy of 75.45mN for external forces and 0.47Nmm for external torques. The intrinsically-sensed external forces can be employed to estimate the induced motion of the soft robot in response to these forces with an accuracy of 0.11mm in translation and 2.47deg in rotational deflection. The derived methodologies could enable designs for more perceptive endoscopic systems and pave the way for developing sensing and control strategies in endoluminal and transluminal soft robots.
# Contact Localization of Continuum and Flexible Robot Using Data-Driven Approach
## Keywords:
- Surgical Robotics: Steerable Catheters/Needles
- Medical Robots and Systems
## Abstract:
Continuum robots such as robotic catheters are increasingly being used in minimally invasive surgery. Compliance contributes to enhanced safety during e.g. catheter insertion, however, estimation of contact force and location may help clinicians avoiding exerting excessive force. Ultimately this could lead to faster and safer interventions. Researchers proposed force sensors integrated in the catheter tip in the past. However, such sensors add extra complexity to the catheter design. Also, tip force sensors do not provide insights on forces that act along the catheter length. This paper proposes a data-driven approach for localizing contact forces that appear over the length of the catheter. The proposed approach consists of a collision detection method and a contact localization method. The framework only requires the measurement of the catheter's shape which can be done by an embedded multi-core Fiber Bragg Grating fiber. The method was validated experimentally with a 3D-printed continuum robot with an integrated multi-core fiber. A second contact localization method which is based on identifying the discontinuity in the measured curvature, is also implemented and compared with the proposed method. The static and dynamic experiments show a mean average localization error of 2.3 mm and 4.3 mm which correspond to respectively 3.3% and 6.1% of a 70 mm long flexible robot. These findings demonstrate that the proposed framework outperforms the previous methods and yields promising results. The contact state estimation algorithm can detect collisions in at most approximately 1.08s.
# Deep-Learning-Based Compliant Motion Control of a Pneumatically-Driven Robotic Catheter
## Keywords:
- Surgical Robotics: Steerable Catheters/Needles
- Medical Robots and Systems
## Abstract:
In cardiovascular interventions, when steering catheters and especially robotic catheters, great care should be paid to prevent applying too large forces on the vessel walls as this could dislodge calcifications, induce scars or even cause perforation. To address this challenge, this paper presents a novel compliant motion control algorithm that relies solely on position sensing of the catheter tip and knowledge of the catheter's behavior. The proposed algorithm features a data-driven tip position controller. The controller is trained based on a so-called control Long Short-Term Memory Network (control-LSTM). Trajectory following experiments on four different trajectories are conducted to validate the quality of the proposed control-LSTM. The performance was compared with the performance of a controller that makes use of an analytical hysteresis model, i.e. the inverse Deadband Rate-Dependent Prandtl-Ishlinskii (IDRDPI) model. Results demonstrated superior positioning capability with sub-degree precision of the new approach in the presence of severe rate-dependent hysteresis. Experiments both in a simplified setup as well as in an aortic phantom further show that the proposed approach allows reducing the interaction forces with the environment by around 70%. This work shows how deep learning can be exploited advantageously to avoid tedious modeling that would be needed to precisely steer continuum robots in constrained environments such as the patient's vasculature.
# Colonoscopy Navigation Using End-To-End Deep Visuomotor Control: A User Study
## Keywords:
- Surgical Robotics: Planning
- Medical Robots and Systems
- Vision-Based Navigation
## Abstract:
Flexible Endoscopes (FEs) for colonoscopy present several limitations due to their inherent complexity, resulting in patient discomfort and lack of intuitiveness for clinicians. Robotic FEs with autonomous control represent a viable solution to reduce the workload of endoscopists and the training time while improving the procedure outcome. Prior works on autonomous endoscope FE control use heuristic policies that limit their generalisation to the unstructured and highly deformable colon environment and require frequent human intervention. This work proposes an image-based FE control using Deep Reinforcement Learning, called Deep Visuomotor Control (DVC), to exhibit adaptive behaviour in convoluted sections of the colon. DVC learns a mapping between the images and the FE control signal. A first user study of 20 expert gastrointestinal endoscopists was carried out to compare their navigation performance with DVC using a realistic virtual simulator. The results indicate that DVC shows equivalent performance on several assessment parameters, being more safer. Moreover, a second user study with 20 novice users was performed to demonstrate easier human supervision compared to a state-of-the-art heuristic control policy. Seamless supervision of colonoscopy procedures would enable endoscopists to focus on the medical decision rather than on the control of FE.
# Shape Memory Polymer Variable Stiffness Magnetic Catheters with Hybrid Stiffness Control
## Keywords:
- Surgical Robotics: Steerable Catheters/Needles
- Soft Robot Materials and Design
- Medical Robots and Systems
## Abstract:
Variable stiffness catheters typically rely on thermally induced stiffness transitions with a transition temperature above body temperature. This imposes considerable safety limitations for medical applications. In this work, we present a variable stiffness catheter using a hybrid control strategy capable of actively heating and actively cooling the catheter material. The proposed catheter is made of a single biocompatible shape memory polymer, which significantly increases its manufacturability and scalability compared to existing designs. Increased safety is obtained by ensuring a lower-risk compliant state at body temperature while maintaining higher stiffness ranges in actively controlled states. Additionally, the combined use of variable stiffness and magnetic actuation increases the dexterity and steerability of the device compared to existing robotic tools.
# Compliance and Impedance Control 1
# Learning Variable Impedance Control for Aerial Sliding on Uneven Heterogeneous Surfaces through Proprioceptive and Tactile Sensing
## Keywords:
- Compliance and Impedance Control
- Aerial Systems: Applications
- Machine Learning for Robot Control
## Abstract:
The recent development of novel aerial vehicles capable of physically interacting with the environment leads to new applications such as contact-based inspection. These tasks require the robotic system to exchange forces with partially-known environments, which may contain uncertainties including unknown spatially-varying friction properties and discontinuous variations of the surface geometry. Finding a solution that senses, adapts, and remains robust against these environmental uncertainties remains an open challenge. This paper presents a learning-based adaptive control strategy for aerial sliding tasks. In particular, the gains of a standard impedance controller are adjusted in real-time by a neural network policy based on proprioceptive and tactile sensing. This policy is trained in simulation with simplified actuator dynamics in a student-teacher learning setup. The real-world performance of the proposed approach is verified using a tilt-arm omnidirectional flying vehicle. The proposed controller structure combines data-driven and model-based control methods, enabling our approach to successfully transfer directly and without adaptation from simulation to the real platform. We attribute the success of the sim-to-real transfer to the inclusion of feedback control in the training and deployment. We achieved tracking performance and disturbance rejection that cannot be achieved using fine-tuned state of the art interaction control method.
# Passivity-Based Skill Motion Learning in Stiffness-Adaptive Unified Force-Impedance Control
## Keywords:
- Compliance and Impedance Control
- Energy and Environment-Aware Automation
- Human-Robot Collaboration
## Abstract:
Tactile robots shall be deployed for dynamic task execution in production lines with small batch sizes. Therefore, these robots should have the ability to respond to changing conditions and be easy to (re-)program. Operating under uncertain environments requires unifying subsystems such as robot motion and force policy into one framework, referred to as tactile skills. In this paper, we propose the enhancement of these skills for passivity-based skill motion learning in stiffness-adaptive unified force-impedance control. To achieve the increased level of adaptability, we represent all tactile skills by three basic primitives: contact initiation, manipulation, and contact termination. To ensure passivity and stability, we develop an energy-based approach for unified force-impedance control that allows humans to teach the robot motion through physical interaction during the execution of a tactile task. We incorporate our proposed framework into a tactile robot to experimentally validate the motion adaptation by interaction performance and stability of the control. While the polishing task is presented as our use case through the paper, the experiments can also be carried out with various tactile skills. Finally, the results show the novel controller's stability and passivity to contact-loss and stiffness adaptation, leading to successful programming by interaction.
# Perturbation-Based Stiffness Inference in Variable Impedance Control
## Keywords:
- Compliance and Impedance Control
- Learning from Demonstration
- Probabilistic Inference
## Abstract:
One of the major challenges in learning from demonstration is to teach the robot a wider set of task features than the plain trajectories to be followed. In this sense, one key parameter is stiffness, i.e., the rigidity that the manipulator should exhibit when performing a task. The required robot stiffness is often not known a priori and varies along the execution of the task, thus its profile needs to be inferred from the demonstrations. In this work, we propose a novel, force-based algorithm for inferring time-varying stiffness profiles, leveraging the relationship between stiffness and tracking error, and involving human-robot interaction. We begin by gathering a set of demonstrations with kinesthetic teaching. Then, the robot executes a perturbed reference, obtained from these demonstrations by means of Gaussian process regression, and the human intervenes if the perturbation makes the manipulator deviate from its expected behaviour. Human intervention is measured and used to infer the desired control stiffness. In the experiments section, we show that our algorithm can be combined with different types of force sensors, and provide suitable processing algorithms. Our approach correctly infers the stiffness profiles from the force and electromyography sensors, their combination permitting also to comply with the physical constraints imposed by the environment. This is demonstrated in three experiments of increasing complexity: a motion in free Cartesian space, a rigid assembly task, and bed-making.
# A Whole-Body Controller Based on a Simplified Template for Rendering Impedances in Quadruped Manipulators
## Keywords:
- Compliance and Impedance Control
- Legged Robots
- Whole-Body Motion Planning and Control
## Abstract:
Quadrupedal manipulators require to be compliant when dealing with external forces during autonomous manipulation, tele-operation or physical human-robot interaction. This paper presents a whole-body controller that allows for the implementation of a Cartesian impedance control to coordinate tracking performance and desired compliance for the robot base and manipulator arm. The controller is formulated through an optimization problem using Quadratic Programming (QP) to impose a desired behavior for the system while satisfying friction cone constraints, unilateral force constraints, joint and torque limits. The presented strategy decouples the arm and the base of the platform, enforcing the behavior of a linear double-mass spring damper system, and allows to independently tune their inertia, stiffness and damping properties. The control architecture is validated through a set of simulations using the 90kg HyQ robot equipped with a 7-DoF manipulator arm. Simulation results show the impedance rendering performance when external forces are applied at the arm's end-effector. The paper presents results for full stance condition (all legs on the ground) and, for the first time, also shows how the impedance rendering is affected by the contact conditions during a dynamic gait.
# Electro-Adhesive Tubular Clutch for Variable-Stiffness Robots
## Keywords:
- Compliance and Impedance Control
- Mechanism Design
- Soft Robot Applications
## Abstract:
Electro-adhesive clutches have become effective tools for variable stiffness functions in many robotic systems due to their light weight, high speed and strong brake force. In this paper, we present a novel, tubular design of an electro-adhesive clutch. Our clutch consists of flexible electrode sheets rolled into a tubular structure. This design allows encapsulating large electrode areas in a compact size for strong brake force. Additionally, the tubular structure acts as a guide for directional sliding without external guides. The structure also ensures that the electrode surfaces are encapsulated, preventing the accumulation of dust and thus leading to reliable performance. This structure is therefore an improvement over the commonly used planar designs. The characterization of the electro-adhesive tubular clutch shows that the frictional force increases with the increase of the electrode contact area, the decrease of the roll diameter and the dielectric layer thickness. A retractable tubular clutch is made by fixing an elastic cable along the clutch axis and achieves a stiffness change factor up to 260. Applications of this retractable clutch in robotics to achieve variable stiffness are demonstrated in two systems: a tensegrity structure and a wing skeleton. Changes in stiffness by 13.2 and 30.2 times are achieved for the two systems, respectively. The proposed tubular clutch is an effective means of achieving variable stiffness, particularly in the case of robotic systems that transmit forces through tensioned cables.
# An Observer-Based Responsive Variable Impedance Control for Dual–User Haptic Training System
## Keywords:
- Compliance and Impedance Control
- Medical Robots and Systems
- Physically Assistive Devices
## Abstract:
This paper proposes a variable impedance control architecture to facilitate eye surgery training in a dual-user haptic system. In this system, an expert surgeon (the trainer) and a novice surgeon (the trainee) collaborate on a surgical procedure using their own haptic devices. The mechanical impedance parameters of the trainer's haptic device remain constant during the operation, whereas those of the trainee vary with his/her proficiency level. The trainee's relative proficiency might be objectively quantified in real-time based on position error between the trainer and the trainee. The proposed architecture enables the trainer to intervene in the training process as needed to ensure the trainee is following the right course of action and to avoid the trainee's from potential tissue injuries. The stability of the overall nonlinear closed-loop system has been investigated using the input-to-state stability (ISS) criterion. High-gain observer with unknown inputs is considered in this work to estimate the interaction forces. Simulation and experimental results under different scenarios confirm the effectiveness of the proposed control methods.
# Development of Low-Inertia Backdrivable Arm Focusing on Learning-Based Control
## Keywords:
- Compliance and Impedance Control
- Compliant Joints and Mechanisms
- Learning from Demonstration
## Abstract:
A robot designed to coexist and work with humans in the same workspace should be able to work at the same speed as humans and have safe contact with humans and with the environment. However, when a robot arm has been given flexibility through mechanisms and controls for the purpose of coexistence, it is difficult for it to perform tasks at the speed and accuracy desired by humans if it is moved simply by using conventional position-based controls. With such an arm, we consider that the use of learning-based control is necessary to achieve both safety and speed. Therefore, we prototyped a low-inertia, high-backdrivability arm as a platform for studying learning-based control and tested two types of learning-based control. This paper describes our design process, in which hardware suitable for learning-based control was developed according to the requirements of the specific task. It also presents the results of our evaluation experiments, in which tasks involving quick movements and motion requiring physical contact with an object were performed using learning-based control.
# BEAR-H: An Intelligent Bilateral Exoskeletal Assistive Robot for Smart Rehabilitation (I)
## Keywords:
- Prosthetics and Exoskeletons
- Rehabilitation Robotics
- Medical Robots and Systems
## Abstract:
One typical application of a robotic exoskeleton is to automate rehabilitation, where the robot is worn by a stroke patient and provides assistance to help perform repetitive motions and regain motor functions. The deployment of exoskeletons can alleviate the shortage of experienced therapists and would also play a vital role in countries with aging populations. However, the intelligence level of existing exoskeletons is relatively low, wherein a robot cannot adapt to either the online change of a subject's motion (e.g., the gait pattern) or the variation of his/her body parameters (i.e., a new subject who is going to wear the robot), potentially resulting in conflict between human and robot and possibly even leading to physical damage. As such, the application of a robotic exoskeleton in clinical studies is limited. This article introduces a new bilateral exoskeletal assistive robot for rehabilitation (i.e., BEAR-H) in which the main novelty is the integration of multiple intelligent features, such as gait recognition and synchronization, cloud-computing diagnosis, and individualized gait generation. Such an integration helps the robot to better understand the patient’s condition and hence provide effective assistance, by the end achieving smart rehabilitation. BEAR-H is a successfully commercialized product, and its performance has been validated in actual clinical studies with 30 patients, producing experimental results from different aspects that are analyzed and presented.
# Data-Driven Variable Impedance Control of a Powered Knee-Ankle Prosthesis for Sit, Stand, and Walk with Minimal Tuning
## Keywords:
- Prosthetics and Exoskeletons
- Compliance and Impedance Control
- Optimization and Optimal Control
## Abstract:
Although the average healthy adult transitions from sit to stand over 60 times per day, the majority of robotic prosthesis control research has focused on walking. In this paper, we present a data-driven controller that enables sitting, standing, and walking with minimal tuning. Our controller comprises two high level modes of sit/stand and walking, and we develop heuristic biomechanical rules to control transitions between the two. We use a phase variable based on the user's thigh angle to parameterize both walking and sit/stand motions, where variable impedance control is used during ground contact and position control is used during the swing phase of walking. We extend previous work on data-driven optimization of continuous impedance parameter functions to design the sit/stand control mode using able-bodied data. We test our controller in experiments with a participant with an above-knee amputation, comparing clinical measures including loading symmetry and sit/stand transition time. The participant completed the sit/stand task 20% faster with approximately half of the loading asymmetry relative to his everyday passive prosthesis. The controller also facilitated a timed up and go test involving sitting, standing, walking, and turning, with only a mild (10%) decrease in speed compared to the everyday prosthesis. Our sit/stand/walk controller enables multiple activities of daily life with minimal tuning and mode switching.
# Software, Middleware and Programming Environments 1
# OHM: GPU Based Occupancy Map Generation
## Keywords:
- Software Tools for Robot Programming
- Autonomous Vehicle Navigation
- Field Robots
## Abstract:
Occupancy grid maps (OGMs) are fundamental to most systems for autonomous robotic navigation. However, CPU-based implementations struggle to keep up with data rates from modern 3D lidar sensors, and provide little capacity for modern extensions which maintain richer voxel representations. This paper presents OHM, our open source, GPU-based OGM framework. We show how the algorithms can be mapped to GPU resources, resolving difficulties with contention to obtain a successful implementation. The implementation supports many modern OGM algorithms including NDT-OM, NDT-TM, decay-rate and TSDF. A thorough performance evaluation is presented based on tracked and quadruped UGV platforms and UAVs, and data sets from both outdoor and subterranean environments. The results demonstrate excellent performance improvements both offline, and for online processing in embedded platforms. Finally, we describe how OHM was a key enabler for the UGV navigation solution for our entry in the DARPA Subterranean Challenge, which placed second at the Final Event.
# IKFlow: Generating Diverse Inverse Kinematics Solutions
## Keywords:
- Software Tools for Robot Programming
- Deep Learning Methods
- Redundant Robots
## Abstract:
Inverse kinematics—finding joint poses that reach a given Cartesian-space end-effector pose—is a fundamental operation in robotics, since goals and waypoints are typically defined in Cartesian space, but robots must be controlled in joint space. However, existing inverse kinematics solvers return a single solution, in contrast, systems with more than 6 degrees of freedom support infinitely many such solutions, which can be useful in the presence of constraints, pose preferences or obstacles. We introduce a method that uses a deep neural network to learn to generate a diverse set of samples from the solution space of such kinematic chains. The resulting samples can be generated quickly (2000 solutions in under 10ms) and accurately (to within 10 millimeters and 2 degrees of an exact solution) and can be rapidly refined by classical methods if necessary.
# Ros2_tracing: Multipurpose Low-Overhead Framework for Real-Time Tracing of ROS 2
## Keywords:
- Software Tools for Robot Programming
- Distributed Robot Systems
- Performance Evaluation and Benchmarking
## Abstract:
Testing and debugging have become major obstacles for robot software development, because of high system complexity and dynamic environments. Standard, middleware-based data recording does not provide sufficient information on internal computation and performance bottlenecks. Other existing methods also target very specific problems and thus cannot be used for multipurpose analysis. Moreover, they are not suitable for real-time applications. In this paper, we present ros2_tracing, a collection of flexible tracing tools and multipurpose instrumentation for ROS 2. It allows collecting runtime execution information on real-time distributed systems, using the low-overhead LTTng tracer. Tools also integrate tracing into the invaluable ROS 2 orchestration system and other usability tools. A message latency experiment shows that the end-to-end message latency overhead, when enabling all ROS 2 instrumentation, is on average 0.0033 ms, which we believe is suitable for production real-time systems. ROS 2 execution information obtained using ros2_tracing can be combined with trace data from the operating system, enabling a wider range of precise analyses, that help understand an application execution, to find the cause of performance bottlenecks and other issues. The source code is available at: https://github.com/ros2/ros2_tracing.
# RobotCore: An Open Architecture for Hardware Acceleration in ROS 2
## Keywords:
- Software, Middleware and Programming Environments
- Computer Architecture for Robotic and Automation
- Hardware-Software Integration in Robotics
## Abstract:
Hardware acceleration can revolutionize robotics, enabling new applications by speeding up robot response times while remaining power-efficient. However, the diversity of acceleration options makes it difficult for roboticists to easily deploy accelerated systems without expertise in each specific hardware platform. In this work, we address this challenge with RobotCore, an architecture to integrate hardware acceleration in the widely-used ROS 2 robotics software framework. This architecture is target-agnostic (supports edge, workstation, data center, or cloud targets) and accelerator-agnostic (supports both FPGAs and GPUs). It builds on top of the common ROS 2 build system and tools and is easily portable across different research and commercial solutions through a new firmware layer. We also leverage the Linux Tracing Toolkit next generation (LTTng) to enable low-overhead real-time tracing and benchmarking of accelerated ROS 2 systems. To demonstrate the acceleration enabled by this architecture, we use it to deploy a ROS 2 perception computational graph on a CPU and FPGA. We also employ our integrated tracing and benchmarking to analyze bottlenecks, uncovering insights that guide us to improve FPGA communication efficiency. In particular, we design an intra-FPGA ROS 2 node communication queue template and use it in conjunction with FPGA-accelerated nodes to achieve a 24.42% speedup over a CPU.
# Tasho: A Python Toolbox for Rapid Prototyping and Deployment of Optimal Control Problem-Based Complex Robot Motion Skills
## Keywords:
- Software Tools for Robot Programming
- Engineering for Robotic Systems
- Optimization and Optimal Control
## Abstract:
We present Tasho (Task specification for receding horizon control), an open-source Python toolbox that facilitates systematic programming of optimal control problem (OCP)-based robot motion skills. Separation-of-concerns is followed while designing the components of a motion skill, which promotes their modularity and reusability. This allows us to program complex motion tasks by configuring and composing simpler tasks. We provide templates for several basic tasks like point-to-point and end-effector path-following tasks to speed up prototyping. Internally, the task's symbolic expressions are computed using CasADi and the resulting OCP is transcribed using Rockit. A wide and growing range of mature open-source optimization solvers are supported for solving the OCP. Monitor functions can be easily specified and are automatically deployed with the motion skill, so that the generated motion skills can be easily embedded in a larger control architecture involving higher-level discrete controllers. The motion skills thus programmed can be directly deployed on robot platforms using the C-code generation capabilities of CasADi. The toolbox has been validated through several experiments both in simulation and on physical robot systems. The open-source toolbox can be accessed at: https://gitlab.kuleuven.be/meco-software/tasho
# Containerization and Orchestration of Software for Autonomous Mobile Robots: A Case Study of Mixed-Criticality Tasks across Edge-Cloud Computing Platforms
## Keywords:
- Software, Middleware and Programming Environments
- Control Architectures and Programming
- Autonomous Agents
## Abstract:
Containerization promises to strengthen platform-independent development, better resource utilization, and secure deployment of software. As these benefits come with negligible overhead in CPU and memory utilization, containerization is increasingly being adopted in mobile robotic applications. An open challenge is supporting software tasks that have mixed-criticality requirements. Even more challenging is the combination of real-time containers with orchestration, which is an emerging paradigm to automate the deployment, networking, scaling, and availability of containerized workloads and services. This paper addresses this challenge by presenting a framework that extends the de-facto reference standard for container orchestration, Kubernetes, to schedule tasks with mixed-criticality requirements. Quantitative experimental results on the software implementing the mission of a Robotnik RB-Kairos mobile robot demonstrate the effectiveness of the proposed approach. The source code is publicly available on GitHub.
# GPU-Accelerated Incremental Euclidean Distance Transform for Online Motion Planning of Mobile Robots
## Keywords:
- Software Tools for Robot Programming
- Mapping
- Motion and Path Planning
## Abstract:
—In this letter, we present a volumetric mapping system that effectively calculates Occupancy Grid Maps (OGMs) and Euclidean Distance Transforms (EDTs) with parallel computing. Unlike these mappers for high-precision structural reconstruction, our system incrementally constructs global EDT and outputs high-frequency local distance information for online robot motion planning. The proposed system constructs OGM with a massive amount of data from multiple types of sensor inputs. Using GPU programming techniques, the system quickly computes EDT in parallel within a local volume. The new observation is continuously integrated into the global EDT using the parallel wavefront algorithm while preserving the historical observations. Experiments with datasets have shown that our proposed approach outperforms existing state-of-the-art robot mapping systems and is particularly suitable for mapping unexplored areas. In its actual implementations on aerial and ground vehicles, the proposed system achieves realtime performance with limited onboard computational resources.
# Transactional Transform Library for ROS
## Keywords:
- Software Tools for Robot Programming
- Software, Middleware and Programming Environments
- Software Architecture for Robotic and Automation
## Abstract:
In the Robot Operating System (ROS), a major middleware for robots, the Transform Library (TF) is a mandatory package that manages transformation information between coordinate systems by using a single-rooted directed tree and providing methods for registering and computing the information. However, the tree has two fundamental problems. The first is its poor scalability: since it accepts only a single thread at a time due to using a single giant lock for mutual exclusion, the access to the tree is sequential. Second, there is a lack of data freshness: it retrieves non-latest synthetic data when computing coordinate transformations because it prioritizes temporal consistency over data freshness. In this paper, we propose methods to solve these problems. First, we decentralize the giant lock to provide performance scalability and show that this results in a throughput 243 times higher than conventional TF on a read-only workload. Second, we design transactional methods based on serializable protocols that prevent anomalies, thus retrieving the freshest data. These transactional methods show a freshness up to 1276 times higher than the conventional one on a read-write combined workload.
# Arena-Bench: A Benchmarking Suite for Obstacle Avoidance Approaches in Highly Dynamic Environments
## Keywords:
- Software Tools for Benchmarking and Reproducibility
- Motion and Path Planning
- Collision Avoidance
## Abstract:
The ability to autonomously navigate safely, especially within dynamic environments is paramount for mobile robotics. In recent years, DRL approaches have shown superior performance in dynamic obstacle avoidance. However, these learning-based approaches are often developed in specially designed simulation environments and are hard to test against conventional planning approaches. Furthermore, the integration and deployment of these approaches into real robotic platforms are not yet completely solved. In this paper, we present Arena-bench, a benchmark suite to train, test, and evaluate navigation planners on different robotic platforms within 3D environments. It provides tools to design and generate highly dynamic evaluation worlds, scenarios, and tasks for autonomous navigation and is fully integrated into the robot operating system. To demonstrate the functionalities of our suite, we trained a DRL agent on our platform and compared it against a variety of existing different model-based and learning-based navigation approaches on a variety of relevant metrics. Finally, we deployed the approaches towards real robots and demonstrated the reproducibility of results. The code is publicly available on github.com/arena-rosnav-3D.
# Wearable Robotics
# An Impedance-Controlled Testbed for Simulating Variations in the Mechanical Fit of Wearable Devices
## Keywords:
- Wearable Robotics
- Compliance and Impedance Control
- Human Performance Augmentation
## Abstract:
The fit of a wearable device, such as a prosthesis, can be quantitatively characterized by the mechanical coupling at the user-device interface. It is thought that the mechanical impedance, specifically the stiffness and damping, of wearable device interfaces can significantly impact human performance while using them. To test this theory, we develop a forearm-mounted testbed with a motorized, two degree of freedom (2-DOF) gimbal to simulate variations in the mechanical fit of an upper-extremity wearable device during pointing and target tracking tasks. The two gimbal motors are impedance-controlled to vary the mechanical stiffness and damping between the user and the device’s laser pointer end-effector. In this paper, experiments are conducted to determine the torque constants of the motors before implementation in the testbed, and to validate the accuracy of the joint impedance controller. The completed impedance-controlled wearable interface testbed is validated further by comparing the gimbal joint displacements and torques, recorded during 2-DOF base excitation experiments, to MATLAB Simulink simulation data.
# Human-Exoskeleton Cooperative Balance Strategy for a Human-Powered Augmentation Lower Exoskeleton
## Keywords:
- Wearable Robotics
- Physical Human-Robot Interaction
- Rehabilitation Robotics
## Abstract:
Lower Limb Exoskeleton (LLE) has received considerable interest in strength augmentation, rehabilitation, and walking assistance scenarios. For strength augmentation, the LLE is expected to have the capability of reducing metabolic energy. However, the energy for adjusting the Center of Gravity (CoG) is the main part of the energy consumption during walking, especially the walking with loads. This paper proposes a novel Human-exoskeleton Cooperative Balance (HCB) strategy for giving balance ability to the assistive torque and combined with the direction selected by the pilot to realize the balance walking of the human-exoskeleton system. In which, a Dynamic Torque Primitive Model (DTPM) is designed to plan a bionic assistive torque, and the balance parameter obtained by an Inverted Pendulum Model (IPM) is superimposed on it. Finally, the improved balance performance can break the limitation of traditional strategies and substantially increase the efficiency of assistance. We demonstrated the effectiveness of the proposed HCB strategy in the HUman-powered Augmentation Lower EXoskeleton (HUALEX) system. Experimental results indicate that the proposed HCB strategy is more efficient than traditional strategies.
# RANK # Robotic Ankle: Design and Testing on Irregular Terrains
## Keywords:
- Wearable Robotics
- Mechanism Design
- Prosthetics and Exoskeletons
## Abstract:
Despite the large amount of available exoskeletons, their use in daily life is still limited due to the absence of testing in real-life environments. This paper aims at presenting the design of a wearable ankle exoskeleton for walking assistance. The system was tested on irregular terrains. Our RANK (Robotic ANKle) is equipped with a servomotor. A four-bar linkage mechanism is used for the torque transmission. An adjustable 3D-printed brace was realized in PC/ABS to connect the exoskeleton to the user shank. The control system processes the output signals of three piezoresistive sensors placed on the insole. Assistive torque was provided during swing phase in order to limit the plantarflexion to avoid the drop-foot. Two healthy male subjects were enrolled in the study. Experimental testing consists of walking tasks performed on three different terrain conditions (flat, soft, and irregular) with and without exoskeleton. Human kinematics was gathered via inertial measurements units (IMUs). The effects of ankle exoskeleton on lower limb joint angles were assessed in terms of range of motion (ROM). Statistical parametric map method was also applied to compare joint angle curves. As expected, a reduction of the ankle ROM in all terrain conditions was found between the trails performed with and without exoskeleton. No effects induced on the hip and knee joint were observed. Moreover, no significant differences have been observed over the almost totality of the gait cycle independently of the terrain conditions. Results demonstrate the capability of the exoskeleton to work properly regardless the type of walking surface.
# A Wearable Smart Glove and Its Application of Pose and Gesture Detection to Sign Language Classification
## Keywords:
- Wearable Robotics
- Gesture, Posture and Facial Expressions
- Soft Sensors and Actuators
## Abstract:
Advances in soft sensors coupled with machine learning are enabling increasingly capable wearable systems. Since hand motion in particular can convey useful information for developing intuitive interfaces, glove-based systems can have a significant impact on many application areas. A key remaining challenge for wearables is to capture, process, and analyze data from the high-degree-of-freedom hand in real time. 
We propose using a commercially available conductive knit to create an unobtrusive network of resistive sensors that spans all hand joints, coupling this with an accelerometer, and deploying machine learning on a low-profile microcontroller to process and classify data. This yields a self-contained wearable device with rich sensing capabilities for hand pose and orientation, low fabrication time, and embedded activity prediction. 
To demonstrate its capabilities, we use it to detect static poses and dynamic gestures from American Sign Language (ASL). By pre-training a long short-term memory (LSTM) neural network and using tools to deploy it in an embedded context, the glove and an ST microcontroller can classify 12 ASL letters and 12 ASL words in real time. Using a leave-one-experiment-out cross validation methodology, networks successfully classify 96.3% of segmented examples and generate correct rolling predictions during 92.8% of real-time streaming trials.
# A Soft Fabric-Based Shrink-To-Fit Pneumatic Sleeve for Comfortable Limb Assistance
## Keywords:
- Wearable Robotics
- Prosthetics and Exoskeletons
- Hydraulic/Pneumatic Actuators
## Abstract:
Upper limb impairments and weakness are common post-stroke and with advanced aging. Rigid exoskeletons have been developed as a potential solution, but have had limited impact. In addition to user concerns about safety, their weight and appearance, the rigid attachment and typical anchoring methods can result in skin damage. In this paper, we present a soft, fabric-based pneumatic sleeve, which can shrink from a loose fit to a tight fit in order to anchor to the limbs temporarily, thereby enabling the application of mechanical assistance only when needed. The sleeve is comfortable, ergonomic and can be embedded unobtrusively with clothing. A mathematical model is built to simulate and design sleeves with different geometric parameters. The best sleeve was capable of generating a friction force of 98 N on the limb when inflated to 25 kPa. This sleeve was used to create a wearable assistive device, integrated with a cable-driven actuator. This device was able to lift a 1.44 kg forearm rig up to 95 degree at low pressure of 20 kPa. The device was tested with six healthy participants, in terms of fit, comfort and assistive functionality. The average acceptable sleeve pressure was found to be 33±4.7 kPa. All participants liked the appearance of the sleeve, with a high average perceived assistance score of 7.33±1.6 (out of 10). The shrink-to-fit sleeve is expected to significantly increase the development and adoption of soft robotic assistive devices and emerging powered clothing.
# Ring-Pull Type Soft Wearable Robotic Glove for Hand Strength Assistance
## Keywords:
- Wearable Robotics
- Human Performance Augmentation
- Rehabilitation Robotics
## Abstract:
This paper proposes and verifies a new method, the ring-pull mechanism, to overcome the disadvantages of existing wearable robotic gloves. By attaching a ring to the metacarpopha# langeal (MCP) joint of the finger, the ring-pull mechanism supplements the grasping force of the user, while reducing the weight of the entire wearable robotic glove system. Ring-pull mechanism experiments were conducted to determine which finger combinations had the most positive effect on muscle strength assistance, and through this, the Ring-Pull type Soft Glove (RPSG) was developed. The main body of the developed RPSG is composed of single polymer silicon, a soft material, and is driven by tendon-driven actuation. The tendon path is secured through a tube attached to the palm that matches the direction of the flexor digitorum superficialis (FDS). The new type of wearable robotic glove was manufactured with the proposed mechanism, and excellent fit and strength support effects were confirmed. The RPSG increased the subject's grasping force by 25.69% on average, and the %MVIC data analysis demonstrated that the activation of FDS decreased by about 23.51%. As a result, it was confirmed that the user's muscle efficiency was increased due to the muscle support and muscle function improvement provided by the RPSG.
# Kinematics-Based Adaptive Assistance of a Semi-Passive Upper-Limb Exoskeleton for Workers in Static and Dynamic Tasks
## Keywords:
- Wearable Robotics
- Physically Assistive Devices
- Human Performance Augmentation
## Abstract:
Typical industrial work activities may include a variety of different gestures, entailing the execution of dynamic and static movements. Occupational upper-limb exoskeletons can assist the shoulder complex in both static and dynamic gestures, but the required assistance level may be different according to the tasks. This article presents the design, development, and experimental evaluation of a novel kinematics-based adaptive assistance algorithm for a semi-passive upper-limb exoskeleton. The algorithm uses kinematic signals gathered by onboard sensors to set the assistance amplitude according to the type of movement being executed. Experimental activities were performed to assess the algorithm’s performance. Results show that the algorithm can effectively provide different assistance levels according to the type of task being executed, such as the minimum level for more dynamic tasks and the maximum level for the most static activities. Additionally, compared to working without the exoskeleton, the exoskeleton controlled by the proposed adaptive algorithm can reduce the users’ flexor muscular activity in both dynamic and static tasks, respectively by 24 ± 6% and 42 ± 2%. Similar results were reported for extensor muscles, which reduced their activations by 7 ± 3%, and 40 ± 4% in dynamic and static tasks.
# Reconfigurable Self-Sensing Pneumatic Artificial Muscle with Locking Ability Based on Modular Multi-Chamber Soft Actuator
## Keywords:
- Wearable Robotics
- Soft Sensors and Actuators
- Hydraulic/Pneumatic Actuators
## Abstract:
Traditional pneumatic artificial muscles (PAMs) have cannot fully satisfy the requirements in wearable applications for safe and sufficient interaction with human body. The requirements include high contraction ratio, self-contained sensing, reconfiguration, locking abilities and no squeezing force worked on human tissue. In this paper, a reconfigurable self-sensing pneumatic artificial muscle (RSPAM) based on modular multi-chamber soft actuator with locking ability is developed, which provides an alternative that can satisfy all the requirements for wearable applications. Contraction principle of the RSPAM, which is transforming the expansion of the soft actuator into contraction by fabric winding, has inherent high contraction ratio (details seen in Appendix) no squeezing on human tissue at all. Self-sensing of contraction stroke based on liquid metal and locking ability based positive pressure jamming are integrated. A driving force of 70.14 N and contraction ratio of 71% were validated at 3 bar air pressure. Modular design of the actuator makes it possible to change configuration by adjusting the actuator amount and the fabric length according to application. In addition, the actuator unit can move on the fabric by itself, allowing an interesting self-adjustment ability to the muscle. The displacement self-sensing ability is verified through square-wave tracking experiments with closed-loop control. Finally, a preliminary test of assisting elbow movement verifies that RSPAM can reduce 25.52% muscle fatigue.
# Design of a Wearable Mechanism with Shape Memory Alloy (SMA)-Based Artificial Muscle for Assisting with Shoulder Abduction
## Keywords:
- Wearable Robotics
- Rehabilitation Robotics
- Soft Robot Applications
## Abstract:
This paper proposes a new mechanism, a four-bar linkage-based support hinge mechanism, for assisting with shoulder abduction with artificial muscle based on a shape memory alloy (SMA). An artificial muscle using the SMA coils is designed to lighten the entire system and support the wearer’s movement both actively and passively. It can generate up to 273 N and 180 N with and without energy input, respectively, while weighing only 0.04 kg. Furthermore, to consider the rotation axis shifts of the arm during shoulder abduction, the trajectory of the arm along the shoulder abduction is modeled using the scapulohumeral rhythm, a combined movement of the scapula and humerus. The mechanism is designed to follow the modeled arm trajectory and achieve the required torque to perform shoulder abduction based on a four-bar linkage mechanism. It can generate up to 10.1 Nm and 6.3 Nm of torque with and without energy input, respectively. To verify the assistive effect of the proposed mechanism, electromyography is measured while performing the same exercise requiring shoulder abduction with and without the support of the mechanism. The results show that the proposed mechanism reduces not only muscle load but also fatigue while performing the shoulder abduction.
# Intention Recognition
# Intention Estimation from Gaze and Motion Features for Human-Robot Shared-Control Object Manipulation
## Keywords:
- Intention Recognition
- Telerobotics and Teleoperation
- Human-Robot Collaboration
## Abstract:
Shared control can help in teleoperated object manipulation by assisting with the execution of the user’s intention. To this end, robust and prompt intention estimation is needed, which relies on behavioral observations. Here, an intention estimation framework is presented, which uses natural gaze and motion features to predict the current action and the target object. The system is trained and tested in a simulated environment with pick and place sequences produced in a relatively cluttered scene and with both hands, with possible hand-over to the other hand. Validation is conducted across different users and hands, achieving good accuracy and earliness of prediction. An analysis of the predictive power of single features shows the predominance of the grasping trigger and the gaze features in the early identification of the current action. In the current framework, the same probabilistic model can be used for the two hands working in parallel and independently, while a rule-based model is proposed to identify the resulting bimanual action. Finally, limitations and perspectives of this approach to more complex, full-bimanual manipulations are discussed.
# Disentangled Sequence Clustering for Human Intention Inference
## Keywords:
- Intention Recognition
- Representation Learning
- Deep Learning Methods
## Abstract:
Equipping robots with the ability to infer human intent is a vital precondition for effective collaboration. Most computational approaches towards this objective derive a probability distribution of "intent" conditioned on the robot's perceived state. However, these approaches typically assume task-specific labels of human intent are known **a priori**. To overcome this constraint, we propose the Disentangled Sequence Clustering Variational Autoencoder (DiSCVAE), a clustering framework capable of learning such a distribution of intent in an **unsupervised** manner. The proposed framework leverages recent advances in unsupervised learning to disentangle latent representations of sequence data, separating time-varying local features from time-invariant global attributes. As a novel extension, the DiSCVAE also infers a discrete variable to form a latent mixture model and thus enable clustering over these global sequence concepts, e.g. high-level intentions. We evaluate the DiSCVAE on a real-world human-robot interaction dataset collected using a robotic wheelchair. Our findings reveal that the inferred discrete variable coincides with human intent, holding promise for collaborative settings, such as shared control.
# Personalized Estimation of Intended Gait Speed for Lower-Limb Exoskeleton Users Via Data Augmentation Using Mutual Information
## Keywords:
- Intention Recognition
- Prosthetics and Exoskeletons
- Rehabilitation Robotics
## Abstract:
This letter presents a method for data-driven user-specific gait speed estimation for people with Spinal Cord Injuries (SCIs) walking in lower-limb exoskeletons. The scarcity of training data for this population is addressed by leveraging common patterns across users that relate gait changes to speed changes. To bootstrap the process, widely available walking data from uninjured individuals was used as a base dataset. The distribution of this data was first transformed to match smaller user-specific training sets from walking trials of subjects with SCIs. User-specific trials were then selected based on the mutual information between gait speed and features for the combined dataset. The resulting selected data was finally used to build a model for estimating the user's intended gait speed. The performance of this approach was evaluated using data from two users with SCIs walking in an EksoGT exoskeleton with a walker or crutches. Estimation trials were compared when using the base data alone versus when providing personalization via the addition of novel data. The average successful estimation of speed-up and slow-down changes increased from 52% to 67% with personalization using only 8 to 12 steps' worth of user-specific data, with a best-case improvement of 32%, from 48% to 80%. Overall, the proposed method uses the mutual information between gait features and speed to provide a reliable alternative to manual data selection while pooling data from healthy and injured individuals.
# Flash: Fast and Light Motion Prediction for Autonomous Driving with Bayesian Inverse Planning and Learned Motion Profiles
## Keywords:
- Intention Recognition
- Probabilistic Inference
- Motion and Path Planning
## Abstract:
Motion prediction of road users in traffic scenes is critical for autonomous driving systems that must take safe and robust decisions in complex dynamic environments. We present a novel motion prediction system for autonomous driving. Our system is based on the Bayesian inverse planning framework, which efficiently orchestrates map-based goal extraction, a classical control-based trajectory generator and a mixture of experts collection of light-weight neural networks specialised in motion profile prediction. In contrast to many alternative methods, this modularity helps isolate performance factors and better interpret results, without compromising performance. This system addresses multiple aspects of interest, namely multi-modality, motion profile uncertainty and trajectory physical feasibility. We report on several experiments with the popular highway dataset NGSIM, demonstrating state-of-the-art performance in terms of trajectory error. We also perform a detailed analysis of our system's components, along with experiments that stratify the data based on behaviours, such as change-lane versus follow-lane, to provide insights into the challenges in this domain. Finally, we present a qualitative analysis to show other benefits of our approach, such as the ability to interpret the outputs.
# MPC-PF: Social Interaction Aware Trajectory Prediction of Dynamic Objects for Autonomous Driving Using Potential Fields
## Keywords:
- Intention Recognition
- Intelligent Transportation Systems
- Agent-Based Systems
## Abstract:
Predicting object motion behaviour is a challenging but crucial task for safe decision making and path planning for an autonomous vehicle. It is challenging in large part due to the uncertain, multi-modal, and practically intractable set of possible human-human and human-space interactions, especially in urban driving settings. Models solely based on constant velocity or social force have an inherent bias and may lead to inaccurate predictions across the prediction horizon whereas purely data driven approaches suffer from a lack of a holistic set of rules governing predictions. We tackle this problem by introducing MPC-PF: a novel potential field-based trajectory predictor that incorporates social interaction and is able to tradeoff between inherent model biases across the prediction horizon. Through evaluation on a variety of common urban driving scenarios, we show that our model is capable of producing accurate predictions for both short and long term timesteps. We also demonstrate the significance of our model architecture through an ablation study.
# Optimization of Forcemyography Sensor Placement for Arm Movement Recognition
## Keywords:
- Intention Recognition
- Datasets for Human Motion
- Human-Robot Collaboration
## Abstract:
How to design an optimal wearable device for human movement recognition is vital to reliable and accurate human-machine collaboration. Previous works mainly fabricate wearable devices heuristically. Instead, this paper raises an academic question: can we design an optimization algorithm to optimize the fabrication of wearable devices such as figuring out the best sensor arrangement automatically? Specifically, this work focuses on optimizing the placement of Forcemyography (FMG) sensors for FMG armbands in the application of arm movement recognition. Firstly, based on graph theory, the armband is modeled considering sensors’ signals and connectivity. Then, a Graph-based Armband Modeling Network (GAM-Net) is introduced for arm movement recognition. Afterward, the sensor placement optimization for FMG armbands is formulated and an optimization algorithm with greedy local search is proposed. To study the effectiveness of our optimization algorithm, a dataset for mechanical maintenance tasks using FMG armbands with 16 sensors is collected. Our experiments show that using only 4 sensors optimized with our algorithm can help maintain a comparable recognition accuracy to using all sensors. Finally, the optimized sensor placement result is verified from a physiological view. This work would like to shed light on the automatic fabrication of wearable devices considering downstream tasks, such as human biological signal collection and movement recognition.
# Pedestrian Intention Prediction Based on Traffic-Aware Scene Graph Model
## Keywords:
- Intention Recognition
- Computer Vision for Transportation
- Intelligent Transportation Systems
## Abstract:
Anticipating the future behavior of pedestrians is a crucial part of deploying Automated Driving Systems (ADS) in urban traffic scenarios. Most recent works utilize a convolutional neural network (CNN) to extract visual information, which is then input to a recurrent neural network (RNN) along with pedestrian-specific features like location and speed to obtain temporal features. However, the majority of these approaches lack the ability to parse the relationships of the related objects in the specific traffic scene, which leads to omitting the interactions between the pedestrians and the interactions between the pedestrians and the traffic. For this purpose, we propose a graph-structured model which can dig out pedestrians' dynamic constraints by constructing a traffic-aware scene graph within each frame. In addition, to capture pedestrian movement more effectively, we also introduce a temporal feature representation model, which first uses inter-frame and intra-frame GRU (II-GRU) to mine inter-frame information and intra-frame information together, and then employs a novel attention mechanism to adaptively generate attention weights. Extensive experiments on the JAAD and PIE datasets prove that our proposed model is effective in reaching and enhancing the state-of-the-art performance.
# Social-PatteRNN: Socially-Aware Trajectory Prediction Guided by Motion Patterns
## Keywords:
- Intention Recognition
- AI-Enabled Robotics
- Human-Centered Robotics
## Abstract:
As robots across domains start collaborating with humans in shared environments, algorithms that enable them to reason over human intent are important to achieve safe interplay. In our work, we study human intent through the problem of predicting trajectories in dynamic environments. We explore domains where navigation guidelines are relatively strictly defined but not clearly marked in their physical environments. We hypothesize that within these domains, agents tend to exhibit short-term motion patterns that reveal context information related to the agent's general direction, intermediate goals and rules of motion, **e.g.**, social behavior. From this intuition, we propose **Social-PatteRNN**, an algorithm for recurrent, multi-modal trajectory prediction that exploits motion patterns to encode the aforesaid contexts. Our approach guides long-term trajectory prediction by learning to predict short-term motion patterns. It then extracts sub-goal information from the patterns and aggregates it as **social** context. We assess our approach across three domains: humans crowds, humans in sports and manned aircraft in terminal airspace, achieving state-of-the-art performance.
# A Hierarchical Deliberative Architecture Framework Based on Goal Decomposition
## Keywords:
- Control Architectures and Programming
- Planning, Scheduling and Coordination
- Engineering for Robotic Systems
## Abstract:
Performing a complex autonomous mission with a multi-robot system requires to integrate several deliberative approaches to perform task allocation, optimization, and execution control. Implementing such a deliberative architecture is a complex task: it requires the developer to master the decision algorithms themselves (e.g., automated planning models), to have a good knowledge of the involved robotic platforms, and to think about how these elements will be assembled as a system architecture.
We propose a framework to help designing such deliberative architectures. The framework relies on the concept of a hierarchical structure of actors, each actor managing goals with specific planning or optimization approaches, and delegating sub-goals to other actors.
# Semantic Scene Understanding 1
# SynWoodScape: Synthetic Surround-View Fisheye Camera Dataset for Autonomous Driving
## Keywords:
- Omnidirectional Vision
- Data Sets for Robotic Vision
- Semantic Scene Understanding
## Abstract:
Surround-view cameras are a primary sensor for automated driving, used for near-field perception. It is one of the most commonly used sensors in commercial vehicles primarily used for parking visualization and automated parking. Four fisheye cameras with a 190° field of view cover the 360° around the vehicle. Due to its high radial distortion, the standard algorithms do not extend easily. Previously, we released the first public fisheye surround-view dataset named WoodScape. In this work, we release a synthetic version of the surround-view dataset, covering many of its weaknesses and extending it. Firstly, it is not possible to obtain ground truth for pixel-wise optical flow and depth. Secondly, WoodScape did not have all four cameras annotated simultaneously in order to sample diverse frames. However, this means that multi-camera algorithms cannot be designed to obtain a unified output in birds-eye space, which is enabled in the new dataset. We implemented surround-view fisheye geometric projections in CARLA Simulator matching WoodScape’s configuration and created SynWoodScape. We release 80 k images from the synthetic dataset with annotations for 10+ tasks. We also release the baseline code and supporting scripts.
# Accurate Instance-Level CAD Model Retrieval in a Large-Scale Database
## Keywords:
- Semantic Scene Understanding
- Deep Learning for Visual Perception
- RGB-D Perception
## Abstract:
We present a new solution to the fine-grained retrieval of clean CAD models from a large-scale database in order to recover detailed object shape geometries for RGBD scans. Unlike previous work simply indexing into a moderately small database using an object shape descriptor and accepting the top retrieval result, we argue that in the case of a large-scale database a more accurate model may be found within a neighborhood of the descriptor. More importantly, we propose that the distinctiveness deficiency of shape descriptors at the instance level can be compensated by a geometry-based re-ranking of its neighborhood. Our approach first leverages the discriminative power of learned representations to distinguish between different categories of models and then uses a novel robust point set distance metric to re-rank the CAD neighborhood, enabling fine-grained retrieval in a large shape database. Evaluation on a real-world dataset shows that our geometry-based re-ranking is a conceptually simple but highly effective method that can lead to a significant improvement in retrieval accuracy compared to the state-of-the-art.
# Low-Latency LiDAR Semantic Segmentation
## Keywords:
- Semantic Scene Understanding
- Object Detection, Segmentation and Categorization
- Recognition
## Abstract:
Several methods of semantic segmentation using light detection and ranging (LiDAR) sensors have been proposed for the recognition of surrounding objects by autonomous driving cars. LiDAR is a sensor that compensates for the weaknesses of other sensors, such as cameras or radar systems, and semantic segmentation assigns a class label to each point in the LiDAR point cloud. Recently, real-time semantic segmentation methods that are capable of processing LiDAR point clouds at frame rates have been proposed. Real-time semantic segmentation is essential for the autonomous driving system because it can output class labels for LiDAR point clouds at high speeds. However, this segmentation method suffers from a delay equal to processing time. To address this challenge, we propose a novel method that combines SalsaNext cite{salsanext}, a method of real-time LiDAR semantic segmentation, and semantic forecasting, which predicts the results of future semantic segmentation. We quantitatively evaluate our method using the Semantic-KITTI dataset, which comprises point cloud data acquired from the LiDAR sensor in the real world, and compare the latency and accuracy of our method with other semantic segmentation methods. Consequently, our method is found to be capable of operating in real-time and with low-latency, and it can achieve a performance similar to that of previously reported real-time semantic segmentation methods.
# Implicit-Part Based Context Aggregation for Point Cloud Instance Segmentation
## Keywords:
- Semantic Scene Understanding
- Object Detection, Segmentation and Categorization
## Abstract:
Context information is important for instance segmentation on point clouds. Existing methods either only use local surroundings by stacking multiple convolution layers or use non-local methods to model long-range interactions. However, they usually directly operate on points which is an unstructured and low-level representation and is highly dependent on context. To address this issue, we propose an effective framework named Implicit-Part Context Aggregation (IPCA), which adopts implicit parts as an intermediate representation and achieves context aggregation through message passing along the implicit part graph. Specifically, we first organize unstructured points into geometrically consistent implicit parts and construct the implicit part graph according to the geometric adjacency. Then, an initial part embedding is extracted using the proposed Implicit Part Network (IPN) which can aggregate point features and capture the intrinsic geometric shape of the part. We further refine the part embedding by a graph reasoning module named Context Aggregation Network (CAN), which helps to make a more precise prediction by well exploiting the context information. Instance proposals are then generated by grouping implicit parts. Finally, we propose an additional step to attribute the entire instance proposal to a Semantic Criterion Net (SCN) to infer the semantics of the instance. The purpose is to correct the semantic prediction errors caused by not knowing the boundary and overall shape of the object in the previous steps. Extensive experiments on two large datasets, ScanNet and 3RScan demonstrate the effectiveness of our method. It outperforms all existing methods on the ScanNet test benchmark and its AP@50 is 9.5 points higher than the baseline.
# Unsupervised Domain Adaptation for Point Cloud Semantic Segmentation Via Graph Matching
## Keywords:
- Semantic Scene Understanding
- Transfer Learning
- Deep Learning for Visual Perception
## Abstract:
Unsupervised domain adaptation for point cloud semantic segmentation has attracted great attention due to its effectiveness in learning with unlabeled data. Most of existing methods use global-level feature alignment to transfer the knowledge from the source domain to the target domain, which may cause the semantic ambiguity of the feature space. In this paper, we propose a graph-based framework to explore the local-level feature alignment between the two domains, which can reserve semantic discrimination during adaptation. Specifically, in order to extract local-level features, we dynamically construct local feature graphs on both of the two domains and then build a memory bank with the graphs from the source domain. In particular, we use optimal transport to generate the graph matching pairs. Then, based on the assignment matrix, we can meticulously align the feature distributions between the two domains by the graph-based local feature loss. Furthermore, we consider the correlation between the features of different categories and design a category-guided contrastive loss to guide the segmentation model to learn discriminative features on the target domain. Extensive experiments on different synthetic-to-real and real-to-real domain adaptation scenarios demonstrate that our method can achieve state-of-the-art performance.
# SectionKey: 3-D Semantic Point Cloud Descriptor for Place Recognition
## Keywords:
- Semantic Scene Understanding
- Localization
- Intelligent Transportation Systems
## Abstract:
Place recognition is seen as a crucial factor to correct cumulative errors in Simultaneous Localization and Mapping (SLAM) applications. Most existing studies focus on visual place recognition, which is inherently sensitive to environmental changes such as illumination, weather and seasons. Considering these facts, more recent attention has been attracted to use 3-D Light Detection and Ranging (LiDAR) scans for place recognition, which demonstrates more credibility by exerting accurate geometric information. Different from pure geometric-based studies, this paper proposes a novel global descriptor, named SectionKey, which leverages both semantic and geometric information to tackle the problem of place recognition in large-scale urban environments. The proposed descriptor is robust and invariant to viewpoint changes. Specifically, the encoded three-layers key serves as a pre-selection step and a `candidate center' selection strategy is deployed before calculating the similarity score, thus improving the accuracy and efficiency significantly. Then, a two-step semantic iterative closest point (ICP) algorithm is applied to acquire the 3-D pose (x, y, theta) that is used to align the candidate point clouds with the query frame and calculate the similarity score. Extensive experiments have been conducted on public Semantic KITTI dataset to demonstrate the superior performance of our proposed system over state-of-the-art baselines.
# Fisheye Object Detection Based on Standard Image Datasets with 24-Points Regression Strategy
## Keywords:
- Semantic Scene Understanding
## Abstract:
Fisheye object detection is a difficult task in robotics and autonomous driving. One of the reasons is that the fisheye datasets are inferior to standard image datasets in scale and quantity, which inspires the idea of using standard image datasets for fisheye object detection. However, the models trained on standard image datasets do not perform well with fisheye data. In this work, we explore the effect of fisheye images on different stages of the YOLOX with published weights generated by standard image datasets. We also propose a new regression strategy for 24-points object representation method, which is insensitive to image distortion. The experiments show that the feature extraction part is robust to fisheye image features, while the regression part of location and category performs poorly. The strategy can achieve the position of discrete points without calculating the IOU of irregular-shaped boxes. Theoretically, the strategy can be widely adopted to regress the irregular bounding boxes composed of discrete points. Source code is at https://github.com/IN2-ViAUn/Exploration-of-Potential
# Real-Time Semantic 3D Reconstruction for High-Touch Surface Recognition for Robotic Disinfection
## Keywords:
- Semantic Scene Understanding
- RGB-D Perception
- Motion and Path Planning
## Abstract:
Disinfection robots have applications in promoting public health and reducing hospital-acquired infections and have drawn considerable interest due to the COVID-19 pandemic. To disinfect a room quickly, motion planning can be used to plan robot disinfection trajectories on a reconstructed 3D map of the room's surfaces. However, existing approaches discard semantic information of the room and, thus, take a long time to perform thorough disinfection. Human cleaners, on the other hand, disinfect rooms more efficiently by prioritizing the cleaning of high-touch surfaces. To address this gap, we present a novel GPU-based volumetric semantic TSDF (Truncated Signed Distance Function) integration system for semantic 3D reconstruction. Our system produces 3D reconstructions that distinguish high-touch surfaces from non-high-touch surfaces at approximately 50 frames per second on a consumer-grade GPU, which is approximately 5 times faster than existing CPU-based TSDF semantic reconstruction methods. In addition, we extend a UV disinfection motion planning algorithm to incorporate semantic awareness for optimizing coverage of disinfection trajectories. Experiments show that our semantic-aware planning outperforms geometry-only planning by disinfecting up to 20% more high-touch surfaces under the same time budget. Further, the real-time nature of our semantic reconstruction pipeline enables future work on simultaneous disinfection and mapping.
# Relationship Oriented Semantic Scene Understanding for Daily Manipulation Tasks
## Keywords:
- Semantic Scene Understanding
- Perception for Grasping and Manipulation
- Task Planning
## Abstract:
Assistive robot systems have been developed to help people accomplish daily manipulation tasks especially for those with disabilities, where scene understanding plays a crucial role in enabling robots to interpret the surroundings and behave accordingly. Most of the current systems approach scene understanding without considering the functional dependencies between objects. However, it is only valuable to interact with some objects when their function-relevant counterparts are considered. In this paper, we augment an assistive robotic arm system with an end-to-end semantic relationship reasoning model. It incorporates functional relationships between pairs of objects for semantic scene understanding. To ensure good generalization to unseen objects and relationships, the model works in a category-agnostic manner. We evaluate our design and three baseline methods on a self-collected benchmark with two levels of difficulty. To further demonstrate the effectiveness, the model is integrated with a symbolic planner for goal-oriented, multi-step manipulation task on a real-world assistive robotic arm platform.
# Multi-Robot Systems 1
# Multi-Robot Unknown Area Exploration Using Frontier Trees
## Keywords:
- Multi-Robot Systems
- Task Planning
- Mapping
## Abstract:
This paper presents a novel approach for multi-robot unknown area exploration. Recently, the frontier tree data structure was used in single robot exploration to memorize frontiers, their positions, exploration state, and the map. This tree could be queried to decide on further exploration steps. In this paper, we take the concept further for multi-robot exploration by proposing a new abstraction called the ‘group,’ meant to share information through a common frontier tree, requisite operations at the group level, and a method to assign goals to multiple robots. A group is a set of robots, the union of whose explored regions forms a contiguous region (a single connected region in a topological sense). As a group has precisely one tree, the robots share a common state of the exploration task. We propose techniques to merge groups and their frontier trees once their maps overlap. Finally, we suggest a method to designate and assign exploration goals to the individual robots by choosing nodes from the frontier tree. The proposed approach outperforms seven state-of-the-art research works in simulation.
# Min-Max Vertex Cycle Covers with Connectivity Constraints for Multi-Robot Patrolling
## Keywords:
- Multi-Robot Systems
- Path Planning for Multiple Mobile Robots or Agents
- Surveillance Robotic Systems
## Abstract:
We consider a multi-robot patrolling scenario with intermittent connectivity constraints, which ensure that data from the robots finally arrive at a base station. In particular, each robot traverses a closed tour periodically and meets with the robots on neighboring tours to exchange data. We model the problem as a variant of the min-max vertex cycle cover problem (MMCCP), which is the problem of covering all vertices with a given number of disjoint tours such that the largest tour length is minimal. In this work we introduce the minimum idleness connectivity-constrained multi-robot patrolling problem, show that it is NP-hard, and model it as a mixed integer linear program (MILP). The computational complexity of exactly solving this problem restrains practical applications, and therefore we develop approximate algorithms taking a solution for MMCCP as input. Our simulation experiments on 10 vertices and up to 3 robots compare the results of different solution approaches (including solving the MILP formulation) and show that our greedy algorithm can obtain an objective value close to the one of the MILP formulations with much shorter computation times. Experiments on instances with up to 100 vertices and up to 10 robots indicate that the greedy approximation algorithm tries to keep the length of the longest tour small by extending smaller tours for data exchange.
# Efficient Range-Constrained Manifold Optimization with Application to Cooperative Navigation
## Keywords:
- Multi-Robot Systems
- Path Planning for Multiple Mobile Robots or Agents
- Swarm Robotics
## Abstract:
We present a manifold optimization approach to solve inference and planning problems with range constraints. The core of our approach is the definition of a manifold that represents points or poses with range constraints. We discover that the manifold of range-constrained points is homogeneous under the rigid transformation group action, and utilize the group action to derive the tangent space, retraction and topology of the manifold. We evaluate the performance of manifold optimization approach on solving range-constrained inference problems over state-of-the-art constrained optimization methods, and the results show that manifold optimization with the range-constraint manifold achieves both faster speed and better constraint satisfaction. We further study the conditions of inference problems that we can treat range measurements as constraints in practice.
# On Coverage Control for Limited Range Multi-Robot Systems
## Keywords:
- Multi-Robot Systems
- Sensor Networks
- Distributed Robot Systems
## Abstract:
This paper presents a coverage based control algorithm to coordinate a group of autonomous robots. Most of the solutions presented in the literature rely on an exact Voronoi partitioning, whose computation requires complete knowledge of the environment to be covered. This can be achieved only by robots with unlimited sensing capabilities, or through communication among robots in a limited sensing scenario. To overcome these limitations, we present a distributed control strategy to cover an unknown environment with a group of robots with limited sensing capabilities and in the absence of reliable communication. The control law is based on a limited Voronoi partitioning of the sensing area, and we demonstrate that the group of robots can optimally cover the environment using only information that is locally detected (without communication). The proposed method is validated by means of simulations and experiments carried out on a group of mobile robots.
# Multi-Goal Multi-Agent Pickup and Delivery
## Keywords:
- Multi-Robot Systems
- Path Planning for Multiple Mobile Robots or Agents
- Task and Motion Planning
## Abstract:
In this work, we consider the Multi-Agent Pickup and Delivery (MAPD) problem, where agents constantly engage with new tasks and need to plan collision-free paths to execute them. To execute a task, an agent needs to visit a pair of goal locations, consisting of a pickup location and a delivery location. We propose two variants of an algorithm that assigns a sequence of tasks to each agent using the anytime algorithm Large Neighborhood Search (LNS) and plans paths using the Multi-Agent Path Finding (MAPF) algorithm Priority-Based Search (PBS). LNS-PBS is complete for well-formed MAPD instances, a realistic subclass of MAPD instances, and empirically more effective than the existing complete MAPD algorithm CENTRAL. LNS-wPBS provides no completeness guarantee but is empirically more efficient and stable than LNS-PBS. It scales to thousands of agents and thousands of tasks in a large warehouse and is empirically more effective than the existing scalable MAPD algorithm HBH+MLA*. LNS-PBS and LNS-wPBS also apply to a more general variant of MAPD, namely the Multi-Goal MAPD (MG-MAPD) problem, where tasks can have different numbers of goal locations.
# Asynchronous Real-Time Decentralized Multi-Robot Trajectory Planning
## Keywords:
- Multi-Robot Systems
- Path Planning for Multiple Mobile Robots or Agents
- Networked Robots
## Abstract:
We present a novel overconstraining and constraint-discarding method for asynchronous, real-time, decentralized, multi-robot trajectory planning that ensures collision avoidance. Our approach utilizes communication between robots. The communication medium is best-effort: messages may be dropped, re-ordered or delayed. Robots conservatively constrain themselves against others assuming they may be working with outdated information, and discard constraints when they receive update messages from others. Our method can augment existing synchronized decentralized receding horizon planning algorithms that utilize separating hyperplanes for collision avoidance thereby making them applicable to asynchronous setups. As an example, we extend an existing model predictive control based, synchronized, decentralized multi-robot planner using our method. We show our method’s effectiveness under asynchronous planning and imperfect communication by comparing our extension to the base version. Our extension does not result in any collisions or synchronization-induced deadlocks to which the base version is prone.
# Decentralized Learning with Limited Communications for Multi-Robot Coverage of Unknown Spatial Fields
## Keywords:
- Multi-Robot Systems
- Path Planning for Multiple Mobile Robots or Agents
- Optimization and Optimal Control
## Abstract:
This paper presents an algorithm for a team of mobile robots to simultaneously learn a spatial field over a domain and spatially distribute themselves to optimally cover it. Drawing from previous approaches that estimate the spatial field through a centralized Gaussian process, this work leverages the spatial structure of the coverage problem and presents a decentralized strategy where samples are aggregated locally by establishing communications through the boundaries of a Voronoi partition. We present an algorithm whereby each robot runs a local Gaussian process calculated from its own measurements and those provided by its Voronoi neighbors, which are incorporated into the individual robot’s Gaussian process only if they provide sufficiently novel information. The performance of the algorithm is evaluated in simulation and compared with centralized approaches.
# Multi-Agent Path Planning Using Medial-Axis-Based Pebble-Graph Embedding
## Keywords:
- Multi-Robot Systems
- Path Planning for Multiple Mobile Robots or Agents
- Motion and Path Planning
## Abstract:
We present a centralized algorithm for labeled, disk-shaped Multi-Agent Path Planning (MPP) in a continuous workspace with polygonal boundaries. Our method automatically constructs a discrete pebble-graph out of the workspace and then routes the agents on the graph. To construct the pebble graph,
we identify inscribed circles in the workspace via medial axis transform and organize agents into layers within each inscribed circle. We show that our layered pebble-graph allows the agents to perform both pebble and rotation motions, such that all the MPP instances restricted to the pebble-graph are feasible. MPP instances with continuous start and goal positions can then be solved via local navigations that route agents from and to graph vertices. We experiment with our method on a row of 5 environments with a high agent-packing density (up to 61:6% of the free space). Such density violates the well-separated assumptions made by state-of-the-art MPP planners, while our method achieves a high success rate.
# Multi-Modal User Interface for Multi-Robot Control in Underground Environments
## Keywords:
- Multi-Robot Systems
- Task Planning
- Human Factors and Human-in-the-Loop
## Abstract:
Leveraging both the autonomy of robots and the expert knowledge of humans can enable a multi-robot system to complete missions in challenging environments with a high degree of adaptivity and robustness. This paper proposes a multimodal task-based graphical user interface for controlling a heterogeneous multi-robot team. The core of the interface is an integrated multi-robot task allocation system to allow the user to encode his/her intents to guide the heterogeneous multi-robot team. The design of the interface aims to provide the human operator continuous situational awareness and effective control for rapid decision-making in time-critical missions. Team CSIRO Data61 came in second place utilizing this interface for the DARPA Subterranean (SubT) Challenge. The ideas used for this user interface can apply to other multi-robot applications.
# Soft Sensors and Actuators 1
# Slip Anticipation for Grasping Deformable Objects Using a Soft Force Sensor
## Keywords:
- Soft Sensors and Actuators
- AI-Based Methods
- Soft Robot Materials and Design
## Abstract:
Robots using classical control have revolutionised assembly lines where the environment and manipulated objects are restricted and predictable. However, they have proven less effective when the manipulated objects are deformable due to their complex and unpredictable behaviour. The use of tactile sensors and continuous monitoring of tactile feedback is therefore particularly important for pick-and-place tasks using these materials. This is in part due to the need to use multiple points of contact for the manipulation of deformable objects which can result in slippage with inadequate coordination between manipulators. In this paper, continuous monitoring of tactile feedback, using a liquid metal soft force sensor, for grasping deformable objects is presented. The trained data-driven model distinguishes between successful grasps, slippage and failure during a manipulation task for multiple deformable objects. Slippage could be anticipated before failure occurred using data acquired over a 30 ms period with a greater than 95% accuracy using a random forest classifier. The results were achieved using a single sensor that can be mounted on the fingertips of existing grippers and contributes to the development of an automated pick-and-place process for deformable objects.
# Estimation of Soft Robotic Bladder Compression for Smart Helmets Using IR Range Finding and Hall Effect Magnetic Sensing
## Keywords:
- Soft Sensors and Actuators
- Soft Robot Applications
## Abstract:
This research focuses on soft robotic bladders that are used to monitor and control the interaction between a user’s head and the shell of a Smart Helmet. Compression of these bladders determines impact dissipation; hence the focus of this paper is sensing and estimation of bladder compression. An IR rangefinder-based solution is evaluated using regression techniques as well as a Neural Network to estimate bladder compression. A Hall-Effect (HE) magnetic sensing system is also examined where HE sensors embedded in the base of the bladder sense the position of a magnet in the top of the bladder. The paper presents the HE sensor array, signal processing of HE voltage data, and then a Neural Network (NN) for predicting bladder compression. Efficacy of different training data sets on NN performance is studied. Different NN configurations are examined to determine a configuration that provides accurate estimates with as few nodes as possible. Different bladder compression profiles are evaluated to characterize IR range finding and HE based techniques in application scenarios.
# Kirigami Skin Based Flexible Whisker Sensor
## Keywords:
- Soft Sensors and Actuators
- Soft Robot Materials and Design
## Abstract:
Whiskers are widely used by animals for sensing physical interactions with their environments. By combining the Kirigami skin pop-up feature and flexible conducting layer, we designed a deployable Kirigami whisker sensor. The sensor can deploy from a flat state to a sensing state while whisker stiffness and initial pop-up angle can be tuned by adjusting the pre-stretch strain. Preliminary results show that the sensor works well both in air and underwater. The sensor is capable of measuring both externally applied forces and water flow.
# Design and Characterisation of a Soft Barometric Sensing Skin for Robotic Manipulation
## Keywords:
- Soft Sensors and Actuators
- Modeling, Control, and Learning for Soft Robots
- In-Hand Manipulation
## Abstract:
Soft sensorised skins are essential for improving robotic manipulation capabilities towards that of humans. Integration of sensors into existing robotic hands is challenging due to rigidity of components, low packing density or poor sensor response. We propose a sensorised skin, based-on barometric sensing, which can be molded over a skeletal robot hand. The sensors connect air chambers embedded in the soft skin to wrist-mounted pressure sensors, allowing sensor spacing 2-4 mm, force ranges from 23 mN to 5700 mN and bandwidth of 20 Hz. Integrating this with a skeletal hand allows us to showcase the potential of these sensors to aid robotic manipulation. We demonstrate 3-axis contact modelling, useful for in-hand manipulation and exploration. In addition, by grasping a chopstick and sensing forces transmitted from the environment, the system can remotely detect small environmental features, e.g., hole finding using tools.
# A Virtual 2D Tactile Array for Soft Actuators Using Acoustic Sensing
## Keywords:
- Soft Sensors and Actuators
- Force and Tactile Sensing
## Abstract:
We create a virtual 2D tactile array for soft pneumatic actuators using embedded audio components. We detect contact-specific changes in sound modulation to infer tactile information. We evaluate different sound representations and learning methods to detect even small contact variations. We demonstrate the acoustic tactile sensor array by the example of a PneuFlex actuator and use a Braille display to individually control the contact of 29 x 4 pins with the actuator's 90 x 10 mm palmar surface. Evaluating the spatial resolution, the acoustic sensor localizes edges in x# and y-direction with a root-mean-square regression error of 1.67 mm and 0.0 mm, respectively. Even light contacts of a single Braille pin with a lifting force of 0.17 N are measured with high accuracy. Finally, we demonstrate the sensor's sensitivity to complex contact shapes by successfully reading the 26 letters of the Braille alphabet from a single display cell with a classification rate of 88%.
# Transferable Shape Estimation of Soft Pneumatic Actuators Based on Active Vibroacoustic Sensing
## Keywords:
- Soft Sensors and Actuators
- Soft Robot Applications
## Abstract:
A soft pneumatic actuator (SPA) is one of the most prominent components in a soft robotic system. The sensing of SPAs is challenging owing to their elasticity and deformability. Sensors for specific factors are required to successfully sense an SPA. A flexible sensor is an important component for sensing the conditions of SPAs, such as the shape and deformation due to contact events during applications. Developing versatile sensors with high flexibility and tolerability for SPAs is challenging. Data-driven sensing approaches involve individual machine learning models for different actuators. In contrast, it is an enormous advantage to have versatile sensors as hardware and machine learning models as software employed on various actuators. Therefore, we propose a transferable shape estimation method based on active vibro-acoustic sensing to achieve tolerability and increase versatility. We created easily transferable sensing devices for SPAs. In addition, we employed a data-driven approach that utilizes a simple transfer learning technique on a two-dimensional convolutional neural network model. We confirm the feasibility and versatility of the proposed method through evaluation experiments. A transferable estimation method was used on SPAs to estimate the bending angle and length under various sensing and environmental conditions, and the average errors were less than 3.5 degrees and 2.1 mm, respectively.
# Shape Reconstruction of Soft Manipulators Using Vision and IMU Feedback
## Keywords:
- Soft Sensors and Actuators
- Soft Robot Applications
- Modeling, Control, and Learning for Soft Robots
## Abstract:
In recent times, soft manipulators have gardened immense interest given their dexterous abilities. A critical aspect for their feedback control involves the reconstruction of the manipulator shape. The research, for the first time, presents shape reconstruction of a soft manipulator through sensor fusion of information available from Inertial Measurement Units (IMUs) and visual tracking. The manipulator is modeled using multi-segment continuous curvature Pythagorean Hodograph (PH) curves. PH curves are a class of continuous curvature curves with an analytical expression for the hodograph (slope). The shape reconstruction is formulated as an optimization problem that minimizes bending energy of the curve with a length constraint and the information from IMUs and/or visual markers. The paper experimentally investigates the robustness of shape reconstruction for scenarios when position of all visual markers, or slope at all the knots (placement of sensors) are known. Occlusion of manipulator segments is frequent, hence, this scenario is simulated by fusing information of available slopes (IMUs) at all knots and position (vision) at some knots. The experiments are performed on a planar tensegrity manipulator with IMUs feedback and visual tracking. The robustness study indicates reliability of these models for real world applications. Additionally, the proposed sensor fusion algorithm provides promising results where, for most cases, the shape estimates benefit from additional position information. Finally, the low dimensionality of the optimization problem argues for extension of the approach for real-time applications.
# FBG-Based Variable-Length Estimation for Shape Sensing of Extensible Soft Robotic Manipulators
## Keywords:
- Soft Sensors and Actuators
- Soft Robot Applications
- Sensor Fusion
## Abstract:
In this paper, we propose a novel variable-length estimation approach for shape sensing of extensible soft robots utilizing fiber Bragg gratings (FBGs). Shape reconstruction from FBG sensors has been increasingly developed for soft robots, while the narrow stretching range of FBG fiber makes it difficult to acquire accurate sensing results for extensible robots. Towards this limitation, we newly introduce an FBG-based length sensor by leveraging a rigid curved channel, through which FBGs are allowed to slide within the robot following its body extension/compression, hence we can search and match the FBGs with specific constant curvature in the fiber to determine the effective length. From the fusion with the above measurements, a model-free filtering technique is accordingly presented for simultaneous calibration of a variable-length model and temporally continuous length estimation of the robot, enabling its accurate shape sensing using solely FBGs. The performances of the proposed method have been experimentally evaluated on an extensible soft robot equipped with an FBG fiber in both free and unstructured environments. The results concerning dynamic accuracy and robustness of length estimation and shape sensing demonstrate the effectiveness of our approach.
# Soft-Skin Actuator Capable of Seawater Propulsion Based on MagnetoHydroDynamics
## Keywords:
- Soft Sensors and Actuators
- Soft Robot Materials and Design
- Soft Robot Applications
## Abstract:
Underwater robots have a variety of potential uses, including marine resource research, ecological research, and disaster relief. Most of the underwater robots currently in practical use have screw propulsion systems, which have several noises, collision, and entrainment problems. There is a lot of research on underwater robots using soft actuators to solve these problems. However, current soft actuators have disadvantages, such as the need for special fluids, pressure sources, and high voltage circuits. Therefore, we have developed a soft-skin actuator based on magnetohydrodynamics (MHD). The soft-skin MHD actuator is made of soft material and the structure is prepared as thin, which allows it to attach to the surface of an object, including curved surfaces, to provide the object with a propulsive function in the sea. Since it has no moving parts, it does not generate mechanical noise, and there is no danger of entrapment. Because it can pump seawater directly, it does not require a special working fluid, and its structure is simple and easy to miniaturize. This paper investigates the thrust and power consumption of the developed soft-skin MHD actuator when attached to a flat surface. As a result, we obtained a thrust of 1.37 mN from a single soft-skin MHD actuator with a maximum power of about 140 W. We also measured the thrust force by attaching it to a curved surface. We obtained a higher thrust on a curved surface by adjusting the crossing of the magnetic field and the current than when using a flat surface. We developed an untethered robot that can remove oil from the sea using soft-skin MHD actuators. We demonstrated the adaptability of the soft-skin MHD actuator by attaching it to a commercial underwater camera weighing about 253.5 g and providing propulsion.
# Path Planning for Multiple Mobile Robots and Agents 1
# Collaborative Navigation-Aware Coverage in Feature-Poor Environments
## Keywords:
- Path Planning for Multiple Mobile Robots or Agents
- Networked Robots
## Abstract:
Multi agent coverage and robot navigation are two very important research fields within robotics. However, their intersection has received limited attention. In multi agent coverage, perfect navigation is often assumed, and in robot navigation, the focus is often to minimize the localization error with the aid of stationary features from the environment. The need for integration of the two becomes clear in environments with very sparse features or landmarks, for example when a group of Autonomous Underwater Vehicles (AUVs) are to search a uniform seafloor for mines or other dangerous objects. In such environments, localization systems are often deprived of detectable features to use that could increase their accuracy. In this paper we propose an algorithm for doing navigation aware multi agent coverage in areas with no landmarks. Instead of using identical lawn mower patterns, we propose to mirror every other pattern to enable the agents to meet up and make inter-agent measurements and share information regularly. This improves performance in two ways, global drift in relation to the area to be covered is reduced, and local coverage gaps between adjacent patterns are reduced. Further, we show that this can be accomplished within the constraints of very limited sensing, computing and communication resources that most AUVs have available. The effectiveness of our method is shown through statistically significant simulated experiments.
# Polynomial Time Near-Time-Optimal Multi-Robot Path Planning in Three Dimensions with Applications to Large-Scale UAV Coordination
## Keywords:
- Path Planning for Multiple Mobile Robots or Agents
- Multi-Robot Systems
- Planning, Scheduling and Coordination
## Abstract:
For enabling efficient, large-scale coordination of unmanned aerial vehicles (UAVs) under	the labeled setting, in this work, we develop the first polynomial time algorithm for the reconfiguration of many moving bodies in three# dimensional spaces, with provable 1.x asymptotic makespan optimality guarantee under high robot density. More precisely, on an m1×m2×m3 gird, m1>= m2>= m3, our method computes solutions for routing up to m1*m2*m3/3 uniquely labeled robots with uniformly randomly distributed start and goal configurations within a makespan of m1+2m2+2m3+o(m1), with high probability. Because the makespan	lower bound for such instances is m1+m2+m3-o(m1), also with high probability, as m1 -> infty, (m1+2m2 +2m3)/(m1+m2+m3) optimality guarantee is achieved. (m1 +2m2+2m3)/(m1+m2+m3)in (1,5/3 ],yielding 1.x optimality.In contrast, it is well-known that multi-robot path planning is NP-hard to optimally solve. In numerical evaluations, our method readily scales to support the motion planning of over 100 000 robots in 3D while simultaneously achieving 1.x optimality. We demonstrate the application of our method in coordinating many quadcopters in both simulation and hardware experiments.
# Energy-Efficient Orienteering Problem in the Presence of Ocean Currents
## Keywords:
- Task and Motion Planning
- Planning, Scheduling and Coordination
- Environment Monitoring and Management
## Abstract:
In many environmental monitoring applications robots are often tasked to visit various distinct locations to make observations and/or collect specific measurements. The problem of scheduling and assigning robots to the various tasks and planning feasible paths for the robots can be posed as an Orienteering Problem (OP). In the standard OP, routing and scheduling is achieved by maximizing an objective function by visiting the most rewarding locations while respecting a limited travel budget. However, traditional formulations for such problems usually neglect some environmental features that can greatly impact the tour, e.g., flows, such as wind or ocean currents. This is of particular importance for applications in marine and atmospheric environments where vehicle motions can be significantly impacted by the environmental dynamics and the environment exerts a non-negligible force on the vehicles. In this paper, we tackle the OP in fluid environments where robots must operate in the presence of ocean and/or atmospheric currents. We introduce a novel multi-objective formulation that combines both task and path planning problems, and whose goals are to (i) maximize the collected reward, while (ii) minimizing the energy expenditure by leveraging the environmental dynamics wherever possible. We validate our strategy using simulated ocean model data to show that our approach can generate a diverse set of solutions that have an adequate compromise between both objectives.
# MAPFASTER: A Faster and Simpler Take on Multi-Agent Path Finding Algorithm Selection
## Keywords:
- Path Planning for Multiple Mobile Robots or Agents
- Multi-Robot Systems
- Deep Learning Methods
## Abstract:
Portfolio-based algorithm selection can help in choosing the best suited algorithm for a given task while leveraging the complementary strengths of the candidates. Solving the Multi-Agent Path Finding (MAPF) problem optimally has been proven to be NP-Hard. Furthermore, no single optimal algorithm has been shown to have the fastest runtime for all MAPF problem instances, and there are no proven approaches for when to use each algorithm. To address these challenges, we develop MAPFASTER, a smaller and more accurate deep learning based architecture aiming to be deployed in fleet management systems to select the fastest MAPF solver in a multi-robot setting. MAPF problem instances are encoded as images and passed to the model for classification into one of the portfolio's candidates. We evaluate our model against state-of-the-art Optimal-MAPF-Algorithm selectors, showing +5.42% improvement in accuracy while being 7.1times faster to train. The dataset, code and analysis used in this research can be found at href{https://github.com/jeanmarcalkazzi/mapfaster}{https://github.com/jeanmarcalkazzi/mapfaster}.
# A Conflict-Driven Interface between Symbolic Planning and Nonlinear Constraint Solving
## Keywords:
- Task and Motion Planning
- Task Planning
- Manipulation Planning
## Abstract:
Robotic planning in real-world scenarios typically requires joint optimization of logic and continuous variables. A core challenge to combine the strengths of logic planners and continuous solvers is the design of an efficient interface that informs the logical search about continuous infeasibilities. In this paper we present a novel iterative algorithm that connects logic planning with nonlinear optimization through a bidirectional interface, achieved by the detection of minimal subsets of nonlinear constraints that are infeasible. The algorithm continuously builds a database of graphs that represent (in)feasible subsets of continuous variables and constraints, and encodes this knowledge in the logical description. As a foundation for this algorithm, we introduce Planning with Nonlinear Transition Constraints (PNTC), a novel planning formulation that clarifies the exact assumptions our algorithm requires and can be applied to model Task and Motion Planning (TAMP) efficiently. Our experimental results show that our framework significantly outperforms alternative optimization-based approaches for TAMP. Webpage: https://quimortiz.github.io/graphnlp/
# Scalable Online Coverage Path Planning for Multi-Robot Systems
## Keywords:
- Path Planning for Multiple Mobile Robots or Agents
- Multi-Robot Systems
- Swarm Robotics
## Abstract:
Online coverage path planning to explore an unknown workspace with multiple homogeneous robots could be either centralized or distributed. While distributed planners are computationally faster, centralized planners can produce more efficient paths, reducing the duration of completing a coverage mission significantly. To exploit the power of a centralized framework, we propose a receding horizon centralized online multi-robot planner. In each planning horizon, it generates collision-free paths that guide the robots to visit some obstacle-free locations (aka goals) not visited so far, which in turn help them explore some new regions with their laser rangefinders. We formally prove that, under reasonable conditions, it enables the robots to cover a workspace completely and subsequently analyze its time complexity. We evaluate our planner for ground and aerial robots by performing experiments with up to 128 robots on six 2D grid-based benchmark obstacle maps, establishing scalability. We also perform Gazebo simulations with 10 quadcopters and real experiments with 2 four-wheel ground robots, demonstrating its practical feasibility. Furthermore, a comparison with a state-of-the-art distributed planner establishes its superiority in coverage completion time.
# DiMOpt: A Distributed Multi-Robot Trajectory Optimization Algorithm
## Keywords:
- Path Planning for Multiple Mobile Robots or Agents
- Integrated Planning and Control
- Multi-Robot Systems
## Abstract:
This paper deals with Multi-robot Trajectory Planning, that is, the problem of computing trajectories for multiple robots navigating in a shared space. Approaches based on trajectory optimization can solve this problem optimally. However, such methods are hampered by complex robot dynamics and collision constraints that couple robot's decision variables. We propose a distributed multi-robot optimization algorithm (DiMOpt) which addresses these issues by exploiting (1) consensus optimization strategies to tackle coupling collision constraints, and (2) a single-robot sequential convex programming (SCP) method for efficiently handling non-convexities introduced by dynamics. We compare DiMOpt with a baseline sequential convex programming algorithm tailored to the multi-robot case (M-SCP). We empirically demonstrate that DiMOpt scales well for large fleets of robots, while computing solutions faster and with lower costs than M-SCP. Moreover, DiMOpt is an iterative algorithm that finds feasible trajectories before converging to an optimal solution, and results suggest the quality of such fast initial solutions is comparable to a converged solution computed via M-SCP. Finally, we also investigate how other factors, including path length, affect the performance of DiMOpt.
# Non-Submodular Maximization Via the Greedy Algorithm and the Effects of Limited Information in Multi-Agent Execution
## Keywords:
- Path Planning for Multiple Mobile Robots or Agents
- Multi-Robot Systems
- Planning under Uncertainty
## Abstract:
We provide theoretical bounds on the worst case performance of the greedy algorithm in seeking to maximize a normalized, monotone, but not necessarily submodular objective function under a simple partition matroid constraint. We also provide worst case bounds on the performance of the greedy algorithm in the case that limited information is available at each planning step. We specifically consider limited information as a result of unreliable communications during distributed execution of the greedy algorithm. We utilize notions of curvature for normalized, monotone set functions to develop the bounds provided in this work. To demonstrate the value of the bounds provided in this work, we analyze a variant of the benefit of search objective function and show, using real-world data collected by an autonomous underwater vehicle, that theoretical approximation guarantees are achieved despite non-submodularity of the objective function.
# Gathering Physical Particles with a Global Magnetic Field Using Reinforcement Learning
## Keywords:
- Path Planning for Multiple Mobile Robots or Agents
- Reinforcement Learning
- Automation at Micro-Nano Scales
## Abstract:
For biomedical applications in targeted therapy delivery and interventions, a large swarm of micro-scale particles ("agents") has to be moved through a maze-like environment ("vascular system") to a target region ("tumor"). Due to limited on-board capabilities, these agents cannot move autonomously; instead, they are controlled by an external global force that acts uniformly on all particles. In this work, we demonstrate how to use a time-varying magnetic field to gather particles to a desired location. We use reinforcement learning to train networks to efficiently gather particles. Methods to overcome the simulation-to-reality gap are explained, and the trained networks are deployed on a set of mazes and goal locations. The hardware experiments demonstrate fast convergence, and robustness to both sensor and actuation noise. To encourage extensions and to serve as a benchmark for the reinforcement learning community, the code is available at Github.
# Transfer Learning
# Contrastive Learning for Cross-Domain Open World Recognition
## Keywords:
- Incremental Learning
- Transfer Learning
- Recognition
## Abstract:
The ability to evolve is fundamental for any valuable autonomous agent whose knowledge cannot remain limited to that injected by the manufacturer. Consider for example a home assistant robot: it should be able to incrementally learn new object categories when requested, but also to recognize the same objects in different environments (rooms) and poses (hand-held/on the floor/above furniture), while rejecting unknown ones. Despite its importance, this scenario has started to raise interest in the robotic community only recently and the related research is still in its infancy, with existing experimental testbeds but no tailored methods. With this work, we propose the first learning approach that deals with all the previously mentioned challenges at once by exploiting a single contrastive objective. We show how it learns a feature space perfectly suitable to incrementally include new classes and is able to capture knowledge which generalizes across a variety of visual domains. Our method is endowed with a tailored effective stopping criterion for each learning episode and exploits a self-paced thresholding strategy that provides the classifier with a reliable rejection option. Both these novel contributions are based on the observation of the data statistics and do not need manual tuning. An extensive experimental analysis confirms the effectiveness of the proposed approach in establishing the new state-of-the-art. The code is available at https://github.com/FrancescoCappio/Contrastive_Open_World.
# Efficient Multi-Task Learning Via Iterated Single-Task Transfer
## Keywords:
- Machine Learning for Robot Control
- Reinforcement Learning
- Transfer Learning
## Abstract:
In order to be effective general purpose machines in real world environments, robots not only will need to adapt their existing manipulation skills to new circumstances, they will need to acquire entirely new skills on-the-fly. One approach to achieving this capability is via Multi-task Reinforcement Learning (MTRL). Most recent work in MTRL trains a single policy to solve all tasks at once. In this work, we investigate the feasibility of instead training separate policies for each task, and only transferring from a task once the policy for it has finished training. We describe a method of finding near optimal sequences of transfers to perform in this setting, and use it to show that performing the optimal sequence of transfer is competitive with other MTRL methods on the MetaWorld MT10 benchmark. Lastly, we describe a method for finding nearly optimal transfer sequences during training that is able to improve on training each task from scratch.
# MPR-RL: Multi-Prior Regularized Reinforcement Learning for Knowledge Transfer
## Keywords:
- Reinforcement Learning
- Transfer Learning
- Machine Learning for Robot Control
## Abstract:
In manufacturing, assembly tasks have been a challenge for learning algorithms due to variant dynamics of different environments. Reinforcement learning (RL) is a promising framework to automatically learn these tasks, yet it is still not easy to apply a learned policy or skill, that is the ability of solving a task, to a similar environment even if the deployment condition is only slightly different. For safety and feasibility reasons, state-of-the-art methods require policy training in simulation to prevent undesired behavior followed by domain transfer, or guided policy search for similar environments. In this paper, we address the challenge of transferring knowledge within a family of similar tasks by leveraging multiple skill priors. We propose to learn prior distribution over the specific skill required to accomplish each task and compose the family of skill priors to guide learning the policy for a new task by comparing the similarity between the target task and the prior ones. Our method learns a latent action space representing the skill embedding from demonstrated trajectories for each prior task. We have evaluated our method on a task in simulation and a set of peg-in-hole insertion tasks and demonstrate better generalization to new tasks that have never been encountered during training. Our Multi-Prior Regularized RL (MPR-RL) method is deployed directly on a real-world Franka Panda arm, requiring only a set of demonstration trajectories from similar, but cruicially not identical, problem instances.
# Unsupervised Reinforcement Learning for Transferable Manipulation Skill Discovery
## Keywords:
- Reinforcement Learning
- Machine Learning for Robot Control
- Transfer Learning
## Abstract:
Current reinforcement learning (RL) in robotics often experiences difficulty in generalizing to new downstream tasks due to the innate task-specific training paradigm. To alleviate it, unsupervised RL, a framework that pre-trains the agent in a task-agnostic manner without access to the task-specific reward, leverages active exploration for distilling diverse experience into essential skills or reusable knowledge. For exploiting such benefits also in robotic manipulation, we propose an unsupervised method for transferable manipulation skill discovery that ties structured exploration toward interacting behavior and transferable skill learning. It not only enables the agent to learn interaction behavior, the key aspect of the robotic manipulation learning, without access to the environment reward, but also to generalize to arbitrary downstream manipulation tasks with the learned task-agnostic skills. Through comparative experiments, we show that our approach achieves the most diverse interacting behavior and significantly improves sample efficiency in downstream tasks including the extension to multi-object, multitask problems.
# Subspace-Based Feature Alignment for Unsupervised Domain Adaptation
## Keywords:
- Transfer Learning
- Object Detection, Segmentation and Categorization
- Deep Learning for Visual Perception
## Abstract:
Autonomous agents need to perceive the world in a robust way, such that the shift in data distribution does not lead to faulty perception results. When agents cannot be trained with abundant data, agents may need to operate on real world environments while trained on simulated data, and suffer from domain shift. This paper proposes an effective and robust unsupervised domain adaptation (UDA) method that can resolve these situations. In the UDA setup, we are given a labeled source domain and an unlabeled target domain that share the same set of classes but are sampled from different distributions. This domain shift prevents agents which employ deep neural networks from generalizing well on the target domain. Recent methods adopt the strategy of self-training the networks with pseudo labeled target samples. However, falsely labeled samples cause negative transfer and deteriorate generalization of a network. To reduce negative transfer we propose an algorithm that can filter the pseudo labels, and use the filtered labels to align the domains in the feature space. The samples whose labels have not passed the filtering process can be used as an index to tune the hyperparameters of our method. Across various benchmarks, we validate the performance of our method. Especially, our method achieves strong performance on the synthetic-to-real adaptation scenario.
# Using Simulation Optimization to Improve Zero-Shot Policy Transfer of Quadrotors
## Keywords:
- Transfer Learning
- Machine Learning for Robot Control
- Reinforcement Learning
## Abstract:
In this work, we propose a data-driven approach to optimize the parameters of a simulation such that control policies can be directly transferred from simulation to a real-world quadrotor. Our neural network-based policies take only onboard sensor data as input and run entirely on the embedded hardware. In real-world experiments, we compare low-level Pulse-Width Modulated control with higher-level control structures such as Attitude Rate and Attitude, which utilize Proportional-Integral-Derivative controllers to output motor commands. Our experiments show that low-level controllers trained with Reinforcement Learning require a more accurate simulation than higher-level control policies at the expense of being less robust towards parameter uncertainties.
# Bilateral Knowledge Distillation for Unsupervised Domain Adaptation of Semantic Segmentation
## Keywords:
- Transfer Learning
- Semantic Scene Understanding
- Computer Vision for Transportation
## Abstract:
Unsupervised domain adaptation (UDA) aims to learn domain-invariant representations between the labeled source domain and the unlabeled target domain. Existing self-training-based UDA methods use ground truth and pseudo-labels to supervise source data and target data respectively. However, strong supervision in the source domain and pseudo-label noise in the target domain lead to some problems, such as biased predictions and over-fitting. To tackle these issues, we propose a novel Bilateral Knowledge Distillation (BKD) framework for UDA in semantic segmentation, which adopts different knowledge distillation strategies depending on the domain. Specifically, we first introduce a Source-Flow Distillation (SD) to smooth the labels of source images, which weakens the supervision in the source domain. Meanwhile, a Target-Flow Distillation (TD) is designed to extract the inter-class knowledge in the probability map output from the teacher model, which alleviates the influence of pseudo-label noise in the target domain. Considering the class imbalance in semantic segmentation, we further propose an Image-Wise Hard Pixel Mining (HPM) to address this issue without estimating class frequency in the unlabeled target domain. The effectiveness of our framework against existing state-of-the-art methods is demonstrated by extensive experiments on two benchmarks: GTA5-to-Cityscapes and SYNTHIA-to-Cityscapes.
# Self-Supervised Noisy Label Learning for Source-Free Unsupervised Domain Adaptation
## Keywords:
- Transfer Learning
- Recognition
- Deep Learning Methods
## Abstract:
Domain adaptation is an important property in robot vision, which enables the neural networks pre-trained on source domains to adapt target domains automatically without any annotation efforts. During this process, source data is not always accessible due to the constraints of expensive storage overhead and data privacy protection. Therefore, the source domain pre-trained model is expected to optimize with only unlabeled target data, termed as source-free unsupervised domain adaptation. In this paper, we view this problem as a special case of noisy label learning, since the given pre-trained model can generate noisy labels for unlabeled target data via network inference. The potential semantic cues for unsupervised domain adaptation exactly lie on these noisy labels. Inspired by this problem modeling, we propose a simple yet effective Self-Supervised Noisy Label Learning method, which injects self-supervised learning to impose the intrinsic data structure and facilitate label-denoising. Extensive experiments have been conducted on diverse benchmarks to validate the effectiveness. Our method achieves state-of-the-art performance.
# Analysis of Randomization Effects on Sim2Real Transfer in Reinforcement Learning for Robotic Manipulation Tasks
## Keywords:
- Transfer Learning
- Incremental Learning
- Deep Learning in Grasping and Manipulation
## Abstract:
Randomization is currently a widely used approach in Sim2Real transfer for data-driven learning algorithms in robotics. Still, most Sim2Real studies report results for a specific randomization technique and often on a highly customized robotic system, making it difficult to evaluate different randomization approaches systematically. To address this problem, we define an easy-to-reproduce experimental setup for a robotic reach-and-balance manipulator task, which can serve as a benchmark for comparison. We compare four randomization strategies with three randomized parameters both in simulation and on a real robot. Our results show that more randomization helps in Sim2Real transfer, yet it can also harm the ability of the algorithm to find a good policy in simulation. Fully randomized simulations and fine-tuning show differentiated results and translate better to the real robot than the other approaches tested.
# Assembly and Additive Manufacturing
# Additive Manufacturing for Tissue Engineering Applications in a Temperature-Controlled Environment
## Keywords:
- Additive Manufacturing
- Product Design, Development and Prototyping
## Abstract:
In recent years, with the combination of tissue engineering and additive manufacturing technologies, the possibility of fabricating scaffolds with porosity and complex structure has been improved. Since the properties of most biomaterial inks are influenced by temperature and thereby affect the quality of the scaffolds, a controlled printing environment is very important. This study focuses on temperature monitoring from the nozzle to the working platform. A compact heating jacket is developed to heat the needle and sense its temperature inside the nozzle. It makes it very different from common cartridge heating mechanisms. Moreover, a semi-closed printing environment composed of an air curtain and temperature circulation device is developed to create a stable cooling environment. It improves the uniformity of the work platform and increases by 50% the cooling time efficiency. To demonstrate the robustness for a wide range of temperatures, this study presents two experiments of printing two biomaterial inks at body and low temperatures, respectively.
# On CAD Informed Adaptive Robotic Assembly
## Keywords:
- Assembly
- Dual Arm Manipulation
- Computer Vision for Automation
## Abstract:
We introduce a robotic assembly system that streamlines the design-to-make workflow for going from a CAD model of a product assembly to a fully programmed and adaptive assembly process. Our system captures (in the CAD tool) the intent of the assembly process for a specific robotic workcell and generates a recipe of task-level instructions. By integrating visual sensing with deep-learned perception models, the robots infer the necessary actions to assemble the design from the generated recipe. The perception models are trained directly from simulation, allowing the system to identify various parts based on CAD information. We demonstrate the system with a workcell of two robots to assemble interlocking 3D part designs. We first build and tune the assembly process in simulation, verifying the generated recipe. Finally, the real robotic workcell assembles the design using the same behavior.
# Graph-Based Reinforcement Learning Meets Mixed Integer Programs: An Application to 3D Robot Assembly Discovery
## Keywords:
- Assembly
- Reinforcement Learning
- Task and Motion Planning
## Abstract:
Robot assembly discovery (RAD) is a challenging problem that lives at the intersection of resource allocation and motion planning. The goal is to combine a predefined set of objects to form something new while considering task execution with the robot-in-the-loop. In this work, we tackle the problem of building arbitrary, predefined target structures entirely from scratch using a set of Tetris-like building blocks and a robotic manipulator. Our novel hierarchical approach aims at efficiently decomposing the overall task into three feasible levels that benefit mutually from each other. On the high level, we run a classical mixed-integer program for global optimization of block-type selection and the blocks’ final poses to recreate the desired shape. Its output is then exploited to efficiently guide the exploration of an underlying reinforcement learning (RL) policy. This RL policy draws its generalization properties from a flexible graph-based representation that is learned through Q-learning and can be refined with search. Moreover, it accounts for the necessary conditions of structural stability and robotic feasibility that cannot be effectively reflected in the previous layer. Lastly, a grasp and motion planner transforms the desired assembly commands into robot joint movements. We demonstrate our proposed method’s performance on a set of competitive simulated RAD environments, showcase real-world transfer, and report performance and robustness gains compared to an unstructured end-to-end approach.
# Assembly Planning from Observations under Physical Constraints
## Keywords:
- Assembly
- Manipulation Planning
## Abstract:
This paper addresses the problem of copying an unknown assembly of primitives with known shape and appearance using information extracted from a single photograph by an off-the-shelf procedure for object detection and pose estimation. The proposed algorithm uses a simple combination of physical stability constraints, convex optimization and Monte Carlo tree search to plan assemblies as sequences of pick-and-place operations represented by STRIPS operators. It is efficient and, most importantly, robust to the errors in object detection and pose estimation unavoidable in any real robotic system. The proposed approach is demonstrated with thorough experiments on a UR5 manipulator.
# Coordinated Toolpath Planning for Multi-Extruder Additive Manufacturing
## Keywords:
- Additive Manufacturing
- Task and Motion Planning
- Cooperating Robots
## Abstract:
We present a new algorithm for coordinating the motion of multiple extruders to increase throughput in fused filament fabrication (FFF)/fused deposition modeling (FDM) additive manufacturing. Platforms based on FFF are commonly available and advantageous to several industries, but are limited by slow fabrication time and could be could be significantly improved through efficient use of multiple extruders. We propose the coordinated toolpath planning problem for systems of extruders mounted as end-effectors on robot arms with the objective of maximizing utilization and avoiding collisions. Building on the idea of dependency graphs introduced in our earlier work, we develop a planning and control framework that precomputes a set of multi-layer toolpath segments from the input model and efficiently assigns them to individual extruders such that executed toolpaths are collision-free. Our method overcomes key limitations of existing methods, including utilization loss from workspace partitioning, precomputed toolpaths subject to collisions with the partially fabricated object, and wasted motion resulting from strict layer-by-layer fabrication. We report simulation results that show a major increase in utilization compared to single and multi-extruder methods, and favorable fabrication results using commodity hardware that demonstrate the feasibility of our method in practice.
# A Hierarchical Finite-State Machine-Based Task Allocation Framework for Human-Robot Collaborative Assembly Tasks
## Keywords:
- Industrial Robots
- Assembly
- Human-Robot Collaboration
## Abstract:
Work-related musculoskeletal disorders (MSD) are one of the major causes of injuries and absenteeism at work. These lead to important costs in the manufacturing industry. Human-robot collaboration can help decrease this issue by appropriately distributing the tasks and decreasing the workload of the factory worker. This paper proposes a novel generic task allocation approach based on hierarchical finite-state machines for human-robot assembly tasks. The developed framework decomposes first the main task into sub-tasks modeled as state machines. Based on capabilities considerations, workload, and performance estimations, the task allocator assigns the sub-task to the human or robot agent. The algorithm was validated on the assembly of a crusher unit of a smoothie machine using the collaborative Franka Emika Panda robot and showed promising results in terms of productivity thanks to task parallelization, with an improvement of more than 30% of the total assembly time with respect to a collaborative scenario, where the agents perform the tasks sequentially.
# Self-Stabilizing Self-Assembly
## Keywords:
- Assembly
- Swarm Robotics
## Abstract:
The emerging field of passive macro-scale tile-based self-assembly (TBSA) shows promise in enabling effective manufacturing processes by harnessing TBSA’s intrinsic parallelism. However, current TBSA methodologies still do not fulfill their potentials, largely because such assemblies are often prone to errors, and the size of an individual assembly is limited due to insufficient mechanical stability. Moreover, the instability issue worsens as assemblies grow in size. Using a novel type of magnetically-bonded tiles carried by bristle-bot drives, we propose here a framework that reverses this tendency; i.e., as an assembly grows, it becomes more stable. Stability is achieved by introducing two sets of tiles that move in opposite directions, thus zeroing the assembly net force. Using physics-based computational experiments, we compare the performance of the proposed approach with the common orbital shaking method, proving that the proposed system of tiles indeed possesses self-stabilizing characteristics. Our approach enables assemblies containing hundreds of tiles to be built, while the shaking approach is inherently limited to a few tens of tiles. Our results indicate that one of the primary limitations of mechanical, agitation-based TBSA approaches, instability, might be overcome by employing a swarm of free-running, sensorless mobile robots, herein represented by passive tiles at the macroscopic scale.
# Flexible and Precision Snap-Fit Peg-In-Hole Assembly Based on Multiple Sensations and Damping Identification
## Keywords:
- Compliant Assembly
- Force and Tactile Sensing
- Sensor Fusion
## Abstract:
Snap-fit peg-in-hole assembly widely exists in both industry and daily life, especially for consumer electronics. The buckle mechanism leads to a damping zone inside the port where insertion force needs to be increased. It is much difficult to automate this process by robots, for size and clearance of the components are always small, and the damping buckle should be perceived and distinguished from solid inner walls of the port. End-effector position control might be invalid, since grasping error will make it difficult to locate the plug accurately. In this article, we undertake this assembly challenge by taking advantage of fingertip tactile perception combined with visual images and force feedback. Raw sensor data is collected, processed, and fused together to be state input of a reinforcement learning network, generating continuous action vectors. We also propose a novel damping zone predictor through feature extraction and multimodal fusion, which is able to identify whether the plug has touched the buckle mechanism, so as to adjust the insertion force. The whole framework is implemented through a common USB Type-C insertion experiment on Franka Panda robot platform, reaching a success rate of 88%. Furthermore, system robustness is verified, and comparisons of different modalities are also conducted.
# A General Method for Autonomous Assembly of Arbitrary Parts in the Presence of Uncertainty
## Keywords:
- Compliant Assembly
- Perception-Action Coupling
- Contact Modeling
## Abstract:
In this paper, we propose a novel and general method for autonomous robotic assembly of arbitrary and complex-shaped parts in the presence of 6-dimensional uncertainty. When a nominal assembly motion of the robot holding a part is stopped by contact due to uncertainty, our method finds the best estimate for the uncertainty and the contact configuration of the part based on sensed force/torque and uses that information to find a more accurate estimate of the goal configuration to guide a recovery motion of the part. It is based on a general, surface-based sphere tree representation of parts, a constrained optimization strategy to find the best estimate of the contact configuration under an uncertainty estimate, and a learned force/torque calibration model to relate computed force/torque and the sensed real force/torque. The method is applied and evaluated on different complex-shaped multi-peg-in-hole tasks. The results show that our method can achieve successful assembly with the presence of realistic 6-D uncertainties more than 10 times of the tight task clearances in terms of orientation clearance (<0.015 rad) and position clearance (<1.5 mm), in all the test cases.
# Motion and Path Planning 7
# Fast-Replanning Motion Control for Non-Holonomic Vehicles with Aborting A*
## Keywords:
- Motion and Path Planning
- Collision Avoidance
- Autonomous Vehicle Navigation
## Abstract:
Autonomously driving vehicles must be able to navigate in dynamic and unpredictable environments in a collision-free manner. So far, this has only been partially achieved in driverless cars and warehouse installations where marked structures such as roads, lanes, and traffic signs simplify the motion planning and collision avoidance problem. We are presenting a new control approach for car-like vehicles that is based on an unprecedentedly fast-paced A* implementation that allows the control cycle to run at a frequency of 30 Hz. This frequency enables us to place our A* algorithm as a low# level replanning controller that is well suited for navigation and collision avoidance in virtually any dynamic environment. Due to an efficient heuristic consisting of rotate-translate-rotate motions laid out along the shortest path to the target, our Short# Term Aborting A* (STAA*) converges fast and can be aborted early in order to guarantee a high and steady control rate. While our STAA* expands states along the shortest path, it takes care of collision checking with the environment including predicted states of moving obstacles, and returns the best solution found when the computation time runs out. Despite the bounded computation time, our STAA* does not get trapped in corners due to the following of the shortest path. In simulated and real-robot experiments, we demonstrate that our control approach eliminates collisions almost entirely and is superior to an improved version of the Dynamic Window Approach with predictive collision avoidance capabilities.
# Collision and Rollover-Free mathcal{G}^2 Path Planning for Mobile Manipulation
## Keywords:
- Motion and Path Planning
- Collision Avoidance
- Robotics and Automation in Agriculture and Forestry
## Abstract:
This paper presents a path planning refinement technique that allows the efficient collision and rollover-free motion planning for mobile manipulator robots working on rough terrain. First, the necessary theoretical background on a mobile manipulator's kinematics and dynamic stability measure is introduced. Then, after the brief introduction of the sampling-based path planning problem, the additional refinement stage and its problem formulation will be introduced. Within the refinement stage, the novel B'{e}zier control point addition method is introduced to allow for fast, collision and rollover-free path smoothing using curvature-continuous parametrized curves. Analytical proofs and simulated comparisons are provided in the paper to show effectiveness. The beneficial effect of the refined path on trajectory planning will also be demonstrated through simulation.
# Fast 3D Sparse Topological Skeleton Graph Generation for Mobile Robot Global Planning
## Keywords:
- Motion and Path Planning
- Autonomous Vehicle Navigation
- Mapping
## Abstract:
In recent years, mobile robots are becoming ambitious and deployed in large-scale scenarios. Serving as a high-level understanding of environments, a sparse skeleton graph is beneficial for more efficient global planning. Currently, existing solutions for skeleton graph generation suffer from several major limitations, including poor adaptiveness to different map representations, dependency on robot inspection trajectories and high computational overhead. In this paper, we propose an efficient and flexible algorithm generating a trajectory-independent 3D sparse topological skeleton graph capturing the spatial structure of the free space. In our method, an efficient ray sampling and validating mechanism are adopted to find distinctive free space regions, which contributes to skeleton graph vertices, with traversability between adjacent vertices as edges. A cycle formation scheme is also utilized to maintain skeleton graph compactness. Benchmark comparison with state-of-the-art works demonstrates that our approach generates sparse graphs in a substantially shorter time, giving high-quality global planning paths. Experiments conducted in real-world maps further validate the capability of our method in real-world scenarios. Our method will be made open source to benefit the community.
# Learning Enabled Fast Planning and Control in Dynamic Environments with Intermittent Information
## Keywords:
- Motion and Path Planning
- Autonomous Vehicle Navigation
- Collision Avoidance
## Abstract:
This paper addresses a safe planning and control problem for mobile robots operating in communication# and sensor-limited dynamic environments. In this case the robots cannot sense the objects around them and must instead rely on intermittent, external information about the environment, as e.g., in underwater applications. The challenge in this case is that the robots must plan using only this stale data, while accounting for any noise in the data or uncertainty in the environment. To address this challenge we propose a compositional technique which leverages neural networks to quickly plan and control a robot through crowded and dynamic environments using only intermittent information. Specifically, our tool uses reachability analysis and potential fields to train a neural network that is capable of generating safe control actions. We demonstrate our technique both in simulation with an underwater vehicle crossing a crowded shipping channel and with real experiments with ground vehicles in communication# and sensor-limited environments.
# NMPC-LBF: Nonlinear MPC with Learned Barrier Function for Decentralized Safe Navigation of Multiple Robots in Unknown Environments
## Keywords:
- Motion and Path Planning
- Multi-Robot Systems
- Machine Learning for Robot Control
## Abstract:
In this paper, we present a decentralized control approach based on a Nonlinear Model Predictive Control (NMPC) method that employs barrier certificates for safe navigation of multiple nonholonomic wheeled mobile robots in unknown environments with static and/or dynamic obstacles. This method incorporates a Learned Barrier Function (LBF) into the NMPC design in order to guarantee safe robot navigation, i.e., prevent robot collisions with other robots and the obstacles. We refer to our proposed control approach as NMPC-LBF. Since each robot does not have a priori knowledge about the obstacles and other robots, we use a Deep Neural Network (DeepNN) running in real-time on each robot to learn the Barrier Function (BF) only from the robot's LiDAR and odometry measurements. The DeepNN is trained to learn the BF that separates safe and unsafe regions. We implemented our proposed method on simulated and actual Turtlebot3 Burger robot(s) in different scenarios. The implementation results show the effectiveness of the NMPC-LBF method at ensuring safe navigation of the robots.
# FISS: A Trajectory Planning Framework Using Fast Iterative Search and Sampling Strategy for Autonomous Driving
## Keywords:
- Motion and Path Planning
- Autonomous Vehicle Navigation
- Intelligent Transportation Systems
## Abstract:
Trajectory planning is a critical component in autonomous vehicles directly responsible for driving safety and efficiency during deployment. The ability to find the optimal trajectory in real-time is critical for autonomous driving. This paper presents a novel general framework using the Fast Iterative Search and Sampling (FISS) strategy for sampling-based trajectory planning, which can find the optimal trajectory from an enormous number of candidates with high efficiency in real-time. Specifically, before generating any trajectories, the proposed method utilizes historical planning results as prior information in heuristics to estimate the cost distribution over the sampling space. On this basis, the Fast Iterative Search and Sampling strategy is employed to explore the sampling space for possible candidates and generate trajectories for verification during the search process. Experimental results show that our method can significantly outperform existing frameworks by order of magnitude in planning efficiency while ensuring safety and maintaining high accuracy.
# Reshaping Local Path Planner
## Keywords:
- Motion and Path Planning
- Collision Avoidance
- Constrained Motion Planning
## Abstract:
This paper proposes a path planner that reshapes a global path locally in response to sensor-based observations of obstacles in the environment. Two fundamental concepts enable the resultant algorithm (a) a path-following synthetic vehicle whose steering actions are non-myopically optimized to result in a smooth traversible path that meets path curvature constraints, and (b) a path-aware turning moment-field that enables obstacle avoidance while eluding the typical local-minimum-induced stagnation associated with potential field methods. The use of the combination of the two concepts results in a reduced action space over which optimization needs to be performed towards minimizing the path deviation subject to obstacle avoidance, and thus results in an efficient algorithm that can be implemented online. We demonstrate the algorithm in simulations as well as in field experiments, performing real time local path planning and obstacle avoidance on two different vehicle platforms (an ackerman steering vehicle two-axled vehicle, and a differential-steering 4-axled vehicle) in an unstructured off-road terrain.
# T-PRM: Temporal Probabilistic Roadmap for Path Planning in Dynamic Environments
## Keywords:
- Motion and Path Planning
- Collision Avoidance
## Abstract:
Sampling-based motion planners are widely used in robotics due to their simplicity, flexibility and computational efficiency. However, in their most basic form, these algorithms operate under the assumption of static scenes and lack the ability to avoid collisions with dynamic (i.e. moving) obstacles. This raises safety concerns, limiting the range of possible applications of mobile robots in the real world. Motivated by these challenges, in this work we present Temporal-PRM, a novel sampling-based path-planning algorithm that performs obstacle avoidance in dynamic environments. The proposed approach extends the original Probabilistic Roadmap (PRM) with the notion of time, generating an augmented graph-like structure that can be efficiently queried using a time-aware variant of the A* search algorithm, also introduced in this paper. Our design maintains all the properties of PRM, such as the ability to perform multiple queries and to find smooth paths, while circumventing its downside by enabling collision avoidance in highly dynamic scenes with a minor increase in the computational cost. Through a series of challenging experiments in highly cluttered and dynamic environments, we demonstrate that the proposed path planner outperforms other state-of-the-art sampling-based solvers. Moreover, we show that our algorithm can run onboard a flying robot, performing obstacle avoidance in real time.
# Hierarchical Planning with Annotated Skeleton Guidance
## Keywords:
- Motion and Path Planning
- Collision Avoidance
- Computational Geometry
## Abstract:
We present a hierarchical skeleton-guided motion planning algorithm to guide mobile robots. A good skeleton maps the connectivity of the subspace of c-space containing significant degrees of freedom and is able to guide the planner to find the desired solutions fast. However, sometimes the skeleton does not closely represent the free c-space, which often misleads current skeleton-guided planners. The hierarchical skeleton-guided planning strategy gradually relaxes its reliance on the workspace skeleton as Cspace is sampled, thereby incrementally returning a sub-optimal path, a feature that is not guaranteed in the standard skeleton-guided algorithm. Experimental comparisons to the standard skeleton guided planners and other lazy planning strategies show significant improvement in roadmap construction run time while maintaining path quality for multi-query problems in cluttered environments.
# Legged Robots 1
# Learning Coordinated Terrain-Adaptive Locomotion by Imitating a Centroidal Dynamics Planner
## Keywords:
- Legged Robots
- Deep Learning Methods
- Reinforcement Learning
## Abstract:
We propose a simple imitation learning procedure for learning locomotion controllers that can walk over very challenging terrains. We use trajectory optimization (TO) to produce a large dataset of trajectories over procedurally generated terrains and use Reinforcement Learning (RL) to imitate these trajectories. We demonstrate with a realistic model of the ANYmal robot that the learned controllers transfer to unseen terrains and provide an effective initialization for fine-tuning on challenging terrains that require exteroception and precise foot placements. Our setup combines TO and RL in a simple fashion that overcomes the computational limitations and need for a robust tracking controller of the former and the exploration and reward-tuning difficulties of the latter.
# A Versatile Co-Design Approach for Dynamic Legged Robots
## Keywords:
- Legged Robots
- Mechanism Design
- Optimization and Optimal Control
## Abstract:
We present a versatile framework for the computational co-design of legged robots and dynamic maneuvers. Current state-of-the-art approaches are typically based on random sampling or concurrent optimization. We propose a novel bilevel optimization approach that exploits the derivatives of the motion planning sub-problem (i.e., the lower level). These motion-planning derivatives allow us to incorporate arbitrary design constraints and costs in an general-purpose nonlinear program (i.e., the upper level). Our approach allows for the use of any differentiable motion planner in the lower level and also allows for an upper level that captures arbitrary design constraints and costs. It efficiently optimizes the robot’s morphology, payload distribution and actuator parameters while considering its full dynamics, joint limits and physical constraints such as friction cones. We demonstrate these capabilities by designing quadruped robots that jump and trot. We show that our method is able to design a more energy-efficient Solo robot for these tasks.
# Motion Planning for Agile Legged Locomotion Using Failure Margin Constraints
## Keywords:
- Legged Robots
- Human and Humanoid Motion Analysis and Synthesis
- Motion and Path Planning
## Abstract:
The complex dynamics of agile robotic legged locomotion requires motion planning to intelligently adjust footstep locations. Often, bipedal footstep and motion planning use mathematically simple models such as the linear inverted pendulum, instead of dynamically-rich models that do not have closed-form solutions. We propose a real-time optimization method to plan for dynamical models that do not have closed form solutions and experience irrecoverable failure. Our method uses a data-driven approximation of the step-to-step dynamics and of a failure margin function. This failure margin function is an oriented distance function in state-action space where it describes the signed distance to success or failure. The motion planning problem is formed as a nonlinear program with constraints that enforce the approximated forward dynamics and the validity of state-action pairs. For illustration, this method is applied to create a planner for an actuated spring-loaded inverted pendulum model. In an ablation study, the failure margin constraints decreased the number of invalid solutions by between 24 and 47 percentage points across different objectives and horizon lengths. While we demonstrate the method on a canonical model of locomotion, we also discuss how this can be applied to data-driven models and full-order robot models.
# Energy-Based Legged Robots Terrain Traversability Modeling Via Deep Inverse Reinforcement Learning
## Keywords:
- Legged Robots
- Energy and Environment-Aware Automation
- Learning from Demonstration
## Abstract:
This work reports on developing a deep inverse reinforcement learning method for legged robots terrain traversability modeling that incorporates both exteroceptive and proprioceptive sensory data. Existing works use robot-agnostic exteroceptive environmental features or handcrafted kinematic features; instead, we propose to also learn robot-specific inertial features from proprioceptive sensory data for reward approximation in a single deep neural network. Incorporating the inertial features can improve the model fidelity and provide a reward that depends on the robot's state during deployment. We train the reward network using the Maximum Entropy Deep Inverse Reinforcement Learning (MEDIRL) algorithm and propose simultaneously minimizing a trajectory ranking loss to deal with the suboptimality of legged robot demonstrations. The demonstrated trajectories are ranked by locomotion energy consumption, in order to learn an energy-aware reward function and a more energy-efficient policy than demonstration. We evaluate our method using a dataset collected by an MIT Mini-Cheetah robot and a Mini-Cheetah simulator. The code is publicly available at https://github.com/ganlumomo/minicheetah-traversability-irl.
# Robust High-Speed Running for Quadruped Robots Via Deep Reinforcement Learning
## Keywords:
- Legged Robots
- Machine Learning for Robot Control
- Motion Control
## Abstract:
Deep reinforcement learning has emerged as a popular and powerful way to develop locomotion controllers for quadruped robots. Common approaches have largely focused on learning actions directly in joint space, or learning to modify and offset foot positions produced by trajectory generators. Both approaches typically require careful reward shaping and training for millions of time steps, and with trajectory generators introduce human bias into the resulting control policies. In this paper, we present a learning framework that leads to the natural emergence of fast and robust bounding policies for quadruped robots. The agent both selects and controls actions directly in task space to track desired velocity commands subject to environmental noise including model uncertainty and rough terrain. We observe that this framework improves sample efficiency, necessitates little reward shaping, leads to the emergence of natural gaits such as galloping and bounding, and eases the sim-to-real transfer at running speeds. Policies can be learned in only a few million time steps, even for challenging tasks of running over rough terrain with loads of over 100% of the nominal quadruped mass. Training occurs in PyBullet, and we perform a sim-to-sim transfer to Gazebo and sim-to-real transfer to the Unitree A1 hardware. For sim-to-sim, our results show the quadruped is able to run at over 4 m/s without a load, and 3.5 m/s with a 10 kg load, which is over 83% of the nominal quadruped mass. For sim-to-real, the Unitree A1 is able to bound at 2 m/s with a 5 kg load, representing 42% of the nominal quadruped mass.
# Toward a Data-Driven Template Model for Quadrupedal Locomotion
## Keywords:
- Legged Robots
- Motion Control
- Multi-Contact Whole-Body Motion Planning and Control
## Abstract:
This work investigates a data-driven template model for trajectory planning of dynamic quadrupedal robots. Many state-of-the-art approaches involve using a reduced-order model, primarily due to computational tractability. The spirit of the trajectory planning approach in this work draws on recent advancements in the area of behavioral systems theory. Here, we aim to capitalize on the knowledge of well-known template models to construct a data-driven model, enabling us to obtain an information rich reduced-order model. In particular, this work considers input-output states similar to that of the single rigid body model and proceeds to develop a data-driven representation of the system, which is then used in a predictive control framework to plan a trajectory for quadrupeds. The optimal trajectory is passed to a low-level and nonlinear model-based controller to be tracked. Preliminary experimental results are provided to establish the efficacy of this hierarchical control approach for trotting and walking gaits of a high-dimensional quadrupedal robot on unknown terrains and in the presence of disturbances.
# Planning of Obstacle-Aided Navigation for Multi-Legged Robots Using a Sampling-Based Method Over Directed Graphs
## Keywords:
- Legged Robots
- Dynamics
## Abstract:
Existing work in legged robot navigation in cluttered environments often seeks collision-free paths that avoid obstacle interactions. Here we present a new approach for multi-legged robots to utilize leg-obstacle collisions to generate desired dynamics across obstacle fields. To predict the change of robot state (i.e., position and orientation) under repeated leg-obstacle collisions, we construct a discretized directed graph model: each node of the graph represents a different robot state, whereas the directed edges pointing from one node to another represent the transitions from one robot state to the next within one stride. These obstacle-modulated state transitions can depend on the robot gaits used. To capture this dependence, an empirical interaction model is used to compute the change of robot state based on initial contact positions between robot legs and obstacles. To validate the prediction of robot state transitions, we experimentally measure the state of a quadrupedal robot as it traverses a periodic obstacle field with three different gaits: bound, trot, and pace. We observed that the robot could passively converge to different steady state orientations, and these steady states corresponded well with the Strongly-Connected-Path-Components (SCPCs) within the directed graph. Searching over the graph for connected paths of SCPCs allows development of a gait planner that can generate gait switching strategies for a robot to achieve desired states by simply engaging with a sequence of leg-obstacle collisions. We demonstrate in experiments that, by using the gait sequences generated by our planner, an open-loop quadrupedal robot was able to successfully achieve desired orientations within a periodic obstacle field without any sensory input or active steering.
# Real-Time Digital Double Framework to Predict Collapsible Terrains for Legged Robots
## Keywords:
- Legged Robots
- Hardware-Software Integration in Robotics
- Sensorimotor Learning
## Abstract:
Inspired by the digital twinning systems, a novel real-time digital double framework is developed to enhance robot perception of the terrain conditions. Based on the very same physical model and motion control, this work exploits the use of such simulated digital double synchronized with a real robot to capture and extract discrepancy information between the two systems, which provides high dimensional cues in multiple physical quantities to represent differences between the modelled and the real world. Soft, non-rigid terrains cause common failures in legged locomotion, whereby visual perception solely is insufficient in estimating such physical properties of terrains. We used digital double to develop the estimation of the collapsibility, which addressed this issue through physical interactions during dynamic walking. The discrepancy in sensory measurements between the real robot and its digital double are used as input of a learning-based algorithm for terrain collapsibility analysis. Although trained only in simulation, the learned model can perform collapsibility estimation successfully in both simulation and real world. Our evaluation of results showed the generalization to different scenarios and the advantages of the digital double to reliably detect nuances in ground conditions.
# Adaptive Feet for Quadrupedal Walkers (I)
## Keywords:
- Compliant Joints and Mechanisms
- Mechanism Design
- Biologically-Inspired Robots
## Abstract:
The vast majority of state-of-the-art walking robots employ flat or ball feet for locomotion, presenting limitations while stepping on obstacles, slopes, or unstructured terrain. Moreover, traditional feet for quadrupeds lack sensing systems that are able to provide information about the environment and about the foot interaction with the surroundings. This further diminishes their value. Inspired by our previous work on soft feet for bipedal robots, we present the SoftFoot-Q, an articulated adaptive foot for quadrupeds. This device is conceived to be robust and able to overcome the limitations of currently employed feet. The core idea behind our adaptive foot design is first introduced and validated through a simplified mathematical formulation of the problem. Subsequently, we present the chosen mechanical implementation to attempt overcoming current limitations. The realized prototype of adaptive foot is integrated and tested on the compliantly actuated quadrupedal robot ANYmal together with a ROS based real-time foot pose reconstruction software. Both extensive field tests and indoor experiments show noticeable performance improvements, in terms of reduced slippage of the robot, with respect to both flat and ball feet.
# Art and Entertainment and Manipulation
# Towards Learning to Play Piano with Dexterous Hands and Touch
## Keywords:
- Art and Entertainment Robotics
- Force and Tactile Sensing
- Sensorimotor Learning
## Abstract:
As Liszt once said "(a virtuoso) must call up scent and blossom, and breathe the breath of life", a virtuoso plays the piano with passion, poetry, and extraordinary technical ability. Hence, piano playing, being a task that is quintessentially human, becomes a hallmark for roboticians and artificial intelligence researchers to pursue. In this paper, we advocate an end-to-end reinforcement learning (RL) paradigm to demonstrate how an agent can learn directly from machine-readable music score to play the piano with touch-augmented dexterous hands on a simulated piano. To achieve the desired tasks, we design useful touch# and audio-based reward functions and a series of tasks. Empirical results show that the RL agent can not only find the correct key position but also deal with the various rhythmic, volume, and fingering requirements. As a result, the agent demonstrates its effectiveness in playing simple pieces that have different musical requirements which show the potential of leveraging reinforcement learning approach for the piano playing tasks.
# Consensus-Based Normalizing-Flow Control: A Case Study in Learning Dual-Arm Coordination
## Keywords:
- Dual Arm Manipulation
- Multi-Robot Systems
- Reinforcement Learning
## Abstract:
We develop two consensus-based learning algorithms for multi-robot systems applied on complex tasks involving collision constraints and force interactions, such as the cooperative peg-in-hole placement. The proposed algorithms integrate multi-robot distributed consensus and normalizing-flow-based reinforcement learning. The algorithms guarantee the stability and the consensus of the multi-robot system's generalized variables in a transformed space. This transformed space is obtained via a diffeomorphic transformation parameterized by normalizing-flow models that the algorithms use to train the underlying task, learning hence skillful, dexterous trajectories required for the task accomplishment. We validate the proposed algorithms by parameterizing reinforcement learning policies, demonstrating efficient cooperative learning, and strong generalization of dual-arm assembly skills in a dynamics-engine simulator.
# Toward Efficient Task Planning for Dual-Arm Tabletop Object Rearrangement
## Keywords:
- Dual Arm Manipulation
- Task Planning
- Cooperating Robots
## Abstract:
We investigate the problem of coordinating two robot arms to solve non-monotone tabletop multi-object rearrangement tasks. In a non-monotone rearrangement task, complex object-object dependencies exist that require moving some objects multiple times to solve an instance. In working with two arms in a large workspace, some objects must be handed off between the robots, which further complicates the planning process. For the challenging dual-arm tabletop rearrangement problem, we develop effective task planning algorithms for scheduling the pick-n-place sequence that can be properly distributed between the two arms. We show that, even without using a sophisticated motion planner, our method achieves significant time savings in comparison to greedy approaches and naive parallelization of single-robot plans.
# Simultaneous Depth Estimation and Localization for Cell Manipulation Based on Deep Learning
## Keywords:
- Biological Cell Manipulation
- Computer Vision for Automation
## Abstract:
Visual localization, which is a key technology to realize the automation of cell manipulation, has been widely studied. Since the depth of field of the microscope is narrow, the planar localization and depth estimation are usually coupled together. At present, most methods adopt the serial working mode of focusing first and then planar localization, but they usually do not have good real-time performance and stability. In this paper, a simultaneous depth estimation and localization network was developed for cell manipulation. The network takes a focused image and a defocus-offset image as inputs, and outputs the defocus in the depth direction and the offset in the plane at the same time after going through defocus-offset information extraction, defocus classification mapping and offset regression mapping. To train and test our network, we also create two datasets: An Adherent Cell dataset and an Injection Micropipette dataset. The experimental results demonstrated that the proposed method achieves the detection of all test samples with a frame rate of more than 40Hz, and the maximum errors of depth estimation and localization are 2.44μm and 0.49μm, respectively. The proposed method has good stability, which is mainly reflected in its strong generalization ability and anti-noise ability.
# Cooperative Object Manipulation under Signal Temporal Logic Tasks and Uncertain Dynamics
## Keywords:
- Dual Arm Manipulation
- Multi-Robot Systems
- Cooperating Robots
## Abstract:
We address the problem of cooperative manipulation of an object whose tasks are specified by a Signal Temporal Logic (STL) formula. We employ the Prescribed Performance Control (PPC) methodology to guarantee predefined transient and steady-state performance on the object trajectory in order to satisfy the STL formula. More specifically, we first provide a way that translates the problem of satisfaction of an STL task to the problem of state evolution within a user-defined time-varying funnel. We then design a control strategy for the robotic agents that guarantees compliance with this funnel. The control strategy is decentralized, in the sense that each agent calculates its own control signal, and does not use any information on the agents' and object's dynamic terms, which are assumed to be unknown. We experimentally verify the results on two manipulator arms, cooperatively working to manipulate an object based on a STL formula.
# DrozBot: Using Ergodic Control to Draw Portraits
## Keywords:
- Art and Entertainment Robotics
- Motion Control
## Abstract:
We present drozBot: le robot portraitiste, a robotic system that draws artistic portraits of people. The input images for the portrait are taken interactively by the robot itself. We formulate the problem of drawing portraits as a problem of coverage which is then solved by an ergodic control algorithm to compute the strokes. The ergodic computation of the strokes for the portrait gives an artistic look to them. The specific ergodic control algorithm that we chose is inspired by the heat equation. We employed a 7-axis Franka Emika robot for the physical drawings and used an optimal control strategy to generate joint angle commands. We explain the influence of the different hyperparameters and show the importance of the image processing steps. The attractiveness of the results was evaluated by conducting a survey where we asked the participants to rank the portraits produced by different algorithms.
# Visual Haptic Reasoning: Estimating Contact Forces by Observing Deformable Object Interactions
## Keywords:
- Physically Assistive Devices
- Deep Learning for Visual Perception
- Perception for Grasping and Manipulation
## Abstract:
Robotic manipulation of highly deformable cloth presents a promising opportunity to assist people with several daily tasks, such as washing dishes; folding laundry; or dressing, bathing, and hygiene assistance for individuals with severe motor impairments. In this work, we introduce a formulation that enables a collaborative robot to perform visual haptic reasoning with cloth--the act of inferring the location and magnitude of applied forces during physical interaction. We present two distinct model representations, trained in physics simulation, that enable haptic reasoning using only visual and robot kinematic observations. We conducted quantitative evaluations of these models in simulation for robot-assisted dressing, bathing, and dish washing tasks, and demonstrate that the trained models can generalize across different tasks with varying interactions, human body sizes, and object shapes. We also present results with a real-world mobile manipulator, which used our simulation-trained models to estimate applied contact forces while performing physically assistive tasks with cloth. Videos can be found at our project webpage: https://sites.google.com/view/visualhapticreasoning/home
# Tactile Feedback Enabling In-Hand Pivoting and Internal Force Control for Dual-Arm Cooperative Object Carrying
## Keywords:
- Dual Arm Manipulation
- In-Hand Manipulation
- Cooperating Robots
## Abstract:
The main purpose of this paper is to demonstrate that smart exploitation of force/tactile feedback can enable successful physical cooperation of two robot manipulators to handle a common object with a high degree of dexterity. The novelty of the paper is that dexterity is provided not only by the degrees of freedom of the robot arms but also by the grasp controller of the sensorized parallel grippers, which allow the robots to manipulate the object either with a tight grasp or with a one-degree-of-freedom rolling contact. The coordinated motion of the robots depends on both the desired motion of the carried object and the control of the internal forces during transportation and in-hand manipulation. The solution exploits only kinematic models of the robots and a dynamic model of the distributed soft contact, which includes both linear force and torsional moment.
# DUQIM-Net: Probabilistic Object Hierarchy Representation for Multi-View Manipulation
## Keywords:
- Deep Learning in Grasping and Manipulation
- Object Detection, Segmentation and Categorization
- Grasping
## Abstract:
Object manipulation in cluttered scenes is a difficult and important problem in robotics. To efficiently manipulate objects, it is crucial to understand their surroundings, especially in cases where multiple objects are stacked one on top of the other, preventing effective grasping. We here present DUQIM-Net, a decision-making approach for object manipulation in a setting of stacked objects. In DUQIM-Net, the hierarchical stacking relationship is assessed using Adj-Net, a model that leverages existing Transformer Encoder-Decoder object detectors by adding an adjacency head. The output of this head probabilistically infers the underlying hierarchical structure of the objects in the scene. We utilize the properties of the adjacency matrix in DUQIM-Net to perform decision making and assist with object-grasping tasks. Our experimental results show that Adj-Net surpasses the state-of-the-art in object-relationship inference on the Visual Manipulation Relationship Dataset (VMRD), and that DUQIM-Net outperforms comparable approaches in bin clearing tasks.
# Aerial Systems 5
# Downwash-Aware Control Allocation for Over-Actuated UAV Platforms
## Keywords:
- Aerial Systems: Mechanics and Control
- Motion Control
## Abstract:
 Tracking position and orientation independently affords more agile maneuver for over-actuated multirotor Unmanned Aerial Vehicles (UAVs) while introducing undesired downwash effects; downwash flows generated by thrust generators may counteract others due to close proximity, which significantly threatens the stability of the platform. The complexity of modeling aerodynamic airflow challenges control algorithms from properly compensating for such a side effect. Leveraging the input redundancies in over-actuated UAVs, we tackle this issue with a novel control allocation framework that considers downwash effects and explores the entire allocation space for an optimal solution. This optimal solution avoids downwash effects while providing high thrust efficiency within the hardware constraints. To the best of our knowledge, ours is the first formal derivation to investigate the downwash effects on over-actuated UAVs. We verify our framework on different hardware configurations in both simulation and experiment.
# Siamese Object Tracking for Vision-Based UAM Approaching with Pairwise Scale-Channel Attention
## Keywords:
- Aerial Systems: Applications
- Deep Learning for Visual Perception
- Data Sets for Robotic Vision
## Abstract:
Although the manipulating of the unmanned aerial manipulator (UAM) has been widely studied, vision-based UAM approaching, which is crucial to the subsequent manipulating, generally lacks effective design. The key to the visual UAM approaching lies in object tracking, while current UAM tracking typically relies on costly model-based methods. Besides, UAM approaching often confronts more severe object scale variation issues, which makes it inappropriate to directly employ state-of-the-art model-free Siamese-based methods from the object tracking field. To address the above problems, this work proposes a novel Siamese network with pairwise scale-channel attention (SiamSA) for vision-based UAM approaching. Specifically, SiamSA consists of a pairwise scale-channel attention network (PSAN) and a scale-aware anchor proposal network (SA-APN). PSAN acquires valuable scale information for feature processing, while SAAPN mainly attaches scale awareness to anchor proposing. Moreover, a new tracking benchmark for UAM approaching, namely UAMT100, is recorded with 35K frames on a flying UAM platform for evaluation. Exhaustive experiments on the benchmarks and real-world tests validate the efficiency and practicality of SiamSA with a promising speed. Both the code and UAMT100 benchmark are now available at https:// github.com/vision4robotics/SiamSA.
# Unsteady Aerodynamic Modeling of Aerobat Using Lifting Line Theory and Wagner's Function
## Keywords:
- Aerial Systems: Mechanics and Control
- Simulation and Animation
- Modeling, Control, and Learning for Soft Robots
## Abstract:
Flying animals possess highly complex physical characteristics and are capable of performing agile maneuvers using their wings. The flapping wings generate complex wake structures that influence the aerodynamic forces, which can be difficult to model. While it is possible to model these forces using fluid-structure interaction, it is very computationally expensive and difficult to formulate. In this paper, we follow a simpler approach by deriving the aerodynamic forces using a relatively small number of states and presenting them in a simple state-space form. The formulation utilizes Prandtl's lifting line theory and Wagner's function to determine the unsteady aerodynamic forces acting on the wing in a simulation, which then are compared to experimental data of the bat-inspired robot called the Aerobat. The simulated trailing-edge vortex shedding can be evaluated from this model, which then can be analyzed for a wake-based gait design approach to improve the aerodynamic performance of the robot.
# Design and Analysis of Truss Aerial Transportation System (TATS): The Lightweight Bar Spherical Joint Mechanism
## Keywords:
- Aerial Systems: Applications
- Intelligent Transportation Systems
## Abstract:
In aerial cooperative transportation missions, it has been recognized that for small-sized but heavy payloads, the cable-suspended framework is a preferred manner. However, to maintain proper safe flight distances, cables always stay inclined, which implies that horizontal force components have to be generated by UAVs, and only partial thrust forces are used for gravity compensation. To overcome this drawback, in this paper, a new cooperative transportation system named Truss Aerial Transportation System (TATS) is proposed, where those horizontal forces can be internally compensated by the bar spherical joint structure. In the TATS, rigid bars can powerfully sustain the desired distances among UAVs for safe flight, resulting in a more compact and effective transportation system. Thanks to the structural advantage of the truss, the rigid bars can be made lightweight so as to minimize their induced gravity burden. The construction method of the proposed TATS is presented. The improvement in energy efficiency is analyzed and compared with the cable-suspended framework. Furthermore, the robustness property of a TATS configuration is evaluated by computing the margin capacity. Finally, a load test experiment is conducted on our made prototype, the results of which show the effectiveness and feasibility of the proposed TATS.
# SytaB: A Class of Smooth-Transition Hybrid Terrestrial/Aerial Bicopters
## Keywords:
- Aerial Systems: Mechanics and Control
- Dynamics
- Motion Control
## Abstract:
This work details the design, modeling and control of SytaB, a vehicle capable of hybrid terrestrial/aerial mobility with smooth transition, where the structure embedding a bicopter is adopted for the first time. In contrast to previous hybrid terrestrial/aerial vehicles with a quadrotor embedded, SytaB not only requires less energy for the same takeoff weight, but also regulates its attitude less frequently to restrain the vibration of sensors. Three modes, the terrestrial/aerial/transitional modes, are considered for the vehicle, and the dynamics modeling and controller design of each mode are carried out. The transition between terrestrial and aerial locomotions is smooth compared with the case of non-inclusion of transitional mode such that the bounce and shake of the vehicle are alleviated. The energy efficiency is compared between the terrestrial and aerial modes, and between the energy-saving and high-maneuverability paradigms (a choice enabled in the terrestrial mode of SytaB). Experimental results are presented to demonstrate the potential of SytaB, the effectiveness of the designed controllers, and the necessity of considering the transition process.
# Real-Time Trajectory Planning for Aerial Perching
## Keywords:
- Aerial Systems: Applications
- Whole-Body Motion Planning and Control
- Motion and Path Planning
## Abstract:
This paper presents a novel trajectory planning method for aerial perching. Compared with the existing work, the terminal states and the trajectory durations can be adjusted adaptively, instead of being determined in advance. Further# more, our planner is able to minimize the tangential relative speed on the premise of safety and dynamic feasibility. This feature is especially notable on micro aerial robots with low maneuverability or scenarios where the space is not enough. Moreover, we design a flexible transformation strategy to eliminate terminal constraints along with reducing optimization variables. Besides, we take precise SE(3) motion planning into account to ensure that the drone would not touch the landing platform until the last moment. The proposed method is validated onboard by a palm-sized micro aerial robot with quite limited thrust and moment (thrust-to-weight ratio 1.7) perching on a mobile inclined surface. Sufficient experimental results show that our planner generates an optimal trajectory within 20ms, and replans with warm start in 2ms.
# Dynamic Free-Space Roadmap for Safe Quadrotor Motion Planning
## Keywords:
- Aerial Systems: Applications
- Motion and Path Planning
- Autonomous Vehicle Navigation
## Abstract:
Free-space-oriented roadmaps typically generate a series of convex geometric primitives, which constitute the safe region for motion planning. However, a static environment is assumed for this kind of roadmap. This assumption makes it unable to deal with dynamic obstacles and limits its applications. In this paper, we present a dynamic free-space roadmap, which provides feasible spaces and a navigation graph for safe quadrotor motion planning. Our roadmap is constructed by continuously seeding and extracting free regions in the environment. In order to adapt our map to environments with dynamic obstacles, we incrementally decompose the polyhedra intersecting with obstacles into obstacle-free regions, while the graph is also updated by our well-designed mechanism. Extensive simulations and real-world experiments demonstrate that our method is practically applicable and efficient.
# Obstacle Avoidance of Resilient UAV Swarm Formation with Active Sensing System in the Dense Environment
## Keywords:
- Aerial Systems: Applications
- Path Planning for Multiple Mobile Robots or Agents
- Swarm Robotics
## Abstract:
This paper proposes a perception-shared and swarm trajectory global optimal (STGO) algorithm fused UAVs formation motion planning framework aided by an active sensing system. First, the point cloud received by each UAV is fit by the gaussian mixture model (GMM) and transmitted in the swarm. Resampling from the received GMM contributes to a global map, which is used as the foundation for consensus. Second, to improve flight safety, an active sensing system is designed to plan the observation angle of each UAV considering the unknown field, overlap of the field of view (FOV), velocity direction and smoothness of yaw rotation, and this planning problem is solved by the distributed particle swarm optimization (DPSO) algorithm. Last, for the formation motion planning, to ensure obstacle avoidance, the formation structure is allowed for affine transformation and is treated as the soft constraint on the control points of the B-spline. Besides, the STGO is introduced to avoid local minima. The combination of GMM communication and STGO guarantees a safe and strict consensus between UAVs. Tests on different formations in the simulation show that our algorithm can contribute to a strict consensus and has a success rate of at least 80% for obstacle avoidance in a dense environment. Besides, the active sensing system can increase the success rate of obstacle avoidance from 50% to 100% in some scenarios.
# Autoexplorer: Autonomous Exploration of Unknown Environments Using Fast Frontier-Region Detection and Parallel Path Planning
## Keywords:
- Autonomous Vehicle Navigation
- Motion and Path Planning
## Abstract:
We propose a fully autonomous system for mobile robot exploration in unknown environments. Our system employs a novel frontier detection algorithm based on the fast front propagation (FFP) technique and uses parallel path planning to reach the detected front regions. Given an occupancy grid map in 2D, possibly updated online, our algorithm can find all the frontier points that can allow mobile robots to visit unexplored regions to maximize the exploratory coverage. Our FFP method is six~seven times faster than the state-of-the-art wavefront frontier detection algorithm in terms of finding frontier points without compromising the detection accuracy. The speedup can be further accelerated by simplifying the map without degrading the detection accuracy. To expedite locating the optimal frontier point, We also eliminate spurious points by the obstacle filter and the novel boundary filter. In addition, we parallelize the global planning phase using the branch-and-bound A*, where the search space of each thread is confined by its best knowledge discovered during the parallel search. As a result, our parallel path-planning algorithm operating on 20 threads is about 30 times faster than the vanilla exploration system that operates on a single thread. Our method is validated through extensive experiments, including autonomous robot exploration in both synthetic and real-world scenarios. In the real-world experiment, we show that an autonomous navigation system using a human-sized mobile manipulator robot equipped with a low-end embedded processor that fully integrates our FFP and parallel path-planning algorithms.
# Navigation Systems 6
# Real-Time Visual Inertial Odometry with a Resource-Efficient Harris Corner Detection Accelerator on FPGA Platform
## Keywords:
- Vision-Based Navigation
- Software-Hardware Integration for Robot Systems
## Abstract:
Visual Inertial Odometry (VIO) is a widely studied localization technique in robotics. State-of-the-art VIO algorithms are composed of two parts: a frontend which performs visual perception and inertial measurement pre-processing, and a backend which fuses vision and inertial measurements to estimate the robot’s pose. Both image processing in the frontend and sensor fusion in the backend are computationally expensive, making it very challenging to run the VIO algorithm, especially the optimization-based VIO algorithm in real time on embedded platforms with limited power budget. In this paper, a real-time optimization-based monocular VIO algorithm is proposed based on algorithm-and-hardware codesign and successfully implemented on an embedded platform with only 2.6W processor power consumption. In particular, the time-consuming Harris corner detection (HCD) is accelerated on Field Programmable Gate Array (FPGA), achieving an average 16* processing time reduction compared with the ARM implementation. Compared with the state-of-the-art HCD accelerator provided by Xilinx, the hardware resource required of our accelerator is largely reduced without any compromise in speed, thanks to the proposed dedicated pruning and parallelization techniques. Finally, experiment on the public dataset demonstrates that the proposed real-time VIO algorithm on the FPGA-based platform has comparable accuracy with respect to the existing state-of-the-art VIO algorithm on the desktop, and 3* faster frontend processing speed over the ARM-based implementation.
# MPNP: Multi-Policy Neural Planner for Urban Driving
## Keywords:
- Autonomous Vehicle Navigation
- Imitation Learning
## Abstract:
Our goal is to train a neural planner that can capture the diverse driving behaviors in complex urban scenarios. We observe that even state-of-the-art neural planners are struggling to perform common maneuvers such as lane-change, which is rather natural for human drivers. We propose to explore the multi-modalities in the planning problem and force the neural planner to explicitly consider different policies. This is achieved by generating the future trajectories conditioned on every possible reference line, which could simply be the centerline of the surrounding lanes. We find this simple strategy yet enables the planner to perform rich and complex behaviors. We train our model using real-world driving data and demonstrate the effectiveness of our method through both open-loop and closed-loop evaluations. Project website https://jchengai.github.io/mpnp.
# Contextual Tuning of Model Predictive Control for Autonomous Racing
## Keywords:
- Autonomous Vehicle Navigation
- Optimization and Optimal Control
## Abstract:
Learning-based model predictive control has been widely applied in autonomous racing to improve the closed-loop behaviour of vehicles in a data-driven manner. When environmental conditions change, e.g., due to rain, often only the predictive model is adapted, but the controller parameters are kept constant. However, this can lead to suboptimal behaviour. In this paper, we address the problem of data-efficient controller tuning, adapting both the model and objective simultaneously. The key novelty of the proposed approach is that we leverage a learned dynamics model to encode the environmental condition as a so-called context. This insight allows us to employ contextual Bayesian optimization to efficiently transfer knowledge across different environmental conditions. Consequently, we require fewer laps to find the optimal controller configuration for each context. The proposed framework is extensively evaluated with more than 3'000 laps driven on an experimental platform with 1:28 scale RC race cars. Our approach successfully optimizes the lap time across different contexts requiring fewer laps compared to other approaches based on standard Bayesian optimization.
# Temporal Logic Path Planning under Localization Uncertainty
## Keywords:
- Autonomous Vehicle Navigation
- Formal Methods in Robotics and Automation
- Motion and Path Planning
## Abstract:
We present a method to find the optimal control strategy for a robot using prior information of localization that maximizes the probability of satisfaction of a temporal logic specification while considering the uncertainty in both motion and sensing, two major causes for localization uncertainty. The specifications are given in the probabilistic computation tree logic (PCTL) formula over a set of propositions, which capture the presence of the robot in some key locations in the environment. A computation model that can deal with the uncertainty in both motion and sensing is the Partially Observable Markov Decision Process (POMDP), which is computationally expensive. We approximate the underlying POMDP using Augmented Markov Decision Process (AMDP) and present a control synthesis algorithm for AMDP. We carry out numerous experiments on workspaces with sizes up to 100times 100 and four different PCTL specifications to evaluate the efficacy of our technique. Experimental results show that our technique for computing robot control policy using localization prior can deal with localization uncertainty effectively and scale to large environments.
# Navigating to Objects in Unseen Environments by Distance Prediction
## Keywords:
- Vision-Based Navigation
- AI-Enabled Robotics
- AI-Based Methods
## Abstract:
Object Goal Navigation (ObjectNav) task is to navigate an agent to an object category in unseen environments without a pre-built map. In this paper, we solve this task by predicting the distance to the target using semantically-related objects as cues. Based on the estimated distance to the target object, our method directly choose optimal mid-term goals that are more likely to have a shorter path to the target. Specifically, based on the learned knowledge, our model takes a bird's-eye view semantic map as input, and estimates the path length from the frontier map cells to the target object. With the estimated distance map, the agent could simultaneously explore the environment and navigate to the target objects based on a simple human-designed strategy. Empirical results in visually realistic simulation environments show that the proposed method outperforms a wide range of baselines on success rate and efficiency. Real-robot experiment also demonstrates that our method generalizes well to the real world.
# Depth-CUPRL: Depth-Imaged Contrastive Unsupervised Prioritized Representations in Reinforcement Learning for Mapless Navigation of Unmanned Aerial Vehicles
## Keywords:
- Autonomous Vehicle Navigation
- Reinforcement Learning
- Autonomous Agents
## Abstract:
Reinforcement Learning (RL) has presented an impressive performance in video games through raw pixel imaging and continuous control tasks. However, RL performs poorly with high-dimensional observations such as raw pixel images. It is generally accepted that physical state-based RL policies such as laser sensor measurements give a more sample-efficient result than learning by pixels. This work presents a new approach that extracts information from a depth map estimation to teach an RL agent to perform the mapless navigation of Unmanned Aerial Vehicle (UAV). We propose the Depth-Imaged Contrastive Unsupervised Prioritized Representations in Reinforcement Learning (Depth-CUPRL) that estimates the depth of images with a prioritized replay memory. We used a combination of RL and Contrastive Learning to lead with the problem of RL based on images. From the analysis of the results with Unmanned Aerial Vehicles (UAVs), it is possible to conclude that our Depth-CUPRL approach is effective for the decision-making and outperforms state-of-the-art pixel-based approaches in the mapless navigation capability.
# DSOL: A Fast Direct Sparse Odometry Scheme
## Keywords:
- Vision-Based Navigation
## Abstract:
In this paper, we describe Direct Sparse Odometry Lite (DSOL), an improved version of Direct Sparse Odometry (DSO). We propose several algorithmic and implementation enhancements which speed up computation by a significant factor (on average 5x) even on resource-constrained platforms. The increase in speed allows us to process images at higher frame rates, which in turn provides better results on rapid motions. Our open-source implementation is available at https://github.com/versatran01/dsol.
# Planning for Negotiations in Autonomous Driving Using Reinforcement Learning
## Keywords:
- Autonomous Vehicle Navigation
- Autonomous Agents
- Reinforcement Learning
## Abstract:
Planning autonomous driving behaviors in dense traffic is challenging. Human drivers are able to influence their road environment to achieve (otherwise unachievable) goals, by communicating their intents to other drivers. An autonomous system that is required to drive in the presence of human traffic must thus possess this fundamental negotiation capability. This work presents a novel benchmark that includes a stochastic driver negotiation model and a framework for training policies to drive and negotiate based on reinforcement learning. It is shown that driving policies trained in this framework lead to greater safety, higher mission accomplishment rates and more driving comfort, and can generalize across scenarios.
# Towards Specialized Hardware for Learning-Based Visual Odometry on the Edge
## Keywords:
- Computer Architecture for Robotic and Automation
- Deep Learning for Visual Perception
- Hardware-Software Integration in Robotics
## Abstract:
Learning-based visual odometry (VO) has gained increasing popularity in autonomous navigation of small robots. However, most methods in the category require computation resources not normally available on edge systems. We contend that specialized hardware accelerators are ideal solutions to this problem because of their superior energy efficiency. In this paper, we first propose a model to derive compute specifications for VO from physical characteristics of unmanned aerial vehicles (UAVs). These specifications serve as the basis to guide our accelerator design process. Based on the specifications derived from the DJI Mavic Air 2 and Crazyflie 2.0 UAVs, we explore the speed/flight-time design spaces for three target VO algorithms on two NVIDIA Jetson systems. Then, we propose a hardware accelerator architecture and present prototype implementations based on FPGAs. Additionally, we illustrate the algorithm/hardware co-design approach with a series of hardware-aware algorithmic redesigns targeting the FPGA prototypes, and quantify the throughput-accuracy tradeoff of them. Our FPGA implementation of DFVO is 2.7x more energy efficient compared to off-the-shelf embedded computers.
# Deep Learning for Visual Perception 1
# MPT-Net: Mask Point Transformer Network for Large Scale Point Cloud Semantic Segmentation
## Keywords:
- Deep Learning for Visual Perception
- Computer Vision for Transportation
- Object Detection, Segmentation and Categorization
## Abstract:
Point cloud semantic segmentation is important for road scene perception, a task for driverless vehicles to achieve full fledged autonomy. In this work, we introduce Mask Point Transformer Network (MPT-Net), a novel architecture for point cloud segmentation that is simple to implement. MPT-Net consists of a local and global feature encoder and a transformer based decoder; a 3D Point-Voxel Convolution encoder backbone with voxel self attention to encode features and a Mask Point Transformer module to decode point features and segment the point cloud. Firstly, we introduce the novel MPT designed to specifically handle point cloud segmentation. MPT offers two benefits. It attends to every point in the point cloud using mask tokens to extract class specific features globally with cross attention, and provide inter-class feature information exchange using self attention on the learned mask tokens. Secondly, we design a backbone to use sparse point voxel convolutional blocks and a self attention block using transformers to learn local and global contextual features. We evaluate MPT-Net on large scale outdoor driving scene point cloud datasets, SemanticKITTI and nuScenes. Our experiments show that by replacing the standard segmentation head with MPT, MPT-Net achieves a state-of-the-art performance over our baseline approach by 3.8% in SemanticKITTI and is highly effective in detecting ’stuffs’ in point cloud.
# Timestamp-Supervised Action Segmentation with Graph Convolutional Networks
## Keywords:
- Deep Learning for Visual Perception
- Human Detection and Tracking
- Human-Robot Collaboration
## Abstract:
We introduce a novel approach for temporal activity segmentation with timestamp supervision. Our main contribution is a graph convolutional network, which is learned in an end-to-end manner to exploit both frame features and connections between neighboring frames to generate dense framewise labels from sparse timestamp labels. The generated dense framewise labels can then be used to train the segmentation model. In addition, we propose a framework for alternating learning of both the segmentation model and the graph convolutional model, which first initializes and then iteratively refines the learned models. Detailed experiments on four public datasets, including 50 Salads, GTEA, Breakfast, and Desktop Assembly, show that our method is superior to the multi-layer perceptron baseline, while performing on par with or better than the state of the art in temporal activity segmentation with timestamp supervision.
# CA-SpaceNet: Counterfactual Analysis for 6D Pose Estimation in Space
## Keywords:
- Deep Learning for Visual Perception
- Aerial Systems: Perception and Autonomy
- Computer Vision for Automation
## Abstract:
Reliable and stable 6D pose estimation of uncooperative space objects plays an essential role in on-orbit servicing and debris removal missions. Considering that the pose estimator is sensitive to background interference, this paper proposes a counterfactual analysis framework named CASpaceNet to complete robust 6D pose estimation of the spaceborne targets under complicated background. Specifically, conventional methods are adopted to extract the features of the whole image in the factual case. In the counterfactual case, a non-existent image without the target but only the background is imagined. Side effect caused by background interference is reduced by counterfactual analysis, which leads to unbiased prediction in final results. In addition, we also carry out lowbit-width quantization for CA-SpaceNet and deploy part of the framework to a Processing-In-Memory (PIM) accelerator on FPGA. Qualitative and quantitative results demonstrate the effectiveness and efficiency of our proposed method. To our best knowledge, this paper applies causal inference and network quantization to the 6D pose estimation of space-borne targets for the first time. The code is available at https://github.com/Shunli-Wang/CA-SpaceNet.
# 3D Object Aided Self-Supervised Monocular Depth Estimation
## Keywords:
- Deep Learning for Visual Perception
- Object Detection, Segmentation and Categorization
- Semantic Scene Understanding
## Abstract:
Monocular depth estimation has been actively studied in fields such as robot vision, autonomous driving, and 3D scene understanding. Given a sequence of color images, unsupervised learning methods based on the framework of Structure-From-Motion (SfM) simultaneously predict depth and camera relative pose. However, dynamically moving objects in the scene violate the static world assumption, resulting in inaccurate depths of dynamic objects. In this work, we propose a new method to address such dynamic object movements through monocular 3D object detection. Specifically, we first detect 3D objects in the images and build the per-pixel correspondence of the dynamic pixels with the detected object pose while leaving the static pixels corresponding to the rigid background to be modeled with camera motion. In this way, the depth of every pixel can be learned via a meaningful geometry model. Besides, objects are detected as cuboids with absolute scale, which is used to eliminate the scale ambiguity problem inherent in monocular vision. Experiments on the KITTI depth dataset show that our method achieves State-of-The-Art performance for depth estimation. Furthermore, joint training of depth, camera motion and object pose also improves monocular 3D object detection performance. To the best of our knowledge, this is the first work that allows a monocular 3D object detection network to be fine-tuned in a self-supervised manner.
# DeepMLE: A Robust Deep Maximum Likelihood Estimator for Two-View Structure from Motion
## Keywords:
- Deep Learning for Visual Perception
- Audio-Visual SLAM
- SLAM
## Abstract:
Two-view structure from motion (SfM) is the cornerstone of 3D reconstruction and visual SLAM (vSLAM). Many existing end-to-end learning-based methods usually formulate it as a brute regression problem. However, the inadequate utilization of traditional geometry model makes the model not robust in unseen environments. To improve the generalization capability and robustness of end-to-end two-view SfM network, we formulate the two-view SfM problem as a maximum likelihood estimation (MLE) and solve it with the proposed framework, denoted as DeepMLE. First, we propose to take the deep multi-scale correlation maps to depict the visual similarities of 2D image matches decided by ego-motion. In addition, in order to increase the robustness of our framework, we formulate the likelihood function of the correlations of 2D image matches as a Gaussian and Uniform mixture distribution which takes the uncertainty caused by illumination changes, image noise and moving objects into account. Meanwhile, an uncertainty prediction module is presented to predict the pixel-wise distribution parameters. Finally, we iteratively refine the depth and relative camera pose using the gradient-like information to maximize the likelihood function of the correlations. Extensive experimental results on several datasets prove that our method significantly outperforms the state-of-the-art end-to-end two-view SfM approaches in accuracy and generalization capability.
# Attention-Guided RGB-D Fusion Network for Category-Level 6D Object Pose Estimation
## Keywords:
- Deep Learning for Visual Perception
- RGB-D Perception
## Abstract:
This work focuses on estimating 6D poses and sizes of category-level objects from a single RGB-D image. How to exploit the complementary RGB and depth features plays an important role in this task yet remains an open question. Due to the large intra-category texture and shape variations, an object instance in test may have different RGB and depth features from those of the object instances in training, which poses challenges to previous RGB-D fusion methods. To deal with such problem, an Attention-guided RGB-D Fusion Network (ARF-Net) is proposed in this work. Our key design is an ARF module that learns to adaptively fuse RGB and depth features with guidance from both structure-aware attention and relation-aware attention. Specifically, the structure-aware attention captures spatial relationship among object parts and the relation-aware attention captures the RGB-to-depth correlations between the appearance and geometric features. Our ARF-Net directly establishes canonical correspondences with a compact decoder based on the multi-modal features from our ARF module. Extensive experiments show that our method can effectively fuse RGB features to various popular point cloud encoders and provide consistent performance improvement. In particular, without reconstructing instance 3D models, our method with its relatively compact architecture outperforms all state-of-the-art models on CAMERA25 and REAL275 benchmarks by a large margin.
# Robust Sim2Real 3D Object Classification Using Graph Representations and a Deep Center Voting Scheme
## Keywords:
- Deep Learning for Visual Perception
- Recognition
- Visual Learning
## Abstract:
While object semantic understanding is essential for service robotic tasks, 3D object classification is still an open problem. Learning from artificial 3D models alleviates the cost of the annotation necessary to approach this problem, but today's methods still struggle with the differences between artificial and real 3D data. We conjecture that one of the causes of this issue is the fact that today's methods learn directly from point coordinates, which makes them highly sensitive to scale changes. We propose to learn from a graph of reproducible object parts whose scale is more reliable. In combination with a voting scheme, our approach achieves significantly more robust classification and improves upon state-of-the-art by up to 16% when transferring from artificial to real objects.
# Weak6D: Weakly Supervised 6D Pose Estimation with Iterative Annotation Resolver
## Keywords:
- Deep Learning for Visual Perception
- Deep Learning Methods
- RGB-D Perception
## Abstract:
6D object pose estimation is an essential task in vision-based robotic grasping and manipulation. Prior works always train models with a large number of pose annotated images, limiting the efficiency of model transfer between different scenarios. This paper presents an end-to-end model named Weak6D, which could be learned with unannotated RGB-D data. The core of the proposed approach is the novel optimizing method Iterative Annotation Resolver, which has the ability to directly utilize the captured RGB-D data through the training process. Furthermore, we employ a weak refinement loss to optimize the pose estimation network with refined object poses. We evaluated the proposed Weak6D in the YCB-Video dataset, and experimental results show our model achieved practical results without annotated data. Our code is available at https://github.com/mufengjun260/Weak6D.
# Robust Human Motion Forecasting Using Transformer-Based Model
## Keywords:
- Deep Learning for Visual Perception
- Human and Humanoid Motion Analysis and Synthesis
- Human-Robot Collaboration
## Abstract:
Comprehending human motion is a fundamental challenge for developing Human-Robot Collaborative applications. Computer vision researchers have addressed this field by only focusing on reducing error in predictions, but not taking into account the requirements needed to facilitate its implementation in robots. In this paper, we propose a new model based on Transformer that simultaneously deals with the real time 3D human motion forecasting in the short and long term. Our 2-Channel Transformer (2CH-TR) is able to efficiently exploit the spatio-temporal information of a shortly observed sequence (400ms) and generates a competitive accuracy against the current state-of-the-art. 2CH-TR stands out for the efficient performance of the Transformer, being lighter and faster than its competitors. In addition, our model is tested in conditions where the human motion is severely occluded, demonstrating its robustness in reconstructing and predicting 3D human motion in a highly noisy environment. Our experiment results show that the proposed 2CH-TR outperforms the ST-Transformer, which is another state-of-the-art model based on the Transformer, in terms of reconstruction and prediction under the same conditions of input prefix. Our model reduces in 8.89% the mean squared error of ST-Transformer in short-term prediction, and 2.57% in long-term prediction in Human3.6M dataset with 400ms input prefix.
# Human-Robot Collaborative Carrying of Objects with Unknown Deformation Characteristics
## Keywords:
- Human-Robot Collaboration
- Physical Human-Robot Interaction
- Human-Centered Automation
## Abstract:
In this work, we introduce an adaptive control framework for human-robot collaborative transportation of objects with unknown deformation behaviour. The proposed framework takes as input the haptic information transmitted through the object, and the kinematic information of the human body obtained from a motion capture system to create reactive whole-body motions on a mobile collaborative robot. In order to validate our framework experimentally, we compared its performance with an admittance controller during a co-transportation task of a partially deformable object. We additionally demonstrate the potential of the framework while co-transporting rigid (aluminum rod) and highly deformable (rope) objects. A mobile manipulator which consists of an Omni-directional mobile base, a collaborative robotic arm, and a robotic hand is used as the robotic partner in the experiments. Quantitative and qualitative results of a 12-subjects experiment show that the proposed framework can effectively deal with objects of unknown deformability and provides intuitive assistance to human partners.
# A Framework for Robot Self-Assessment of Expected Task Performance
## Keywords:
- Human-Robot Teaming
- Methods and Tools for Robot System Design
- Simulation and Animation
## Abstract:
We propose a self-assessment framework which enables a robot to estimate how well it will be able to perform a known or possibly novel task. The robot simulates the task to generate a state distribution of possible outcomes and determines (1) the likelihood of overall success, (2) the most probable failure location, and (3) the expected time to task completion. We evaluate the framework on the ``FetchIt!'' mobile manipulation challenge which requires the robot to fetch a variety of parts around a small enclosed arena. By comparing the simulated and actual task resulting state distributions, we show that the robot can effectively assesses its expected performance which can be communicated to humans.
# An Empirical Study of Reward Explanations with Human-Robot Interaction Applications
## Keywords:
- Human Factors and Human-in-the-Loop
- Human-Centered Automation
- Human-Robot Collaboration
## Abstract:
Explainable AI techniques that describe agent reward functions can enhance human-robot collaboration in a variety of settings. However, in order to effectively explain reward information to humans, it is important to understand the efficacy of different types of explanation techniques in scenarios of varying complexity. In this paper, we compare the performance of a broad range of explanation techniques in scenarios of differing reward function complexity through a set of human-subject experiments. To perform this analysis, we first introduce a categorization of reward explanation information types and then apply a suite of assessments to measure human reward understanding. Our findings indicate that increased reward complexity (in number of features) corresponded to higher workload and decreased reward understanding, while providing direct reward information was an effective approach across reward complexities. We also observed that providing full or near full reward information was associated with increased workload and that providing abstractions of the reward was more effective at supporting reward understanding than other approaches (besides direct information) and was associated with decreased workload and improved subjective assessment in high complexity settings.
# The Predictive Kinematic Control Tree: Enhancing Teleoperation of Redundant Robots through Probabilistic User Models
## Keywords:
- Telerobotics and Teleoperation
- Motion Control
- Redundant Robots
## Abstract:
When teleoperating complex robotic manipulators, operators often find it most natural to issue commands that dictate end effector movements in task space. If the robot has redundant degrees of freedom, the translation of this command from task space into configuration space can affect the robot’s maneuverability, smoothness of motion, and the general precision of the teleoperated system. In this paper, we propose a novel method for performing this translation that predicts future operator commands in order to choose joint motions that maintain maneuverability in future timesteps. We introduce a Predictive Kinematic Control Tree (PrediKCT) that optimizes joint movement in the nullspace of the Jacobian over multiple future timesteps by reasoning over probabilistic models of the human operator. In essence, PrediKCT builds out and evaluates a tree of possible future commands. We implement this system on two simulated and one physical 7-degree-of-freedom robotic arms and characterize performance by analyzing robot motions produced through multiple command trajectories with differing user model accuracies and tree parameters, demonstrating benefits to path accuracy over both a minimum-norm joint velocity solution and local optimization of joint movement.
# Sociable and Ergonomic Human-Robot Collaboration through Action Recognition and Augmented Hierarchical Quadratic Programming
## Keywords:
- Human-Robot Collaboration
- Optimization and Optimal Control
- Behavior-Based Systems
## Abstract:
The recognition of actions performed by humans and the anticipation of their intentions are important enablers to yield sociable and successful collaboration in human-robot teams. Meanwhile, robots should have the capacity to deal with multiple objectives and constraints, arising from the collaborative task or the human. In this regard, we propose vision techniques to perform human action recognition and image classification, which are integrated into an Augmented Hierarchical Quadratic Programming (AHQP) scheme to hierarchically optimize the robot’s reactive behavior and human ergonomics. The proposed framework allows one to intuitively command the robot in space while a task is being executed. The experiments confirm increased human ergonomics and usability, which are fundamental parameters for reducing musculoskeletal diseases and increasing trust in automation.
# Learning on the Job: Long-Term Behavioural Adaptation in Human-Robot Interactions
(Finalist for IROS Best Paper Award on Cognitive Robotics Sponsored by KROS)
## Keywords:
- Social HRI
- Reinforcement Learning
- Art and Entertainment Robotics
# Bounded Rational Game-Theoretical Modeling of Human Joint Actions with Incomplete Information
## Keywords:
- Human-Robot Collaboration
- Human-Robot Teaming
- Physical Human-Robot Interaction
## Abstract:
As humans and robots start to collaborate in close proximity, robots are tasked to perceive, comprehend, and anticipate human partners' actions, which demands a predictive model to describe how humans collaborate with each other in joint actions. Previous studies either simplify the collaborative task as an optimal control between two agents or do not consider the learning process of humans during repeated interaction. This idyllic representation is thus not able to model human rationality and the learning process. In this paper, a bounded-rational and game-theoretical human cooperative model is developed to describe the cooperative behaviors of the human dyad. An experiment of a joint object pushing collaborative task was conducted with 30 human subjects using haptic interfaces in a virtual environment. The proposed model uses inverse optimal control (IOC) to model the reward parameters in the collaborative task. The collected data verified the accuracy of the predicted human trajectory generated from the bounded rational model excels the one with a fully rational model. We further provide insight from the conducted experiments about the effects of leadership on the performance of human collaboration.
# COSM2IC: Optimizing Real-Time Multi-Modal Instruction Comprehension
## Keywords:
- Human-Robot Collaboration
- Virtual Reality and Interfaces
- Multi-Modal Perception for HRI
## Abstract:
Supporting real-time, on-device execution of multi# modal referring instruction comprehension models is an important challenge to be tackled in embodied Human-Robot Interaction. However, state-of-the-art deep learning models are resource intensive and unsuitable for real-time execution on embedded devices. While model compression can achieve reduction in computational resources upto a certain point, further optimizations result in a severe drop in accuracy (upto 50%). To minimize this loss in accuracy, we propose the COSM2IC framework, with a lightweight Task Complexity Predictor, that uses multiple sensor inputs to assess the instructional complexity and thereby dynamically switch between a set of models of varying computational intensity such that computationally less demanding models are invoked whenever possible. To demonstrate the benefits of COSM2IC, we utilize a representative human-robot collaborative “table-top target acquisition” task, to curate a new multi-modal instruction dataset where a human issues instructions in a natural manner using a combination of visual, verbal and gestural (pointing) cues. We show that COSM2IC achieves a 3-fold reduction in comprehension latency when compared to a baseline DNN model while suffering an accuracy loss of only ~5%. When compared to state-of-the-art model compression methods COSM2IC is able to achieve a further 30% reduction in latency and energy consumption for a comparable performance.
# Quantifying Changes in Kinematic Behavior of a Human-Exoskeleton Interactive System
## Keywords:
- Human-Robot Collaboration
- Prosthetics and Exoskeletons
- Human-Centered Robotics
## Abstract:
While human-robot interaction studies are becoming more common, quantification of the effects of repeated interaction with an exoskeleton remains unexplored. We draw upon existing literature in human skill assessment and present extrinsic and intrinsic performance metrics that quantify how the human-exoskeleton system's behavior changes over time. Specifically, in this paper, we present a new performance metric that provides insight into the system's kinematics associated with `successful' movements resulting in a richer characterization of changes in the system's behavior. A human subject study is carried out wherein participants learn to play a challenging and dynamic reaching game over multiple attempts, while donning an upper-body exoskeleton. The results demonstrate that repeated practice results in learning over time as identified through the improvement of extrinsic performance. Changes in the newly developed kinematics-based measure further illuminate how the participant's intrinsic behavior is altered over the training period. Thus, we are able to quantify the changes in the human-exoskeleton system's behavior observed in relation with learning.
# Learning from Demonstration 3
# Socially CompliAnt Navigation Dataset (SCAND): A Large-Scale Dataset of Demonstrations for Social Navigation
## Keywords:
- Data Sets for Robot Learning
- Learning from Demonstration
- Imitation Learning
## Abstract:
Social navigation is the capability of an autonomous agent, such as a robot, to navigate in a socially compliant manner in the presence of other intelligent agents such as humans. With the emergence of autonomously navigating mobile robots in human-populated environments (e.g., domestic service robots in homes and restaurants and food delivery robots on public sidewalks), incorporating socially compliant navigation behaviors on these robots becomes critical to ensuring safe and comfortable human-robot coexistence. To address this challenge, imitation learning is a promising framework, since it is easier for humans to demonstrate the task of social navigation rather than to formulate reward functions that accurately capture the complex multi-objective setting of social navigation. The use of imitation learning and inverse reinforcement learning to social navigation for mobile robots, however, is currently hindered by a lack of large-scale datasets that capture socially compliant robot navigation demonstrations in the wild. To fill this gap, we introduce Socially CompliAnt Navigation Dataset ( SCAND ) a large-scale, first-person-view dataset of socially compliant navigation demonstrations. Our dataset contains 8.7 hours, 138 trajectories, 25 miles of socially compliant, human tele-operated driving demonstrations that comprises multi-modal data streams including 3D lidar, joystick commands, odometry, visual and inertial information, collected on two morphologically different mobile robots --# a Boston Dynamics Spot and a Clearpath Jackal by four different human demonstrators in both indoor and outdoor environments. We additionally perform preliminary analysis and validation through real-world robot experiments and show that navigation policies learned by imitation learning on SCAND generate socially compliant behaviors.
# Learning Deformable Object Manipulation from Expert Demonstrations
## Keywords:
- Deep Learning in Grasping and Manipulation
- Learning from Demonstration
- Reinforcement Learning
## Abstract:
We present a novel Learning from Demonstration (LfD) method, Deformable Manipulation from Demonstrations (DMfD), to solve deformable manipulation tasks using states or images as inputs, given expert demonstrations. Our method uses demonstrations in three different ways, and balances the trade-off between exploring the environment online and using guidance from experts to explore high dimensional spaces effectively. We test DMfD on a set of representative manipulation tasks for a 1-dimensional rope and a 2-dimensional cloth from the SoftGym suite of tasks, each with state and image observations. Our method exceeds baseline performance by up to 12.9% for state-based tasks and up to 33.44% on image-based tasks, with comparable or better robustness to randomness. Additionally, we create two challenging environments for folding a 2D cloth using image-based observations, and set a performance benchmark for them. We deploy DMfD on a real robot with a minimal loss in normalized performance during real-world execution compared to simulation (~6%). Source code is on github.com/uscresl/dmfd
# Transporters with Visual Foresight for Solving Unseen Rearrangement Tasks
## Keywords:
- Deep Learning in Grasping and Manipulation
- Learning from Demonstration
- Task and Motion Planning
## Abstract:
Rearrangement tasks have been identified as a crucial challenge for intelligent robotic manipulation, but few methods allow for precise construction of unseen structures. We propose a visual foresight model for pick-and-place rearrangement manipulation which is able to learn efficiently. In addition, we develop a multi-modal action proposal module which builds on the Goal-Conditioned Transporter Network, a state-of-the-art imitation learning method. Our image-based task planning method, Transporters with Visual Foresight, is able to learn from only a handful of data and generalize to multiple unseen tasks in a zero-shot manner. TVF is able to improve the performance of a state-of-the-art imitation learning method on unseen tasks in simulation and real robot experiments. In particular, the average success rate on unseen tasks improves from 55.4% to 78.5% in simulation experiments and from 30% to 63.3% in real robot experiments when given only tens of expert demonstrations. Video and code are available on our project website: https://chirikjianlab.github.io/tvf/
# Learning Perceptual Concepts by Bootstrapping from Human Queries
## Keywords:
- Learning Categories and Concepts
- Learning from Demonstration
- Visual Learning
## Abstract:
When robots operate in human environments, it's critical that humans can quickly teach them new concepts: object-centric properties of the environment that they care about (e.g. objects near, upright, etc). However, teaching a new perceptual concept from high-dimensional robot sensor data (e.g. point clouds) is demanding, requiring an unrealistic amount of human labels. To address this, we propose a framework called Perceptual Concept Bootstrapping (PCB). First, we leverage the inherently lower-dimensional privileged information, e.g., object poses and bounding boxes, available from a simulator only at training time to rapidly learn a low-dimensional, geometric concept from minimal human input. Second, we treat this low-dimensional concept as an automatic labeler to synthesize a large-scale high-dimensional data set with the simulator. With these two key ideas, PCB alleviates human label burden while still learning perceptual concepts that work with real sensor input where no privileged information is available. We evaluate PCB for learning spatial concepts that describe object state or multi-object relationships, and show it achieves superior performance compared to baseline methods. We also demonstrate the utility of the learned concepts in motion planning tasks on a 7-DoF Franka Panda robot.
# Extending Extrapolation Capabilities of Probabilistic Motion Models Learned from Human Demonstrations Using Shape-Preserving Virtual Demonstrations
## Keywords:
- Learning from Demonstration
- Imitation Learning
- Motion and Path Planning
## Abstract:
Learning from Demonstration (LfD) requires methodologies able to generalize tasks in new situations. This paper studies the use of virtual demonstrations to extend the extrapolation capabilities of probabilistic motion models such as the traPPCA method. Similarly to other LfD methods, traPPCA is able to calculate new trajectories very fast, but does not generalize well outside the area covered by the demonstrations. Another approach, the invariants method, shows outstanding generalization capabilities thanks to its shape-preserving properties, while being limited by long computation times. The proposed methodology combines the advantages of the two methods by learning traPPCA models using virtual demonstrations generated by the invariants method. The proposed approach is analyzed in three case studies. Furthermore, a comparison is made between learning with virtual demonstrations and learning with only real demonstrations. The results encourage the use of virtual demonstrations to extend the extrapolation capabilities of probabilistic motion models and hence reduce the required number of real demonstrations. The latter has the potential of reducing the cost of commissioning robot tasks.
# Learning High Speed Precision Table Tennis on a Physical Robot
## Keywords:
- Machine Learning for Robot Control
- Learning from Demonstration
## Abstract:
Learning goal conditioned control in the real world is a challenging open problem in robotics. Reinforcement learning systems have the potential to learn autonomously via trial-and-error, but in practice the costs of manual reward design, ensuring safe exploration, and hyperparameter tuning are often enough to preclude real world deployment. Imitation learning approaches, on the other hand, offer a simple way to learn control in the real world, but typically require costly curated demonstration data and lack a mechanism for continuous improvement. Recently, iterative imitation methods have been shown to be effective at relaxing both these constraints, learning goal directed control from undirected demonstration data, and improving continuously via self-supervised goal reaching. These approaches, however, have not yet been shown to scale beyond simple simulated environments. In this work, we present the first evidence that simple iterative imitation learning can scale to goal-directed behavior on a real robot in a dynamic setting: high speed, precision table tennis (e.g. ``land the ball on this particular target"). We find that this approach offers a straightforward way to do continuous on-robot learning, without complexities such as reward design, value function learning, or sim-to-real transfer. We also find that this approach is scalable --# sample efficient enough to train on a physical robot in just a few hours. In real world evaluations, we find that that the resulting policy can perform on par or better than amateur humans (with players sampled randomly from a robotics lab) at the task of returning the ball to specific targets on the table. Finally, we analyze the effect of an initial undirected bootstrap dataset size on performance, finding that a modest amount of unstructured demonstration data provided up-front drastically speeds up the convergence of a general purpose goal-reaching policy. See supplementary video for examples of the policy on a physical robot.
# Behaviour Learning with Adaptive Motif Discovery and Interacting Multiple Model
## Keywords:
- Learning from Demonstration
- Behavior-Based Systems
- Vision-Based Navigation
## Abstract:
We propose an approach that enables simultaneous interpretable learning of a high-level discrete behaviour and its low-level rhythmic sub-behaviour. We do this though a unified reward function, where a reward function that only describes low-level behaviour, with less impact on learning of other behaviors is recovered from few-shot motion demonstrations. To this end, we first extract local behaviour motifs from state-only human demonstrations and random driving samples using an adaptive motif discovery approach derived from the Matrix Profile algorithm. We then optimize parameters for motif discovery by maximizing the sum and entropy over motif sizes. Interacting Multiple Model (IMM) estimators are constructed on top of linear-Gaussian dynamics of discovered motifs, the cumulative distributions over motifs estimated by IMMs serve as the basis of the reward function. 
By combining the recovered reward with terrain type signal gathered from the environment, we are able to train a dual-objective off-road vehicle controller that demonstrates both terrain selection and human-like driving behaviours. Compared with related approaches across 10 people, our rhythmic behaviour reward recovery approach enables the controller to produce higher preference over human driving demonstrations. As well as performing more stable across different people with 87% less variance than the best baseline in rhythmic behaviour indicator, reducing negative effects on higher-level behaviour learning, while maintaining high interpretability at all stages of the algorithm.
# Learning from Demonstration Using a Curvature Regularized Variational Auto-Encoder (CurvVAE)
## Keywords:
- Learning from Demonstration
- Representation Learning
- Physically Assistive Devices
## Abstract:
Learning intricate manipulation skills from human demonstrations requires good sample efficiency. We introduce a novel learning algorithm, the Curvature-regularized Variational Auto-Encoder (CurvVAE), to achieve this goal. The CurvVAE is able to model the natural variations in human-demonstrated trajectory data without overfitting. It does so by regularizing the curvature of the learned manifold. To showcase our algorithm, our robot learns an interpretable model of the variation in how humans acquire soft, slippery banana slices with a fork. We evaluate our learned trajectories on a physical robot system, resulting in banana slice acquisition performance better than current state-of-the-art.
# Constrained Probabilistic Movement Primitives for Robot Trajectory Adaptation (I)
## Keywords:
- Learning from Demonstration
- Probability and Statistical Methods
- Collision Avoidance
## Abstract:
Placing robots outside controlled conditions requires versatile movement representations that allow robots to learn new tasks and adapt them to environmental changes. The introduction of obstacles or the placement of additional robots in the workspace, the modification of the joint range due to faults or range-of-motion constraints are typical cases where the adaptation capabilities play a key role for safely performing the robot's task. Probabilistic movement primitives (ProMPs) have been proposed for representing adaptable movement skills, which are modelled as Gaussian distributions over trajectories. These are analytically tractable and can be learned from a small number of demonstrations. However, both the original ProMP formulation and the subsequent approaches only provide solutions to specific movement adaptation problems, e.g., obstacle avoidance, and a generic, unifying, probabilistic approach to adaptation is missing. In this paper we develop a generic probabilistic framework for adapting ProMPs. We unify previous adaptation techniques, for example, various types of obstacle avoidance, via-points, mutual avoidance, in one single framework and combine them to solve complex robotic problems. Additionally, we derive novel adaptation techniques such as temporally unbound via-points and mutual avoidance. We formulate adaptation as a constrained optimisation problem where we minimise the Kullback-Leibler divergence between the adapted distribution and the distribution of the original primitive while we constrain the probability mass associated with undesired trajectories to be low. We demonstrate our approach on several adaptation problems on simulated planar robot arms and 7-DOF Franka-Emika robots in a dual robot arm setting.
# Deep Learning for Visual Perception 2
# Bayesian Active Learning for Sim-To-Real Robotic Perception
## Keywords:
- Deep Learning for Visual Perception
- Rehabilitation Robotics
- Object Detection, Segmentation and Categorization
## Abstract:
While learning from synthetic training data has recently gained an increased attention, in real-world robotic applications, there are still performance deficiencies due to the so-called Sim-to-Real gap. Therefore, we focus on an efficient acquisition of real data within a Sim-to-Real learning pipeline. Concretely, we employ deep Bayesian active learning to minimize manual annotation efforts and devise an autonomous learning paradigm to select the data that is considered useful for the human expert to annotate. To achieve this, a Bayesian Neural Network (BNN) object detector providing reliable uncertainty estimates is adapted to infer the informativeness of the unlabeled data. Furthermore, to cope with misalignments of the label distribution in uncertainty-based sampling, we develop an effective randomized sampling strategy that performs favorably compared to other complex alternatives. In our experiments on object classification and detection, we show benefits of our approach and provide evidence that labeling efforts can be reduced significantly. Finally, we demonstrate the practical effectiveness of this idea in a grasping task on an assistive robot.
# DiffCloud: Real-To-Sim from Point Clouds with Differentiable Simulation and Rendering of Deformable Objects
## Keywords:
- Deep Learning for Visual Perception
- Deep Learning in Grasping and Manipulation
- Simulation and Animation
## Abstract:
Research in manipulation of deformable objects is typically conducted on a limited range of scenarios, because handling each scenario on hardware takes significant effort. Realistic simulators with support for various types of deformations and interactions have the potential to speed up experimentation with novel tasks and algorithms. However, for highly deformable objects it is challenging to align the output of a simulator with the behavior of real objects. Manual tuning is not intuitive, hence automated methods are needed. We view this alignment problem as a joint perception-inference challenge and demonstrate how to use recent neural network architectures to successfully perform simulation parameter inference from real point clouds. We analyze the performance of various architectures, comparing their data and training requirements. Furthermore, we propose to leverage differentiable point cloud sampling and differentiable simulation to significantly reduce the time to achieve the alignment. We employ an efficient way to propagate gradients from point clouds to simulated meshes and further through to the physical simulation parameters, such as mass and stiffness. Experiments with highly deformable objects show that our method can achieve comparable or better alignment with real object behavior, while reducing the time needed to achieve this by more than an order of magnitude. Videos and supplementary material are available at https://tinyurl.com/diffcloud.
# Dynamics-Aware Spatiotemporal Occupancy Prediction in Urban Environments
## Keywords:
- Deep Learning for Visual Perception
- Computer Vision for Transportation
- Computer Vision for Automation
## Abstract:
Detection and segmentation of moving obstacles, along with prediction of the future occupancy states of the local environment, are essential for autonomous vehicles to proactively make safe and informed decisions. In this paper, we propose a framework that integrates the two capabilities together using deep neural network architectures. Our method first detects and segments moving objects in the scene, and uses this information to predict the spatiotemporal evolution of the environment around autonomous vehicles. To address the problem of direct integration of both static-dynamic object segmentation and environment prediction models, we propose using occupancy-based environment representations across the whole framework. Our method is validated on the real-world Waymo Open Dataset and demonstrates higher prediction accuracy than baseline methods.
# What's in the Black Box? the False Negative Mechanisms Inside Object Detectors
## Keywords:
- Deep Learning for Visual Perception
- Recognition
- Object Detection, Segmentation and Categorization
## Abstract:
In object detection, false negatives arise when a detector fails to detect a target object. To understand why object detectors produce false negatives, we identify five 'false negative mechanisms', where each mechanism describes how a specific component inside the detector architecture failed. Focusing on two-stage and one-stage anchor-box object detector architectures, we introduce a framework for quantifying these false negative mechanisms. Using this framework, we investigate why Faster R-CNN and RetinaNet fail to detect objects in benchmark vision datasets and robotics datasets. We show that a detector's false negative mechanisms differ significantly between computer vision benchmark datasets and robotics deployment scenarios. This has implications for the translation of object detectors developed for benchmark datasets to robotics applications.
# RVMOS: Range-View Moving Object Segmentation Leveraged by Semantic and Motion Features
## Keywords:
- Deep Learning for Visual Perception
- Object Detection, Segmentation and Categorization
- Semantic Scene Understanding
## Abstract:
Detecting traffic participants is an essential and age-old problem in autonomous driving. Recently, the recognition of moving objects has emerged as a major issue in this field for safe driving. In this paper, we present RVMOS, a LiDAR Range-View-based Moving Object Segmentation framework that segments moving objects given a sequence of range-view images. In contrast to the conventional method, our network incorporates both motion and semantic features, each of which encodes the motion of objects and the surrounding circumstance of the objects. In addition, we design a new feature extraction module suitably designed for range-view images. Lastly, we introduce simple yet effective data augmentation methods: time interval modulation and zero residual image synthesis. With these contributions, we achieve a 19% higher performance (mIoU) with 10% faster computational time (34 FPS on RTX 3090) than the state-of-the-art method with the SemanticKitti benchmark. Extensive experiments demonstrate the effectiveness of our network design and data augmentation scheme.
# Pseudo-Label Guided Cross-Video Pixel Contrast for Robotic SurgicalScene Segmentation with Limited Annotations
## Keywords:
- Deep Learning for Visual Perception
- Computer Vision for Medical Robotics
- Surgical Robotics: Laparoscopy
## Abstract:
Surgical scene segmentation is fundamentally crucial for prompting cognitive assistance in robotic surgery. However, pixel-wise annotating surgical video in a frame-by-frame manner is expensive and time consuming. To greatly reduce the labeling burden, in this work, we study semi-supervised scene segmentation from robotic surgical video, which is practically essential yet rarely explored before. We consider a clinically suitable annotation situation under the equidistant sampling. We then propose PGV-CL, a novel pseudo-label guided cross-video contrast learning method to boost scene segmentation. It effectively leverages unlabeled data for a trusty and global model regularization that produces more discriminative feature representation. Concretely, for trusty representation learning, we propose to incorporate pseudo labels to instruct the pair selection, obtaining more reliable representation pairs for pixel contrast. Moreover, we expand the representation learning space from previous image-level to cross-video, which can capture the global semantics to benefit the learning process. We extensively evaluate our method on a public robotic surgery dataset EndoVis18 and a public cataract dataset CaDIS. Experimental results demonstrate the effectiveness of our method, consistently outperforming the state-of-the-art semi-supervised methods under different labeling ratios, and even surpassing fully supervised training on EndoVis18 with 10.1% labeling. Our code will be publicly available.
# An Unsupervised Domain Adaptive Approach for Multimodal 2D Object Detection in Adverse Weather Conditions
## Keywords:
- Deep Learning for Visual Perception
- Transfer Learning
- Sensor Fusion
## Abstract:
Integrating different representations from complementary sensing modalities is crucial for robust scene interpretation in autonomous driving. While deep learning architectures that fuse vision and range data for 2D object detection have thrived in recent years, the corresponding modalities can degrade in adverse weather or lighting conditions, ultimately leading to a drop in performance. Although domain adaptation methods attempt to bridge the domain gap between source and target domains, they do not readily extend to heterogeneous data distributions. In this work, we propose an unsupervised domain adaptation framework, which adapts a 2D object detector for RGB and lidar sensors to one or more target domains featuring adverse weather conditions. Our proposed approach consists of three components. First, a data augmentation scheme that simulates weather distortions is devised to add domain confusion and prevent overfitting on the source data. Second, to promote cross-domain foreground object alignment, we leverage the complementary features of multiple modalities through a multi-scale entropy-weighted domain discriminator. Finally, we use carefully designed pretext tasks to learn a more robust representation of the target domain data. Experiments performed on the DENSE dataset show that our method can substantially alleviate the domain gap under the single-target domain adaptation (STDA) setting and the less explored yet more general multi-target domain adaptation (MTDA) setting.
# BIMS-PU: Bi-Directional and Multi-Scale Point Cloud Upsampling
## Keywords:
- Deep Learning for Visual Perception
## Abstract:
The learning and aggregation of multi-scale features are essential in empowering neural networks to capture the fine-grained geometric details in the point cloud upsampling task. Most existing approaches extract multi-scale features from a point cloud of a fixed resolution, hence obtain only a limited level of details. Though an existing approach aggregates a feature hierarchy of different resolutions from a cascade of upsampling sub-network, the training is complex with expensive computation. To address these issues, we construct a new point cloud upsampling pipeline called BIMS-PU that integrates the feature pyramid architecture with a bi-directional up and downsampling path. Specifically, we decompose the up/downsampling procedure into several up/downsampling sub-steps by breaking the target sampling factor into smaller factors. The multi-scale features are naturally produced in a parallel manner and aggregated using a fast feature fusion method. Supervision signal is simultaneously applied to all upsampled point clouds of different scales. Moreover, we formulate a residual block to ease the training of our model. Extensive quantitative and qualitative experiments on different datasets show that our method achieves superior results to state-of-the-art approaches. Last but not least, we demonstrate that point cloud upsampling can improve robot perception by ameliorating the 3D data quality.
# LiCaS3: A Simple LiDAR–Camera Self-Supervised Synchronization Method (I)
## Keywords:
- Deep Learning Methods
- Autonomous Vehicle Navigation
- Calibration and Identification
## Abstract:
Recent advances in robotics and deep learning demonstrate promising 3-D perception performances via fusing the light detection and ranging (LiDAR) sensor and camera data, where both spatial calibration and temporal synchronization are generally required. While the LiDAR–camera calibration problem has been actively studied during the past few years, LiDAR–camera synchronization has been less studied and mainly addressed by employing a conventional pipeline consisting of clock synchronization and temporal synchronization. The conventional pipeline has certain potential limitations, which have not been sufficiently addressed and could be a bottleneck for the potential wide adoption of low-cost LiDAR–camera platforms. Different from the conventional pipeline, in this article, we propose the LiCaS3, the first deep-learning-based framework, for the LiDAR–camera synchronization task via self-supervised learning. The proposed LiCaS3 does not require hardware synchronization or extra annotations and can be deployed both online and offline. Evaluated on both the KITTI and Newer College datasets, the proposed method shows promising performances. The code will be publicly available at https://github.com/KleinYuan/LiCaS3.
# Machine Learning for Robot Control 2
# Multiscale Sensor Fusion and Continuous Control with Neural CDEs
## Keywords:
- Machine Learning for Robot Control
- Sensor Fusion
- Perception-Action Coupling
## Abstract:
Though robot learning is often formulated in terms of discrete-time Markov decision processes (MDPs), physical robots require near-continuous multiscale feedback control. Machines operate on multiple asynchronous sensing modalities, each with different frequencies, e.g., video frames at 30Hz, proprioceptive state at 100Hz, force-torque data at 500Hz, etc. While the classic approach is to batch observations into fixed-time windows then pass them through feed-forward encoders (e.g., with deep networks), we show that there exists a more elegant approach -# one that treats policy learning as modeling latent state dynamics in continuous-time. Specifically, we present 'InFuser', a unified architecture that trains continuous time-policies with Neural Controlled Differential Equations (CDEs). InFuser evolves a single latent state representation over time by (In)tegrating and (Fus)ing multi-sensory observations (arriving at different frequencies), and inferring actions in continuous-time. This enables policies that can react to multi-frequency multi sensory feedback for truly end-to-end visuomotor control, without discrete-time assumptions. Behavior cloning experiments demonstrate that InFuser learns robust policies for dynamic tasks (e.g., swinging a ball into a cup) notably outperforming several baselines in settings where observations from one sensing modality can arrive at much sparser intervals than others.
# SMS-MPC: Adversarial Learning-Based Simultaneous Prediction Control with Single Model for Mobile Robots
## Keywords:
- Machine Learning for Robot Control
- Model Learning for Control
- Motion Control
## Abstract:
Model predictive control is a promising method in robot control tasks. How to design an effective model structure and efficient prediction framework for model predictive control is still an open challenge. To reduce the time consumption and avoid compounding-error of the multi-step prediction process in model predictive control, we propose a single-model simultaneous framework, which uses single dynamics model to predict the entire prediction horizon simultaneously by taking all control actions with the current state as inputs. Based on this framework, we further propose an adversarial dynamics model that contains two parts. The generator provides a dynamics model for the prediction process, while the discriminator provides constraints that are hard to describe by manually defined loss. This adversarial dynamics model can accelerate training and improve model accuracy in unstructured environments. Experiments conducted in Gazebo simulator and on a real mobile robot demonstrate the efficiency and accuracy of the single-model simultaneous framework with an adversarial dynamics model.
# Dynamic Inference on Graphs Using Structured Transition Models
## Keywords:
- Machine Learning for Robot Control
- Model Learning for Control
- Robust/Adaptive Control
## Abstract:
Enabling robots to perform complex dynamic tasks such as picking up an object in one sweeping motion or pushing off a wall to quickly turn a corner is a challenging problem. The dynamic interactions implicit in these tasks are critical towards the successful execution of such tasks. Graph neural networks (GNNs) provide a principled way of learning the dynamics of interactive systems but can suffer from scaling issues as the number of interactions increases. Furthermore, the problem of using learned GNN-based models for optimal control is insufficiently explored. In this work, we present a method for efficiently learning the dynamics of interacting systems by simultaneously learning a dynamic graph structure and a stable and locally linear forward model of the system. The dynamic graph structure encodes evolving contact modes along a trajectory by making probabilistic predictions over the edges of the graph. Additionally, we introduce a temporal dependence in the learned graph structure which allows us to incorporate contact measurement updates during execution thus enabling more accurate forward predictions. The learned stable and locally linear dynamics enable the use of optimal control algorithms such as iLQR for long-horizon planning and control for complex interactive tasks. Through experiments in simulation and in the real world, we evaluate the performance of our method by using the learned interaction dynamics for control and demonstrate generalization to more objects and interactions not seen during training. We introduce a control scheme that takes advantage of contact measurement updates and hence is robust to prediction inaccuracies during execution.
# Grasp Planning for Occluded Objects in a Confined Space with Lateral View Using Monte Carlo Tree Search
## Keywords:
- Deep Learning in Grasping and Manipulation
- Manipulation Planning
## Abstract:
In the lateral access environment, the robot behavior should be planned considering surrounding objects and obstacles because object observation directions and approach angles are limited. To safely retrieve a partially occluded target object in these environments, we have to relocate objects using prehensile actions to create a collision-free path for the target. We propose a learning-based method for object rearrangement planning applicable to objects of various types and sizes in the lateral environment. We plan the optimal rearrangement sequence by considering both collisions and approach angles at which objects can be grasped. The proposed method finds the grasping order through Monte Carlo tree search, significantly reducing the tree search cost using point cloud states. In the experiment, the proposed method shows the best and most stable performance in various scenarios compared to the existing TAMP methods. In addition, we confirm that the proposed method trained in simulation can be easily applied to a real robot without additional fine-tuning, showing the robustness of the proposed method.
# Non-Blocking Asynchronous Training for Reinforcement Learning in Real-World Environments
## Keywords:
- Machine Learning for Robot Control
- Reinforcement Learning
## Abstract:
 Deep Reinforcement Learning (DRL) faces challenges bridging the sim-to-real gap to enable real-world applications. In contrast to the simulated environments used in conventional DRL training, real-world systems are non-linear and evolve in an asynchronous fashion; sensors and actuators have limited precision; communication channels are noisy; and many components introduce variable delays. While these issues are known to many researchers, published methods for systematically tackling the problem of DRL training under these conditions without using simulation are sparse in the field. To this end, this paper proposes a non-blocking and asynchronous DRL training architecture for non-linear, real-time dynamical systems tailored to handling variable delays. Compared to conventional DRL training, we: (i) decouple the RL loop into separate processes run independently at their own frequencies, (ii) further decouple collection of transition tuples (st , att, st+1 ) via asynchronous and independent streaming of both actions and observations, and (iii) mitigate the effects of delays and increase sample efficiency by providing delay-length measurements to the training loop and regular retraining of the DRL network. This allows the action step time to be tuned to find an optimal control frequency for a given system, and handles streamed observations that arrive with random delays and independently of action timing. We demonstrate the efficacy of this architecture with a physical implementations of a commodity-grade swing-up pendulum and a quadrupedal robot. Our architecture achieves the best results balancing the pendulum for almost entire length of the episode, compared to conventional blocking approaches which fail to learn effective policies. Our results show that these techniques scale to more complex tasks such as quadrupedal locomotion.
# End-To-End Learning to Grasp Via Sampling from Object Point Clouds
## Keywords:
- Deep Learning in Grasping and Manipulation
- Deep Learning for Visual Perception
- Grasping
## Abstract:
The ability to grasp objects is an essential skill that enables many robotic manipulation tasks. Recent works have studied point cloud-based methods for object grasping by starting from simulated datasets and have shown promising performance in real-world scenarios. Nevertheless, many of them still rely on ad-hoc geometric heuristics to generate grasp candidates, which fail to generalize to objects with significantly different shapes with respect to those observed during training. Several approaches exploit complex multi-stage learning strategies and local neighborhood feature extraction while ignoring semantic global information. Furthermore, they are inefficient in terms of number of training samples and time required for inference. In this paper, we propose an end-to-end learning solution to generate 6-DOF parallel-jaw grasps starting from the 3D partial view of the object. Our Learning to Grasp (L2G) method gathers information from the input point cloud through a new procedure that combines a differentiable sampling strategy to identify the visible contact points, with a feature encoder that leverages local and global cues. Overall, L2G is guided by a multi-task objective that generates a diverse set of grasps by optimizing contact point sampling, grasp regression, and grasp classification. With a thorough experimental analysis, we show the effectiveness of L2G as well as its robustness and generalization abilities.
# Robot Skill Learning with Identification of Preconditions and Postconditions Via Level Set Estimation
## Keywords:
- Machine Learning for Robot Control
- AI-Based Methods
- Task and Motion Planning
## Abstract:
Hierarchical algorithms have often been used to plan and execute complicated robotic sequential manipulation tasks, where an abstract planner searches for a skill sequence in an abstract space, and each skill generates actual motions on the basis of the planned skill sequences. To generate executable plans, the abstract planner should know the pre-/postconditions of each skill and appropriately choose skills so that the generated plan satisfies their pre-/postconditions. For such hierarchical planning, this paper presents a novel method for robot skill learning that learns not only a control policy but also the learned skill's pre-/postconditions to complete a given task. Our method combines an optimal control method and an active learning approach called level set estimation (LSE) to effectively collect training data for learning control policies and pre-/postconditions. Although there exists a LSE-based policy learning algorithm that identifies preconditions, its performance is limited to cases where the dimension of the search space for pre-/postconditions is low. The main contribution of this paper is the proposal of a new learning method that can handle tasks having a high-dimensional search space for pre-/postconditions. We demonstrate our proposed method in two robotic tasks. The results show that our method can more effectively learn a control policy and its pre-/postconditions compared with the existing LSE-based method.
# Sex Parity in Cognitive Fatigue Model Development for Effective Human-Robot Collaboration
## Keywords:
- Machine Learning for Robot Control
- Human Factors and Human-in-the-Loop
- Human-Robot Collaboration
## Abstract:
In recent years, robots have become vital to achieving manufacturing competitiveness. Especially in industrial environments, a strong level of interaction is reached when humans and robots form a dynamic system that works together towards achieving a common goal or accomplishing a task. However, the human-robot collaboration can be cognitively demanding, potentially contributing to cognitive fatigue. Therefore, the consideration of cognitive fatigue becomes particularly important to ensure the efficiency and safety in the overall human-robot collaboration. Additionally, sex is an inevitable human factor that needs further investigation for machine learning model development given the perceptual and physiological differences between the sexes in responding to fatigue. As such, this study explored sex differences and labeling strategies in the development of machine learning models for cognitive fatigue detection. Sixteen participants, balanced by sex, recruited to perform a surface finishing task with a UR10 collaborative robot under fatigued and non-fatigued states. Fatigue perception and heart rate activity data collected throughout to create a dataset for cognitive fatigue detection. Equitable machine learning models developed based on perception (survey responses) and condition (fatigue manipulation). The labeling approach had a significant impact on the accuracy and F1-score, where perception-based labels lead to lower accuracy and F1-score for females likely due to sex differences in reporting of fatigue. Additionally, we observed a relationship between heart rate, algorithm type, and labeling approach, where heart rate was the most significant predictor for the two labeling approaches and for all the algorithms utilized. Understanding the implications of label type, algorithm type, and sex on the design of fatigue detection algorithms is essential to designing equitable fatigue-adaptive human-robot collaborations across the sexes.
# Online Adaptive Compensation for Model Uncertainty Using Extreme Learning Machine-Based Control Barrier Functions
## Keywords:
- Machine Learning for Robot Control
- Robot Safety
## Abstract:
A control barrier functions-based quadratic programming (CBF-QP) method has emerged as a controller synthesis tool to assure safety of autonomous systems owing to the appealing safe forward invariant set. However, the provable safety relies on a precisely described dynamic model, which is not always available in practice. Recent works leverage learning to compensate model uncertainty for a CBF controller. However, these approaches based on reinforcement learning or episodic learning are limited to dealing with time-invariant uncertainty. Also, the reinforcement learning approach learns the uncertainty offline, while episodic learning only updates the controller after a batch of data is available by the end of an episode. Instead, we propose a novel tuning extreme learning machine (tELM)-based CBF controller that can compensate time-variant and time-invariant model uncertainty adaptively in an online manner. We validate our approach's effectiveness in a simulation of an Adaptive Cruise Control (ACC) system.
# Soft Robot Modeling and Control 2
# Task-Space Control of Continuum Robots Using Underactuated Discrete Rod Models
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Dynamics
## Abstract:
Underactuation is a core challenge associated with controlling soft and continuum robots, which possess theoretically infinite degrees of freedom, but few actuators. However, m actuators may still be used to control a dynamic soft robot in an m-dimensional output task space. In this paper we develop a task-space control approach for planar continuum robots that is robust to modeling error and requires very little sensor information. The controller is based on a highly underactuated discrete rod mechanics model in maximal coordinates and does not require conversion to a classical robot dynamics model form. This promotes straightforward control design, implementation and efficiency. We perform input-output feedback linearization on this model, apply sliding mode control to increase robustness, and formulate an observer to estimate the full state from sparse output measurements. Simulation results show exact task-space reference tracking behavior can be achieved even in the presence of significant modeling error, inaccurate initial conditions, and output-only sensing.
# Nonlinear Dynamics Modeling and Fault Detection for a Soft Trunk Robot: An Adaptive NN-Based Approach
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Failure Detection and Recovery
- Model Learning for Control
## Abstract:
This paper presents a radial basis function neural network (RBF NN) based methodology to investigate the dynamics modeling and fault detection (FD) problems for soft robots. Finite element method (FEM) is first used to derive a mathematical model to describe the dynamics of a soft trunk robot. An adaptive dynamics modeling approach is then designed based on this FEM model by incorporating model-reduction and RBF NN techniques. This approach is capable of achieving accurate identification of the soft robot’s highly-nonlinear dynamics, with the identified knowledge being obtained and stored in constant RBF NN models. Finally, a model-based FD scheme is proposed with the modeling results, which can achieve efficient FD for the soft robot whenever it encounters an unknown fault. Note that the proposed methods are generic and usable for general soft robots. Validation of these methods is performed through both computer simulation and physical experiments.
# Shape Representation and Modeling of Tendon-Driven Continuum Robots Using Euler Arc Splines
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Flexible Robotics
- Kinematics
## Abstract:
Due to the compliance of tendon-driven continuum robots, carrying a load or experiencing a tip force result in variations in backbone curvature. While the spatial robot configuration theoretically needs an infinite number of parameters for exact description, it can be well approximated using Euler Arc Splines which use only six of them. In this letter, we first show the accuracy of this representation by fitting the Euler Arc splines directly to experimentally measured robot shapes. Additionally, we propose a 3D static model that can account for gravity, friction and tip forces. We demonstrate the utility of using efficient parameterization by analyzing the computation time of the proposed model and then, using it to propose a hybrid model that combines physics-based model with observed data. The average tip error for the Euler arc spline representation is 0.43% and the proposed static model is 3.25% w.r.t. robot length. The average computation time is 0.56 ms for nonplanar deformations for a robot with ten disks. The hybrid model reduces the maximum error predicted by the static model from 8.6% to 5.1% w.r.t. robot length, while using 30 observations for training.
# Geometrically-Exact Inverse Kinematic Control of Sof Manipulators with General Threadlike Actuators’ Routing
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Kinematics
- Flexible Robotics
## Abstract:
The inverse kinematic control of soft robots appears as an open challenge that has been the subject of a number of papers presented in the last decade. Some solutions have been provided based on specific assumptions on the robot’s shape or the actuation mechanism. Other more generic approaches are characterized by a significant computational cost or by a low level of accuracy for very high deformations. In the effort to overcome some of these limitations, here we present a Geometrically-Exact (GE) inverse kinematics controller, which can be applied to soft manipulators having general threadlike actuators’ routing. Being GE, the approach is suitable to applications involving arbitrarily large bending and twisting, and, on the other side, it relies on a reduced number of Degrees of Freedom (DOFs). We prove the feasibility of the proposed Jacobian-based inverse kinematic control in simulation for soft manipulators with complex and discontinuous actuators’ routing.
# Quasi-Static FEA Model for a Multi-Material Soft Pneumatic Actuator in SOFA
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Simulation and Animation
- Kinematics
## Abstract:
The increasing interest in soft robotics has led to new designs that exploit the combination of multiple materials, increasing robustness and enhancing performance. However, the combination of multiple non-linear materials makes modelization and eventually control of these highly flexible systems challenging. This article presents a methodology to model multi-material soft pneumatic actuators using finite element analysis (FEA), based on (hyper)elastic constitutive laws fitted on experimental material characterisation. The model in SOFA, the FEA software, allows to model and control in real-time soft robotic structures. One of the novelties presented in this paper is the development of a new user-friendly technique for the mesh partitioning in SOFA, using MATLAB algorithms, that allow the creation of uniform and more refined meshes and a mesh domain partitioning that can be adapted for any geometry. As a case study, a cylindrical multimaterial soft pneumatic actuator is considered. It is composed of an internal chamber, which is constituted of an autonomous self-healing hydrogel, modelled as a hyperelastic material, and an external elastic reinforcement, made of thermoplastic polyetherpolyurethane elastomer (TPPU), approached as a linear elastic
material. The simulation of the combination of a hyperelastic and a linear elastic material in a single design is another contribution of this work to the scientific literature of SOFA simulations. Finally, the multi-material model obtained with the new mesh partitioning technique is simulated in quasi-static conditions and is experimentally validated, demonstrating an accurate fit, between simulation and reality.
# Controlling Soft Fluidic Actuators Using Soft DEA-Based Valves
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Soft Sensors and Actuators
- Soft Robot Applications
## Abstract:
Fluidic soft actuators have been widely used for applications where compliance is desirable -# such as in delicate robotic manipulation. As their operation is based on pressurization, fluidic actuators typically rely on bulky, rigid pumps, valves, and pressure regulators for control. This dependence on rigid components hinders the development of compact and fully-soft robots. Soft regulation systems designed for control of these actuators have been recently developed based on soft valves using dielectric elastomer actuators, but precise control has not been achieved. In this work, we leverage these valves to introduce a soft regulation system capable of precise closed-loop position control of a soft hydraulic actuator with multiple controllers. We also achieve open-loop trajectory tracking based on a data-driven model of the fluidic system. Finally, we combine the valve system with wearable strain sensors to create the first teleoperated fluidic circuit where the sensor, actuator, and regulation system are all soft. This work presents control strategies for fluid-driven actuators with soft sensors and regulation systems, showing the potential for future all-soft motion control of soft hydraulic robots.
# Omnidirectional Walking of a Quadruped Robot Enabled by Compressible Tendon-Driven Soft Actuators
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Soft Sensors and Actuators
- Motion Control
## Abstract:
Using soft actuators as legs, soft quadruped robots have shown great potential in traversing unstructured and complex terrains and environments. However, unlike rigid robots whose gaits can be generated using foot pattern design and kinematic model of the rigid legs, the gait generation of soft quadruped robots remains challenging due to the high DoFs of the soft actuators and the uncertain deformations during their contact with the ground. This study is based on a quadruped robot using four Compressible Tendon-driven Soft Actuators (CTSAs) as the legs, with the actuator's compression motion being utilized to improve the walking performance of the robot. For the gait design, an inverse kinematics model considering the compression of the CTSA is developed and validated in simulation. Based on this model, walking gaits realizing different motion speeds and directions are generated. Closed loop direction and speed controllers are developed for increasing the robustness and precision of the robot walking. Simulation and experimental results show that omnidirectional locomotion and complex walking tasks can be realized by tuning the gait parameters and the motions are resistant to external disturbances.
# Estimating Forces Along Continuum Robots
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Surgical Robotics: Steerable Catheters/Needles
## Abstract:
Continuum robots can be slender and flexible to navigate through complex environments, such as passageways in the human body. In order to control the forces that continuum robots apply during navigation and manipulation, we would like to detect the location, direction, and magnitude of contact forces distributions as they arise. In this paper, we present a model-based framework for sensing distributed loads along continuum robots. Using sensed positions along the robot, we use a nonlinear optimization algorithm to estimate the loading which fits the model-predicted robot shape to the data. We propose that Gaussian load distributions provide a seamless way to account for a wide range of loadings, including approximate point loads and uniform distributed loads, while avoiding the ill-conditioning associated with highly resolved force distributions. In addition, we gain computational efficiency by re-framing the problem as unconstrained weighted least-squares minimization and by solving this problem with an Extended Kalman-filter framework. We validate the approach on two prototype tendon-driven continuum robots in multiple 3D loading scenarios, displaying a mean error of 0.58 N in load magnitude and 7% mean error in load location with respect to the length of the respective robot.
# Learning Physics-Informed Simulation Models for Soft Robotic Manipulation: A Case Study with Dielectric Elastomer Actuators
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Machine Learning for Robot Control
- Reinforcement Learning
## Abstract:
Soft actuators offer a safe, adaptable approach to tasks like gentle grasping and dexterous manipulation. Creating accurate models to control such systems however is challenging due to the complex physics of deformable materials. Accurate Finite Element Method (FEM) models incur prohibitive computational complexity for closed-loop use. Using a differentiable simulator is an attractive alternative, but their applicability to soft actuators and deformable materials remains underexplored. This paper presents a framework that combines the advantages of both. We learn a differentiable model consisting of a material properties neural network and an analytical dynamics model of the remainder of the manipulation task. This physics-informed model is trained using data generated from FEM, and can be used for closed-loop control and inference. We evaluate our framework on a dielectric elastomer actuator (DEA) coin-pulling task. We simulate the task of using DEA to pull a coin along a surface with frictional contact, using FEM, and evaluate the physics-informed model for simulation, control, and inference. Our model attains ≤5% simulation error compared to FEM, and we use it as the basis for an MPC controller that requires fewer iterations to converge than model-free actor-critic, PD, and heuristic policies.
# SLAM 8
# Detecting Invalid Map Merges in Lifelong SLAM
## Keywords:
- SLAM
- Mapping
- Localization
## Abstract:
For Lifelong SLAM, one has to deal with temporary localization failures, e.g., induced by kidnapping. We achieve this by starting a new map and merging it with the previous map as soon as relocalization succeeds. Since relocalization methods are fallible, it can happen that such a merge is invalid, e.g., due to perceptual aliasing. To address this issue, we propose methods to detect and undo invalid merges. These methods compare incoming scans with scans that were previously merged into the current map and consider how well they agree with each other. Evaluation of our methods takes place using a dataset that consists of multiple flat and office environments, as well as the public MIT Stata Center dataset. We show that methods based on a change detection algorithm and on comparison of gridmaps perform well in both environments and can be run in real-time with a reasonable computational cost.
# MD-SLAM: Multi-Cue Direct SLAM
## Keywords:
- SLAM
- Mapping
## Abstract:
Simultaneous Localization and Mapping (SLAM) systems are fundamental building blocks for any autonomous robot navigating in an unknown environment. The SLAM implementation heavily depends on the sensor modality employed on the mobile platform. For this reason, assumptions on the scene's structure are often made to maximize estimation accuracy. This paper presents a novel direct 3D SLAM pipeline that works independently for RGB-D and LiDAR sensors. Building upon prior work on multi-cue photometric frame-to-frame alignment, our proposed approach provides an easy-to-extend and generic SLAM system. Our pipeline requires only minor adaptations within the projection model to handle different sensor modalities. We couple a position tracking system with an appearance-based relocalization mechanism that handles large loop closures. Loop closures are validated by the same direct registration algorithm used for odometry estimation. We present comparative experiments with state-of-the-art approaches on publicly available benchmarks using RGB-D cameras and 3D LiDARS. Our system performs well in heterogeneous datasets compared to other sensor-specific methods while making no assumptions about the environment. Finally, we release an open-source C++ implementation of our system.
# Visual-Inertial Multi-Instance Dynamic SLAM with Object-Level Relocalisation
## Keywords:
- SLAM
- Mapping
- Visual-Inertial SLAM
## Abstract:
In this paper, we present a tightly-coupled visual-inertial object-level multi-instance dynamic SLAM system. Even in extremely dynamic scenes, it can robustly optimise for the camera pose, velocity, IMU biases and build a dense 3D reconstruction object-level map of the environment. Our system can robustly track and reconstruct the geometries of arbitrary objects, their semantics and motion by incrementally fusing associated colour, depth, semantic, and foreground object probabilities into each object model thanks to its robust sensor and object tracking. In addition, when an object is lost or moved outside the camera field of view, our system can reliably recover its pose upon re-observation. We demonstrate the robustness and accuracy of our method by quantitatively and qualitatively testing it in real-world data sequences.
# ACEFusion # Accelerated and Energy-Efficient Semantic 3D Reconstruction of Dynamic Scenes
## Keywords:
- SLAM
- Mapping
- Embedded Systems for Robotic and Automation
## Abstract:
Abstract— ACEFusion is the first 3D reconstruction system able to capture the geometry and semantics of dynamic scenes using an RGB-D camera in real-time on a robotic computing platform. Harnessing the hardware accelerators of an Nvidia Jetson AGX Xavier, the system uses heterogeneous computing to achieve 30 FPS under a 30W power budget. Using a dataparallel design, we perform most image computation on the dedicated hardware accelerators, freeing the general purpose cores and GPU to process 3D geometry. To further increase efficiency, we employ a hybrid geometry representation with octrees for static-semantic reconstruction and surfels for dynamic reconstruction. ACEFusion achieves competitive results on standard benchmarks while efficiently performing a more complex overall task than existing SLAM techniques. Figure. 1 shows the output of our system on a dynamic sequence.
# A Spanning Tree-Based Multi-Resolution Approach for Pose-Graph Optimization
## Keywords:
- SLAM
- Mapping
- Optimization and Optimal Control
## Abstract:
This paper proposes a computationally efficient method for pose-graph optimization that makes use of a multi-resolution representation of pose-graph transformation constructed on a spanning tree. It is shown that the proposed spanning tree-based hierarchy has a number of advantages over the previously known serial chain-based hierarchy in terms of preservation of sparsity and compatibility with parallel computation. It is demonstrated in numerical experiments using several public datasets that the proposed method outperforms a state-of-the-art solver for large-scale datasets.
# Situational Graphs for Robot Navigation in Structured Indoor Environments
## Keywords:
- SLAM
- Mapping
- Localization
## Abstract:
Mobile robots should be aware of their situation, comprising the deep understanding of their surrounding environment along with the estimation of its own state, to successfully make intelligent decisions and execute tasks autonomously in real environments. 3D scene graphs are an emerging field of research that propose to represent the environment in a joint model comprising geometric, semantic and relational/topological dimensions. Although 3D scene graphs have already been combined with SLAM techniques to provide robots with situational understanding, further research is still required to effectively deploy them on-board mobile robots.
To this end, we present in this paper a novel, real-time, online built Situational Graph (S-Graph), which combines in a single optimizable graph, the representation of the environment with the aforementioned three dimensions, together with the robot pose. Our method utilizes odometry readings and planar surfaces extracted from 3D LiDAR scans, to construct and optimize in real-time a three layered S-Graph that includes (1) a robot tracking layer where the robot poses are registered, (2) a metric-semantic layer with features such as planar walls and (3) our novel topological layer constraining the planar walls using higher-level features such as corridors and rooms. Our proposal does not only demonstrate state-of-the-art results for pose estimation of the robot, but also contributes with a metric-semantic-topological model of the environment.
# PFilter: Building Persistent Maps through Feature Filtering for Fast and Accurate LiDAR-Based SLAM
## Keywords:
- Mapping
- SLAM
## Abstract:
 Simultaneous localization and mapping (SLAM) based on laser sensors has been widely adopted by mobile robots and autonomous vehicles. These SLAM systems are required to support accurate localization with limited computational resources. In particular, point cloud registration, i.e., the process of matching and aligning multiple LiDAR scans collected at multiple locations in a global coordinate framework, has been deemed as the bottleneck step in SLAM. In this paper, we propose a feature filtering algorithm, PFilter, that can filter out invalid features and can thus greatly alleviate this bottleneck. Meanwhile, the overall registration accuracy is also improved due to the carefully curated feature points. We integrate PFilter into the well-established scan-to-map LiDAR odometry framework, F-LOAM, and evaluate its performance on the KITTI dataset. The experimental results show that PFilter can remove about 48.4% of the points in the local feature map and reduce feature points in scan by 19.3% on average, which save 20.9% processing time per frame. In the mean time, we improve the accuracy by 9.4%.
# Nested Sampling for Non-Gaussian Inference in SLAM Factor Graphs
## Keywords:
- Localization
- Mapping
## Abstract:
We present nested sampling for factor graphs (NSFG), a novel nested sampling approach to approximate inference for posterior distributions expressed over factor-graphs. Performing such inference is a key step in simultaneous localization and mapping (SLAM). Although the Gaussian approximation often works well, in other more challenging SLAM situations, the posterior distribution is non-Gaussian and cannot be explicitly represented with standard distributions. Our technique applies to settings where the posterior distribution is substantially non-Gaussian (e.g., multi-modal) and thus needs a more expressive representation. NSFG exploits nested sampling methods to directly sample the posterior to represent the distribution without parametric density models. While nested sampling methods are known for their powerful capability in	sampling multi-modal distributions, the application of the methods to SLAM factor graphs is not straightforward. NSFG leverages the structure of factor graphs to construct informative prior distributions which are efficiently sampled and provide notable computational benefits for nested sampling methods. We compare NSFG to state-of-the-art sampling approaches and Gaussian/non-Gaussian SLAM techniques in experiments. NSFG performs most robustly in describing non-Gaussian posteriors and computes solutions over an order of magnitude faster than other sampling approaches. We believe the primary value of NSFG is as a reference solution of posterior distributions, aiding offline accuracy evaluation of approximate distributions found by other SLAM algorithms.
# City-Wide Street-To-Satellite Image Geolocalization of a Mobile Ground Agent
## Keywords:
- Localization
- Vision-Based Navigation
- Deep Learning for Visual Perception
## Abstract:
Cross-view image geolocalization provides an estimate of an agent's global position by matching a local ground image to an overhead satellite image without the need for GPS. It is challenging to reliably match a ground image to the correct satellite image since the images have significant viewpoint differences. Existing works have demonstrated localization in constrained scenarios over small areas but have not demonstrated wider-scale localization. Our approach, called Wide-Area Geolocalization (WAG), combines a neural network with a particle filter to achieve global position estimates for agents moving in GPS-denied environments, scaling efficiently to city-scale regions. WAG introduces a trinomial loss function for a Siamese network to robustly match non-centered image pairs and thus enables the generation of a smaller satellite image database by coarsely discretizing the search area. A modified particle filter weighting scheme is also presented to improve localization accuracy and convergence. Taken together, WAG's network training and particle filter weighting approach achieves city-scale position estimation accuracies on the order of 20 meters, a 98% reduction compared to a baseline training and weighting approach. Applied to a smaller-scale testing area, WAG reduces the final position estimation error by 64% compared to a state-of-the-art baseline from the literature. WAG’s search space discretization additionally significantly reduces storage and processing requirements. We include in our submission a video demonstrating particle filter convergence results for WAG compared to the baseline for the Chicago test area.
# Rehabilitation Robotics
# Soft Actuators for Facial Reanimation
## Keywords:
- Soft Robot Applications
- Soft Robot Materials and Design
- Medical Robots and Systems
## Abstract:
Facial paralysis is a challenging condition that alters a patient's ability to express emotion and communicate. Restoring facial movements thus has crucial implications for the patients' quality of life. This publication introduces an approach for artificial muscles implementation targeting facial reanimation, as well as the challenges and limitations of the proposed strategy. The aim is to develop a Dielectric Elastomer Actuator (DEA) prosthesis for patients suffering from facial paralysis. DEAs are chosen as they are soft, have large strain (up to 200%) and high dynamic behaviour (up to 20 kHz), making them a promising actuator for the application. Myoelectric signals are extracted using electromyography sensors from the Zygomaticus Major muscle, and they are processed in order to emphasize the activation phases. The resulting actuating signal is used to control a high voltage power supply to operate the DEA in an open loop. The resulting induced movement qualitatively matches the myoelectric signal, showing great potential of the proposed approach for facial paralysis reanimation.
# Development and Experimental Evaluation of a Novel Portable Haptic Robotic Exoskeleton Glove System for Patients with Brachial Plexus Injuries
## Keywords:
- Rehabilitation Robotics
- Wearable Robotics
- Grasping
## Abstract:
This paper presents the development and experimental evaluation of a portable haptic exoskeleton glove system designed for people who suffer from brachial plexus injuries to restore their lost grasping functionality. The proposed glove system involves force perception, linkage-driven finger mechanism, and personalized voice control to achieve various grasping functionality requirements. The fully integrated system provides our wearable device with lightweight, portable, and comfortable characterization for grasping objects used in daily activities. Rigid articulated linkages powered by Series Elastic Actuators (SEAs) with slip detection on the fingertips provide stable and robust grasp for multiple objects. The passive abduction-adduction motion of each finger is also considered to provide better grasping flexibility for the user. The continuous voice control with bio-authentication also provides a hands-free user interface. The experiments with different objects verify the functionalities and capabilities of the proposed exoskeleton glove system in grasping objects with various shapes and weights used in activities of daily living (ADLs).
# Development of a Novel Low-Profile Robotic Exoskeleton Glove for Patients with Brachial Plexus Injuries
## Keywords:
- Rehabilitation Robotics
- Mechanism Design
- Prosthetics and Exoskeletons
## Abstract:
This paper presents the design and development of a novel, low-profile, exoskeleton robotic glove aimed for people who suffer from brachial plexus injuries to restore their lost grasping functionality. The key idea of this new glove lies in its new finger mechanism that takes advantage of the rigid coupling hybrid mechanism (RCHM) concept. This mechanism concept couples the motions of the adjacent human finger links using rigid coupling mechanisms so that the overall mechanism motion (e.g., bending, extension, etc.) could be achieved using fewer actuators. The finger mechanism utilizes the single degree of freedom case of the RCHM that uses a rack-and-pinion mechanism as the rigid coupling mechanism. This special arrangement enables to design each finger mechanism of the glove as thin as possible while maintaining mechanical robustness simultaneously. Based on this novel finger mechanism, a two-finger low-profile robotic glove was developed. Remote center of motion mechanisms were used for the metacarpophalangeal (MCP) joints. Kinematic analysis and optimization-based kinematic synthesis were conducted to determine the design parameters of the new glove. Passive abduction/adduction joints were considered to improve the grasping flexibility. A proof-of-concept prototype was built and pinch grasping experiments of various objects were conducted. The results validated the mechanism and the mechanical design of the new robotic glove and demonstrated its functionalities and capabilities in grasping objects with various shapes and weights that are used in activities of daily living (ADLs).
# A Novel Wheelchair-Exoskeleton Hybrid Robot to Assist Movement and Aid Rehabilitation
## Keywords:
- Rehabilitation Robotics
- Physical Human-Robot Interaction
- Wearable Robotics
## Abstract:
As a traditional movement assist equipment for people with lower-limb dysfunction, the wheelchair can support and carry users to perform a long-distance movement indoor and outdoor, however, prolonged inactivity can lead to muscle atrophy and deteriorate motion functions. As a promising solution, the lower limb exoskeleton provides people the ability of standing and walking to avoid these problems. However, the exoskeleton has inevitable shortcomings in long-distance movement and balance, which do not exist in a wheelchair. To integrate the advantages of both devices, in this paper, we proposed a wheelchair-exoskeleton hybrid robot (WeHR) that can not only provide users long-time support and long-distance movement but also provide walking training and keep self-balance. Moreover, motion transitions such as sit-to-stand and stand-to-sit can also be implemented by the newly proposed device without help from caregivers. We have developed the prototype to implement the above functions. In this paper, we emphasize the strategy of motion transition including two trajectory planning methods for the Sit-To-Stand (STS) process as well as the mechanism design to implement it. Furthermore, the preliminary experiments of motion transition and walking test are also conducted and the results prove that our device can support users sitting, standing, and walking and the motion transition.
# Facial Expressions-Controlled Flight Game with Haptic Feedback for Stroke Rehabilitation: A Proof-Of-Concept Study
## Keywords:
- Rehabilitation Robotics
## Abstract:
Most stroke patients suffer from a combination of motor and sensory dysfunction and central facial paralysis. Specific rehabilitation training is required to restore those functions. Current research focuses on developing stimulating and straightforward rehabilitation training processes so that patients adhere to the training at home after hospital release. This study proposes enhancing patients’ enthusiasm to participate in facial muscle exercises and improving their postural perception and balance by controlling virtual objects to complete assigned tasks in virtual reality games using different facial expressions with the assistance of haptic feedback. The different rehabilitation exercises for motor, sensory, and facial dysfunctions were combined in one virtual reality game for the first time. The proposed haptic feedback device was modeled, simulated, and characterized. A user study was conducted to validate the proposed system. The experiment result shows that all the designed functions of the comprehensive stroke rehabilitation virtual reality game can be achieved. The added haptic feedback enhances the performance of the aircraft control with facial expressions by lowering the trajectory deviation by 22.57%. This implies that the proposed game may improve users' performance, thus attracting them to conduct more training.
# An Intention Prediction Based Shared Control System for Point-To-Point Navigation of a Robotic Wheelchair
## Keywords:
- Rehabilitation Robotics
- Human-Robot Collaboration
- Intention Recognition
## Abstract:
Shared control approaches for robotic wheelchairs aim to provide navigation assistance to humans by utilizing robot’s intelligence in environment perception and motion planning. They can be broadly classified into two categories based on human intention prediction. Without human intention prediction, control authority lies with humans and assistance is provided only to avoid collisions. This can cause difficulty in cases where fine motor control is required, such as when entering narrow doorways, especially for users with severe upper limb disability. Intention prediction based approaches are able to better assist with such tasks but do not give enough control authority to the user as possible user intentions are pre-defined. In this work, we present an intention prediction based shared control system for point-to-point navigation of wheelchair which gives control authority to the user and also assists in fine motor control tasks. We compute various possible user intentions online using generalized Voronoi diagram, link them across time steps using their homotopy class and thus are able to calculate their probability given user input history. A shared local path planner then steers user towards the most likely path. This allows the user to follow any path. Our simulation experiments with 18 healthy subjects and both simulation and real wheelchair experiments, with 2 Cerebral Palsy (CP) subjects, show that our system can improve navigation outcome for people with disability and in general leads to around 10% faster completion of the task for even healthy people as compared to a local obstacle avoidance system while allowing users to follow their desired path with similar accuracy.
# A Wearable System with Harmonic Oscillations to Assess Finger Biomechanics
## Keywords:
- Rehabilitation Robotics
- Wearable Robotics
## Abstract:
This paper presents a wearable device for finger assessment that can identify finger joint impedance parameters through harmonic oscillation perturbations. This device is designed to help assess motor impairments related to hypertonic soft-tissue changes, that can arise from a number of conditions such as stroke. By measuring the ratio of the applied torque and resulting velocities, the impedance values for any bending direction of a metacarpophalangeal (MCP) joint can be esti# mated. The ability of this device to effectively estimate finger parameters was tested in experiments with six participants. The experimental result was validated through comparison to prior works on finger impedance estimation. The user experience of the presented system was also analysed, indicating that the device design is comfortable and acceptable for participants.
# Evaluation of TENS Based Biofeedback and Warning for Improvement of Seated Balance on a Trunk Rehabilitation Robot
## Keywords:
- Rehabilitation Robotics
- Haptics and Haptic Interfaces
- Human-Centered Robotics
## Abstract:
Provision of visual feedback under unstable and forcefully perturbed seat conditions can help improve seated balance performance. However, due to visual limitations, some patients may require use of a different modality. Additionally, warning about an upcoming perturbation may improve balance reactions, and use of a system that provides such warnings and balance biofeedback through different modalities may result in further improvement. Transcutaneous electrical nerve stimulation (TENS), which can generate electro-tactile stimulation, may be useful in this regard. Therefore, in this study with 21 healthy subjects, we have used our recently developed trunk rehabilitation robot to evaluate the performance of TENS as a feedback and perturbation warning modality against visual and vibrotactile stimulation. The center of pressure (COP) and trunk acceleration results show that both TENS and vibrotactile stimulation may serve as viable alternatives for visual feedback under unstable condition. Under perturbation condition, provision of warning improves balancing performance, and TENS shows the overall best performance as a warning modality, with vibrotactile showing the lowest performance. Thus, TENS may be considered a feasible feedback/warning modality for use during seated balance rehabilitation.
# Soft Robotic Fabric Actuator with Elastic Bands for High Force & Bending Performance in Hand Exoskeletons
## Keywords:
- Soft Sensors and Actuators
- Prosthetics and Exoskeletons
- Soft Robot Applications
## Abstract:
In current designs soft robotic bending actuators, the need for high force capabilities is not adequately addressed. In this paper, we present a new inflatable actuator that exploits textile manufacturing techniques, using an elastic band to improve both bend and force performance. At a pressure of 102 kPa, the index finger sized actuator exerts 24.8 N of force on the environment. It is also capable of a full 360 degree bending angle for pressures between 30 kPa and 102 kPa with a maximum bending stiffness of 288.4 N/m. We further demonstrate feasibility of this new actuator in a case study of an entirely fabric based soft robotic hand exoskeleton that increases robustness and user comfort. Our results suggest that textile robotics could provide an attractive solution in terms of the development of user-friendly hand exoskeletons.
# Compliance and Impedance Control 2
# Integrating Impedance Control and Nonlinear Disturbance Observer for Robot-Assisted Arthroscope Control in Elbow Arthroscopic Surgery
## Keywords:
- Compliance and Impedance Control
- Physical Human-Robot Interaction
- Medical Robots and Systems
## Abstract:
Robot-assisted arthroscopic surgery is transforming the tradition in orthopaedic surgery. Compliance and stability are essential features that a surgical robot must have for safe physical human-robot interaction (pHRI). Surgical tools attached at the robot end-effector and human-robot interaction will affect the robot dynamics inevitably. This could undermine the utility and stability of the robotic system if the varying robot dynamics are not identified and updated in the robot control law. In this paper, an integrated framework for robot impedance control and nonlinear disturbance observer (NDOB)-based compensation of uncertain dynamics is proposed, where the former ensures compliant robot behavior and the latter compensates for dynamic uncertainties when necessary. The combination of impedance controller and NDOB is analyzed theoretically in three scenarios. A complete simulation and experimental studies involving three common conditions are then conducted to evaluate the theoretical analyses. A preliminary pHRI application on arthroscopic surgery is designed to implement the proposed framework on a robotic surgeon-assist system and evaluate its effectiveness experimentally. By integrating impedance controller with NDOB, the proposed framework allows an accurate impedance control when dynamic model inaccuracy and external disturbance exist.
# Reinforcement Learning of Impedance Policies for Peg-In-Hole Tasks: Role of Asymmetric Matrices
## Keywords:
- Compliance and Impedance Control
- Machine Learning for Robot Control
- Reinforcement Learning
## Abstract:
Robotic manipulators are playing an increasing role in a wide range of industries. However, their application to assembly tasks is hampered by the need for precise control over the environment and for task-specific coding. Cartesian impedance control is a well-established method for interacting with the environment and handling uncertainties. With the advance of Reinforcement Learning (RL) it has been suggested to learn the impedance matrices. However, most of the current work is limited to learning diagonal impedance matrices in addition to the trajectory itself. We argue that asymmetric impedance matrices enhance the ability to properly correct reference trajectories generated by a baseline planner, alleviating the need for learning the trajectory. Moreover, a task-specific set of asymmetric impedance matrices can be sufficient for simple tasks, alleviating the need for learning variable impedance control. We learn impedance policies for small (few mm) peg-in-hole using model-free RL, and investigate the advantage of using asymmetric impedance matrices and their space-invariance. Finally, we demonstrate zero-shot policy transfer from the simulation to a real robot, and generalization to new real-world environments, with larger parts and semi-flexible pegs.
# A Self-Tuning Impedance-Based Interaction Planner for Robotic Haptic Exploration
## Keywords:
- Compliance and Impedance Control
- Integrated Planning and Control
- Planning under Uncertainty
## Abstract:
This paper presents a novel interaction planning method that exploits impedance tuning techniques in response to environmental uncertainties and unpredictable conditions using haptic information only. The proposed algorithm plans the robot’s trajectory based on the haptic interaction with the environment and adapts planning strategies as needed. Two approaches are considered: Exploration and Bouncing strategies. The Exploration strategy takes the actual motion of the robot into account in planning, while the Bouncing strategy exploits the forces and the motion vector of the robot. Moreover, self-tuning impedance is performed according to the planned trajectory to ensure compliant contact and low contact forces. In order to show the performance of the proposed methodology, two experiments with a torque-controller robotic arm are carried out. The first considers a maze exploration without obstacles, whereas the second includes obstacles. The proposed method performance is analyzed and compared against previously proposed solutions in both cases. Experimental results demonstrate that: i) the robot can successfully plan its trajectory autonomously in the most feasible direction according to the interaction with the environment, and ii) a compliant interaction with an unknown environment despite the uncertainties is achieved. Finally, a scalability demonstration is carried out to show the potential of the proposed method under multiple scenarios.
# Probabilistic Approach to Online Stiffness Estimation for Robotic Tasks
## Keywords:
- Compliance and Impedance Control
- Contact Modeling
- Force and Tactile Sensing
## Abstract:
The stiffness of the environment is useful information for robotic tasks involving interactions with unstructured and unknown environments. However, its online estimation remains challenging. Owing to the nature of its calculation algorithm, a large amount of noise may be generated depending on the response value of the force and position. In this paper, we propose a variable gain filter that predicts the degree of such noise using a probabilistic approach and reflects only reliable data in the estimation. We experimentally show that the proposed method improves the accuracy of stiffness estimation without degrading the estimation time constant.
# Efficient Learning of Inverse Dynamics Models for Adaptive Computed Torque Control
## Keywords:
- Dynamics
- Compliance and Impedance Control
## Abstract:
Modelling robot dynamics accurately is essential for control, motion optimisation and safe human-robot collaboration. Given the complexity of modern robotic systems, dynamics modelling remains non-trivial, mostly in the presence of compliant actuators, mechanical inaccuracies, friction and sensor noise. Recent efforts have focused on utilising data-driven methods such as Gaussian processes and neural networks to overcome these challenges, as they are capable of capturing these dynamics without requiring extensive knowledge beforehand. While Gaussian processes have shown to be an effective method for learning robotic dynamics with the ability to also represent the uncertainty in the learned model through its variance, they come at a cost of cubic time complexity rather than linear, as is the case for deep neural networks. In this work, we leverage the use of deep kernel models, which combine the computational efficiency of deep learning with the non-parametric flexibility of kernel methods (Gaussian processes), with the overarching goal of realising an accurate probabilistic framework for uncertainty quantification. Through using the predicted variance, we adapt the feedback gains as more accurate models are learned, leading to low-gain control without compromising tracking accuracy. Using simulated and real data recorded from a seven degree-of-freedom robotic manipulator, we illustrate how using stochastic variational inference with deep kernel models increases compliance in the computed torque controller, and retains tracking accuracy. We empirically show how our model outperforms current state-of-the-art methods with prediction uncertainty for online inverse dynamics model learning, and solidify its adaptation and generalisation capabilities across different setups.
# On the Performance and Passivity of Admittance Control with Feed-Forward Input
## Keywords:
- Compliance and Impedance Control
## Abstract:
This paper analyzes the effect of control parameters of feed-forward and inner loop velocity controller in an admittance control scheme on the performance and passivity. The interaction force, inertia, and damping compensation were considered as the feed-forward input. Sufficient conditions and guidelines for each parameter were provided to enable the implementation of a wide range of desired admittance satisfying passivity. The proposed guidelines were verified through experiments.
# Feel the Tension: Manipulation of Deformable Linear Objects in Environments with Fixtures Using Force Information
## Keywords:
- Force Control
- Perception for Grasping and Manipulation
- Compliant Assembly
## Abstract:
Humans are able to manipulate Deformable Linear Objects (DLOs) such as cables and wires, with little or no visual information, relying mostly on force sensing. In this work, we propose a reduced DLO model which enables such blind manipulation by keeping the object under tension. Further, an online model estimation procedure is also proposed. A set of elementary sliding and clipping manipulation primitives are defined based on our model. The combination of these primitives allows for more complex motions such as winding of a DLO. The model estimation and manipulation primitives are tested individually but also together in a real-world cable harness production task, using a dual-arm YuMi, thus demonstrating that force-based perception can be sufficient even for such a complex scenario.
# A Comparative Study of Force Observers for Accurate Force Control of Multisensor-Based Force Controlled Motion Systems
## Keywords:
- Force Control
- Motion Control
- Sensor Fusion
## Abstract:
This paper presents a comprehensive comparative study of the multisensor-based force observers for accurate force control. A force controlled system which contains a force sensor for measuring force transmitted to the load by the motor and an encoder for measuring motor position is considered as the general multisensor-based motion system in this study. Even though these multisensor-based motion systems are emerging as potential motion systems as the demands for collaborative robots increase, there has been few studies that investigate their advantages and limitations. To address this issue, three types of observer-based force controllers that utilize the multisensors are designed and implemented. These controllers exploit the availability of force sensor, motor encoder, and motor torque information from the multisensor-based motion system to estimate accurate force which is later utilized to close the feedback loop. Mathematical and quantitative analyses are conducted to compare performances of the proposed observer-based force control and through this, their advantages and limitations are pointed out. Finally, simulation and an experimental case study with an actual robot are conducted to validate the force tracking performance of the designed force control systems.
# Bio-Inspired Grasping Controller for Sensorized 2-DoF Grippers
## Keywords:
- Force Control
- Grasping
- Mobile Manipulation
## Abstract:
We present a holistic grasping controller, combining free-space position control and in-contact force-control for reliable grasping given uncertain object pose estimates. Employing tactile fingertip sensors, undesired object displacement during grasping is minimized by pausing the finger closing motion for individual joints on first contact until force-closure is established. While holding an object, the controller is compliant with external forces to avoid high internal object forces and prevent object damage. Gravity as an external force is explicitly considered and compensated for, thus preventing gravity-induced object drift. We evaluate the controller in two experiments on the TIAGo robot and its parallel-jaw gripper proving the effectiveness of the approach for robust grasping and minimizing object displacement. In a series of ablation studies, we demonstrate the utility of the individual controller components.
# Software, Middleware and Programming Environments 2
# Gazebo Fluids: SPH-Based Simulation of Fluid Interaction with Articulated Rigid Body Dynamics
## Keywords:
- Software, Middleware and Programming Environments
- Dynamics
- Biologically-Inspired Robots
## Abstract:
Physical simulation is an indispensable component of robotics simulation platforms that serves as the basis for a plethora of research directions. Looking strictly at robotics, the common characteristic of the most popular physics engines, such as ODE, DART, MuJoCo, bullet, SimBody, PhysX or RaiSim, is that they focus on the solution of articulated rigid bodies with collisions and contacts problems, while paying less attention to other physical phenomena. This restriction limits the range of addressable simulation problems, rendering applications such as soft robotics, cloth simulation, simulation of viscoelastic materials, and fluid dynamics, especially surface swimming, infeasible. In this work, we present Gazebo Fluids, an open-source extension of the popular Gazebo robotics simulator that enables the interaction of articulated rigid body dynamics with particle-based fluid and deformable solid simulation. We implement fluid dynamics and highly viscous and elastic material simulation capabilities based on the Smoothed Particle Hydrodynamics method. We demonstrate the practical impact of this extension for previously infeasible application scenarios in a series of experiments, showcasing one of the first self-propelled robot swimming simulations with SPH in a robotics simulator.
# SOCIALGYM: A Framework for Benchmarking Social Robot Navigation
## Keywords:
- Software Tools for Benchmarking and Reproducibility
- Human-Aware Motion Planning
- Data Sets for Robot Learning
## Abstract:
Robots moving safely and in a socially compliant manner in dynamic human environments is an essential benchmark for long-term robot autonomy. However, it is not feasible to learn and benchmark social navigation behaviors entirely in the real world, as learning is data-intensive, and it is challenging to make safety guarantees during training. Therefore, simulation-based benchmarks that provide abstractions for social navigation are required. A framework for these benchmarks would need to support a wide variety of learning approaches, be extensible to the broad range of social navigation scenarios, and abstract away the perception problem to focus on social navigation explicitly. While there have been many proposed solutions, including high fidelity 3D simulators and grid world approximations, no existing solution satisfies all of the aforementioned properties for learning and evaluating social navigation behaviors. In this work, we propose SOCIALGYM, a lightweight 2D simulation environment for robot social navigation designed with extensibility in mind, and a benchmark scenario built on SOCIALGYM. Further, we present benchmark results that compare and contrast human-engineered and model-based learning approaches to a suite of off-the-shelf Learning from Demonstration (LfD) and Reinforcement Learning (RL) approaches applied to social robot navigation. These results demonstrate the data efficiency, task performance, social compliance, and environment transfer capabilities for each of the policies evaluated to provide a solid grounding for future social navigation research.
# SROS2: Usable Cyber Security Tools for ROS 2
## Keywords:
- Software, Middleware and Programming Environments
- Software Tools for Robot Programming
- Software Architecture for Robotic and Automation
## Abstract:
ROS 2 is rapidly becoming a standard in the robotics industry. Built upon DDS as its default communication middleware and used in safety-critical scenarios, adding security to robots and ROS computational graphs is increasingly becoming a concern. The present work introduces SROS2, a series of developer tools and libraries that facilitate adding security to ROS 2 graphs. Focusing on a usability-centric approach in SROS2, we present a methodology for securing graphs systematically while following the DevSecOps model. We also demonstrate the use of our security tools by presenting an application case study that considers securing a graph using the popular Navigation2 and SLAM Toolbox stacks applied in a TurtleBot3 robot. We analyse the current capabilities of SROS2 and discuss the shortcomings, which provides insights for future contributions and extensions. Ultimately, we present SROS2 as usable security tools for ROS 2 and argue that without usability, security in robotics will be greatly impaired.
# Automatic Co-Design of Aerial Robots Using a Graph Grammar
## Keywords:
- Methods and Tools for Robot System Design
## Abstract:
Unmanned aerial vehicles (UAVs) have broad applications including disaster response, transportation, photography, and mapping. A significant bottleneck in the development of UAVs is the limited availability of automatic tools for task-specific co-design of a UAV's shape and controller. The development of such tools is particularly challenging as UAVs can take many forms, including fixed-wing planes, radial copters, and hybrid topologies, with each class of topology showing different advantages. In this work, we present a computational design pipeline for UAVs based on a graph grammar that can search across a wide range of topologies. Graphs generated by the grammar encode different topologies and component selections, while continuous parameters encode the dimensions and properties of each component. We further augment the shape representation with deformation cages, which allow expressing a variety of wing shapes. Each UAV design is associated with an LQR controller with tunable continuous parameters. To search over this complex discrete and continuous design space, we develop a hybrid algorithm that combines discrete graph search strategies and gradient-based continuous optimization methods using a differentiable UAV simulator. We evaluate our pipeline on a set of simulated flight tasks requiring dynamic motions, showing that it discovers novel UAV designs that outperform canonical UAVs typically made by engineers.
# ARviz – an Augmented Reality-Enabled Visualization Platform for ROS Applications (I)
## Keywords:
- Virtual Reality and Interfaces
- Human-Robot Collaboration
- Telerobotics and Teleoperation
## Abstract:
Current robot interfaces such as teach pendants and 2D screen displays used for task visualization and interaction often seem unintuitive and limited in terms of information flow. This compromises task efficiency as interacting with the interface can distract the user from the task at hand. Augmented Reality (AR) technology offers the capability to create visually rich displays and intuitive interaction elements in situ. In recent years, AR has shown promising potential to enable effective human-robot interaction. We introduce ARviz # a versatile, extendable AR visualization platform built for robot applications developed with the widely used Robot Operating System (ROS) framework. ARviz aims to provide both a universal visualization platform with the capability of displaying any ROS message data type in AR, as well as a multimodal user interface for interacting with robots over ROS. ARviz is built as a platform incorporating a collection of plugins that provide visualization and/or interaction components. Users can also extend the platform by implementing new plugins to suit their needs. We present three use cases as well as two potential use cases to showcase the capabilities and benefits of the ARviz platform for human-robot interaction applications. The open access source code for our ARviz platform is available at: https://github.com/hri-group/arviz.
# A RoboStack Tutorial: Using the Robot Operating System Alongside the Conda and Jupyter Data Science Ecosystems (I)
## Keywords:
- Software Tools for Robot Programming
- Software Tools for Benchmarking and Reproducibility
- Software Architecture for Robotic and Automation
## Abstract:
RoboStack tightly couples the widely-used Robot Operating System with Conda, a cross-platform, language-agnostic package manager, and Jupyter, a web-based interactive computational environment affording scientific computing. RoboStack provides new ROS packages for Conda, enabling the installation of ROS alongside data-science and machine-learning packages with ease. Multiple ROS versions (currently ROS1 Melodic and Noetic as well as ROS2 Foxy, Galactic and Humble) can run simultaneously on one machine, with pre-compiled binaries available for Linux, Windows and OSX, and the ARM architecture (e.g. the Raspberry Pi and the new Apple Silicon). To deal with the large size of the ROS ecosystem, we significantly improved the speed of the Conda solver and build system by rewriting the crucial parts in C++. We further contribute a collection of JupyterLab extensions for ROS, including plugins for live plotting, debugging and robot control, as well as tight integration with Zethus, an RViz like visualization tool. Taken together, RoboStack combines the best of the data-science and robotics worlds to help researchers and developers to build custom solutions for their academic and industrial projects.
# Safe-Control-Gym: A Unified Benchmark Suite for Safe Learning-Based Control and Reinforcement Learning in Robotics
## Keywords:
- Software Tools for Benchmarking and Reproducibility
- Machine Learning for Robot Control
- Reinforcement Learning
## Abstract:
In recent years, both reinforcement learning and learning-based control---as well as the study of their safety, which is crucial for deployment in real-world robots---have gained significant traction. However, to adequately gauge the progress and applicability of new results, we need the tools to equitably compare the approaches proposed by the controls and reinforcement learning communities. Here, we propose a new open-source benchmark suite, called safe-control-gym, supporting both model-based and data-based control techniques. We provide implementations for three dynamic systems---the cart-pole, the 1D, and 2D quadrotor---and two control tasks---stabilization and trajectory tracking. We propose to extend OpenAI's Gym API---the de facto standard in reinforcement learning research---with (i) the ability to specify (and query) symbolic dynamics and (ii) constraints, and (iii) (repeatably) inject simulated disturbances in the control inputs, state measurements, and inertial properties. To demonstrate our proposal and in an attempt to bring research communities closer together, we show how to use safe-control-gym to quantitatively compare the control performance, data efficiency, and safety of multiple approaches from the fields of traditional control, learning-based control, and reinforcement learning.
# On-Device CPU Scheduling for Robot Systems
## Keywords:
- Software Tools for Robot Programming
- Engineering for Robotic Systems
- Methods and Tools for Robot System Design
## Abstract:
Robots have to take highly responsive real-time actions, driven by complex decisions involving a pipeline of sensing, perception, planning, and reaction tasks. These tasks must be scheduled on resource-constrained devices such that the performance goals and the requirements of the application are met. This is a difficult problem that requires handling multiple scheduling dimensions, and variations in computational resource usage and availability. In practice, system designers manually tune parameters for their specific hardware and application, which results in poor generalization and increases the development burden. In this work, we highlight the emerging need for scheduling CPU resources at runtime in robot systems. We use robot navigation as a case-study to understand the key scheduling requirements for such systems. Armed with this understanding, we develop a CPU scheduling framework, Catan, that dynamically schedules compute resources across different components of an app so as to meet the specified application requirements. Through experiments with a prototype implemented on ROS, we show the impact of system scheduling on meeting the application’s performance goals, and how Catan dynamically adapts to runtime variations.
# Whole-Body Motion Planning and Control 1
# Whole-Body Control with Motion/Force Transmissibility for Parallel-Legged Robot
## Keywords:
- Whole-Body Motion Planning and Control
- Parallel Robots
- Humanoid and Bipedal Locomotion
## Abstract:
Whole-body control (WBC) with task priority transition is an important technology for robots to switch multiple behaviors, change different objectives, and adapt to various environments. Many methods have solved the problem of control continuity in the priority transition process. However, they either increased the computation consumption or sacrificed the accuracy of tasks in practical application. In this work, we propose a Recursive Hierarchical Projection (RHP) matrix and introduce it in Hierarchical Quadratic Programming (HQP). This RHP-HQP scheme can form continuously changing hierarchical projection and regard the WBC problem with task priority transition as a unified formulation. This unified formulation can be smoothly transitioned without increasing computation consumption and solved without losing task accuracy. The comparative simulations of the reactive collision avoidance verify that this priority transition scheme can guarantee high computational efficiency and task accuracy.
# Recursive Hierarchical Projection for Whole-Body Control with Task Priority Transition
## Keywords:
- Whole-Body Motion Planning and Control
- Optimization and Optimal Control
- Collision Avoidance
## Abstract:
Whole-body control (WBC) with task priority transition is an important technology for robots to switch multiple behaviors, change different objectives, and adapt to various environments. Many methods have solved the problem of control continuity in the priority transition process. However, they either increased the computation consumption or sacrificed the accuracy of tasks in practical application. In this work, we propose a Recursive Hierarchical Projection (RHP) matrix and introduce it in Hierarchical Quadratic Programming (HQP). This RHP-HQP scheme can form continuously changing hierarchical projection and regard the WBC problem with task priority transition as a unified formulation. This unified formulation can be smoothly transitioned without increasing computation consumption and solved without losing task accuracy. The comparative simulations of the reactive collision avoidance verify that this priority transition scheme can guarantee high computational efficiency and task accuracy.
# Multimodal Generation of Novel Action Appearances for Synthetic-To-Real Recognition of Activities of Daily Living
## Keywords:
- Multi-Modal Perception for HRI
- Transfer Learning
- Modeling and Simulating Humans
## Abstract:
Domain shifts, such as appearance changes, are a key challenge in real-world applications of activity recognition models, which range from assistive robotics and smart homes to driver observation in intelligent vehicles. For example, while simulations are an excellent way of economical data collection, a Synthetic->Real domain shift leads to >60% drop in accuracy when recognizing Activities of Daily Living (ADLs). We tackle this challenge and introduce an activity domain generation framework which creates novel ADL appearances (novel domains) from different existing activity modalities (source domains) inferred from video training data. Our framework computes human poses, heatmaps of body joints, and optical flow maps and uses them alongside the original RGB videos to learn the essence of source domains in order to generate completely new ADL domains. The model is optimized by maximizing the distance between the existing source appearances and the generated novel appearances while ensuring that the semantics of an activity is preserved through an additional classification loss. While source data multimodality is an important concept in this design, our setup does not rely on multi-sensor setups, (i.e., all source modalities are inferred from a single video only.) The newly created activity domains are then integrated in the training of the ADL classification networks, resulting in models far less susceptible to changes in data distributions. Extensive experiments on the Synthetic->Real benchmark Sims4Action demonstrate the potential of the domain generation paradigm for cross-domain ADL recognition, setting new state-of-the-art results. We will make our code publicly available to the community.
# Learning a Group-Aware Policy for Robot Navigation
## Keywords:
- Human-Aware Motion Planning
- Social HRI
- Modeling and Simulating Humans
## Abstract:
Human-aware robot navigation promises a range of applications in which mobile robots bring versatile assistance to people in common human environments. While prior research has mostly focused on modeling pedestrians as independent, intentional individuals, people move in groups; consequently, it is imperative for mobile robots to respect human groups when navigating around people. This paper explores learning group-aware navigation policies based on dynamic group formation using deep reinforcement learning. Through simulation experiments, we show that group-aware policies, compared to baseline policies that neglect human groups, achieve greater robot navigation performance (e.g., fewer collisions), minimize violation of social norms and discomfort, and reduce the robot’s movement impact on pedestrians. Our results contribute to the development of social navigation and the integration of mobile robots into human environments.
# Feedback-Efficient Active Preference Learning for Socially Aware Robot Navigation
## Keywords:
- Human-Aware Motion Planning
- Reinforcement Learning
- AI-Based Methods
## Abstract:
Socially aware robot navigation, where a robot is required to optimize its trajectory to maintain comfortable and compliant spatial interactions with humans in addition to reaching its goal without collisions, is a fundamental yet challenging task in the context of human-robot interaction. While existing learning-based methods have achieved better performance than the preceding model-based ones, they still have drawbacks: reinforcement learning depends on the handcrafted reward that is unlikely to effectively quantify broad social compliance, and can lead to reward exploitation problems; meanwhile, inverse reinforcement learning suffers from the need for expensive human demonstrations. In this paper, we propose a feedback-efficient active preference learning approach, FAPL, that distills human comfort and expectation into a reward model to guide the robot agent to explore latent aspects of social compliance. We further introduce hybrid experience learning to improve the efficiency of human feedback and samples, and evaluate benefits of robot behaviors learned from FAPL through extensive simulation experiments and a user study (N=10) employing a physical robot to navigate with human subjects in real-world scenarios. Source code and experiment videos for this work are available at: https://sites.google.com/view/san-fapl.
# Watch Out! There May Be a Human. Addressing Invisible Humans in Social Navigation
## Keywords:
- Human-Aware Motion Planning
- Human Detection and Tracking
- Human-Robot Collaboration
## Abstract:
Current approaches in human-aware or social robot navigation address the humans that are visible to the robot. However, it is also important to address the possible emergences of humans to avoid shocks or surprises to humans and erratic behavior of the robot planner. In this paper, we propose a novel approach to detect and address these human emergences called `invisible humans'. We determine the places from which a human, currently not visible to the robot, can appear suddenly and then adapt the path and speed of the robot with the anticipation of potential collisions. This is done while still considering and adapting humans present in the robot's field of view. We also show how this detection can be exploited to identify and address the doorways or narrow passages. Finally, the effectiveness of the proposed methodology is shown through several simulated and real-world experiments.
# Momentum-Aware Trajectory Optimization and Control for Agile Quadrupedal Locomotion
## Keywords:
- Whole-Body Motion Planning and Control
- Legged Robots
- Optimization and Optimal Control
## Abstract:
In this paper, we present a versatile hierarchical offline planning algorithm, along with and an online control pipeline for agile quadrupedal locomotion. Our offline planner alternates between optimizing centroidal dynamics for a reduced-order model and whole-body trajectory optimization, with the aim of achieving dynamics consensus. Our novel momentum-inertia-aware centroidal optimization, which uses an equimomental ellipsoid parameterization, is able to generate highly acrobatic motions via ``inertia shaping". Our whole-body optimization approach significantly improves upon the quality of standard DDP-based approaches by iteratively exploiting feedback from the centroidal level. For online control, we have developed a novel linearization of the full centroidal dynamics, and incorporated these into a convex model predictive control scheme. Our controller can efficiently optimize for both contact forces and joint accelerations in single optimization, enabling more straightforward tracking for momentum-rich motions compared to existing quadrupedal MPC controllers. We demonstrate the capability and generality of our trajectory planner on four different dynamic maneuvers. We then present hardware experiments on the MIT Mini Cheetah platform to demonstrate performance of the entire planning and control pipeline on a twisting jump maneuver.
# Discover Life Skills for Planning As Bandits Via Observing and Learning How the World Works
## Keywords:
- Hybrid Logical/Dynamical Planning and Verification
- Planning, Scheduling and Coordination
- Task Planning
## Abstract:
We propose a novel approach for planning agents to compose abstract skills via observing and learning from historical interactions with the world. Our framework operates in a Markov state-space model via a set of actions under unknown pre-conditions. We formulate skills as high-level abstract policies that propose action plans based on the current state. Each policy learns new plans by observing the states' transitions while the agent interacts with the world. Such an approach automatically learns new plans to achieve specific intended effects, but the success of such plans is often dependent on the states in which they are applicable. Therefore, we formulate the evaluation of such plans as infinitely many multi-armed bandit problems, where we balance the allocation of resources on evaluating the success probability of existing arms and exploring new options. The result is a planner capable of automatically learning robust high-level skills under a noisy environment; such skills implicitly learn the action pre-condition without explicit knowledge. We show that this planning approach is experimentally very competitive in high-dimensional state space domains.
# An Optimal Motion Planning Framework for Quadruped Jumping
## Keywords:
- Whole-Body Motion Planning and Control
- Optimization and Optimal Control
- Legged Robots
## Abstract:
This paper presents an optimal motion planning framework to generate versatile energy-optimal quadrupedal jumping motions automatically (e.g., flips, spin). The jumping motions via the centroidal dynamics are formulated as a 12-dimensional black-box optimization problem subject to the robot kino-dynamic constraints. Gradient-based approaches offer great success in addressing trajectory optimization (TO), yet, prior knowledge (e.g., reference motion, contact schedule) is required and results in sub-optimal solutions. The new proposed framework first employed a heuristics-based optimization method to avoid these problems. Moreover, a prioritization fitness function is created for heuristics-based algorithms in robot ground reaction force (GRF) planning, enhancing convergence and searching performance considerably. Since heuristics-based algorithms often require significant time, motions are planned offline and stored as a pre-motion library. A selector is designed to automatically choose motions with user-specified or perception information as input. The proposed framework has been successfully validated only with a simple continuously tracking PD controller in an open-source Mini-Cheetah by several challenging jumping motions, including jumping over a window-shaped obstacle with 30 cm height and left-flipping over a rectangle obstacle with 27 cm height.
# Intelligent Transportation Systems 1
# Trajectory Prediction with Graph-Based Dual-Scale Context Fusion
## Keywords:
- Intelligent Transportation Systems
- Deep Learning Methods
- Computer Vision for Transportation
## Abstract:
Motion prediction for traffic participants is essential for a safe and robust automated driving system, especially in cluttered urban environments. However, it is highly challenging due to the complex road topology as well as the uncertain intentions of the other agents. In this paper, we present a graph-based trajectory prediction network named the Dual Scale Predictor (DSP), which encodes both the static and dynamical driving context in a hierarchical manner. Different from methods based on a rasterized map or sparse lane graph, we consider the driving context as a graph with two layers, focusing on both geometrical and topological features. Graph neural networks (GNNs) are applied to extract features with different levels of granularity, and features are subsequently aggregated with attention-based inter-layer networks, realizing better local-global feature fusion. Following the recent goal-driven trajectory prediction pipeline, goal candidates with high likelihood for the target agent are extracted, and predicted trajectories are generated conditioned on these goals. Thanks to the proposed dual-scale context fusion network, our DSP is able to generate accurate and human-like multi-modal trajectories. We evaluate the proposed method on the large-scale Argoverse motion forecasting benchmark, and it achieves promising results, outperforming the recent state-of-the-art methods. We release the code on our project website.
# IMU Dead-Reckoning Localization with RNN-IEKF Algorithm
## Keywords:
- Intelligent Transportation Systems
- Autonomous Vehicle Navigation
- AI-Enabled Robotics
## Abstract:
In complex urban environments, the Inertial Navigation System (INS) is important for navigating unmanned ground vehicles (UAVs) for its environment-independency and reliability of real-time localization. It is usually employed as the baseline in the case of other sensors failures, such as the GPS, Lidar, or Cameras. However, one problem for the INS is that its estimation error of localization accumulates over time, and thus the estimated trajectories of the UAVs continue to drift away from their ground truths. To solve this problem, this paper proposes an improved algorithm based on the Invariant Extended Kalman Filter (IEKF) for dead-reckoning of autonomous vehicles, which dynamically adjusts the process noise and the observation noise covariance matrixes through Attention mechanism and Recurrent Neural Network (RNN). The algorithm achieves more robust and accurate dead-reckoning localization in the experiments conducted on the KITTI dataset, reducing the translational error by about 45%compared to the baseline.
# A Value-Based Dynamic Learning Approach for Vehicle Dispatch in Ride-Sharing
## Keywords:
- Intelligent Transportation Systems
- Planning, Scheduling and Coordination
## Abstract:
To ensure real-time response to passengers, existing solutions to the vehicle dispatch problem typically optimize dispatch policies using small batch windows and ignore the spatial-temporal dynamics over the long-term horizon. In this paper, we focus on improving the long-term performance of ride-sharing services and propose a deep reinforcement learning based approach for the ride-sharing dispatch problem. In particular, this work includes: (1) an offline policy evaluation (OPE) based method to learn a value function that indicates the expected reward of a vehicle reaching a particular state; (2) an online learning procedure to update the offline trained value function to capture the real-time dynamics during the operation; (3) an efficient online dispatch method that optimizes the matching policy by considering both past and future influences. Extensive simulations are conducted based on New York City taxi data, and show that the proposed solution further increases the service rate compared to the state-of-the-art farsighted ride-sharing dispatch approach.
# Deep Kernel Learning for Uncertainty Estimation in Multiple Trajectory Prediction Networks
## Keywords:
- Intelligent Transportation Systems
- AI-Based Methods
## Abstract:
Predicting future paths of vehicles or pedestrians is an essential task for automated vehicles to allow for planning the own trajectory. Using predicted paths, a planning algorithm can, e.g., react to anticipated manoeuvres of other traffic participants. For calculating risks of planned manoeuvres, it is essential that the predicted paths are generated with information about their uncertainty. Since today's state of the art trajectory prediction algorithms are based on deep neural networks (DNNs), the estimation of uncertainty is left to the neural networks as well, which usually provide no means of assessing how the uncertainty estimation works. In this paper, we present a combination of DNNs with Gaussian processes via Deep Kernel Learning (DKL), which combines the ability of DNNs to perform the prediction task with the advantage of Gaussian processes of having more interpretable probabilistic outputs. We propose and evaluate two different variants for the task of multimodal trajectory prediction using Stochastic Variational Gaussian Processes (SVGPs) and the recently proposed regression method Deep Sigma Point Processes (DSPPs), respectively. We evaluate the predictive distributions of both approaches on the publicly available Argoverse Motion Forecasting dataset and compare them to other, purely neural network based methods for uncertainty estimation.
# Development of a Research Testbed for Cooperative Driving in Mixed Traffic of Human-Driven and Autonomous Vehicles
## Keywords:
- Intelligent Transportation Systems
- Cooperating Robots
- Robot Companions
## Abstract:
This paper presents a cooperative driving testbed based on vehicle-to-vehicle (V2V) communication, which can be used for research in intelligent transportation systems, such as collision avoidance in mixed traffic of both human-driven vehicles and autonomous vehicles. To achieve the goal, an intelligent copilot is developed. The copilot can share the data regarding vehicle status, intention, etc, with other nearby vehicles through V2V communication. Several case studies are conducted to validate the proposed testbed and evaluate the performances of cooperative driving. When dangerous situations occur, the copilot solves the collision avoidance problem using Mixed Integer Programming (MIP), which either provides control commands to the autonomous vehicle, or advises the human driver to take action. Experimental results show that the safety and stability of the involved vehicles have been significantly enhanced. This cooperative driving testbed can be used by researchers to develop and test cooperative driving algorithms before they are deployed in real vehicles.
# Interventional Behavior Prediction: Avoiding Overly Confident Anticipation in Interactive Prediction
## Keywords:
- Intelligent Transportation Systems
- Agent-Based Systems
## Abstract:
Conditional behavior prediction (CBP) builds up the foundation for a coherent interactive prediction and planning framework that can enable more efficient and less conservative maneuvers in interactive scenarios. In CBP task, we train a prediction model approximating the posterior distribution of target agents' future trajectories conditioned on the future trajectory of an assigned ego agent. However, we argue that CBP may provide overly confident anticipation on how the autonomous agent may influence the target agents' behavior. Consequently, it is risky for the planner to query a CBP model. Instead, we should treat the planned trajectory as an intervention and let the model learn the trajectory distribution under intervention. We refer to it as the interventional behavior prediction (IBP) task. Moreover, to properly evaluate an IBP model with offline datasets, we propose a Shapley-value-based metric to verify if the prediction model satisfies the inherent temporal independence of an interventional distribution. We show that the proposed metric can effectively identify a CBP model violating the temporal independence, which plays an important role when establishing IBP benchmarks.
# InterSim: Interactive Traffic Simulation Via Explicit Relation Modeling
## Keywords:
- Intelligent Transportation Systems
- Simulation and Animation
- Computer Vision for Transportation
## Abstract:
Interactive traffic simulation is crucial to autonomous driving systems by enabling testing for planners in a more scalable and safe way compared to real-world road testing. Existing approaches learn an agent model from large-scale driving data to simulate realistic traffic scenarios, yet it remains an open question to produce consistent and diverse multi-agent interactive behaviors in crowded scenes. In this work, we present InterSim, an interactive traffic simulator for testing autonomous driving planners. Given a test plan trajectory from the ego agent, InterSim reasons about the interaction relations between the agents in the scene and generates realistic trajectories for each environment agent that are consistent with the relations. We train and validate our model on a large-scale interactive driving dataset. Experiment results show that InterSim achieves better simulation realism and reactivity in two simulation tasks compared to a state-of-the-art learning-based traffic simulator.
# Driving Anomaly Detection Using Contrastive Multiview Coding to Interpret Cause of Anomaly
## Keywords:
- Intelligent Transportation Systems
- Human-Centered Automation
- Multi-Modal Perception for HRI
## Abstract:
Modern advanced driver assistant systems (ADAS) rely on various types of sensors to monitor the vehicle status, driver’s behaviors and road condition. The multimodal systems in the vehicle include sensors, such as accelerometers, pressure sensors, cameras, lidar and radars. When looking at a given scene with multiple modalities, there should be congruent information among different modalities. Exploring the congruent information across modalities can lead to appealing solutions to create robust multimodal representations. This work proposes an unsupervised approach based on contrastive multiview coding (CMC) to capture the correlations in representations extracted from different modalities, learning a more discriminative representation space for unsupervised anomaly driving detection. We use CMC to train our model to extract view-invariant factors by maximizing the mutual information between multiple representations from a given view, and increasing the distance of views from unrelated segments. We consider the vehicle driving data, driver’s physiological data, and external environment data consisting of distances to nearby pedestrians, bicycles, and vehicles. The experimental results on the driving anomaly dataset (DAD) indicate that the CMC representation is effective for driving anomaly detection. The approach is efficient, scalable and interpretable, where the distances in the contrastive embedding for each view can be used to understand potential causes of the detected anomalies.
# TIP: Task-Informed Motion Prediction for Intelligent Vehicles
## Keywords:
- Intelligent Transportation Systems
- Intention Recognition
- Computer Vision for Transportation
## Abstract:
When predicting trajectories of road agents, motion predictors often approximate the future distribution by a limited number of samples. This constraint requires the predictors to generate samples that best support the task given task specifications. However, existing predictors are often optimized and evaluated via task-agnostic measures without accounting for the use of predictions in downstream tasks, and thus could result in sub-optimal task performance.
In this paper, we propose a task-informed motion prediction model that better supports the tasks through its predictions by jointly reasoning about prediction accuracy and the utility of the downstream tasks during training. The task utility function is commonly used to evaluate task performance. It does not require the full task information, but rather a specification of the utility of the task, resulting in predictors that are tailored to different downstream tasks. We demonstrate our approach on two use cases of common decision making tasks and their utility functions, in the context of autonomous driving and parallel autonomy. Experiment results show that our predictor produces accurate predictions that improve the task performance by a large margin in both tasks when compared to task-agnostic baselines on the Waymo Open Motion dataset.
# Semantic Scene Understanding 2
# Hybrid Belief Pruning with Guarantees for Viewpoint-Dependent Semantic SLAM
## Keywords:
- Semantic Scene Understanding
- Vision-Based Navigation
- Visual Servoing
## Abstract:
Semantic simultaneous localization and mapping is a subject of increasing interest in robotics and AI that directly influences the autonomous vehicles industry, the army industries, and more. One of the challenges in this field is to obtain object classification jointly with robot trajectory estimation. Considering view-dependent semantic measurements, there is a coupling between different classes, resulting in a combinatorial number of hypotheses. A common solution is to prune hypotheses that have a sufficiently low probability and to retain only a limited number of hypotheses. However, after pruning and renormalization, the updated probability is overconfident with respect to the original probability. This is especially problematic for systems that require high accuracy. If the prior probability of the classes is independent, the original normalization factor can be computed efficiently without pruning hypotheses. To the best of our knowledge, this is the first work to present these results. If the prior probability of the classes is dependent, we propose a lower bound on the normalization factor that ensures cautious results. The bound is calculated incrementally and with similar efficiency as in the independent case. After pruning and updating based on the bound, this belief is shown empirically to be close to the original belief.
# Invariant-Based World Models for Robust Robotic Systems Demonstrated on an Autonomous Football Table
## Keywords:
- Semantic Scene Understanding
- Mapping
- Engineering for Robotic Systems
## Abstract:
This work explains the use of invariants in robotic perception and control skills. An “invariant” is a mathematical constraint that remains unchanged under a particular transformation in a system. This property makes robotic functionalities more robust against “disturbances” that cause these transformation. These invariants are stored in a world model (WM), which has a central role in the information architecture of the robot to share information between components. A “robotic” football table serves as an example to illustrate the effectiveness of invariants. Despite looking different, all standard football tables satisfy the same set of invariants; the common layout of the field, line markings and puppets, which are not identical but satisfy the same set of constraints, such as parallelism, partial ordering, and relative colour and intensity differences between objects. During initialization, the invariants are actively identified and saved to the world model. During game play this world model is used by the perception and action skills and is updated when necessary. This work shows how the use of invariants creates robustness against variation in placement of the perception system and against variation in table dimensions and colours. When the camera is misaligned or moved mid-play, the world model is updated to ensure a smooth continuation of the game. The approach is tested on three standard football tables, with different dimensions and colours, showing that the approach is robust on standard tables that adhere to the invariants.
# Efficient Spatial-Temporal Information Fusion for LiDAR-Based 3D Moving Object Segmentation
## Keywords:
- Semantic Scene Understanding
- Deep Learning Methods
- Deep Learning for Visual Perception
## Abstract:
Accurate moving object segmentation is an essential task for autonomous driving. It can provide effective information for many downstream tasks, such as collision avoidance, path planning, and static map construction. How to effectively exploit the spatial-temporal information is a critical question for 3D LiDAR moving object segmentation (LiDAR-MOS). In this work, we propose a novel deep neural network exploiting both spatial-temporal information and different representation modalities of LiDAR scans to improve LiDAR-MOS performance. Specifically, we first use a range image-based dual-branch structure to separately deal with spatial and temporal information that can be obtained from sequential LiDAR scans, and later combine them using motion-guided attention modules. We also use a point refinement module via 3D sparse convolution to fuse the information from both LiDAR range image and point cloud representations and reduce the artifacts on the borders of the objects. We verify the effectiveness of our proposed approach on the LiDAR-MOS benchmark of SemanticKITTI. Our method outperforms the state-of-the-art methods significantly in terms of LiDAR-MOS IoU. Benefiting from the devised coarse-to-fine architecture, our method operates online at sensor frame rate. Code is available at: https://github.com/haomo-ai/MotionSeg3D.
# Robust Visual Teach and Repeat for UGVs Using 3D Semantic Maps
## Keywords:
- Semantic Scene Understanding
- SLAM
- Vision-Based Navigation
## Abstract:
In this paper, we propose a Visual Teach and Repeat (VTR) algorithm using semantic landmarks extracted from environmental objects for ground robots with fixed mount monocular cameras. The proposed algorithm is robust to changes in the starting pose of the camera/robot, where a pose is defined as the planar position plus the orientation around the vertical axis. VTR consists of a teach phase in which a robot moves in a prescribed path, and a repeat phase in which the robot tries to repeat the same path starting from the same or a different pose. Most available VTR algorithms are pose dependent and cannot perform well in the repeat phase when starting from an initial pose far from that of the teach phase. To achieve more robust pose independency, the key is to generate a 3D semantic map of the environment containing the camera trajectory and the positions of surrounding objects during the teach phase. For specific implementation, we use ORB-SLAM to collect the camera poses and the 3D point clouds of the environment, and YOLOv3 to detect objects in the environment. We then combine the two outputs to build the semantic map. In the repeat phase, we relocalize the robot based on the detected objects and the stored semantic map. The robot is then able to move toward the teach path, and repeat it in both forward and backward directions. We have tested the proposed algorithm in different scenarios and compared it with two most relevant recent studies. The results show that our algorithm is much more robust with respect to pose variations as well as environmental alterations. Our code and data are available at the following Github page: https://github.com/mmahdavian/semantic_visual_teach_repeat.
# Perceiving the Invisible: Proposal-Free Amodal Panoptic Segmentation
## Keywords:
- Semantic Scene Understanding
- Object Detection, Segmentation and Categorization
- Deep Learning for Visual Perception
## Abstract:
Amodal panoptic segmentation aims to connect the perception of the world to its cognitive understanding. It entails simultaneously predicting the semantic labels of visible scene regions and the entire shape of traffic participant instances, including regions that may be occluded. In this work, we formulate a proposal-free framework that tackles this task as a multi-label and multi-class problem by first assigning the amodal masks to different layers according to their relative occlusion order and then employing amodal instance regression on each layer independently while learning background semantics. We propose the net architecture that incorporates a shared backbone and an asymmetrical dual-decoder consisting of several modules to facilitate within-scale and cross-scale feature aggregations, bilateral feature propagation between decoders, and integration of global instance-level and local pixel-level occlusion reasoning. Further, we propose the amodal mask refiner that resolves the ambiguity in complex occlusion scenarios by explicitly leveraging the embedding of unoccluded instance masks. Extensive evaluation on the BDD100K-APS and KITTI-360-APS datasets demonstrate that our approach set the new state-of-the-art on both benchmarks.
# Meta-RangeSeg: LiDAR Sequence Semantic Segmentation Using Multiple Feature Aggregation
## Keywords:
- Semantic Scene Understanding
- Object Detection, Segmentation and Categorization
- Deep Learning for Visual Perception
## Abstract:
LiDAR sensor is essential to the perception system in autonomous vehicles and intelligent robots. To fulfill the real-time requirements in real-world applications, it is necessary to efficiently segment the LiDAR scans. Most of previous approaches directly project 3D point cloud onto the 2D spherical range image so that they can make use of the efficient 2D convolutional operations for image segmentation. Although having achieved the encouraging results, the neighborhood information is not well-preserved in the spherical projection. Moreover, the temporal information is not taken into consideration in the single scan segmentation task. To tackle these problems, we propose a novel approach to semantic segmentation for LiDAR sequences named Meta-RangeSeg, where a new range residual image representation is introduced to capture the spatial-temporal information. Specifically, Meta-Kernel is employed to extract the meta features, which reduces the inconsistency between the 2D range image coordinates input and 3D Cartesian coordinates output. An efficient U-Net backbone is used to obtain the multi-scale features. Furthermore, Feature Aggregation Module (FAM) strengthens the role of range channel and aggregates features at different levels. We have conducted extensive experiments for performance evaluation on SemanticKITTI and SemanticPOSS. The promising results show that our proposed Meta-RangeSeg method is more efficient and effective than the existing approaches. Our full implementation is publicly available at https://github.com/songw-zju/Meta-RangeSeg.
# Receding Moving Object Segmentation in 3D LiDAR Data Using Sparse 4D Convolutions
## Keywords:
- Semantic Scene Understanding
- Deep Learning Methods
## Abstract:
A key challenge for autonomous vehicles is to navigate in unseen dynamic environments. Separating moving objects from static ones is a key task for navigation, pose estimation, and understanding how other traffic participants are likely to move in the near future. In this work, we tackle the problem of distinguishing 3D LiDAR points that belong to currently moving objects, like walking pedestrians or driving cars, from points that are obtained from non-moving objects, like walls but also parked cars. Our approach takes a sequence of observed LiDAR scans and turns them into a voxelized sparse 4D point cloud. We apply computationally efficient sparse 4D convolutions to jointly extract spatial and temporal features and predict moving object confidence scores for all points in the sequence. We develop a receding horizon strategy that allows us to predict moving objects online and to refine predictions on the go based on new observations. We use a binary Bayes filter to recursively integrate new predictions of a scan resulting in more robust estimation. We evaluate our approach on the SemanticKITTI moving object segmentation challenge and show more accurate predictions than existing methods. Since our approach only operates on the geometric information of point clouds over time, it generalizes well to new, unseen environments, which we evaluate on the Apollo dataset.
# Unsupervised Class-Agnostic Instance Segmentation of 3D LiDAR Data for Autonomous Vehicles
## Keywords:
- Semantic Scene Understanding
- Deep Learning Methods
## Abstract:
Fine-grained scene understanding is essential for autonomous driving. The context around a vehicle can change drastically while navigating, making it hard to identify and understand the different objects that may appear. Although recent efforts on semantic and panoptic segmentation pushed the field of scene understanding forward, it is still a challenging task. Current methods depend on annotations provided before deployment and are bound by the labeled classes, ignoring long-tailed classes not annotated in the training data due to the scarcity of examples. However, those long-tailed classes, such as baby strollers or unknown animals, can be crucial when interpreting the vehicle surroundings, e.g., for safe interaction. We address the problem of class-agnostic instance segmentation in this paper that also tackles the long-tailed classes. We propose a novel approach and a benchmark for class-agnostic instance segmentation and a thorough evaluation of our method on real-world data. Our method relies on a self-supervised trained network to extract point-wise features to build a graph representation of the point cloud. Then, we use GraphCut to perform foreground and background separation, achieving instance segmentation without requiring any label. Our results show that our approach is able to achieve instance segmentation and a competitive performance compared to state-of-the-art supervised methods.
# FedDrive: Generalizing Federated Learning to Semantic Segmentation in Autonomous Driving
## Keywords:
- Semantic Scene Understanding
- Computer Vision for Automation
- Deep Learning for Visual Perception
## Abstract:
Semantic Segmentation is essential to make self-driving vehicles autonomous, enabling them to understand their surroundings by assigning individual pixels to known categories. However, it operates on sensible data collected from the users’ cars; thus, protecting the clients’ privacy becomes a primary concern. For similar reasons, Federated Learning has been recently introduced as a new machine learning paradigm aiming to learn a global model while preserving privacy and leveraging data on millions of remote devices. Despite several efforts on this topic, no work has explicitly addressed the challenges of federated learning in semantic segmentation for driving so far. To fill this gap, we propose FedDrive, a new benchmark consisting of three settings and two datasets, incorporating the real-world challenges of statistical heterogeneity and domain generalization. We benchmark state-of-the-art algorithms from the federated learning literature through an in-depth analysis, combining them with style transfer methods to improve their generalization ability. We demonstrate that correctly handling normalization statistics is crucial to deal with the aforementioned challenges. Furthermore, style transfer improves performance when dealing with significant appearance shifts. Official website: https://feddrive.github.io.
# Multi-Robot Systems 2
# Collecting a Flock with Multiple Sub-Groups by Using Multi-Robot System
## Keywords:
- Multi-Robot Systems
- Distributed Robot Systems
- Robotics and Automation in Agriculture and Forestry
## Abstract:
In this letter, we present a distributed approach to automatically collect a flock with a group of robots. This collecting problem is challenging due to the fact that the flock size is usually much greater than that of robots, meantime the local sensing range of robots may not ensure a globally successful collecting. Existing literature for collecting flocks assumes that the flocks are coherent, however, this limits the practicality of these approaches especially in the case where there are multiple sub-groups. To address these issues, we relax the assumption and propose a density-based strategy, which can drive the robots to move towards the edge of the flock in an edge-following behavior and ultimately encircle the flock. Once encircled, a shrink mechanism is used for squeezing the flock into a tight cluster. Collecting a single cluster and collecting a flock with multiple sub-groups can be achieved by using such edge-following behavior in combination with shrink mechanism. The lower bound on the minimum number of robots required for successfully collecting a given flock size is also theoretically investigated. We validate the performance of our approach via numerical simulations and the number of robots required for a successful collecting operation is validated by using statistical simulation results for a range of flock sizes.
# A Hybrid PSO Algorithm for Multi-Robot Target Search and Decision Awareness
## Keywords:
- Multi-Robot Systems
- Swarm Robotics
- Cooperating Robots
## Abstract:
Groups of robots can be tasked with identifying a location in an environment where a feature cue is past a threshold, then disseminating this information throughout the group -# such as identifying a high-enough elevation location to place a communications tower. This is a continuous-cue target search, where multi-robot search algorithms like particle swarm optimization (PSO) can improve search time through parallelization. However, many robots lack global communication in large spaces, and PSO-based algorithms often fail to consider how robots disseminate target knowledge after a single robot locates it. We present a two-stage hybrid algorithm to solve this task: (1) locating a target with a variation of PSO, and (2) moving to maximize target knowledge across the group. We conducted parameter sweep simulations of up to 32 robots in a grid-based grayscale environment. Pre-decision, we find that PSO with a variable velocity update interval improves target localization. In the post-decision phase, we show that dispersion is the fastest strategy to communicate with all other robots. Our algorithm is also competitive with a coverage sweep benchmark, while requiring significantly less inter-individual coordination.
# Interactive Multi-Robot Aerial Cinematography through Hemispherical Manifold Coverage
## Keywords:
- Multi-Robot Systems
- Aerial Systems: Applications
- Cooperating Robots
## Abstract:
This paper presents a distributed interactive framework to provide high-level position instructions for multi-robot aerial cinematography based on coverage over a hemisphere. The control strategy based on optimization of the coverage functional and geometric relationships over a hemisphere is presented. It enables multiple Unmanned Aerial Vehicles (UAVs) to coordinate their motion while tracking a dynamic (real or virtual) target, and can accommodate high-level human inputs to influence UAV concentration. In this framework, each UAV uses local information combined with exogenous inputs to determine its motion. The two inputs to the system, i.e., the predicted trajectory of the target and user-defined aesthetic preferences, are agnostic to the size of the multi-robot system (MRS). The proposed framework is validated using the PX4 SITL Autopilot simulator in Gazebo, and the scalability of the framework is verified via simulations.
# Passive Multiuser Teleoperation of a Multirobot System with Connectivity-Preserving Containment (I)
## Keywords:
- Telerobotics and Teleoperation
- Multi-Robot Systems
- Networked Robots
## Abstract:
A remote multirobot system (RMRS) outfitted with wireless sensors for large-scale data collection may need to be tele-driven by several human users simultaneously. The long distances between the users’ local robots and the RMRS can inject time-varying delays in their communications. This paper enables such multiuser teleoperation of an RMRS through a control strategy that: robustly synchronizes an RMRS with tree topology and proximity-limited 1-hop communications among its robots; enables multiple users to tele-guide the RMRS and to feel the actions of the other users over time-delayed communications between the users’ local robots and the RMRS; and contains the RMRS to the stationary convex hull spanned by the local robots of all users in steady-state. A control design constrained by the connectivity of the RMRS and by the passivity of the teleoperator guarantees effective coordination, safe teleoperation and steady-state containment. The design is a dynamic feedforward-feedback passivation strategy facilitated by a suitable decomposition of the teleoperator into interconnected subsystems. The analysis of the storage functions, and thus of the input-output relations, of all subsystems and their interconnections proves the properties of the design.
# PD-FAC: Probability Density Factorized Multi-Agent Distributional Reinforcement Learning for Multi-Robot Reliable Search
## Keywords:
- Multi-Robot Systems
- Reinforcement Learning
- Cooperating Robots
## Abstract:
This paper presents a new range of multi-robot search for a non-adversarial moving target problems, namely, multi-robot reliable search (MuRRS). The term `reliability' in MuRRS is defined as the expectation of a predefined utility function over the probability density function (PDF) of the target's capture time. We argue that MuRRS subsumes the canonical multi-robot efficient search (MuRES) problem, which minimizes the target's expected capture time, as its special case, and offers the end user with a wide range of objective selection options. Since state-of-the-art algorithms are usually targeting the multi-robot efficient problem, and cannot offer up-to-standard performance to the various MuRRS objectives, we, thereby, propose a probability density factorized multi-agent distributional reinforcement learning method, namely, PD-FAC, as a unified solution to the MuRRS problem. PD-FAC decomposes the PDF of the multi-robot system's overall value distribution into a set of individual value distributions and guarantees that any reliability objective defined as a function of the overall system's value distribution can be linearly approximated by the same reliability metric defined over the agent's individual value distribution. In this way, the individual global maximum (IGM) principle is satisfied for all the pre-defined reliability metrics. It means that when each reinforcement learning agent is executing the individual policy, which maximizes its own reliability metric, the system's overall reliability performance is also maximized. We evaluate and compare the performance of PD-FAC with state of the arts in a range of canonical multi-robot search environments with satisfying results, and also deploy PD-FAC to a real multi-robot system for the moving target search in a self-constructed indoor environment.
# Cooperative Towing by Multi-Robot System That Maintains Welding Cable in Optimized Shape
## Keywords:
- Multi-Robot Systems
- Industrial Robots
- Constrained Motion Planning
## Abstract:
As considerable amounts of welding are required during ship construction, robotic automation is being promoted. However, current welding robots do not automate work in high or narrow places. One reason is that welding cannot be performed with sufficient accuracy because a welding robot with a torch cannot tow a heavy cable and thus may go off path. This paper proposes a swarm robot system for automating the execution of long welds in high and narrow places to address this problem. In the proposed method, towing vehicles are placed along the supply cable to reduce the load on the lead welding vehicle. In confined-space welding, the cable must not be excessively loaded, and obstacles such as walls must be avoided. Under the proposed method, autonomous movement of the towing vehicles is achieved by solving an optimization problem that considers these aims and minimizes the amount of change from the estimated current cable shape. The method was evaluated through simulation and real-world tests, in which it was applied successfully to tow the cable with a welding torch in a working area of 2.6 × 10 m2 (simulation) and of 3.4 × 5.5 m2 (real-world environment) without disturbing the lead vehicle’s movement.
# Impressionist Algorithms for Autonomous Multi-Robot Systems: Flocking As a Case Study
## Keywords:
- Multi-Robot Systems
- Behavior-Based Systems
- Autonomous Agents
## Abstract:
Robot swarms have the potential to revolutionize areas ranging from warehouse management and agriculture to underwater and space exploration. However, there remains a substantial gap between theory and robot implementation. While algorithms might assume reliable communication, perfect sensing, and instantaneous cognition, most robots have lossy or even no communication, imperfect sensing, and limited cognition speed. In our previous work on implicit vision-based coordination, we demonstrated autonomous three-dimensional behaviors underwater by removing the need for radio communication between robots. Here we explore impressionist algorithms, capable of working with even more minimal in# formation where traditional algorithms are prone to fail. Our case study focuses on classic flocking behaviors, where a robot swarm must coordinate group motion. We demonstrate that reliable alignment, dispersion, and milling can be achieved with only infrequent and imperfect sensory impressions. In simulation studies and theoretical analyses, we investigate the effect of systematically reducing spatial and temporal fidelity of individual information on the success metrics for the group; we also demonstrate physical experiments with Blueswarm robots using simple color detection. Our results show the potential of impressionist algorithms that operate on simpler neighborhood# awareness metrics and still achieve desired global goals.
# Decentralized Multi-Robot Velocity Estimation for UAVs Enhancing Onboard Camera-Based Velocity Measurements
## Keywords:
- Multi-Robot Systems
- Distributed Robot Systems
- Localization
## Abstract:
 Within the field of multi-robot systems, developing systems that rely only on onboard sensing without the use of external infrastructure (e.g. GNSS) has many potential applications. However, relying only on visual-based modalities for localization presents challenges in terms of accuracy and reliability. We introduce a decentralized multi-robot lateral velocity estimation method for Unmanned Aerial Vehicles (UAVs) to improve onboard measurements in case GNSS infrastructure is not available. This method relies on sharing the onboard measurements of neighbors, as well as the estimation of the relative motion of a focal UAV within the swarm, based on observation of coworking robots. The proposed velocity estimation method does not rely on centralized communication to achieve high reliability and scalability within the swarm system. The performance of the state estimation approach has been verified in simulations and real-world experiments. The results have shown that a swarm of UAVs using the proposed velocity estimator can stabilize individual robots when their primary onboard localization source is not reliable enough.
# Autonomous Service Robots for Urban Waste Management # Multiagent Route Planning and Cooperative Operation
## Keywords:
- Multi-Robot Systems
- Swarm Robotics
- Robotics in Hazardous Fields
## Abstract:
Sustainable approach towards smart waste management means reduced impact on the health of the workers, lower greenhouse gas emissions and
low operational costs. Incorporating fleets of the robot MARBLE (Mobile
Autonomous RoBot for Litter Emptying) effectuates these requirements for autonomously emptying the dustbins on the streets of Berlin. The dedicated waypoints for the route formulation are the global positions of the dustbins, and the garbage emptying position from the robots after reaching the maximum compressed-garbage storage capacity. In this
paper, we provide a cost function efficient solution for providing global routes to the robots. The cost function includes operational energy expenditure. After conducting numerous experiments with varying algorithm parameter values, the specific weightage of route permutation
operators and the initial temperature for a simulated annealing method with nearest neighbour approach was narrowed down to an well-performing
set. This set was used in three different operation scenarios. The results of the cost function on the basis of the chosen parameters show
an improvement of average 28% for two different exemplary datasets, and
30% improvement for an implementation in an actual existing park in Berlin for operation scenarios as compared to results from a nearest neighbour heuristic.
# Soft Sensors and Actuators 2
# Mechanically Programmable Jamming Based on Articulated Mesh Structures for Variable Stiffness Robots
## Keywords:
- Soft Sensors and Actuators
- Soft Robot Applications
- Actuation and Joint Mechanisms
## Abstract:
Soft robots are capable of effortlessly adapting to their environment using elastic materials that impart structural compliance into their designs, allowing them to execute complex tasks with minimal sensing and control. However, soft robots cannot exert high forces and can only handle low deformation forces. These characteristics typically limit their applicability to tasks that require delicate interactions. In this work, we present a mechanically programmable, variable stiffness, jamming actuator based on an articulated mesh structure. The proposed actuator can elastically bend when it is not activated but compresses to attain a pre-programmed shape that is determined by the mesh geometry of the multi-layer jamming architecture when pressure is applied to the silicone pouch containing it. Unlike traditional jamming structures the utilisation of the articulated mesh structure facilitates elastic deformations past the yield point when jammed. The actuator can become >27 times stiffer than its relaxed configuration when exposed to only 90 kPa pressure. We demonstrate the efficiency of this actuator by developing variable stiffness joints that can be used to create: i) underactuated, tendon driven robotic grippers and soft, disposable robotic grippers that exhibit increased dexterity and ii) wearable, affordable, lightweight elbow exoskeleton systems that can assist humans in holding heavy objects with minimal effort.
# Electroadhesive Clutches for Programmable Shape Morphing of Soft Actuators
## Keywords:
- Soft Sensors and Actuators
- Soft Robot Materials and Design
- Soft Robot Applications
## Abstract:
Soft robotic actuators are safe and adaptable devices with inherent compliance, which makes them attractive for manipulating delicate and complex objects. Researchers have integrated stiff materials into soft actuators to increase their force capacity and direct their deformation. However, these embedded materials have largely been pre-prescribed and static, which constrains the actuators to a predetermined range of motion. In this work, electroadhesive (EA) clutches integrated on a single-chamber soft pneumatic actuator (SPA) provide local programmable stiffness modulation to control the actuator deformation. We show that activating different clutch patterns inflates a silicone membrane into pyramidal, round, and plateau shapes. Curvatures from these shapes are combined during actuation to apply forces on both a 3.7 g and 820 g object along five different degrees of freedom (DoF). The actuator workspace is up to 12 mm for light objects. Clutch deactivation, which results in local elastomeric expansion, rapidly applies forces up to 3.2 N to an object resting on the surface and launches a 3.7 g object in controlled directions. The actuator also rotates a heavier, 820 g, object by 5 degrees and rapidly restores it to horizontal alignment after clutch deactivation. This actuator is fully powered by a 5 V battery, AA battery, DC-DC transformer, and 4.5 V (63 g) DC air pump. These results demonstrate a first step towards realizing a soft actuator with high DoF shape change that preserves the inherent benefits of pneumatic actuation while gaining the electrical controllability and strength of EA clutches. We envision such a system supplying human contact forces in the form of a low-profile sit-to-stand assistance device, bed-ridden patient manipulator, or other ergonomic mechanism.
# Modeling and Position Control of the HASEL Actuator Via Port-Hamiltonian Approach
## Keywords:
- Soft Sensors and Actuators
- Modeling, Control, and Learning for Soft Robots
- Robust/Adaptive Control
## Abstract:
This paper deals with the modeling and control problem of a Hydraulically Amplified Self-healing Electrostatic (HASEL) actuator based on the port-Hamiltonian framework. A nonlinear spring-damper system is used to approximate the mechanical deformation of the actuator due to the motion of the fluid while a nonlinear capacitance is used to approximate the electric behavior of the system. The actuator position control strategy is investigated based on the Interconnection Damping Assignment-Passivity Based Control (IDA-PBC) method, with further Integral Actions (IA) added to cope with load uncertainties. The proposed model and control laws are validated on an experimental benchmark. The experimental tests demonstrate that the proposed model is accurate up to 94% of fitness. The controllers allow assigning the actuator position with ramp and sinusoidal references with the relative error less than 5%. At last, the robustness of the proposed IDA-PBC controller with IA has been shown with the experimental result for the unknown load disturbance rejection.
# Motion Tracking Smart Work Suit with a Modular Joint Angle Sensor Using Screw Routing
## Keywords:
- Soft Sensors and Actuators
- Soft Robot Applications
- Human Detection and Tracking
## Abstract:
Activity data of workers can be used to manage their safety and working processes. To date, the adoption of motion measuring systems in industrial sites has been limited, due to cost and noisy environments. In this study, a motion-tracking smart work suit is presented to monitor the movements of workers. This system comprises modular joint-angle sensors that utilize a BoASensor mechanism, a conventional work suit with added sensor sleeves, and a monitoring device. The modularized joint-angle sensor can be easily attached or detached onto or from the normal work suit, improving its usability and washability. This suit could experience relative motion and deformation between the body, degrading sensor robustness, unlike conventional motion sensing suits. The screw sensor routing method is proposed to minimize the coordination effect between the sensor and skeletal system during body movements. Various postures recorded with the suit exhibited root mean square errors lower than 7.75% from the elbow range of motion (150°) compared with the inertial-measurement-unit-(IMU)-based motion tracker. It was determined that there exists statistical significance between the proposed screw-routing method and the IMU in precision, thereby demonstrating sensing robustness with various upper limb motions. Additionally, the linearity analysis revealed that screw-routing has the highest linear behavior. The proposed work suit is expected to be utilized in preventing industrial accidents at various sites, owing to its low production cost and high accessibility.
# 3D Curvature-Based Tip Load Estimation for Continuum Robots
## Keywords:
- Soft Sensors and Actuators
- Micro/Nano Robots
- Modeling, Control, and Learning for Soft Robots
## Abstract:
This letter presents a method intended for the estimation of external force and moment applied at the tip of thin rods using vision-based shape measurements, with a view to be applied on continuum robots. A versatile vision process is developed that does not require any additional markers nor sensors to provide an accurate tri-dimensional reconstruction of the deformable rod shape. Then, the tip loads (i.e., forces and moments) are directly deduced from the curvature along this curve formed by deformed rod thanks to the resolution of a linear system without requiring any iterative optimization. The curvature is determined with a robust method that allows filtering out measurement noise and artifacts. Simulations show that this approach gives fast and precise results in both 2D (planar forces estimation without torsion) and 3D (spatial forces estimation). Experimental results on cantilever rods demonstrate an accuracy of 2.2% and 2.7% of the applied forces and moments, respectively.
# Optimizing Out-Of-Plane Stiffness for Soft Grippers
## Keywords:
- Soft Sensors and Actuators
- Soft Robot Materials and Design
- Soft Robot Applications
## Abstract:
In this paper, we presented a data-driven framework to optimize the out-of-plane stiffness for soft grippers to achieve mechanical properties as hard-to-twist and easy-to-bend. The effectiveness of this method is demonstrated in the design of a soft pneumatic bending actuator (SPBA). First, a new objective function is defined to quantitatively evaluate the out-of-plane stiffness as well as the bending performance. Then, sensitivity analysis is conducted on the parametric model of an SPBA design to determine the optimized design parameters with the help of Finite Element Analysis (FEA). To enable the computation of numerical optimization, a data-driven approach is employed to learn a cost function that directly represents the out-of-plane stiffness as a differentiable function of the design variables. A gradient-based method is used to maximize the out-of-plane stiffness of the SPBA while ensuring specific bending performance. The effectiveness of our method has been demonstrated in physical experiments taken on 3D-printed grippers.
# Wire-Storage Pantograph Mechanism for Strain and Force Amplification of a Twisted and Coiled Polymer Fiber
## Keywords:
- Soft Sensors and Actuators
- Soft Robot Applications
- Tendon/Wire Mechanism
## Abstract:
A twisted and coiled polymer fiber (TCPF) is a soft thermal actuator increasingly used in current robotics applications. When implementing TCPF in robotics applications, amplifying the TCPF strain and force is necessary to obtain the desired performance. Therefore, this study proposes a mechanism to amplify the strain and force of a TCPF. Considering the TCPF as a wire, the fixed and movable pulley mechanisms are available to amplify the TCPF strain and force, respectively. However, the amplification mechanism becomes bulky when the fixed pulleys are installed separately from the movable pulleys; thus, the TCPF utility reduces. This study focuses on two characteristics of the pantograph to design a compact amplification mechanism. The first characteristic is that the pulleys on the pantograph diagonal axes can be used as a movable pulley mechanism. The other characteristic is that the pantograph circumference can be a fixed pulley mechanism, as the circumference is always invariant. Based on these characteristics, the proposed mechanism can amplify both the TCPF strain and force. The experiments show that the force is amplified based on the number of loops around the diagonal axes. Although the load and temperature affect the strain amplification, the experiments confirm that the strain is amplified. In particular, depending on the loop number, the strain becomes 5.8 times the TCPF strain while maintaining the force level. Furthermore, changing the loop number, the strain and force are amplified 2.8 times and 2 times, respectively.
# Vision-Based Sensing for Electrically-Driven Soft Actuators
## Keywords:
- Soft Sensors and Actuators
- Perception for Grasping and Manipulation
- Force and Tactile Sensing
## Abstract:
Developing reliable control strategies in soft robotics requires advances in soft robot perception. However, current soft robotic sensors pose many performance limitations, and available materials and manufacturing techniques complicate soft sensorized robot design. To address these long-standing needs, we introduce a method for using vision to sensorize robust, electrically-driven soft robotic actuators constructed from a new class of architected materials. Specifically, we use cameras positioned within the hollow interiors of handed shearing auxetic (HSA) actuators to record deformation during motion. We train a convolutional neural network (CNN) that maps the visual feedback to the actuator's tip pose. Our model provides predictions with sub-millimeter accuracy from only six minutes of training data, while remaining lightweight with an inference time of 18 milliseconds per frame. We also develop a model that additionally predicts the horizontal tip force acting on the actuator and generalizes to previously unseen forces. Finally, we demonstrate the viability of our sensorization strategy for contact-rich applications by training a CNN that predicts the tip pose accurately during tactile interactions. Overall, our methods present a reliable vision-based approach for designing sensorized soft robots built from electrically-actuated, architected materials.
# FEA-Based Inverse Kinematic Control: Hyperelastic Material Characterization of Self-Healing Soft Robots (I)
## Keywords:
- Kinematics
- Soft Sensors and Actuators
- Modeling, Control, and Learning for Soft Robots
## Abstract:
Recent advances in soft continuum robots revealed the need for accurate models, required to develop advanced control strategies. In this paper a general methodology is presented that allows to create an accurate inverse kinematic control based on hyperelastic models, fitted on mechanical material properties. This methodology is based on finite element analysis (FEA) and links the mechanical properties of the material to the simulated behaviour of a Pneunet actuator. This procedure is valid for any sort of hyperelastic material used in soft robotics, however, as a case study, a specific material with a self-healing ability is considered. This elastomeric polymer can recover from macroscopic damages without losing its mechanical performances, after undergoing a heat treatment. In this article, an accurate characterisation of the mechanical behaviour of this material is provided, involving mechanical testing, both in tensile and compression. On this experimental characterisation data constitutive laws are fitted, using a FEA simulator. The robustness of this material modelling is shown, re-fitting the curve for material samples that were exposed to multiple damagehealing cycles. With this obtained constitutive model, a FEA simulation of a bending soft pneumatic actuator is developed. The simulation results are experimentally validated with a dedicated test bench consisting of a pressure control unit and a motion tracking camera. Using this validated model, an inverse kinematic control is developed, including the FEA simulation in the control scheme.
# Path Planning for Multiple Mobile Robots and Agents 2
# Planning with Intermittent State Observability: Knowing When to Act Blind
## Keywords:
- Planning, Scheduling and Coordination
- Autonomous Agents
- AI-Enabled Robotics
## Abstract:
Contemporary planning models and methods often rely on constant availability of free state information at each step of execution. However, autonomous systems are increasingly deployed in the open world where state information may be costly or simply unavailable in certain situations. Failing to account for sensor limitations may lead to costly behavior or even catastrophic failure. While the partially observable Markov decision process (POMDP) can be used to model this problem, solving POMDPs is often intractable. We introduce a planning model called a semi-observable Markov decision process (SOMDP) specifically designed for MDPs where state observability may be intermittent. We propose an approach for solving SOMDPs that uses memory states to proactively plan for the potential loss of sensor information while exploiting the unique structure of SOMDPs.
# Selecting the Partial State Abstractions of MDPs: A Metareasoning Approach with Deep Reinforcement Learning
## Keywords:
- Planning, Scheduling and Coordination
- Task Planning
## Abstract:
Markov decision processes (MDPs) are a common general-purpose model used in robotics for representing sequential decision-making problems. Given the complexity of robotics applications, a popular approach for approximately solving MDPs relies on state aggregation to reduce the size of the state space but at the expense of policy fidelity---offering a trade-off between policy quality and computation time. Naturally, this poses a challenging metareasoning problem: how can an autonomous system dynamically select different state abstractions that optimize this trade-off as it operates online? In this paper, we formalize this metareasoning problem with a notion of time-dependent utility and solve it using deep reinforcement learning. To do this, we develop several general, cheap heuristics that summarize the reward structure and transition topology of the MDP at hand to serve as effective features. Empirically, we demonstrate that our metareasoning approach outperforms several baseline approaches and a strong heuristic approach on a standard benchmark domain.
# Adaptive Online Sampling of Periodic Processes with Application to Coral Reef Acoustic Abundance Monitoring
## Keywords:
- Reactive and Sensor-Based Planning
- Marine Robotics
- Robotics and Automation in Life Sciences
## Abstract:
In this paper, we present an approach that enables long-term monitoring of biological activity on coral reefs by extending mission time and adaptively focusing sensing resources on high-value periods. Coral reefs are one of the most biodiverse ecosystems on the planet; yet they are also among the most imperiled: facing bleaching, ecological community collapses due to global climate change, and degradation from human activities. Our proposed method improves the ability of scientists to monitor biological activity and abundance using passive acoustic sensors. We accomplish this by extracting periodicities from the observed abundance, and using them to predict future abundance. This predictive model is then used with a Monte Carlo Tree Search planning algorithm to schedule sampling at periods of high biological activity, and power down the sensor during periods of low activity. In simulated experiments using long-term acoustic datasets collected in the US Virgin Islands, our adaptive Online Sensor Scheduling algorithm is able to double the lifetime of a sensor while simultaneously increasing the average observed acoustic activity by 21%.
# Learning Coordination Policies Over Heterogeneous Graphs for Human-Robot Teams Via Recurrent Neural Schedule Propagation
## Keywords:
- Planning, Scheduling and Coordination
- Reinforcement Learning
- Human-Robot Collaboration
## Abstract:
As human-robot collaboration increases in the workforce, it becomes essential for human-robot teams to coordinate efficiently and intuitively. Traditional approaches for human-robot scheduling either utilize exact methods that are intractable for large-scale problems and struggle to account for stochastic, time varying human task performance, or application-specific heuristics that require expert domain knowledge to develop. We propose a deep learning-based framework, called HybridNet, combining a heterogeneous graph-based encoder with a recurrent schedule propagator for scheduling stochastic human-robot teams under upper# and lower-bound temporal constraints. The HybridNet's encoder leverages Heterogeneous Graph Attention Networks to model the initial environment and team dynamics while accounting for the constraints. By formulating task scheduling as a sequential decision-making process, the HybridNet's recurrent neural schedule propagator leverages Long Short-Term Memory (LSTM) models to propagate forward consequences of actions to carry out fast schedule generation, removing the need to interact with the environment between every task-agent pair selection. The resulting scheduling policy network provides a computationally lightweight yet highly expressive model that is end-to-end trainable via Reinforcement Learning algorithms. We develop a virtual task scheduling environment for mixed human-robot teams in a multi-round setting, capable of modeling the stochastic learning behaviors of human workers. Experimental results showed that HybridNet outperformed other human-robot scheduling solutions across problem sizes for both deterministic and stochastic human performance, with faster runtime compared to pure-GNN-based schedulers.
# Deep Reinforcement Learning Based Robot Navigation in Dynamic Environments Using Occupancy Values of Motion Primitives
## Keywords:
- Reactive and Sensor-Based Planning
- Autonomous Vehicle Navigation
- Reinforcement Learning
## Abstract:
This paper presents a Deep Reinforcement Learning based navigation approach in which we define the occupancy observations as heuristic evaluations of motion primitives, rather than using raw sensor data. Our method enables fast mapping of the occupancy data, generated by multi-sensor fusion, into trajectory values in 3D workspace. The computationally efficient trajectory evaluation allows dense sampling of the action space. We utilize our occupancy observations in different data structures to analyze their effects on both training process and navigation performance. We train and test our methodology on two different robots within challenging physics-based simulation environments including static and dynamic obstacles. We benchmark our occupancy representations with other conventional data structures from state-of-the-art methods. The trained navigation policies are also validated successfully with physical robots in dynamic environments. The results show that our method not only decreases the required training time but also improves the navigation performance as compared to other occupancy representations. The open-source implementation of our work and all related info are available at url{https://github.com/RIVeR-Lab/tentabot}.
# A Polynomial Time Approximation Scheme for the Scheduling Problem in the AGV System
## Keywords:
- Planning, Scheduling and Coordination
## Abstract:
Logistics warehouses face the challenge of fulfilling large bulk pick orders limit in a given time, as the information of logistics orders is different and timeliness. Therefore, in automated warehouses, it is imperative to improve the efficiency and intelligence of order picking by robotic systems. However, the existing automated guided vehicle (AGV) system has only a few fixed functions (such as order sorting and transportation, etc.), which cannot be changed in time according to actual needs. Meanwhile, the scheduling algorithm has only mass heuristics results and a few approximate algorithm results. In this paper, we build a new AGV system, including two kinds of shelves and four kinds of stations, where the system can add new station types according to the actual situation. We establish the equivalent relationship between the order group picking task in this system and the multi-stage hybrid flow shop scheduling problem, without considering the order group transfer process between stations. Furthermore, we propose a polynomial time approximation scheme (PTAS) for the scheduling problem in this system which has been proved to be strongly NP-hard.
# Fast and Compute-Efficient Sampling-Based Local Exploration Planning Via Distribution Learning
## Keywords:
- Reactive and Sensor-Based Planning
- Integrated Planning and Learning
- Motion and Path Planning
## Abstract:
Exploration is a fundamental problem in robotics. While sampling-based planners have shown high performance, they are oftentimes compute intensive and can exhibit high variance. To this end, we propose to directly learn the underlying distribution of informative views based on the spatial context in the robot's map. We further explore a variety of methods to also learn the information gain. We show in thorough experimental evaluation that our proposed system improves exploration performance by up to 28% over classical methods, and find that learning the gains in addition to the sampling distribution can provide favorable performance vs. compute trade-offs for compute-constrained devices. We demonstrate in simulation and on a low-cost mobile robot that our system generalizes well to varying environments.
# DC-MRTA: Decentralized Multi-Robot Task Allocation and Navigation in Complex Environments
## Keywords:
- Multi-Robot Systems
- Planning, Scheduling and Coordination
- Distributed Robot Systems
## Abstract:
We present a novel reinforcement learning (RL) based task allocation and decentralized navigation algorithm for mobile robots in warehouse environments. Our approach is designed for scenarios in which multiple robots are used to perform various pick up and delivery tasks. We consider the problem of joint decentralized task allocation and navigation and present a two level approach to solve it. At the higher level, we solve the task allocation by formulating it in terms of Markov Decision Processes and choosing the appropriate rewards to minimize the total travel delay. At the lower level, we use a decentralized navigation scheme based on ORCA that enables each robot to perform these tasks in an independent manner, and avoid collisions with other robots and dynamic obstacles. We combine these lower and upper levels by defining rewards for the higher level as the feedback from the lower level ORCA algorithm. We perform extensive evaluation in complex warehouse layouts with large number of agents and highlight the benefits over state-of-the-art algorithms based on myopic pickup distance minimization and regret-based task selection. We observe improvement up to 14% in terms of task completion time and up-to 40% reduction in computing collision-free trajectories for the robots.
# Prioritized Safe Interval Path Planning for Multi-Agent Pathfinding with Continuous Time on 2D Roadmaps
## Keywords:
- Path Planning for Multiple Mobile Robots or Agents
- Collision Avoidance
- Computational Geometry
## Abstract:
We address a challenging multi-agent pathfinding (MAPF) problem for hundreds of agents moving on a 2D roadmap with continuous time. Despite its known potential for producing better solutions compared to typical grid and discrete-time cases, few approaches have been established to solve this problem due to the intractability of collision checks on a large scale. In this work, we propose Prioritized Safe-Interval Path Planning with Continuous-Time Conflicts (PSIPP/CTC) that extends a scalable prioritized planning algorithm to work on the 2D roadmap and continuous-time setup by alleviating intensive collision checks. Our approach involves a novel concept named Continuous-Time Conflict (CTC), which describes a pair among vertices and edges associated with continuous-time intervals within which collisions can happen between agents. We pre-compute CTCs using geometric neighbor-search and sweeping techniques and annotate roadmaps with the CTCs just once before planning starts. Doing so allows us to efficiently enumerate collision-free time intervals for all vertices and edges and find each agent's path with continuous time in prioritized planning. Extensive experimental evaluations demonstrate that PSIPP/CTC significantly outperforms existing methods in terms of planning success rate and runtime while maintaining an acceptable solution quality. As a proof of concept, we also confirmed the effectiveness of the proposed approach on a physics simulation with differential wheeled robots.
# Optimization and Optimal Control 1
# Simulation Aided Co-Design for Robust Robot Optimization
## Keywords:
- Optimization and Optimal Control
- Actuation and Joint Mechanisms
- Robust/Adaptive Control
## Abstract:
This paper outlines a bi-level algorithm to concurrently optimize robot hardware and control parameters in order to minimize energy consumption during the execution of tasks and to ensure robust performance. The outer loop consists in a genetic algorithm that optimizes the co-design variables according to the system average performance when tracking a locally optimal trajectory in perturbed simulations. The tracking controller exploits the locally optimal feedback gains computed in the inner loop with a Differential Dynamic Programming algorithm, which finds the optimal reference trajectories. Our simulations feature a complete actuation model, including friction compensation and bandwidth limits. This strategy can potentially account for arbitrary perturba# tions, and discards solutions that cannot robustly meet the task requirements. The results show improved performance of the designed platform in realistic application scenarios, autonomously leading to the selection of lightweight and more transparent hardware.
# Reference Acceleration Model Predictive Control (RA-MPC) for Cable-Driven Robots
## Keywords:
- Optimization and Optimal Control
- Tendon/Wire Mechanism
- Motion Control
## Abstract:
In this paper, a computationally efficient model predictive control (MPC) is proposed for the trajectory tracking of cable-driven robots subject to state/input constraints. While MPC has been an effective tool in dealing with various constraints, the primary drawback is the high computational load caused by the non-convexity of the corresponding optimization problem. In order to avoid the non-convexity, the prediction model in the proposed reference acceleration MPC (RA-MPC) is simplified into a linear one by assuming the reference accelerations being taken in the future horizon steps. As a result, RA-MPC only optimizes for the instantaneous joint accelerations and the corresponding actuator commands for the current step, resulting in a convex quadratic program that can be efficiently solved. It is further shown that by properly selecting parameters, RA-MPC can be interpreted as 'soft-CTC' and 'soft-LQR', where the joint acceleration is allowed to deviate from the corresponding desired value, computed from a PD gain or an LQR gain. The effectiveness of the proposed RA-MPC are demonstrated in both simulation and hardware experiment using cable-driven robots.
# CARLA Simulator-Based Evaluation Framework Development of Lane Detection Accuracy Performance under Sensor Blockage Caused by Heavy Rain for Autonomous Vehicle
## Keywords:
- Performance Evaluation and Benchmarking
- RGB-D Perception
- Simulation and Animation
## Abstract:
As self-driving cars have been developed targeting level 4 and 5 autonomous driving, the capability of the vehicle to handle environmental effects has been considered importantly. The sensors installed on autonomous vehicles can be easily affected by blockages (e.g., rain, snow, dust, fog, and others) covering the surface of them. In a virtual environment, we can safely observe the behavior of the vehicle and the degradation of the sensors by blockages. In this paper, the CARLA simulator-based evaluation framework has been developed and the assessment of lane detection performance under sensor blockage by heavy rain, which was analyzed by using the experimental data. Thus, we thoroughly note that the accuracy of lane detection for the autonomous vehicle has been decreased as the rainfall rate increases, and the impact of the blockage is more critical to curved lanes than straight lanes. Finally, we have suggested a critical rainfall rate causing safety failures of the autonomous vehicles, based on reasonably established rainfall equation based on experimental rain datasets.
# Planning under Periodic Observations: Bounds and Bounding-Based Solutions
## Keywords:
- Optimization and Optimal Control
- Planning, Scheduling and Coordination
- Motion and Path Planning
## Abstract:
We study planning problems faced by robots operating in uncertain environments with incomplete knowledge of state, and actions that are noisy and/or imprecise. This paper identifies a new problem sub-class that models settings in which information is revealed only intermittently through some exogenous process that provides state information periodically. Several practical domains fit this model, including the specific scenario that motivates our research: autonomous navigation of a planetary exploration rover augmented by remote imaging. With an eye to efficient specialized solution methods, we examine the structure of instances of this sub-class. They lead to Markov Decision Processes with exponentially large action-spaces but for which, as those actions comprise sequences of more atomic elements, one may establish performance bounds by comparing policies under different information assumptions. This provides a way in which to construct performance bounds systematically. Such bounds are useful because, in conjunction with the insights they confer, they can be employed in bounding-based methods to obtain high-quality solutions efficiently; the empirical results we present demonstrate their effectiveness for the considered problems. The foregoing has also alluded to the distinctive role that time plays for these problems—more specifically: time until information is revealed— and we uncover and discuss several interesting subtleties in this regard.
# Real-Time Predictive Kinematics Control of Redundancy: A Benchmark of Optimal Control Approaches
## Keywords:
- Optimization and Optimal Control
- Kinematics
## Abstract:
Modern collaborative manipulators operate in unknown environments and share the work space with human coworkers. To ensure flexibility, their kinematic design is redundant which increases the solution space of the inverse kinematics (IK). We propose a real-time capable Predictive Kinematics Controller (PKC) that tracks task space trajectories as a first priority and computes optimal joint trajectories w.r.t. secondary objectives based on model predictive control (MPC). Therefor, the PKC solves a MPC problem in the nullspace of the task space trajectory. We benchmark a direct shooting, a direct collocation and an indirect gradient method in simulation and we identify the direct shooting method as the most efficient. We demonstrate the superior performance of the PKC compared to state-of-the-art local redundancy resolution approaches. In experiments, we show the real-time capability of our implementation.
# Automatic Generation of Optimization Model Using Process Mining and Petri Nets for Optimal Motion Planning of 6-DOF Manipulators
## Keywords:
- Optimization and Optimal Control
- Industrial Robots
- Petri Nets for Automation Control
## Abstract:
We propose an optimization system for motion planning of robot arms using Petri Nets. The proposed optimization system consists of four sub-systems consisting of automatic generation of Petri Nets from event log data, optimization system of firing sequence of derived Petri Net model, verification system using Petri Net simulation, and an automatic program generation system. The model generation system automatically generates the Petri Net model from the event logs using process mining. The Petri Net verification system is used to check the consistency of the generated Petri Nets to obtain the optimal firing sequence for robot motion. The motion planning algorithm generates motion programs for robots based on optimal firing sequences. The proposed optimization model is applied to a 6-DOF (Degree of Freedom) robot manipulator (Niryo Ned). Experimental results show that the proposed method achieves motion plan optimization for the pick-and-place operation with different robot configurations.
# Physically Consistent Lie Group Mesh Models for Robot Design and Motion Co-Optimization
## Keywords:
- Optimization and Optimal Control
- Computational Geometry
## Abstract:
With recent advances in rapid prototyping and mechatronics, the problem of simultaneous design and motion optimization, or the co-design problem, is becoming more and more relevant in robotics. For reasons of computational tractability, all existing methods use simplified approximations of a robot's kinodynamic model. We empirically confirm that any model approximations that are not physically consistent, i.e., the kinodynamic model parameters do not accurately reflect the actual link shapes, can sometimes lead to large errors in the optimization. We then propose a physically consistent, Lie group-based mesh element model for robot links that (i) parametrizes a wide variety of link shapes, and (ii) provides closed-form analytic gradients for the mesh deformations. The latter property is key to developing efficient co-design optimization algorithms that significantly improve numerical convergence and stability. Our co-design methodology is validated through extensive numerical and hardware experiments involving 3D-printed serial and parallel robots.
# Analytical Second-Order Partial Derivatives of Rigid-Body Inverse Dynamics
## Keywords:
- Dynamics
- Optimization and Optimal Control
- Whole-Body Motion Planning and Control
## Abstract:
Optimization-based robot control strategies often rely on first-order dynamics approximation methods, as in iLQR. Using second-order approximations of the dynamics is expensive due to the costly second-order partial derivatives of the dynamics with respect to the state and control. Current approaches for calculating these derivatives typically use automatic differentiation (AD) and chain-rule accumulation or finite-difference. In this paper, for the first time, we present analytical expressions for the second-order partial derivatives of inverse dynamics for open-chain rigid-body systems with floating base and multi-DoF joints. A new extension of spatial vector algebra is proposed that enables the analysis. A recursive algorithm with complexity of O(Nd^2) is also provided where N is the number of bodies and d is the depth of the kinematic tree. A comparison with AD in CasADi shows speedups of 1.5-3x for serial kinematic trees with N> 5, and a C++ implementation shows runtimes of ~51 mu s for a quadruped.
# High-Speed Accurate Robot Control Using Learned Forward Kinodynamics and Non-Linear Least Squares Optimization
## Keywords:
- Optimization and Optimal Control
- Autonomous Vehicle Navigation
- Dynamics
## Abstract:
Accurate control of robots at high speeds requires a control system that can take into account the kinodynamic interactions of the robot with the environment. Prior works on learning inverse kinodynamic (IKD) models of robots have shown success in capturing the complex kinodynamic effects. However, the types of control problems these approaches can be applied to are limited only to that of following pre-computed kinodynamically feasible trajectories. In this paper we present Optim-FKD, a new formulation for accurate, high-speed robot control that makes use of a learned forward kinodynamic (FKD) model and non-linear least squares optimization. Optim-FKD can be used for accurate, high speed control on any control task specifiable by a non-linear least squares objective. Optim-FKD can solve for control objectives such as path following and time-optimal control in real time, without needing access to pre-computed kinodynamically feasible trajectories. We empirically demonstrate these abilities of our approach through experiments on a scale one-tenth autonomous car. Our results show that Optim-FKD can follow desired trajectories more accurately and can find better solutions to optimal control problems than baseline approaches.
# Bimanual and In-Hand Manipulation
# Kinesthetic Teaching of Bi-Manual Tasks with Known Relative Constraints
## Keywords:
- Bimanual Manipulation
- Physical Human-Robot Interaction
## Abstract:
Kinesthetic teaching allows the direct skill transfer from the human to the robot and has been widely used to teach single arm tasks intuitively. In the bi-manual case, simultaneously moving both end-effectors is challenging due to the high physical and cognitive load imposed to the user. Thus, previous works on bi-manual task teaching resort to less intuitive methods by teaching each arm separately. This in turn requires motion synthesis and synchronization before execution. In this work, we leverage knowledge from the relative task space to facilitate a kinesthetic demonstration by guiding both end-effectors which is more human-like and intuitive way for performing bi-manual tasks. Our method utilizes the notion of virtual fixtures and inertia minimization in the null space of the task. The controller is experimentally validated in a bi-manual task which involves the drawing of a preset line on a workpiece utilizing two KUKA IIWA7 R800 robots. Results from ten participants were compared with a gravity compensation scheme demonstrating improved performance.
# Transferring Dexterous Manipulation from GPU Simulation to a Remote Real-World TriFinger
## Keywords:
- Manipulation Planning
- In-Hand Manipulation
- Reinforcement Learning
## Abstract:
This work presents a robot systems approach to learning dexterous manipulation tasks involving moving objects to arbitrary 6-DoF poses. We show empirical benefits, both in simulation and sim-to-real transfer, of using keypoint-based representations for object pose in policy observations and reward calculation to train a model-free reinforcement learning agent. By utilizing domain randomization strategies and large-scale training, we achieve a high success rate of 83% on a real TriFinger system, with a single policy able to perform grasping, ungrasping, and finger gaiting in order to achieve arbitrary poses within the workspace. We demonstrate that our policy can generalise to unseen objects, and success rates can be further improved through finetuning. With the aim of assisting further research in learning in-hand manipulation, we provide a detailed exposition of our system and make the codebase of our system available, along with checkpoints trained on billions of steps of experience, at https://s2r2-ig.github.io
# A System for Imitation Learning of Contact-Rich Bimanual Manipulation Policies
## Keywords:
- Bimanual Manipulation
- Imitation Learning
- Methods and Tools for Robot System Design
## Abstract:
In this paper, we discuss a framework for teaching bimanual manipulation tasks by imitation. To this end, we present a system and algorithms for learning compliant and contact-rich robot behavior from human demonstrations. The presented system combines insights from admittance control and machine learning to extract control policies that can (a) recover from and adapt to a variety of disturbances in time and space, while also (b) effectively leveraging physical contact with the environment. We demonstrate the effectiveness of our approach using a real-world insertion task involving multiple simultaneous contacts between a manipulated object and insertion pegs. We also investigate efficient means of collecting training data for such bimanual settings. To this end, we conduct a human-subject study and analyze the effort and mental demand as reported by the users. Our experiments show that, while harder to provide, the additional force/torque information available in teleoperated demonstrations is crucial for phase estimation and task success. Ultimately, force/torque data substantially improves manipulation robustness, resulting in a 90% success rate in a multipoint insertion task. Code and videos can be found at https://bimanualmanipulation.com/
# Optical Proximity Sensing for Pose Estimation During In-Hand Manipulation
## Keywords:
- Perception for Grasping and Manipulation
- In-Hand Manipulation
- Sensor-based Control
## Abstract:
During in-hand manipulation, robots must be able to continuously estimate the pose of the object in order to generate appropriate control actions. The performance of algorithms for pose estimation hinges on the robot’s sensors being able to detect discriminative geometric object features, but previous sensing modalities are unable to make such measurements robustly. The robot’s fingers can occlude the view of environmentor robot-mounted image sensors, and tactile sensors can only measure at the local areas of contact. Motivated by fingertipembedded proximity sensors’ robustness to occlusion and ability to measure beyond the local areas of contact, we present the first evaluation of proximity sensor based pose estimation for inhand manipulation. We develop a novel two-fingered hand with fingertip-embedded optical time-of-flight proximity sensors as a testbed for pose estimation during planar in-hand manipulation. Here, the in-hand manipulation task consists of the robot moving a cylindrical object from one end of its workspace to the other. We demonstrate, with statistical significance, that proximity-sensor based pose estimation via particle filtering during in-hand manipulation: a) exhibits about 50% lower average pose error than a tactile-sensor based baseline; b) empowers a model predictive controller to achieve 30% lower final positioning error compared to when using tactile-sensor based pose estimates.
# E-TRoll: Tactile Sensing and Classification Via a Simple Robotic Gripper for Extended Rolling Manipulations
## Keywords:
- In-Hand Manipulation
- Grippers and Other End-Effectors
- Force and Tactile Sensing
## Abstract:
Robotic tactile sensing provides a method of recognizing objects and their properties where vision fails. Prior work on tactile perception in robotic manipulation has frequently focused on exploratory procedures (EPs). However, the also-human-inspired technique of in-hand-manipulation can glean rich data in a fraction of the time of EPs. We propose a simple 3-DOF robotic hand design, optimized for object rolling tasks via a variable-width palm and associated control system. This system dynamically adjusts the distance between the finger bases in response to object behavior. Compared to fixed finger bases, this technique significantly increases the area of the object that is exposed to finger-mounted tactile arrays during a single rolling motion (an increase of over 60% was observed for a cylinder with a 30-millimeter diameter). In addition, this paper presents a feature extraction algorithm for the collected spatiotemporal dataset, which focuses on object corner identification, analysis, and compact representation. This technique drastically reduces the dimensionality of each data sample from 10×1500 time series data to 80 features, which was further reduced by Principal Component Analysis (PCA) to 22 components. An ensemble subspace k-nearest neighbors (KNN) classification model was trained with 90 observations on rolling three different geometric objects, resulting in a three-fold cross-validation accuracy of 95.6% for object shape recognition.
# Variable Friction Based In-Hand Manipulation of Fabrics Applied to Unfolding Operations
## Keywords:
- In-Hand Manipulation
- Grasping
- Dexterous Manipulation
## Abstract:
As a typical deformable object, a fabric is characterized by its difficulties in automatic state recognition and handling. The development of the related technology on fabric manipulation is still far from practically deployment. This research was inspired by the process that humans handle fabrics with fingers. We proposed an in-hand manipulation method for fabrics based on variable friction and verified its effectiveness by experiments of sliding a single sheet of fabric and unfolding utilizing the in-hand manipulation functions. The experimental results demonstrated that the in-hand manipulation functions proposed in this paper has the potential to wisely solve many complex problems confronted with fabric handling.
# A Target-Guided Telemanipulation Architecture for Assisted Grasping
## Keywords:
- Telerobotics and Teleoperation
- Bimanual Manipulation
- Perception for Grasping and Manipulation
## Abstract:
Teleoperation offers the possibility to combine human intelligence with robot power and endurance, making it a perfect solution for hostile-for-human environments. Nonetheless, when it concerns prolonged and repetitive operations, classical teleoperation interfaces that replicate one-to-one human commands can be quite demanding in terms of physical and mental efforts. Shared-autonomy approaches, which foresee the combination of direct teleoperation with autonomous control, can help the operator in overcoming such issues without sacrificing the task execution efficiency. Following this philosophy, in this letter we propose a novel technique to assist the operators in reaching and manipulation of objects with one or two arms, combining local visual perception and operator’s action monitoring. In more details, the reaching intention of an operator towards a target object is detected, which is used to adapt robot trajectories autonomously towards a successful grasping pose. In addition, based on the detected size of a target object, single# or dual-arm coordinated movements are autonomously generated without the need for additional human interventions. The experimental results on thirteen participants confirm the potential of the proposed framework in terms of success rate and operator effort.
# DA^2 Dataset: Toward Dexterity-Aware Dual-Arm Grasping
## Keywords:
- Perception for Grasping and Manipulation
- Dual Arm Manipulation
- Deep Learning in Grasping and Manipulation
## Abstract:
In this paper, we introduce DA^2, the first large-scale dual-arm dexterity-aware dataset for the generation of optimal bimanual grasping pairs for arbitrary large objects. The dataset contains about 9M pairs of parallel-jaw grasps, generated from more than 6000 objects and each labeled with various grasp dexterity measures. In addition, we propose an end-to-end dual-arm grasp evaluation model trained on the rendered scenes from this dataset. We utilize the evaluation model as our baseline to show the value of this novel and nontrivial dataset by both online analysis and real robot experiments. All data and related code will be open-sourced at https://sites.google.com/view/da2dataset.
# A Shared Autonomy Reconfigurable Control Framework for Telemanipulation of Multi-Arm Systems
## Keywords:
- Telerobotics and Teleoperation
- Bimanual Manipulation
- Human-Robot Collaboration
## Abstract:
Teleoperation is a widely adopted strategy to control robotic manipulators executing complex tasks that require highly dexterous movements and critical high-level intelligence. Classical teleoperation schemes are based on either joystick control, or on more intuitive interfaces which map directly the user arm motions into one robot arm’s motions. These approaches have limits when the execution of a given task requires reconfigurable multiple robotic arm systems. Indeed, the simultaneous teleoperation of two or more robot arms could extend the workspace of the manipulation cell, or increase its total payload, or afford other advantages. In different phases of a reconfigurable multi-arm system, each robot could act as an independent arm, or as one of a pair of cooperating arms, or as one of the fingers of a virtual, large robot hand. This manuscript proposes a novel telemanipulation framework that enables both the individual and combined control of any number of robotic arms. Thanks to the designed control architecture, the human operator can intuitively choose the proposed control modalities and the manipulators that make the task convenient to execute through the user interface. Moreover, through the tele-impedance paradigm, the system can address complex tasks that require physical interaction by letting the robot mimic the arm impedance and position references of the human operator. The proposed framework is validated with 8 subjects controlling 4 Franka Emika Panda robots with 7# DOFS to execute a telemanipulation task. Qualitative results of the experiments show us the promising applicability of our framework.
# Motion and Path Planning 8
# Generating Safe Corridors Roadmap for Urban Air Mobility
## Keywords:
- Motion and Path Planning
- Nonholonomic Motion Planning
- Robot Safety
## Abstract:
Personal air transportation on short distances, so-called Urban Air Mobility (UAM), is a trend in modern aviation that raises new challenges as flying in urban areas at low altitudes induces an additional risk to people and properties on the ground. Risk-aware trajectory planning can mitigate the risk by detouring and flying over less populated and thus less risky areas. Existing risk-aware trajectory planning approaches are computationally demanding single-query methods that are impractical for online usage. Moreover, coordinated planning for multiple aircraft is prohibitively expensive. Therefore, we propose to reduce computational demands by determining low-risk areas called safe corridors and creating a roadmap of safe corridors based on multiple least risky trajectories. The created roadmap can be used in graph-based multi-agent planning methods for coordinated trajectory planning. The proposed method has been evaluated in a realistic urban scenario, suggesting a significant computational burden reduction and less risky trajectories than the current state-of-the-art methods.
# Explainable Robotic Plan Execution Monitoring under Partial Observability (I)
## Keywords:
- Task and Motion Planning
- Formal Methods in Robotics and Automation
- AI-Enabled Robotics
## Abstract:
Successful plan generation for autonomous systems is necessary but not sufficient to guarantee reaching a goal state by an execution of a plan. Various discrepancies between an expected state and the observed state may occur during the plan execution (e.g., due to unexpected exogenous events, changes in the goals, or failure of robot parts) and these discrepancies may lead to plan failures. For that reason, autonomous systems should be equipped with execution monitoring algorithms so that they can autonomously recover from such discrepancies. We introduce a plan execution monitoring algorithm that operates under partial observability. This algorithm relies on novel formal methods for hybrid prediction, diagnosis and explanation generation, and planning. The prediction module generates an expected state after the execution of a part of the plan from an incomplete state to check for discrepancies. The diagnostic reasoning module generates meaningful hypotheses to explain failures of robot parts. Unlike the existing diagnosis methods, the previous hypotheses can be revised, based on new partial observations, increasing the accuracy of explanations as further information becomes available. The replanning module considers these explanations while computing a new plan that would avoid such failures. All these reasoning modules are hybrid in that they combine high-level logical reasoning with low-level feasibility checks based on probabilistic methods. We experimentally show that these hybrid formal reasoning modules improve the performance of plan execution monitoring.
# Sampling-Based View Planning for MAVs in Active Visual-Inertial State Estimation
## Keywords:
- Motion and Path Planning
- Vision-Based Navigation
- Aerial Systems: Perception and Autonomy
## Abstract:
Micro aerial vehicles usually have strap-down sensors on the vehicle body, leading to the severe coupling effect between perception and trajectory planning. As a result, visual inertial simultaneous localization and mapping (VI-SLAM) technologies implemented on MAVs suffer from tracking failure problems, especially in featureless environments. To overcome these challenges, based on MAVs with movable camera mechanisms (e.g., gimbal stabilizer, pan-tilt, or bionic neck-eye system), we proposed two sampling-based algorithms for known and unknown environments respectively. The first active perception planning algorithm based on a scene richness model is developed with a built feature map for the environment. Differ from the first algorithm, the second one is modified for active localization in unknown 3D space. It is basically a time-based sampling-based approach that uses the same scene richness model. In addition, it also achieved a balance between exploitation and exploration. With the above solutions, the robustness of visual perception is improved while avoiding over-exploitation of known information. Simulation and real-world experiments are performed to verify the feasibility of our algorithms.
# Maximizing the Probability of Task Completion for Redundant Robots Experiencing Locked Joint Failures (I)
## Keywords:
- Redundant Robots
- Motion and Path Planning
- Failure Detection and Recovery
## Abstract:
This article considers the problem of planning a trajectory that maximizes the probability that a robot will be able to complete a set of point-to-point tasks, after experiencing locked joint failures. The proposed approach first develops a method to calculate the probability of task failure for an arbitrary trajectory based on its failure scenarios, which are efficiently computed by identifying the ranges of task point self-motion manifolds. Then, a novel trajectory planning algorithm is proposed to find the optimal trajectory with maximum probability of task completion. The planning algorithm exploits the overlap of self-motion manifold bounding boxes, as opposed to always using the shortest distance, to determine an optimal trajectory. The proposed trajectory planning algorithm is demonstrated on planar positioning 3R, spatial positioning 4R, and spatial positioning/orienting 7R redundant robots, resulting in average improvement of 17%, 22%, and 30%, respectively, compared to the best shortest distance trajectory.
# Dynamic Compressed Sensing of Unsteady Flows with a Mobile Robot
## Keywords:
- Motion and Path Planning
- Optimization and Optimal Control
- Environment Monitoring and Management
## Abstract:
Large-scale environmental sensing with a finite number of mobile sensors is a challenging task that requires tremendous resources and time. This is especially true when the environmental features of interest are spatiotemporally changing with unknown or partially known dynamics. Fortunately, these dynamic features often evolve in a low-dimensional space, making it possible to capture their dynamics sufficiently well with a finite number of sensor measurements. This paper investigates the problem of dynamic compressed sensing of an unsteady, periodic flow field with a mobile sensor. We take advantage of the inherently low dimensionality of the underlying flow dynamics to reduce number of critical waypoints for sensor trajectory. The optimal set of sensing waypoints are identified by an iterative compressed sensing algorithm that optimizes the flow reconstruction based on the proper orthogonal decomposition modes. An optimal sampling trajectory is then found to traverse these waypoints while minimizing the energy consumption, time, and flow reconstruction error. Simulation results in a double-gyre flow field is presented to demonstrate the efficacy of the proposed algorithms. Experimental results with an indoor quadcopter are presented to show the tracking feasibility of the resulting trajectory.
# Adaptive Coverage Path Planning for Efficient Exploration of Unknown Environments
## Keywords:
- Motion and Path Planning
- Reactive and Sensor-Based Planning
- Search and Rescue Robots
## Abstract:
We present a method for solving the coverage problem with the objective of autonomously exploring an unknown environment under mission time constraints. Here, the robot is tasked with planning a path over a horizon such that the accumulated area swept out by its sensor footprint is maximized. Because this problem exhibits a diminishing returns property known as submodularity, we choose to formulate it as a tree-based sequential decision making process. This formulation allows us to evaluate the effects of the robot's actions on future world coverage states, while simultaneously accounting for traversability risk and the dynamic constraints of the robot. To quickly find near-optimal solutions, we propose an effective approximation to the coverage sensor model which adapts to the local environment. Our method was extensively tested across various complex environments and served as the local exploration algorithm for a competing entry in the DARPA Subterranean Challenge.
# Path Planning and Energy Management of Hybrid Air Vehicles for Urban Air-Mobility
## Keywords:
- Motion and Path Planning
- Energy and Environment-Aware Automation
- Aerial Systems: Applications
## Abstract:
A novel coupled path planning and energy management problem for a hybrid unmanned air vehicle is considered, where the hybrid vehicle is powered by a dual gas/electric system. Such an aerial robot is envisioned for use in an urban setting where noise restrictions are in place in certain zones necessitating battery only operation. We consider the discrete version of this problem, where a graph is constructed by sampling the boundaries of the restricted zones, and develop a path planning algorithm. The planner simultaneously solves the path planing along with the energy mode switching control, under battery constraints and noise restrictions. This is a coupled problem involving discrete decision making to find the path to travel, and determining the state of charge of the battery along the path, which is a continuous variable. A sampling based algorithm to find near optimal solution to this problem is presented. To quantify the efficacy of the solution, an algorithm that computes tight lower bounds is also presented. The algorithms presented are verified using numerical simulations, and the average gap between the feasible solutions (upper bounds) and the lower bounds are, empirically, shown to be within 15% of each other.
# Informative Path Planning for Active Learning in Aerial Semantic Mapping
## Keywords:
- Motion and Path Planning
- Reactive and Sensor-Based Planning
- Semantic Scene Understanding
## Abstract:
Semantic segmentation of aerial imagery is an important tool for mapping and earth observation. However, supervised deep learning models for segmentation rely on large amounts of high-quality labelled data, which is labour-intensive and time-consuming to generate. To address this, we propose a new approach for using unmanned aerial vehicles (UAVs) to autonomously collect useful data for model training. We exploit a Bayesian approach to estimate model uncertainty in semantic segmentation. During a mission, the semantic predictions and model uncertainty are used as input for terrain mapping. A key aspect of our pipeline is to link the mapped model uncertainty to a robotic planning objective based on active learning. This enables us to adaptively guide a UAV to gather the most informative terrain images to be labelled by a human for model training. Our experimental evaluation on real-world data shows the benefit of using our informative planning approach in comparison to static coverage paths in terms of maximising model performance and reducing labelling efforts.
# Towards Autonomous Grading in the Real World
## Keywords:
- Robotics and Automation in Construction
- Task and Motion Planning
- Imitation Learning
## Abstract:
In this work, we aim to tackle the problem of autonomous grading, where a dozer is required to flatten an uneven area. In addition, we explore methods for bridging the gap between a simulated environment and real scenarios. We design both a realistic physical simulation and a scaled real prototype environment mimicking the real dozer dynamics and sensory information. We establish heuristics and learning strategies in order to solve the problem. Through extensive experimentation, we show that although heuristics are capable of tackling the problem in a clean and noise-free simulated environment, they fail catastrophically when facing real world scenarios. As the heuristics are capable of successfully solving the task in the simulated environment, we show they can be leveraged to guide a learning agent which can generalize and solve the task both in simulation and in a scaled prototype environment.
# Legged Robots 2
# Vastus and Gastrocnemius Improve Hopping Efficiency and Joints Synchronicity at Different Frequencies: A Robotic Study
## Keywords:
- Legged Robots
- Biologically-Inspired Robots
- Compliant Joints and Mechanisms
## Abstract:
The lower limb morphology of biological locomotors is abundant in muscle-tendon units. Yet, not much is known about how these actuation units contribute to the output performance and energy economy of movements. In this work, we investigate the functionality of four of the important lower limb muscles # Vastus, Popliteus, Soleus, and Gastrocnemius # in a hopping task at different frequencies (1.5-3.5Hz). These muscles are implemented as pneumatic artificial muscles (PAMs) on the EPA-Hopper-II robot, which is a human-sized 3-segmented leg co-actuated by electrical motors and PAMs. A bioinspired reflex-based Force Modulated Control (FMC) is also implemented on the robot to achieve hopping at different frequencies. The results show that the Vastus contributes the most to energy-efficient hopping at low to mid frequencies. The biarticular Gastrocnemius also helps increase efficiency at low frequencies. Further, it is found that the Gastrocnemius synchronizes the knee-ankle motion and mitigates lateral knee motion. The outcomes of this work add further evidence to hypotheses regarding human lower-limb actuation and proper recruitment of muscles for building more efficient robots.
# Animal Motions on Legged Robots Using Nonlinear Model Predictive Control
## Keywords:
- Legged Robots
- Optimization and Optimal Control
- Motion Control
## Abstract:
This work presents a motion capture-driven locomotion controller for quadrupedal robots that replicates the non-periodic footsteps and subtle body movement of animal motions. We adopt a nonlinear model predictive control (NMPC) formulation that generates optimal base trajectories and stepping locations. By optimizing both footholds and base trajectories, our controller effectively tracks retargeted animal motions with natural body movements and highly irregular strides. We demonstrate our approach with prerecorded animal motion capture data. In simulation and hardware experiments, our motion controller enables quadrupedal robots to robustly reproduce fundamental characteristics of a target animal motion regardless of the significant morphological disparity.
# Improved Performance of CPG Parameter Inference for Path-Following Control of Legged Robots
## Keywords:
- Legged Robots
- Underactuated Robots
- Machine Learning for Robot Control
## Abstract:
The difficulty associated with the coordinated locomotion of legged robots grows quickly as the number of joints increases. Although prior approaches have addressed this problem through sampling-based planners, learning-based techniques have recently been explored as a means to handle such complexity. Among these recent approaches are systems that utilize probabilistic graphical models in order to infer parameters for central pattern generators (CPGs) which enable the path-following locomotion of highly-articulated legged robots through unstructured terrain. This paper presents a novel formulation of a CPG parameter inference-based path-following controller. The new inference process and accompanying CPG formulation enforce oscillator convergence to the limit-cycle specified by the inferred parameters in addition to biasing towards parameters that quickly reach stable-state. This formulation is shown to improve the performance of CPG parameter inference-based path-following control for legged robots across a number of simulated and physical experiments.
# Zero-Shot Retargeting of Learned Quadruped Locomotion Policies Using Hybrid Kinodynamic Model Predictive Control
## Keywords:
- Legged Robots
- Optimization and Optimal Control
- Reinforcement Learning
## Abstract:
Reinforcement Learning (RL) has witnessed great strides for quadruped locomotion, with continued progress in the reliable sim-to-real transfer of policies. However, it remains a challenge to reuse a policy on another robot, which could save time for retraining. In this work, we present a framework for zero-shot policy retargeting wherein diverse motor skills can be transferred between robots of different shapes and sizes. The new framework centers on a planning-and-control pipeline that systematically integrates RL and Model Predictive Control (MPC). The planning stage employs RL to generate a dynamically plausible trajectory as well as the contact schedule, avoiding the combinatorial complexity of contact sequence optimization. This information is then used to seed the MPC to stabilize and robustify the policy roll-out via a new Hybrid Kinodynamic (HKD) model that implicitly optimizes the foothold locations. Hardware results show an ability to transfer policies from both the A1 and Laikago robots to the MIT Mini Cheetah robot without requiring any policy re-tuning.
# Contact-Implicit Differential Dynamic Programming for Model Predictive Control with Relaxed Complementarity Constraints
## Keywords:
- Legged Robots
- Optimization and Optimal Control
## Abstract:
In this work, we propose a novel differential dynamic programming (DDP) framework for systems involving contact with the ground. The approach converts a general constrained differential dynamic programming into contact-implicit one by incorporating contact dynamics in a linear complementarity problem (LCP) formulation. Analytical gradients of the contact dynamics are obtained through a relaxed complementarity condition in the LCP formulation that helps the search directions of optimization avoid stalling in bad local minima or saddle points. Incorporation of contact dynamics and its analytical gradients into DDP enables an online discovery of not only dynamically-feasible trajectories of states, control inputs, and contact forces but also contact mode sequences. We demonstrate that our Contact-Implicit Differential Dynamic Programming framework successfully finds totally new dynamic motions with contact mode sequences in a variety of robotic systems including an one-legged hopping robot and planar quadrupedal robot in simulation environment.
# Robust Predictive Control for Quadrupedal Locomotion: Learning to Close the Gap between Reduced and Full-Order Models
## Keywords:
- Legged Robots
- Motion Control
- Multi-Contact Whole-Body Motion Planning and Control
## Abstract:
Template-based reduced-order models have provided a popular methodology for real-time trajectory planning of dynamic quadrupedal locomotion. However, the abstraction and unmodeled dynamics in template models significantly increase the gap between reduced# and full-order models. This letter presents a computationally tractable robust model predictive control (RMPC) formulation, based on convex quadratic programs (QP), to bridge this gap. The RMPC framework considers the single rigid body model subject to a set of unmodeled dynamics and plans for the optimal reduced-order trajectory and ground reaction forces (GRFs). The generated optimal GRFs of the high-level RMPC are then mapped to the full-order model using a low-level nonlinear controller based on virtual constraints and QP. The proposed hierarchical control framework is employed for locomotion over rough terrains. We leverage deep reinforcement learning to train a neural network to compute the set of unmodeled dynamics for the RMPC framework. The proposed controller is finally validated via extensive numerical simulations and experiments for robust and blind locomotion of the A1 quadrupedal robot on different terrains.
# Contact-Timing and Trajectory Optimization for 3D Jumping on Quadruped Robots
## Keywords:
- Legged Robots
## Abstract:
Performing highly agile acrobatic motions with a long flight phase requires perfect timing, high accuracy, and coordination of the full-body motion. To address these challenges, we present a novel approach on timings and trajectory optimization framework for legged robots performing aggressive 3D jumping. In our method, we firstly utilize an effective optimization framework using simplified rigid body dynamics to solve for contact timings and a reference trajectory of the robot body. The solution of this module is then used to formulate a full-body trajectory optimization based on the full nonlinear dynamics of the robot. This combination allows us to effectively optimize for contact timings while ensuring that the jumping trajectory can be effectively realized in the robot hardware. We first validate the efficiency of the proposed framework on the A1 robot model for various 3D jumping tasks such as double-backflips off the high altitude of 2m. Experimental validation was then successfully conducted for various aggressive 3D jumping motions such as diagonal jumps, barrel roll, and double barrel roll from a box of heights 0.4m and 0.9m, respectively.
# Improved Control Scheme for the Solo Quadruped and Experimental Comparison of Model Predictive Controllers
## Keywords:
- Legged Robots
- Optimization and Optimal Control
- Motion Control
## Abstract:
This paper presents significant improvements to the nominal control architecture of the open-access Solo-12 quadruped that were done to implement and compare different centroidal Model Predictive Controllers (MPC). This work was motivated by our previous study in which various MPC schemes of increasing complexity were tested in simulation. They range from a simplified linearized model with contact points fixed by a heuristic, to a nonlinear one that also optimizes the contact points locations. We describe the developments that were necessary to implement such control schemes on the real robot while doubling its maximum velocity. Notably, to synthesize a stable whole-body controller, the inverse dynamics resolution was replaced by a mixed inverse kinematics and quadratic programming scheme. These developments enabled the successful deployments of the various centroidal MPCs on Solo-12. Experimental results show that all MPCs lead to quite similar performances with the proposed whole-body controller and, as a consequence, do not confirm the result of previous simulation study that concluded on the preeminence of the nonlinear centroidal MPC optimizing both the center of mass trajectory and the foot placements.
# The Geometry of Optimal Gaits for Inertia-Dominated Kinematic Systems (I)
## Keywords:
- Nonholonomic Motion Planning
- Dynamics
- Kinematics
## Abstract:
Isolated mechanical systems---e.g., those floating in space, in free-fall, or on a frictionless surface---are able to achieve net rotation by cyclically changing their shape, even if they have no net angular momentum. Similarly, swimmers immersed in ``perfect fluids" are able to use cyclic shape changes to both translate and rotate even if the swimmer-fluid system has no net linear or angular momentum. Finally, systems fully constrained by direct nonholonomic constraints (e.g., passive wheels) can push against these constraints to move through the world. Previous work has demonstrated that the net displacement induced by these shape changes corresponds to the amount of *constraint curvature* that the gaits enclose. 
To properly assess or optimize the utility of a gait, however, we must also consider the time or resources required to execute it: A gait that produces a small displacement per cycle, but that can be executed in a short time, may produce a faster average velocity than a gait that produces a large displacement per cycle, but takes much longer to complete a cycle at the same average instantaneous effort.
In this paper, we consider two effort-based cost functions for assessing the costs associated with executing these cycles. For each of these cost functions, we demonstrate that fixing the average instantaneous cost to a unit value allows us to transform the effort costs into time-to-execute costs for any given gait cycle. We then illustrate how the interaction between the constraint curvature and these costs leads to characteristic geometries for optimal cycles, in which the gait trajectories resemble elastic hoops distended from within by internal pressures.
# Task Planning
# Optimal Constrained Task Planning As Mixed Integer Programming
## Keywords:
- Task Planning
- Task and Motion Planning
- Optimization and Optimal Control
## Abstract:
For robots to successfully execute tasks assigned to them, they must be capable of planning the right sequence of actions. These actions must be both optimal with respect to a specified objective and satisfy whatever constraints exist in their world. We propose an approach for robot task planning that is capable of planning the optimal sequence of grounded actions to accomplish a task given a specific objective function while satisfying all specified numerical constraints. Our approach accomplishes this by encoding the entire task planning problem as a single mixed integer convex program, which it then solves using an off-the-shelf Mixed Integer Programming solver. We evaluate our approach on several mobile manipulation tasks in both simulation and on a physical humanoid robot. Our approach is able to consistently produce optimal plans while accounting for all specified numerical constraints in the mobile manipulation tasks.
# Extended Time Dependent Vehicle Routing Problem for Joint Task Allocation and Path Planning in Shared Space
## Keywords:
- Task Planning
- Path Planning for Multiple Mobile Robots or Agents
- Autonomous Agents
## Abstract:
We address the joint task allocation and path planning problem whereby an operator with a fleet of vehicles must assign multiple tasks to each vehicle, while ensuring collision-free paths for them such that the total travel cost is minimized. Instead of sequentially solving the task allocation problem first, and then resolving all predicted collisions, i.e. conflicts between vehicles, we propose a novel method that solves in a simultaneous way task allocation and multi-agent path planning. Specifically, we introduce an extension of the Time Dependent Vehicle Routing Problem (TDVRP) whereby we propose to integrate conflicts information into a time dependent cost function used in the task allocation resolution. We compare our approach to two baseline approaches that both use a standard Capacitated VRP (CVRP) solver, a "one-shot" method and a "multi-shot" method. We perform simulations on benchmark realistic warehouse scenarios and the obtained results show that our proposed approach is able to generate improvements in the solutions costs compared to the baseline approaches.
# Multi-Objective Task Allocation for Multi-Agent Systems Using Hierarchical Cost Function
## Keywords:
- Task Planning
- Multi-Robot Systems
- Autonomous Agents
## Abstract:
Multi-agent systems are deployed to accomplish tasks that take a long time with a single agent. The task allocation problem becomes particularly difficult when the objectives are conflicting with one another (e.g. minimizing the mission time while respecting the task priorities, while simultaneously maximizing agent's fitness for the task). This paper presents an algorithm to create task assignments for a group of autonomous agents with competing objectives. We consider a variety of constraints including agent capabilities to perform tasks, priorities set by a human supervisor, as well as temporal constraints such as arrival time or coalition formation. We propose a multi-objective Particle Swarm Optimization (PSO) that uses a hierarchical cost function by leveraging the paradigm of lexicographic optimization. The particles are driven by higher ranked objectives with lower ranked objectives used to break ties. We demonstrate the effectiveness of this algorithm in a battlefield scenario where sub-teams of aerial vehicles are assigned to perform area reconnaissance, target strikes, and intelligence gathering.
# Probabilistic Planning for AUV Data Harvesting from Smart Underwater Sensor Networks
## Keywords:
- Task Planning
- Marine Robotics
- Autonomous Agents
## Abstract:
Harvesting valuable ocean data, ranging from climate and marine life analysis to industrial equipment monitoring, is an extremely challenging real-world problem. Sparse underwater sensor networks are a promising approach to scale to larger and deeper environments, but these have difficulty offloading their data without external assistance. Traditionally, offloading data has been achieved by costly, fixed communication infrastructure. In this paper, we propose a planning under uncertainty method that enables an autonomous underwater vehicle (AUV) to adaptively collect data from smart sensor networks in underwater environments. Our novel solution exploits the ability of sensor nodes to provide the AUV with time-of-flight acoustic localisation, and is able to prioritise nodes with the most valuable data. In both simulated experiments and a real-world field trial, we demonstrate that our method outperforms the type of hand-designed behaviours that has previously been used in the context of underwater data harvesting.
# Efficient Task/Motion Planning for a Dual-Arm Robot from Language Instructions and Cooking Images
## Keywords:
- Task Planning
- Industrial Robots
- Manipulation Planning
## Abstract:
When generating robot motions based on instructions such as cooking recipes, ambiguity of the instructions and lack of necessary information are problematic for the robot. To solve this problem, we propose an efficient motion planning approach for a dual-arm robot by constructing a graph representing a motion sequence based on a recipe consisting of verbal instructions and cooking images. A functional unit is generated based on the linguistic instructions in the recipe. Since most recipes lack the necessary information for executing the motion, we first consider extracting the information about the cooking motion like cutting from the food images of the recipe and supplementing it. In addition, to supplement the actions that humans perform unconsciously, we generate functional units for actions not explicitly mentioned in the recipe based on the current situation of the cooking process, and then connect them to the functional units generated from the recipe. Moreover, during the connection, we consider the motion of the robot's arms in parallel for efficient execution of the recipe, similar to those of a human. Through experiments, we demonstrate that for a given recipe, the proposed method can be used to generate a cooking sequence with the supplementary information needed, and executed by a dual-arm robot. The results show that the proposed method is effective and can simplify robot teaching in cooking tasks.
# Clustering Trust Dynamics in a Human-Robot Sequential Decision-Making Task
## Keywords:
- Acceptability and Trust
- Human-Robot Teaming
- Planning under Uncertainty
## Abstract:
In this paper, we present a framework for trust# aware sequential decision-making in a human-robot team wherein the human agent’s trust in the robotic agent is dependent on the reward obtained by the team. We model the problem as a finite-horizon Markov Decision Process with the trust of the human on the robot as a state variable. We develop a reward# based performance metric to drive the trust update model, allowing the robotic agent to make trust-aware recommendations. We conduct a human-subject experiment with a total of 45 participants and analyze how the human agent’s trust evolves over time. Results show that the proposed trust update model is able to accurately capture the human agent’s trust dynamics. Moreover, we cluster the participants’ trust dynamics into three categories, namely, Bayesian decision makers, oscillators, and disbelievers, and identify personal characteristics that could be used to predict which type of trust dynamics a person will belong to. We find that the disbelievers are less extroverted, less agreeable, and have lower expectations toward the robotic agent, compared to the Bayesian decision makers and oscillators. The oscillators tend to get significantly more frustrated than the Bayesian decision makers.
# Behavior-Tree Embeddings for Robot Task-Level Knowledge
## Keywords:
- Control Architectures and Programming
- Learning Categories and Concepts
- Software, Middleware and Programming Environments
## Abstract:
Recently, the behavior tree is gaining popularity as a robotic task-level knowledge representation. Manual design of behavior trees from scratch is tedious and cumbersome. Motivated by the need for an efficient way to reuse or transfer robot task-level knowledge, we propose a vector-space embedding approach that encodes a symbolic task into a numerical form. This approach, called behavior-tree embedding, takes a complete behavior tree as input and generates a corresponding vector. By exploiting the pre-trained language-embedding model and the node-aggregation mechanism, the produced embedding is capable of preserving both semantic information of task description and structural information of the hierarchical task organization. We evaluated the effectiveness and versatility of our proposed vector-space embedding approach in three different tasks.
# Can We Reach Human Expert Programming Performance? a Tactile Manipulation Case Study in Learning Time and Task Performance
## Keywords:
- Performance Evaluation and Benchmarking
- Machine Learning for Robot Control
- Human-Centered Robotics
## Abstract:
Reaching human-level performance in tactile manipulation is one of the grand challenges in nowadays robotics research. Over the past decade significant progress in both skill control and learning was made. However, the achievable execution speed still falls behind the human ability, without clearly understanding whether the specific shortcomings are mainly in the control, skill learning, or motion planning layer. For gaining a better understanding of this complex problem, we draw an experimental side-by-side comparative case study. 
First, given a task program for a challenging benchmarking task, the goal is to objectify the achievable task performance from a human expert programmer against autonomously learning these assembly behaviors with a state-of-the-art skill learning framework. Second, we compare the manually tuned and learned robot skills to the performance of an adult human solving the task manually. 
For the former, it could be shown that despite longer learning duration, the task execution speed of the machine learning-based solution is equivalent to the one programmed by the human expert. For the latter, the identified performance gap remained significantly larger, where only for some specific isolated skills the system was able to reach comparable or even faster than human execution speeds. The overall analysis gave also useful hints where in particular manipulation policies and arm-hand coordination still need significant improvements in the future.
# Data-Driven Abstractions for Robots with Stochastic Dynamics (I)
## Keywords:
- Motion and Path Planning
- Formal Methods in Robotics and Automation
- Probability and Statistical Methods
## Abstract:
This paper describes the construction of stochastic, data-based discrete abstractions for uncertain random processes continuous in time and space. Motivated by the fact that modeling processes often introduce errors which interfere with the implementation of control strategies, here the abstraction process proceeds in reverse: the methodology does not abstract models; rather it models abstractions. Specifically, it first formalizes a template for a family of stochastic abstractions, and then fits the parameters of that template to match the dynamics of the underlying process and ground the abstraction. The paper also shows how the parameter fitting approach can be implemented based on a probabilistic model validation approach which draws from randomized algorithms, and results in a discrete abstract model which is approximately simulated by the actual process physics, at a desired confidence level. In this way, the models afford the implementation of symbolic control plans with probabilistic guarantees at a desired level of fidelity.
# Aerial Systems 6
# Linear and Nonlinear Model Predictive Control Strategies for Trajectory Tracking Micro Aerial Vehicles: A Comparative Study
## Keywords:
- Aerial Systems: Mechanics and Control
- Aerial Systems: Applications
- Motion and Path Planning
## Abstract:
This paper presents a comparison of linear and nonlinear Model Predictive Control (MPC) strategies for trajectory tracking Micro Aerial Vehicles (MAVs). In this comparative study, we paid particular attention to establish quantitatively fair metrics and testing conditions for both strategies. In particular, we chose the most suitable numerical algorithms to bridge the gap between linear and nonlinear MPC, leveraged the very same underlying solver and estimation algorithm with identical parameters, and allow both strategies to operate with a similar computational budget. In order to obtain a well-tuned performance from the controllers, we employed the parameter identification results determined in a previous study for the same robotic platform and added a reliable disturbance observer to compensate for model uncertainties. We carried out a thorough experimental campaign involving multiple representative trajectories. Our approach included three different stages for tuning the algorithmic parameters, evaluating the predictive control feasibility, and validating the performances of both MPC-based strategies. As a result, we were able to propose a decisional recipe for selecting a linear or nonlinear MPC scheme that considers the predictive control feasibility for a peculiar trajectory, characterized by specific speed and acceleration requirements, as a function of the available on-board resources.
# Design and Trajectory Tracking Control of a New Bi-Copter UAV
## Keywords:
- Aerial Systems: Mechanics and Control
- Mechanism Design
## Abstract:
A pair of vectored thrusts brings versatility and power efficiency to bi-copter unmanned aerial vehicles (UAVs). One common difficulty confronted by state-of-the-art bi-copter UAVs is the non-minimum phase nature, which puts fundamental limitations in the system and challenges the control.
This paper introduces a new minimum phase bi-copter UAV that outperforms the conventional bi-copter UAV on attitude control with faster angular response and halved settling time. The comparison is made based on the optimal performance found by a particle swarm optimization (PSO)-based attitude controller on SO(3). The differential flatness property of generic bi-copter UAVs considering servo dynamics is analyzed, providing necessary conditions for the system to be flat. Flatness-based trajectory generation and tracking control of the new bi-copter UAV are described in detail together with flight experiments demonstrating the performance of the bi-copter flying through a drone race gate following a four-dimensional trajectory.
# Local Perception-Aware Transformer for Aerial Tracking
## Keywords:
- Aerial Systems: Perception and Autonomy
- Deep Learning for Visual Perception
- Aerial Systems: Applications
## Abstract:
Transformer-based visual object tracking has been utilized extensively. However, the Transformer structure is lack of enough inductive bias. In addition, only focusing on encoding the global feature does harm to modeling local details, which restricts the capability of tracking in aerial robots. Specifically, with local-modeling to global-search mechanism, the proposed tracker replaces the global encoder by a novel local-recognition encoder. In the employed encoder, a local-recognition attention and a local element correction network are carefully designed for reducing the global redundant information interference and increasing local inductive bias. Meanwhile, the latter can model local object details precisely under aerial view through detail-inquiry net. The proposed method achieves competitive accuracy and robustness in several authoritative aerial benchmarks with 316 sequences in total. The proposed tracker’s practicability and efficiency have been validated by the real-world tests. The source code is available at https://github.com/vision4robotics/LPAT.
# End-To-End Feature Decontaminated Network for UAV Tracking
## Keywords:
- Aerial Systems: Perception and Autonomy
- Aerial Systems: Applications
- Deep Learning for Visual Perception
## Abstract:
Object feature pollution is one of the burning issues in vision-based UAV tracking, commonly caused by occlusion, fast motion, and illumination variation. Due to the contaminated information in the polluted object features, most trackers fail to precisely estimate the object location and scale. To address the above disturbing issue, this work proposes a novel end-to-end feature decontaminated network for efficient and effective UAV tracking, i.e., FDNT. FDNT mainly includes two modules: a decontaminated downsampling network and a decontaminated upsampling network. The former reduces the interference information of the feature pollution and enhanced the expression of the object location information with two asymmetric convolution branches. The latter restores the object scale information with the super-resolution technology-based low-to-high encoder, achieving a further decontamination effect. Moreover, a novel pooling distance loss is carefully developed to assist the decontaminated downsampling network in concentrating on the critical regions with the object information. Exhaustive experiments on three well-known benchmarks validate the effectiveness of FDNT, especially on the sequences with feature pollution. In addition, real-world tests show the efficiency of FDNT with 31.4 frames per second. The code and demo videos are available at https://github.com/ vision4robotics/FDNT.
# Blind As a Bat: Audible Echolocation on Small Robots
## Keywords:
- Aerial Systems: Perception and Autonomy
- Range Sensing
- Robot Audition
## Abstract:
For safe and efficient operation, mobile robots need to perceive their environment, and in particular, perform tasks such as obstacle detection, localization, and mapping. Although robots are often equipped with microphones and speakers, the audio modality is rarely used for these tasks. Compared to the localization of sound sources, for which many practical solutions exist, algorithms for active echolocation are less developed and often rely on hardware requirements that are out of reach for small robots. 
We propose an end-to-end pipeline for sound-based localization and mapping that is targeted at, but not limited to, robots equipped with only simple buzzers and low-end microphones. The method is model-based, runs in real time, and requires no prior calibration or training. We successfully test the algorithm on the e-puck robot with its integrated audio hardware, and on the Crazyflie drone, for which we design a reproducible audio extension deck. We achieve centimeter-level wall localization on both platforms when the robots are static during the measurement process. Even in the more challenging setting of a flying drone, we can successfully localize walls, which we demonstrate in a proof-of-concept multi-wall localization and mapping demo.
# HighlightNet: Highlighting Low-Light Potential Features for Real-Time UAV Tracking
## Keywords:
- Aerial Systems: Applications
- Deep Learning for Visual Perception
- Aerial Systems: Perception and Autonomy
## Abstract:
Low-light environments have posed a formidable challenge for robust unmanned aerial vehicle (UAV) tracking even with state-of-the-art (SOTA) trackers since the potential image features are hard to extract under adverse light conditions. Besides, due to the low visibility, accurate online selection of the object also becomes extremely difficult for human monitors to initialize UAV tracking in ground control stations. To solve these problems, this work proposes a novel enhancer, i.e., HighlightNet, to light up potential objects for both human operators and UAV trackers. By employing Transformer, HighlightNet can adjust enhancement parameters according to global features and is thus adaptive for the illumination variation. Pixel-level range mask is introduced to make HighlightNet more focused on the enhancement of the tracking object and regions without light sources. Furthermore, a soft truncation mechanism is built to prevent background noise from being mistaken for crucial features. Evaluations on image enhancement benchmarks demonstrate HighlightNet has advantages in facilitating human perception. Experiments on the public UAVDark135 benchmark show that HightlightNet is more suitable for UAV tracking tasks than other state-of-the-art (SOTA) low-light enhancers. In addition, real-world tests on a typical UAV platform verify HightlightNet’s practicability and efficiency in nighttime aerial tracking-related applications. The code and demo videos are available at https://github. com/vision4robotics/HighlightNet.
# Drone with Pneumatic-Tethered Suction-Based Perching Mechanism for High Payload Application
## Keywords:
- Aerial Systems: Applications
- Mechanism Design
- Field Robots
## Abstract:
Concrete infrastructures provide the means to connect cities and transport people and goods. They require regular inspection to assess their current conditions. Aerial work platforms and underbridge platforms or scaffolding are the common equipment used for inspection of elevated infrastructure. These methods often cost more to operate and maintain, are time-consuming, and raise risks for the inspector. One interesting field of research for UAVs that can be used for infrastructure inspection is aerial perching. A perching UAV can be loaded with an inspection apparatus foregoing the need for costly equipment and risks involved in the inspection. Many have presented aerial perching for various applications and not as much for applications related to concrete infrastructure inspection. This study investigates a perching UAV that can perform perching on both smooth and rough concrete surfaces.
This paper presents an unmanned aerial system that utilizes a suction-based perching mechanism with a pneumatic supply tethered from the ground. The proposed perching mechanism provides a reliable and high payload capacity needed for nondestructive testing of the infrastructure. The paper introduces the concept, presents the design and proof of concept, and validates the idea through actual bridge experiments.
# Geometrically Constrained Trajectory Optimization for Multicopters (I)
## Keywords:
- Aerial Systems: Applications
- Motion and Path Planning
- Autonomous Vehicle Navigation
## Abstract:
In this article, we present an optimization-based framework for multicopter trajectory planning subject to geometrical configuration constraints and user-defined dynamic constraints. The basis of the framework is a novel trajectory representation built upon our novel optimality conditions for unconstrained control effort minimization. We design linear-complexity operations on this representation to conduct spatial-temporal deformation under various planning requirements. Smooth maps are utilized to exactly eliminate geometrical constraints in a lightweight fashion. A variety of state-input constraints are supported by the decoupling of dense constraint evaluation from sparse parameterization, and backward differentiation of flatness map. As a result, this framework transforms a generally constrained multicopter planning problem into an unconstrained optimization that can be solved reliably and efficiently. Our framework bridges the gaps among solution quality, planning efficiency, and constraint fidelity for a multicopter with limited resources and maneuvering capability. Its generality and robustness are both demonstrated by applications to different flight tasks. Extensive simulations and benchmarks are also conducted to show its capability of generating high-quality solutions while retaining the computation speed against other specialized methods by orders of magnitude.
# Robust Trajectory Planning for Spatial-Temporal Multi-Drone Coordination in Large Scenes
## Keywords:
- Aerial Systems: Applications
- Collision Avoidance
- Autonomous Vehicle Navigation
## Abstract:
In this paper, we describe a robust multi-drone planning framework for high-speed trajectories in large scenes. It uses a free-space-oriented map to free the optimization from cumbersome environment data. A capsule-like safety constraint is designed to avoid reciprocal collisions when vehicles deviate from their nominal flight progress under disturbance. We further show the minimum-singularity differential flatness of our drone dynamics with nonlinear drag effects involved. Leveraging the flatness map, trajectory optimization is efficiently conducted on the flat outputs while still subject to physical limits considering drag forces at high speeds. The robustness and effectiveness of our framework are both validated in large-scale simulations. It can compute collision-free trajectories satisfying high-fidelity vehicle constraints for hundreds of drones within 10 minutes.
# Navigation Systems 7
# Dynamic-GAN: Learning Spatial-Temporal Attention for Dynamic Object Removal in Feature Dense Environments
## Keywords:
- Vision-Based Navigation
- Deep Learning Methods
## Abstract:
This paper presents an attention-based, deep learning framework that converts robot camera frames with dynamic content into static frames to more easily apply simultaneous localization and mapping (SLAM) algorithms. The vast majority of SLAM methods have difficulty in the presence of dynamic objects appearing in the environment and occluding the area being captured by the camera. Despite past attempts to deal with dynamic objects, challenges remain to reconstruct large, occluded areas with complex backgrounds. Our proposed Dynamic-GAN framework employs a generative adversarial network to remove dynamic objects from a scene and inpaint a static image free of dynamic objects. The Dynamic-GAN framework utilizes spatial-temporal transformers, and a novel spatial-temporal loss function. The evaluation of Dynamic-GAN was comprehensively conducted both quantitatively and qualitatively by testing it on benchmark datasets, and on a mobile robot in indoor navigation environments. As people appeared dynamically in close proximity to the robot, results showed that large, feature-rich occluded areas can be accurately reconstructed with our attention-based deep learning framework for dynamic object removal. Through experiments we demonstrate that our proposed algorithm has up to 25% better performance on average as compared to the standard benchmark algorithms.
# Heterogeneous-Agent Trajectory Forecasting Incorporating Class Uncertainty
## Keywords:
- Autonomous Vehicle Navigation
- Intelligent Transportation Systems
- Data Sets for Robotic Vision
## Abstract:
Reasoning about the future behavior of other agents is critical to safe robot navigation. The multiplicity of plausible futures is further amplified by the uncertainty inherent to agent state estimation from data, including positions, velocities, and semantic class. Forecasting methods, however, typically neglect class uncertainty, conditioning instead only on the agent's most likely class, even though perception models often return full class distributions. To exploit this information, we present HAICU, a method for heterogeneous-agent trajectory forecasting that explicitly incorporates agents' class probabilities. We additionally present PUP, a new challenging real-world autonomous driving dataset, to investigate the impact of Perceptual Uncertainty in Prediction. It contains challenging crowded scenes with unfiltered agent class probabilities that reflect the long-tail of current state-of-the-art perception systems. We demonstrate that incorporating class probabilities in trajectory forecasting significantly improves performance in the face of uncertainty, and enables new forecasting capabilities such as counterfactual predictions.
# Lifelong Topological Visual Navigation
## Keywords:
- Vision-Based Navigation
- Deep Learning for Visual Perception
## Abstract:
Commonly, learning-based topological navigation approaches produce a local policy while preserving some loose connectivity of the space through a topological map. Nevertheless, spurious or missing edges in the topological graph often lead to navigation failure. In this work, we propose a sampling-based graph building method, which results in sparser graphs yet with higher navigation performance compared to baseline methods. We also propose graph maintenance strategies that eliminate spurious edges and expand the graph as needed, which improves lifelong navigation performance. Unlike controllers that learn from fixed training environments, we show that our model can be fine-tuned using only a small number of collected trajectory images from a real-world environment where the agent is deployed. We demonstrate successful navigation after fine-tuning on real-world environments, and notably show significant navigation improvements over time by applying our lifelong graph maintenance strategies.
# D-LC-Nets: Robust Denoising and Loop Closing Networks for LiDAR SLAM in Complicated Circumstances with Noisy Point Clouds
## Keywords:
- Autonomous Vehicle Navigation
- Semantic Scene Understanding
- Deep Learning for Visual Perception
## Abstract:
The current LiDAR SLAM (Simultaneous Localization and Mapping) system suffers greatly from low accuracy and limited robustness when faced with complicated circumstances. From our experiments, we find that current LiDAR SLAM systems have limited performance when the noise level in the obtained point clouds is large. Therefore, in this work, we propose a general framework to tackle the problem of denoising and loop closure for LiDAR SLAM in complex environments with many noises and outliers caused by reflective materials. Current approaches for point clouds denoising are mainly designed for small-scale point clouds and can not be extended to large-scale point clouds scenes. In this work, we firstly proposed a lightweight network for large-scale point clouds denoising. Subsequently, we have also designed an efficient loop closure network for place recognition in global optimization to improve the localization accuracy of the whole system. Finally, we have demonstrated by extensive experiments and benchmark studies that our method can have a significant boost on the localization accuracy of the LiDAR SLAM system when faced with noisy point clouds, with a marginal increase in computational cost.
# State Dropout-Based Curriculum Reinforcement Learning for Self-Driving at Unsignalized Intersections
## Keywords:
- Autonomous Vehicle Navigation
- Reinforcement Learning
- Motion and Path Planning
## Abstract:
Traversing intersections is a challenging problem for autonomous vehicles, especially when the intersections do not have traffic control. Recently deep reinforcement learning has received massive attention due to its success in dealing with autonomous driving tasks. In this work, we address the problem of traversing unsignalized intersections using a novel curriculum for deep reinforcement learning. The proposed curriculum leads to: 1) A faster training process for the reinforcement learning agent, and 2) Better performance compared to an agent trained without curriculum. Our main contribution is two-fold: 1) Presenting a unique curriculum for training deep reinforcement learning agents, and 2) demonstrating the performance improvement using the proposed curriculum in the unsignalized intersection traversal task. The framework expects processed observations of the surroundings from the perception system of the autonomous vehicle. We test our method in the CommonRoad motion planning simulator on T-intersections and four-way intersections.
# Vehicle Type Specific Waypoint Generation
## Keywords:
- Autonomous Vehicle Navigation
## Abstract:
We develop a generic mechanism for generating vehicle-type specific sequences of waypoints from a probabilistic foundation model of driving behavior. Many foundation behavior models are trained on data that does not include vehicle information, which limits their utility in downstream applications such as planning. Our novel methodology conditionally specializes such a behavior predictive model to a vehicle-type by utilizing byproducts of the reinforcement learning algorithms used to produce vehicle specific controllers. We show how to compose a vehicle specific value function estimate with a generic probabilistic behavior model to generate vehicle-type specific waypoint sequences that are more likely to be physically plausible then their vehicle-agnostic counterparts.
# Autonomous Navigation of AGVs in Unknown Cluttered Environments: Log-MPPI Control Strategy
## Keywords:
- Autonomous Vehicle Navigation
- Motion Control
- Collision Avoidance
## Abstract:
Sampling-based model predictive control (MPC) optimization methods, such as Model Predictive Path Integral (MPPI), have recently shown promising results in various robotic tasks. However, it might produce an infeasible trajectory when the distributions of all sampled trajectories are concentrated within high-cost even infeasible regions. In this study, we propose a new method called log-MPPI equipped with a more effective trajectory sampling distribution policy which significantly improves the trajectory feasibility in terms of satisfying system constraints. The key point is to draw the trajectory samples from the normal log-normal (NLN) mixture distribution, rather than from Gaussian distribution. Furthermore, this work presents a method for collision-free navigation in unknown cluttered environments by incorporating the 2D occupancy grid map into the optimization problem of the sampling-based MPC algorithm. We first validate the efficiency and robustness of our proposed control strategy through extensive simulations of 2D autonomous navigation in different types of cluttered environments as well as the cartpole swing-up task. We further demonstrate, through real# world experiments, the applicability of log-MPPI for performing a 2D grid-based collision-free navigation in an unknown cluttered environment, showing its superiority to be utilized with the local costmap without adding additional complexity to the optimization problem. A video demonstrating the real-world and simulation results is available at https://youtu.be/_uGWQEFJSN0.
# Cross-Modal Fusion-Based Prior Correction for Road Detection in Off-Road Environments
## Keywords:
- Autonomous Vehicle Navigation
- Computer Vision for Transportation
- Computer Vision for Automation
## Abstract:
Road detection plays a fundamental role in the visual navigation system of autonomous vehicles. However, it’s still challenging to achieve robust road detection in offroad scenarios due to their complicated road appearances and ambiguous road structures. Therefore, existing image-based road detection approaches usually fail to extract the right routes due to the lack of the effective fusion of the image and prior reference paths(road guidances generated via map annotations and GPS localization). Besides, the reference paths are not always reliable because of GPS localization errors and mapping errors. To achieve robust road detection in off-road scenarios, we propose a prior-correction-based road detection network named PR-ROAD via fusing the cross-model information provided by both the reference path and the input image. These two heterogeneous data, prior and image, are deeply fused by a cross-attention module and formulate contextual inter-dependencies. We conduct experiments in our collected rural, off-road and urban datasets. The experimental results demonstrate the effectiveness of the proposed method both on unstructured and structured roads.
# InterFusion: Interaction-Based 4D Radar and Lidar Fusion for 3D Object Detection
## Keywords:
- Automation Technologies for Smart Cities
- Intelligent Transportation Systems
- Object Detection, Segmentation and Categorization
## Abstract:
Many recent works detect 3D objects by several sensor modalities for autonomous driving, where high-resolution cameras and high-line LiDARs are mostly used but relatively expensive. To achieve a balance between overall cost and detection accuracy, many multi-modal fusion techniques have been suggested. In recent years, the fusion of LiDAR and Radar has gained ever-increasing attention, especially 4D Radar, which can adapt to bad weather conditions due to its penetrability. Although features have been fused from multiple sensing modalities, most methods cannot learn interactions from different modalities, which does not make for their best use. Inspired by the self-attention mechanism, we present InterFusion, an interaction-based fusion framework, to fuse 16-line LiDAR with 4D Radar. It aggregates features from two modalities and identifies cross-modal relations between Radar and LiDAR features. In experimental evaluations on the Astyx HiRes 2019 dataset, our method outperformed the baseline by 4.20% mAP in 3D and 10.76% BEV mAP for the car class at the moderate level.
# Prosthetics and Exoskeletons 1
# Experimental Assessment of a Control Strategy for Locomotion Assistance Relying on Simplified Motor Primitives
## Keywords:
- Prosthetics and Exoskeletons
- Physically Assistive Devices
- Wearable Robotics
## Abstract:
Lower-limb exoskeletons are robotic devices that can provide assistance to human locomotion. Since they are expected to be used in ecological environments, their control strategy should handle different kinds of daily-life situations. Taking inspiration from the human neuromuscular system – and particularly from the so-called motor primitives – may help in adapting the type of delivered assistance to different locomotion tasks. In this work, we validated the combination of simplified primitives and a musculoskeletal model for assisting healthy subjects with a hip exoskeleton. This framework showed adaptation to the user’s gait for different slope inclinations, although its effects on the subject’s speed and their perceived effort showed no significant improvement compared to wearing the device in transparent mode.
# Design of EMG-Driven Musculoskeletal Model for Volitional Control of a Robotic Ankle Prosthesis
## Keywords:
- Prosthetics and Exoskeletons
- Physical Human-Robot Interaction
- Wearable Robotics
## Abstract:
Existing robotic lower-limb prostheses use autonomous control to address cyclic, locomotive tasks, but are inadequate in adapting to variations in non-cyclic and unpredictable tasks. This study aims to address this challenge by designing a novel electromyography (EMG)-driven musculoskeletal model for volitional control of a robotic ankle-foot prosthesis. The proposed controller ensures continuous control of the device, allowing users to freely manipulate the prosthesis behavior. A Hill-type muscle model was implemented to model a dorsiflexor and a plantarflexor to function around a virtual ankle joint. The model parameters for a subject specific model was determined by fitting the model to the experimental data collected from an able-bodied subject. EMG signals recorded from antagonist muscle pairs were used to activate the virtual muscle models. This model-based approach was then validated via offline simulations and real-time prosthesis control. Additionally, the feasibility of the proposed prosthesis control on assisting the user’s functional tasks was demonstrated. The present control may further improve the function of robotic prosthesis for supporting versatile activities in individuals with lower-limb amputations.
# Visual Environment Perception for Obstacle Detection and Crossing of Lower-Limb Exoskeletons
## Keywords:
- Prosthetics and Exoskeletons
- Vision-Based Navigation
- Rehabilitation Robotics
## Abstract:
Lower limb exoskeletons offer support for patients suffering from mobility disorders due to injury, stroke, etc. But these devices are not used in day-to-day life and environments due to their limited human-computer interface to perceive and handle different terrains and tasks. In this paper, we introduce a simple vision-based environment perception pipeline for lower-limb exoskeletons for obstacle crossing tasks. The proposed pipeline consists of three stages, namely, ground plane and obstacle detection, estimating obstacle location and dimensions, and obstacle tracking. To reduce noisy artifacts and reliably detect obstacles, we propose a similarity metric based on color, gradient orientation, and 2D surface normal. Depth map of the detected obstacle region is utilized for estimating the obstacle location and dimensions. Also, we consider two obstacle tracking modes for obstacle crossing, visual tracking using a RGB-D camera and positional tracking using a SLAM camera. The proposed vision-based perception pipeline is integrated with an exoskeleton, where we propose a control scheme that can vary step length adaptively to successfully cross detected obstacles. We conduct offline and online experiments to validate the proposed perception pipeline and provide insights on the same. Our experiments show that the proposed pipeline allows exoskeletons to understand their environment and successfully cross obstacles.
# Unilateral Stiffness Modulation with a Robotic Hip Exoskeleton Elicits Adaptation During Gait
## Keywords:
- Prosthetics and Exoskeletons
- Physical Human-Robot Interaction
- Wearable Robotics
## Abstract:
Wearable robotic exoskeletons show promise in their ability to provide gait assistance and rehabilitation in real-world contexts. However, a better understanding is needed of how exoskeletons contribute to neural adaptation in locomotion, a critical component of neurological gait rehabilitation. We tested whether unilateral perturbations elicit neural adaptation in healthy participants using a novel robotic hip exoskeleton, taking inspiration from asymmetry augmentation strategies used in split-belt treadmill training. We found that applying a virtual stiffness parallel to the hip joint on one side elicited changes in hip range of motion and step length, and that these changes were time varying, indicating an adaptation response. However, participants converged on asymmetric hip ranges of motion and step lengths both with and without applied stiffness from the exoskeleton. These results suggest that while adaptation appears to have occurred, it was not solely driven by the nervous system reducing gait asymmetry. Our findings indicate that applying mechanical impedance asymmetrically to the joints may be an effective gait training and rehabilitation approach, as well as a method to elicit a novel adaptation response to further study neuromotor control of locomotion.
# A Piecewise Monotonic Smooth Phase Variable for Speed-Adaptation Control of Powered Knee-Ankle Prostheses
## Keywords:
- Prosthetics and Exoskeletons
- Sensor-based Control
- Human Performance Augmentation
## Abstract:
Researchers are currently making progress in unifying the entire gait cycle of powered prostheses by using a human-inspired phase variable but constructing a robust phase variable to more accurately estimate the gait phase and desired joint trajectories of prostheses during varying walking speeds remains an open problem. Firstly, this study proposed a piecewise monotonic and smooth phase variable to predict the gait phase from only the measured thigh angle. Compared to the two most widely used methods, thigh angle integral vs. thigh angle and thigh angular rate vs. thigh angle, the proposed method addressed the drift problem of the integral-based method and the noise the problem of the angular rate-based. Then a predictive tuning-free model that represents gait kinematics as a continuous function of proposed phase variable and walking speed was constructed to generate desired joint virtual constraints for speed-adaptation control of powered knee-ankle prosthesis during continuously varying walking speeds. Experiments were conducted with six able-bodied participants wearing inertial measurement units and performing periodic and non-periodic (quick start and stop) tasks, and one transfemoral amputee wearing a powered kneeankle prosthesis walking on a treadmill. Experimental results illustrated that the root mean squared error of the gait phase estimated by the proposed approach was 75% lower than the integral-based and angular rate-based methods, and the proposed approach performed well in the continuous phase control of a powered knee-ankle prosthesis during varying walking speeds.
# Imposing Healthy Hip Movement Pattern and Range by Exoskeleton Control for Individualized Assistance
## Keywords:
- Prosthetics and Exoskeletons
- Machine Learning for Robot Control
- Reinforcement Learning
## Abstract:
Powered exoskeletons are promising devices to improve the walking patterns of people with neurological impairments, such as those who suffer from stroke and multiple sclerosis. Providing personalized external assistance though is challenging due to uncertainties and the time-varying nature of human-robot interaction. Recently, human-in-the-loop (HIL) optimization has been investigated for providing assistance to minimize energetic expenditure, usually quantified by metabolic cost, of a human user in walking and running tasks. However, this full-body global effect evaluation may not directly reflect the local functions of the targeted joint(s). This makes it difficult to assess the direct effect when robotic assistance is provided. In addition, the HIL optimization method usually does not take into account local joint trajectories, a consideration that is important in textcolor{black}{imposing healthy} joint movements and gait patterns for individuals with lower limb motor deficits. In this paper, we propose a model-free reinforcement learning (RL)-based control framework to achieve a normative range of motion and gait pattern of the hip joint during walking. Our RL-based control provides personalized assistance torque profile by heuristically manipulating three control parameters for hip flexion and extension, respectively during walking. A least square policy iteration was devised to optimize a cost function associated with control efforts and hip joint trajectory errors textcolor{black}{by tuning} the control parameters. To evaluate the performance of the design approach, a compression sleeve was used to constrain the hip joint of unimpaired human participants to simulate motor deficits. The proposed RL control successfully achieved the desired goal of enlarging hip ROM in three participants walking on a treadmill.
# Characterizing Prosthesis Control Fault During Human-Prosthesis Interactive Walking Using Intrinsic Sensors
## Keywords:
- Prosthetics and Exoskeletons
- Physical Human-Robot Interaction
- Safety in HRI
## Abstract:
The physical interactions between wearable lower limb robots and humans have been investigated to inform effective robot design for walking augmentation. However, human-robot interactions when internal faults occur within robots have not been systematically reported, but it is essential to improve the robustness of robotic devices and ensure the user’s safety. This paper aims to (1) present a methodology to characterize the behavior of the robotic transfemoral prosthesis as an effective wearable robot platform while interacting with the users in the presence of internal faults, and (2) identify the potential data sources for accurate detection of the prosthesis fault. We first obtained the human perceived response in terms of their walking stability when the prosthesis control fault (inappropriate intrinsic control output/command) was emulated/applied in level-ground walking. Then the measurements and their features, obtained from the transfemoral prosthesis, were examined for the emulated faults that elicited a sense of instability in human users. The optimal features that contributed the most in separating faulty interaction from the normal walking condition were determined using two machine-learning-based approaches: One-Class Support Vector Machine (OCSVM) and Mahalanobis Distance (MD) classifier. The OCSVM anomaly detector could achieve an average sensitivity of 85.7% and an average false alarm rate of 1.7% with a reasonable detecting time of 147.6 ms for detecting emulated control errors among all subjects. The result demonstrates the potential of using machine-learningbased schemes in identifying prosthesis control faults based on intrinsic sensors on the prosthesis. This study presents a procedure to study human-robot fault tolerance and inform the future design of robust prosthesis control.
# A Piecewise Monotonic Gait Phase Estimation Model for Controlling a Powered Transfemoral Prosthesis in Various Locomotion Modes
## Keywords:
- Prosthetics and Exoskeletons
- Human-Robot Collaboration
## Abstract:
Gait phase-based control is a trending research topic for walking-aid robots, especially robotic lower-limb prostheses. Gait phase estimation is a challenge for gait phase-based control. Previous researches used the integration or the differential of the human's thigh angle to estimate the gait phase, but accumulative measurement errors and noises can affect the estimation results. In this paper, a more robust gait phase estimation method is proposed using a unified form of piecewise monotonic gait phase-thigh angle models for various locomotion modes. The gait phase is estimated from only the thigh angle, which is a stable variable and avoids phase drifting. A Kalman filter-based smoother is designed to further suppress the mutations of the estimated gait phase. Based on the proposed gait phase estimation method, a gait phase-based joint angle tracking controller is designed for a transfemoral prosthesis. The proposed gait estimation method, the gait phase smoother, and the controller is evaluated through offline analysis on walking data in various locomotion modes. And the real-time performance of the gait phase-based controller is validated in an experiment on the transfemoral prosthesis.
# Understanding Modulation of Ankle Stiffness During Stance Phase of Walking on Different Environments and Its Implications for the Design of Impedance Controllers
## Keywords:
- Physically Assistive Devices
- Prosthetics and Exoskeletons
- Compliance and Impedance Control
## Abstract:
Understanding how human ankle mechanics are modulated when walking on various mechanical environments (e.g., soft and unstable ground) is essential for the development of intuitive controllers for lower extremity robots. With this goal in mind, this paper investigates how ankle stiffness is modulated throughout the stance phase of walking over rigid and compliant surfaces. A robotic platform, capable of simulating varying mechanical environments, was used to quantify ankle stiffness along the sagittal plane at 20, 40, and 60% of the stance phase while the subject walked over compliant and rigid surfaces. The group average results of 10 unimpaired individuals demonstrated that stiffness increased with the progression of stance phase and there was no significant environmental effect on the stiffness modulation on a group level. However, further investigation into individual subject data found significant differences in ankle stiffness modulation across environments which strongly correlated with the differences in center of pressure position during walking regardless of the type of surfaces on an individual level (Pearson correlation coefficient: ~0.93). Implications of the observed results for the development of continuous impedance controllers for lower extremity robots are discussed.
# Aerial Systems 7
# Robust and Efficient Velocity Estimation for MAVs with an RGB-D Camera
## Keywords:
- Aerial Systems: Perception and Autonomy
- Computer Vision for Automation
- RGB-D Perception
## Abstract:
Micro Aerial Vehicles (MAVs) have become increasingly popular due to their wide applications in many areas. For autonomous navigation and safe control of MAVs, it is essential to have accurate and reliable velocity and position estimation. However, due to limited computational power and payload, it is still challenging for autonomous operation of MAVs in complex environments. In this paper, we propose a robust and efficient velocity estimation framework for MAVs with a single downward-facing RGB-D camera, which is able to provide metric velocity estimation in three dimensions as well as yaw rate in real time without the fusion of additional sensors. Unlike traditional algorithms, our method uses kernel cross-correlators (KCCs) to efficiently determine optical flow for motion estimation, which does not rely on costly feature extraction and matching process. Moreover, we utilize depth images to estimate the vertical velocity of MAVs without the assumption of a flat ground. Autonomous flight tests on a quadrotor in complex environments demonstrate the robustness and efficiency of our method.
# Geometric MPC Techniques for Reduced Attitude Control on Quadrotors with Bidirectional Thrust
## Keywords:
- Aerial Systems: Mechanics and Control
- Optimization and Optimal Control
## Abstract:
We present two novel nonlinear MPC formulations for reduced attitude tracking on quadrotors with bidirectional thrust capabilities. Reduced attitude tracking is relevant to recovery from partial thrust loss, which can occur due to the failure of one or more motors. The first formulation builds on a linearization of the quadrotor attitude dynamics on S(2) to achieve simultaneous tracking of reduced attitude and total thrust targets. The second formulation, meanwhile, accomplishes the same goal using a linearization of the dynamics on the Lie algebra of SO(3) and a proposed method for projecting Lie algebra errors onto reduced attitude errors. Both methods achieve global tracking on S(2) without requiring the use of computationally expensive sequential quadratic program solvers. Through simulations, we show that the second approach generally tracks aggressive attitude references better, while the first controller offers more reliable regulation.
# Tightly-Coupled EKF-Based Radar-Inertial Odometry
## Keywords:
- Aerial Systems: Perception and Autonomy
- Localization
- Sensor Fusion
## Abstract:
Multicopter Unmanned Aerial Vehicles (UAV) are small and agile robots with the potential to become prominent in performing autonomous tasks in various Global Navigation Satellite System (GNSS)-denied environments. These environments can potentially be rendered even more challenging due to external factors impairing the robot’s perception such as low or too bright light, permeation with aerosols or smoke. Precondition of autonomous operation, though, is the ability of a robot to accurately localize itself in the surrounding environment. Millimeter-wave Frequency Modulated Continuous Wave (FMCW) radar sensors are resilient to the aforementioned factors while being lightweight, inexpensive and highly accurate. In this paper, we present a Radar-Inertial Odometry (RIO) method for estimating the full 6DoF pose and 3D velocity of a UAV. In an Extended Kalman Filter (EKF) framework, we fuse range measurements and velocity measurements of 3D points detected by an FMCW radar sensor together with Inertial Measurement Unit (IMU) readings. In real experiments we show that our approach enables accurate state estimation of a UAV and that it exhibits improvements over similar existing state-of-the-art method.
# Accurate Vision-Based Flight with Fixed-Wing Drones
## Keywords:
- Aerial Systems: Perception and Autonomy
- Visual Servoing
- Hardware-Software Integration in Robotics
## Abstract:
Fixed-wing drones must navigate to the desired location accurately for maneuvers such as picking up objects and perching. However, current GNSS receivers limit their navigation accuracy to several meters in outdoor environments, making such maneuvers impossible. RTK GNSS can improve flight accuracy, but it requires ground stations at the target location and additional communication modules on the drone. Here, we describe a fixed-wing platform with onboard computation that uses positional information from a GNSS receiver and vision from an onboard camera. The drone relies on a GNSS signal for flying towards a point of interest and switches to vision-based information to accurately reach the target. We conducted outdoor experiments to compare the flight accuracy of three navigation methods: GNSS, RTK GNSS, and the proposed GNSS-vision method. We also systematically assessed the robustness of vision-based control to compensate for GNSS errors and quantify the accuracy of the proposed method. Our results show that the accuracy of the proposed GNSS-vision system is on par with RTK GNSS. GNSS-vision reduces the average error of GNSS by over an order of magnitude, from 3.033~m to 0.283~m, and reduces the variance across repeated flights from 2.095~m to 0.309~m. We open-source the software-hardware architecture used in this paper to enable the research community to build on these results and expand the capabilities of fixed-wing drones.
# Autonomous Quadrotor Landing on Inclined Surfaces in High Particle Environments Using Radar Sensor Perception
## Keywords:
- Aerial Systems: Perception and Autonomy
- Sensor-based Control
- Aerial Systems: Applications
## Abstract:
This paper presents an autonomous approach for landing a quadrotor on inclined surfaces up to 40 degrees using radar perception in a high particle environment, such as dust, rain, or fog. This system uses five radar sensors to determine the direction, angle, and smoothness of a slope through eigenvalue decomposition of a point cloud covariance matrix. The point cloud itself is generated using a FIFO queue with the radar sensors after their points are transformed to a common frame. Then, two asymmetric landing skids of different lengths actively conform to a slope in order to maintain level body attitude upon landing. For perception error tolerance, a study to understand the distance between the propeller and slope surface with respect to slope angles was developed. We evaluate the accuracy and consistency of radar sensors in accomplishing these tasks, to include a comparison of the results with a depth camera while in a high particle environment. Finally, the experimental result shows that the detected slope angle and direction were within 2.2 and 2.4 degrees of ground, and the proposed system is viable and robust for use in real-world applications.
# Retro-RL: Reinforcing Nominal Controller with Deep Reinforcement Learning for Tilting-Rotor Drones
## Keywords:
- Aerial Systems: Mechanics and Control
- Machine Learning for Robot Control
- Reinforcement Learning
## Abstract:
Studies that broaden drone applications into complex tasks require a stable control framework. Recently, deep reinforcement learning (RL) algorithms have been exploited in many studies for robot control to accomplish complex tasks. Unfortunately, deep RL algorithms might not be suitable for being deployed directly into a real-world robot platform due to the difficulty in interpreting the learned policy and lack of stability guarantee, especially for a complex task such as a wall-climbing drone. This paper proposes a novel hybrid architecture that reinforces a nominal controller with a robust policy learned using a model-free deep RL algorithm. The proposed architecture employs an uncertainty-aware control mixer to preserve guaranteed stability of a nominal controller while using the extended robust performance of the learned policy. The policy is trained in a simulated environment with thousands of domain randomizations to achieve robust performance over diverse uncertainties. The performance of the proposed method was verified through real-world experiments and then compared with a conventional controller and the state-of-the-art learning-based controller trained with a vanilla deep RL algorithm.
# TAPE: Tether-Aware Path Planning for Autonomous Exploration of Unknown 3D Cavities Using a Tangle-Compatible Tethered Aerial Robot
## Keywords:
- Aerial Systems: Perception and Autonomy
- Mining Robotics
- Task and Motion Planning
## Abstract:
This paper presents the first method for autonomous exploration of unknown cavities in three dimensions (3D) that focuses on minimizing the distance traveled and the length of tether unwound. Considering that the tether entanglements are little influenced by the global path, our approach employs a 2-level hierarchical architecture. The global frontier-based planning solves a Traveling Salesman Problem (TSP) to minimize the distance. The local planning attempts to minimize the path cost and the tether length using an adjustable decision function whose parameters play on the trade-off between these two values. The proposed method, TAPE, is evaluated through detailed simulation studies as well as field tests. On average, our method generates a 4.1% increase in distance traveled compared to the TSP solution without our local planner, with which the length of the tether remains below the maximum allowed value in 53% of the simulated cases against 100% with our method.
# Sweep-Your-Map: Efficient Coverage Planning for Aerial Teams in Large-Scale Environments
## Keywords:
- Aerial Systems: Perception and Autonomy
- Path Planning for Multiple Mobile Robots or Agents
- Mapping
## Abstract:
The efficiency of path-planning in robot navigation is crucial in tasks such as search-and-rescue and disaster surveying, but this is emphasized even more when considering multi-rotor aerial robots due to the limited battery and flight time. In this spirit, this work proposes an efficient, hierarchical planner to achieve comprehensive visual coverage of large-scale outdoor scenarios for small drones. Following an initial reconnaissance flight, a coarse map of the scene gets built in real-time. Then, regions of the map that were not appropriately observed are identified and grouped by a novel perception-aware clustering process that enables the generation of continuous trajectories (emph{sweeps}) to cover them efficiently. Thanks to this partitioning of the map into a set of tasks, we can generalize the planning to an arbitrary number of drones and perform a well-balanced workload distribution among them. We compare our approach against a state-of-the-art method for exploration and show the advantages of our pipeline in terms of efficiency for obtaining coverage in large environments.
# Predicting Visual Differentiability for Unmanned Aerial Vehicle Gestures
## Keywords:
- Gesture, Posture and Facial Expressions
- Design and Human Factors
- Human-Robot Collaboration
## Abstract:
Unmanned Aerial Vehicles (UAVs) are increasingly being integrated into diverse human interaction domains that require robust human-robot communication systems. Visual communication techniques have shown promise in their ability to communicate concrete information to observers. Such techniques, often described as a UAV `gesture', may be especially useful in the domain of unmanned aerial flight as they can be integrated as a stand-alone software solution in contrast to light or sound-based systems that often require additional hardware that adds weight to a vehicle. Gestures may also be useful in contexts where long distance operation reduces the effectiveness of sound-based communication strategies. However, as gesture is a visual communication technique, it is critical that gestures are designed to optimize an observer's ability to visually perceive the shape of a gesture's motion. Factors such as low visual differentiability between gestures within a set may reduce an observer's ability to accurately classify the shape of a gestural motion. In this work, we discuss the results from multiple gesture perception surveys. We also develop and evaluate techniques to predict in advance how participants may perceive a UAV gesture. We demonstrate that participant gesture classification accuracy correlates to trajectory distance measures and present a method for developing high-differentiabilty gesture sets. This work will enable gesture designers to create gesture sets that are differentiable with high-confidence.
# Learning from Experience
# Robot Task Learning with Motor Babbling Using Pseudo Rehearsal
## Keywords:
- Continual Learning
- Perception-Action Coupling
- Learning from Demonstration
## Abstract:
The paradigm of deep robot learning from demonstrations allows robots to solve complex manipulation tasks by capturing motor skills from given demonstrations; however, collecting demonstrations can be costly. As an alternative, robots can acquire embodiment and motor skills by randomly moving their bodies, which is referred to as motor babbling. Motor babbling data provide relatively inexpensive demonstrations and can be used to enhance the generalizability of robot motions, but they are often used for pre-training or joint training with target task demonstrations. This study focused on the concept of pseudo-rehearsal and retaining the embodiment information acquired from motor babbling data for effective task learning. Pseudo-rehearsal has beneficial features that allow robot models to be retrained and distributed without access to the motor babbling dataset. In this paper, we propose a pseudo-rehearsal framework that can be jointly trained with task trajectories and rehearsed motor babbling trajectories. Using our proposed method, robots can retain motor skills from motor babbling and exhibit improved performance in task execution.
# Continual Learning in Real-Life Applications
## Keywords:
- Continual Learning
- Learning from Experience
## Abstract:
Existing Continual Learning benchmarks only partially address the complexity of real-life applications, limiting the realism of learning agents. In this paper, we propose and focus on benchmarks characterized by common key elements of real-life scenarios, including temporally ordered streams as input data, strong correlation of samples in short time ranges, high data distribution drift over the long time frame, and heavy class unbalancing. Moreover, we enforce online training constraints such as the need for frequent model updates without the possibility of storing a large amount of past data or passing the dataset multiple times through the model. Besides, we introduce a novel hybrid approach based on Continual Learning, whose architectural elements and replay memory management proved to be useful and effective in the considered scenarios. The experimental validation carried out, including comparisons with existing methods and an ablation study, confirms the validity and the suitability of the proposed approach.
# Autonomous Cycle Time Reduction of Robotic Tasks Using Iterative Learning Control
## Keywords:
- Learning Categories and Concepts
- Learning from Experience
- Industrial Robots
## Abstract:
When robots are used to automate repetitive production tasks, the productivity of the manufacturing system crucially depends on the robot’s task execution speed. An out-of-the-box solution is typically slow, whereas achieving shorter cycle times typically requires large efforts with respect to controller design and tuning. This dilemma can be resolved by learning control algorithms that autonomously improve performance without requiring any system-specific tuning. In the present work, we propose a novel learning control scheme that autonomously reduces the execution times of robotic systems that perform repetitive manufacturing tasks. To this end, we combine an Iterative Learning Control (ILC) approach with a trial-varying reference adaptation. The reference trajectory is slowly adapted to ensure that the given task is performed successfully on every single iteration without constraint violations. Therefore, the learning process can be carried out during operation. We validate the practical applicability of the method by real-world experiments on a 6-axis robot that performs a linear motion and a contact-force task. Despite the fundamentally different characteristics of these two tasks, the proposed algorithm achieves a remarkable reduction of cycle times, namely, by a factor of 4 in the linear motion task and a factor of 10 in the contact-force task. These results provide an important step toward robotic manufacturing systems that autonomously optimize their own performance during operation.
# Medical Ultrasound Image Quality Assessment for Autonomous Robotic Screening
## Keywords:
- Learning from Experience
- Computer Vision for Medical Robotics
- Deep Learning for Visual Perception
## Abstract:
Autonomous ultrasound scanning robots have attracted the attention of researchers, and the real-time quality assessment of ultrasound images is the key technology of them. Existing robot systems usually use pixel-level feature statistical methods such as grayscale, confidence map, etc. However, in clinical practice doctors’ evaluation of ultrasound image quality not only relies on the pixel quality, but also on the image content. In this study, we introduced the deep learning method to the quality assessment of medical breast ultrasound images to learn the doctors’ clinical evaluation standards. We collected 1205 breast ultrasound images of 533 patients and asked experienced doctors to score them. The ResNet18 with a shallow number of layers is adopted to extract features of ultrasound images, and the high-order feature coding model BCNN (Bilinear CNN) in fine-grained categorization is adopted to improve the accuracy of quality assessment. The consistency between the ultrasound image quality assessment results of our method and the doctors’ annotation results reached 0.842 by PLCC (Pearson Linear Correlation Coefficient). Compared with the confidence map method commonly used for quality assessment in the automatic ultrasound scanning robots, our method achieves a higher consistency with the evaluation results of doctors and provides a new image evaluation method and idea for the visual servo control framework of ultrasound autonomous scanning robots.
# Self-Supervised Traversability Prediction by Learning to Reconstruct Safe Terrain
## Keywords:
- Learning from Experience
- Autonomous Vehicle Navigation
- Deep Learning for Visual Perception
## Abstract:
Navigating off-road with a fast autonomous vehicle depends on a robust perception system that differentiates traversable from non-traversable terrain. Typically, this depends on a semantic understanding which is based on supervised learning from images annotated by a human expert. This requires a significant investment in human time, assumes correct expert classification, and small details can lead to misclassification. To address these challenges, we propose a method for predicting high# and low-risk terrains from only past vehicle experience in a self-supervised fashion. First, we develop a tool that projects the vehicle trajectory into the front camera image. Second, occlusions in the 3D representation of the terrain are filtered out. Third, an autoencoder trained on masked vehicle trajectory regions identifies low# and high-risk terrains based on the reconstruction error. We evaluated our approach with two models and different bottleneck sizes with two different training and testing sites with a four-wheeled off-road vehicle. Comparison with two independent test sets of semantic labels from similar terrain as training sites demonstrates the ability to separate the ground as low-risk and the vegetation as high-risk with 81.1% and 85.1% accuracy.
# SafeAPT: Safe Simulation-To-Real Robot Learning Using Diverse Policies Learned in Simulation
## Keywords:
- Learning from Experience
- Machine Learning for Robot Control
- Evolutionary Robotics
## Abstract:
The framework of sim-to-real learning, i.e, training policies in simulation and transferring them to real-world systems, is one of the most promising approaches towards data-efficient learning in robotics. However, due to the inevitable reality gap between the simulation and the real world, a policy learned in the simulation may not always generate a safe behaviour on the real robot. As a result, during policy adaptation in the real world, the robot may damage itself or cause harm to its surroundings. In this work, we introduce SafeAPT, a multi-goal robot learning algorithm that leverages a diverse repertoire of policies evolved in simulation and transfers the most promising safe policy to the real robot through episodic interaction. To achieve this, SafeAPT iteratively learns probabilistic reward and safety models from real-world observations using simulated experiences as priors. Then, it performs Bayesian optimization to select the best policy from the repertoire with the reward model, while maintaining the specified safety constraint using the safety model. SafeAPT allows a robot to adapt to a wide range of goals safely with the same repertoire of policies evolved in the simulation. We compare SafeAPT with several baselines, both in simulated and real robotic experiments, and show that SafeAPT finds high-performing policies within a few minutes of real-world operation while minimizing safety violations during the interactions.
# Self-Supervised Learning of Visual Servoing for Low-Rigidity Robots Considering Temporal Body Changes
## Keywords:
- Learning from Experience
- Learning from Demonstration
- Visual Servoing
## Abstract:
In this study, we investigate object grasping by visual servoing in a low-rigidity robot. It is difficult for a low-rigidity robot to handle its own body as intended compared to a rigid robot, and calibration between vision and body takes some time. In addition, the robot must constantly adapt to changes in its body, such as the change in camera position and change in joints due to aging. Therefore, we develop a method for a low-rigidity robot to autonomously learn visual servoing of its body. We also develop a mechanism that can adaptively change its visual servoing according to temporal body changes. We apply our method to a low-rigidity 6-axis arm, MyCobot, and confirm its effectiveness by conducting object grasping experiments based on visual servoing.
# Safe Adaptation in Multiagent Competition
## Keywords:
- Reinforcement Learning
- Deep Learning Methods
- Learning from Experience
## Abstract:
Achieving the capability of adapting to ever-changing environments is a critical step towards building fully autonomous robots that operate safely in complicated scenarios. In multiagent competitive scenarios, agents may have to adapt to new opponents with previously unseen behaviors by learning from the interaction experiences between the ego-agent and the opponent. However, this adaptation is susceptible to opponent exploitation. As the ego-agent updates its own behavior to exploit the opponent, its own behavior could become more exploitable as a result of overfitting to this specific opponent's behavior. To overcome this difficulty, we developed a safe adaptation approach in which the ego-agent is trained against a regularized opponent model, which effectively avoids overfitting and consequently improves the robustness of the ego-agent's policy. We evaluated our approach in the Mujoco domain with two competing agents. The experiment results suggest that our approach effectively achieves both adaptation to the specific opponent that the ego-agent is interacting with and maintaining low exploitability to other possible opponent exploitation.
# Learning Pneumatic Non-Prehensile Manipulation with a Mobile Blower
## Keywords:
- Reinforcement Learning
- Learning from Experience
- Deep Learning in Grasping and Manipulation
## Abstract:
We investigate pneumatic non-prehensile manipulation (i.e., blowing) as a means of efficiently moving scattered objects into a target receptacle. Due to the chaotic nature of aerodynamic forces, a blowing controller must (i) continually adapt to unexpected changes from its actions, (ii) maintain fine-grained control, since the slightest misstep can result in large unintended consequences (e.g., scatter objects already in a pile), and (iii) infer long-range plans (e.g., move the robot to strategic blowing locations). We tackle these challenges in the context of deep reinforcement learning, introducing a multi-frequency version of the spatial action maps framework. This allows for efficient learning of vision-based policies that effectively combine high-level planning and low-level closed-loop control for dynamic mobile manipulation. Experiments show that our system learns efficient behaviors for the task, demonstrating in particular that blowing achieves better downstream performance than pushing, and that our policies improve performance over baselines. Moreover, we show that our system naturally encourages emergent specialization between the different subpolicies spanning low-level fine-grained control and high-level planning. On a real mobile robot equipped with a miniature air blower, we show that our simulation-trained policies transfer well to a real environment and can generalize to novel objects.
# Deep Learning Methods
# PUA-MOS: End-To-End Point-Wise Uncertainty Weighted Aggregation for Moving Object Segmentation
## Keywords:
- Deep Learning Methods
- Object Detection, Segmentation and Categorization
## Abstract:
Segmenting moving objects in the 3D LiDAR point cloud can provide important guidance to localization, mapping and decision-making for self-driving vehicles. As for the conventional approaches to point cloud segmentation, they rely on semantic-level information, which makes it inevitable for long-tail problems to arise as there are always unseen types of objects on the road. To achieve moving segmentation while avoiding the reliance on the object category, the point motion is identified in this paper by fully exploring and aggregating the point-level geometric consistency in sequential point clouds. More specifically, an end-to-end point-wise uncertainty weighted aggregation approach known as PUA-MOS is proposed to segment the moving points in 3D LiDAR Data. Our method is applicable to estimate point-wise moving mask, scene flow and rigid-body transformation simultaneously in a coarse-to-fine network, where the relations between each prediction are implicitly learned. To explicitly model the inner and inter-relations across these predictions among all points, the pointwise estimation and the average value of the same motion points are aggregated according to a predicted uncertainty. Then, the aggregated estimation is fed again into the next-level fusion, where the points will be re-segmented using the aggregated mask from the last level. Through iterative joint aggregation, our PUA-MOS outperforms the previous methods significantly on both KITTI [4] and Waymo [26] datasets. The code will be provided to generate the moving segmentation labels on both datasets for reproduction.
# Grounding Commands for Autonomous Vehicles Via Layer Fusion with Region-Specific Dynamic Layer Attention
## Keywords:
- Deep Learning Methods
- Representation Learning
- Multi-Modal Perception for HRI
## Abstract:
Grounding a command to the visual environment is an essential ingredient for interactions between autonomous vehicles and humans. In this work, we study the problem of language grounding for autonomous vehicles, which aims to localize a region in a visual scene according to a natural language command from a passenger. Prior work only employs the top layer representations of a vision-and-language pre-trained model to predict the region referred to by the command. However, such a method omits the useful features encoded in other layers, and thus results in inadequate understanding of the input scene and command. To tackle this limitation, we present the first layer fusion approach for this task. Since different visual regions may require distinct types of features to disambiguate them from each other, we further propose the region-specific dynamic (RSD) layer attention to adaptively fuse the multimodal information across layers for each region. Extensive experiments on the Talk2Car benchmark demonstrate that our approach helps predict more accurate regions and outperforms state-of-the-art methods.
# Neural-Guided Runtime Prediction of Planners for Improved Motion and Task Planning with Graph Neural Networks
## Keywords:
- Deep Learning Methods
- Motion and Path Planning
- Task and Motion Planning
## Abstract:
The past decade has amply demonstrated the remarkable functionality that can be realized by learning complex input/output relationships. Algorithmically, one of the most important and opaque relationships is that between a problem's structure and an effective solution method. Here, we quantitatively connect the structure of a planning problem to the performance of a given sampling-based motion planning (SBMP) algorithm. We demonstrate that the geometric relationships of motion planning problems can be well captured by graph neural networks (GNNs) to predict SBMP runtime. By using an algorithm portfolio we show that GNN predictions of runtime on particular problems can be leveraged to accelerate online motion planning in both navigation and manipulation tasks. Moreover, the problem-to-runtime map can be inverted to identify subproblems easier to solve by particular SBMPs. We provide a motivating example of how this knowledge may be used to improve integrated task and motion planning on simulated examples. These successes rely on the relational structure of GNNs to capture scalable generalization from low-dimensional navigation tasks to high degree-of-freedom manipulation tasks in 3D environments.
# OpenDR: An Open Toolkit for Enabling High Performance, Low Footprint Deep Learning for Robotics
## Keywords:
- Deep Learning Methods
- Software Architecture for Robotic and Automation
- Deep Learning for Visual Perception
## Abstract:
Existing Deep Learning (DL) frameworks typically do not provide ready-to-use solutions for robotics, where very specific learning, reasoning, and embodiment problems exist. Their relatively steep learning curve and the different methodologies employed by DL compared to traditional approaches, along with the high complexity of DL models, which often leads to the need of employing specialized hardware accelerators, further increase the effort and cost needed to employ DL models in robotics. Also, most of the existing DL methods follow a static inference paradigm, as inherited by the traditional computer vision pipelines, ignoring active perception, which can be employed to actively interact with the environment in order to increase perception accuracy. In this paper, we present the Open Deep Learning Toolkit for Robotics (OpenDR). OpenDR aims at developing an open, non-proprietary, efficient, and modular toolkit that can be easily used by robotics companies and research institutions to efficiently develop and deploy AI and cognition technologies to robotics applications, providing a solid step towards addressing the aforementioned challenges. We also detail the design choices, along with an abstract interface that was created to overcome these challenges. This interface can describe various robotic tasks, spanning beyond traditional DL cognition and inference, as known by existing frameworks, incorporating openness, homogeneity and robotics-oriented perception e.g., through active perception, as its core design principles.
# FloorGenT: Generative Vector Graphic Model of Floor Plans for Robotics
## Keywords:
- Deep Learning Methods
- Motion and Path Planning
- AI-Enabled Robotics
## Abstract:
Floor plans are the basis of reasoning in and communicating about indoor environments. In this paper, we show that by modelling floor plans as sequences of line segments seen from a particular point of view, recent advances in autoregressive sequence modelling can be leveraged to model and predict floor plans. The line segments are canonicalized and translated to sequence of tokens and an attention-based neural network is used to fit a one-step distribution over next tokens. We fit the network to sequences derived from a set of large-scale floor plans, and demonstrate the capabilities of the model in four scenarios: novel floor plan generation, completion of partially observed floor plans, generation of floor plans from simulated sensor data, and finally, the applicability of a floor plan model in predicting the shortest distance with partial knowledge of the environment.
# Robot Motion Planning As Video Prediction: A Spatio-Temporal Neural Network-Based Motion Planner
## Keywords:
- Deep Learning Methods
- Motion and Path Planning
- Representation Learning
## Abstract:
Neural network (NN)-based methods have emerged as an attractive approach for robot motion planning due to strong learning capabilities of NN models and their inherently high parallelism. Despite the current development in this direction, the efficient capture and processing of important sequential and spatial information, in a direct and simultaneous way, is still relatively under-explored. To overcome the challenge and unlock the potentials of neural networks for motion planning tasks, in this paper, we propose STP-Net, an end-to-end learning framework that can fully extract and leverage important spatio-temporal information to form an efficient neural motion planner. By interpreting the movement of the robot as a video clip, robot motion planning is transformed to a video prediction task that can be performed by STP-Net in both spatially and temporally efficient ways. Empirical evaluations across different seen and unseen environments show that, with nearly 100% accuracy, STP-Net demonstrates very promising performance with respect to both planning speed and path cost. Compared with existing NN-based motion planners, STP-Net achieves at least 5x, 2.6x and 1.8x faster speed with lower path cost on 2D Random Forest, 2D Maze and 3D Random Forest environments, respectively. Furthermore, STP-Net can quickly and simultaneously compute multiple near-optimal paths in multi-robot motion planning tasks. The code will release once the paper is accepted.
# Adversarial Attacks on Monocular Pose Estimation
## Keywords:
- Deep Learning Methods
- Deep Learning for Visual Perception
- Vision-Based Navigation
## Abstract:
Advances in deep learning have resulted in steady progress in computer vision with improved accuracy on tasks such as object detection and semantic segmentation. Nevertheless, deep neural networks are vulnerable to adversarial attacks, thus presenting a challenge in reliable deployment. Two of the prominent tasks in 3D scene-understanding for robotics and advanced driver assistance systems are monocular depth and pose estimation, often learned together in an unsupervised manner. While studies	evaluating the impact of adversarial attacks on monocular depth estimation exist, a systematic demonstration and analysis of adversarial perturbations against pose estimation is lacking. We show how additive imperceptible perturbations can not only change predictions to increase the trajectory drift but also catastrophically alter its geometry. We also study the relation between adversarial perturbations targeting monocular depth and pose estimation networks, as well as the transferability of perturbations to other networks with different architectures and losses. Our experiments show how the generated perturbations lead to notable errors on relative rotation and translation predictions,	and elucidate vulnerabilities of the networks.
# Don’t Share My Face: Privacy Preserving Inpainting for Visual Localization
## Keywords:
- Deep Learning Methods
- Localization
## Abstract:
Visual localization is an important task for many robotic and augmented reality applications. As localizing within large scale maps can be memory and computationally demanding, cloud-based localization services are appealing for developers. However, such services raise important privacy concerns for both passive and active users. In particular, some sensitive information might be revealed by an attacker who intercepts data during the data-sharing process. Therefore, the sensitive data in the image should be concealed before it is shared. As a motivating case, we demonstrated the exposure generated by the common feature descriptor SIFT when attempting to recover private content. In this paper, we propose a pipeline to effectively conceal privacy-sensitive image regions from possible attacks to the transmission or localization services, by making use of learning-based image inpainting techniques while preserving, and even boosting, the localization performance. We tested our pipeline with two off-the-shelf localization services based on deep neural networks on the publicly available Oxford Robotcar dataset, showing that the localization performance on our generated private concealed images is on par with the non-private baseline.
# Torque Control of Hydraulic Pressure Servo Valve Driven Actuator with Deep Neural Network
## Keywords:
- Deep Learning Methods
- Hydraulic/Pneumatic Actuators
- Force Control
## Abstract:
Non-linear dynamics, model uncertainties due to hydraulic fluid, and disturbances in hydraulic systems make it difficult to obtain accurate torque tracking performance. In this study, a learning-based torque-tracking method is proposed, which does not require approximating the torque dynamics. The proposed method can capture disturbances and model uncertainties of system. The applied neural network comprises a nonlinear autoregressive model with exogenous inputs (NARX) and a long short-term neural network (LSTM). NARX is employed due to its ability to predict time series control input from the states of system, and LSTM is used to overcome the vanishing and exploding gradient, which causes long-term memory loss in NARX, leading to inaccurate torque tracking performance. LSTM with NARX achieved a better prediction performance with a mean square error and standard deviation of 0.0015 ± 0.4 ×10-3 compared to only NARX with a mean square error of 0.004 ± 1.0 ×10-3 at 10 K training data size.
# AI-Enabled Robotics
# SGL: Symbolic Goal Learning in a Hybrid, Modular Framework for Human Instruction Following
## Keywords:
- Deep Learning in Grasping and Manipulation
- AI-Enabled Robotics
- Representation Learning
## Abstract:
This paper investigates human instruction following for robotic manipulation via a hybrid, modular system with symbolic and connectionist elements. Symbolic methods build modular systems with semantic parsing and task planning modules for producing sequences of actions from natural language requests. Modern connectionist methods employ deep neural networks that learn visual and linguistic features for mapping inputs to a sequence of low-level actions, in an endto-end fashion. The hybrid, modular system blends these two approaches to create a modular framework: it formulates instruction following as symbolic goal learning via deep neural networks followed by task planning via symbolic planners. Connectionist and symbolic modules are bridged with Planning Domain Definition Language. The vision-and-language learning network predicts its goal representation, which is sent to a planner for producing a task-completing action sequence. For improving the flexibility of natural language, we further incorporate implicit human intents with explicit human instructions. To learn generic features for vision and language, we propose to separately pretrain vision and language encoders on scene graph parsing and semantic textual similarity tasks. Benchmarking evaluates the impacts of different components of, or options for, the vision-and-language learning model and shows the effectiveness of pretraining strategies. Manipulation experiments conducted in the simulator AI2THOR show the robustness of the framework to novel scenarios.
# Towards Defensive Autonomous Driving: Collecting and Probing Driving Demonstrations of Mixed Qualities
## Keywords:
- AI-Based Methods
- Big Data in Robotics and Automation
- Data Sets for Robot Learning
## Abstract:
Designing or learning an autonomous driving policy is undoubtedly a challenging task as the policy has to maintain its safety in all corner cases. In order to secure safety in autonomous driving, the ability to detect hazardous situations, which can be seen as an out-of-distribution (OOD) detection problem, becomes crucial. However, conventional datasets often only contain expert driving demonstrations, although some non-expert or uncommon driving behavior data are needed to implement a safety guaranteed autonomous driving platform. To this end, we present a dataset called the textit{R3 Driving Dataset}, composed of driving data with different qualities. The dataset categorizes abnormal driving behaviors into eight categories and 369 different detailed situations. The situations include dangerous lane changes and near-collision situations. To further enlighten how these abnormal driving behaviors can be detected, we utilize different uncertainty estimation and anomaly detection methods for the proposed dataset. From the results of the proposed experiment, it can be inferred that by using both uncertainty estimation and anomaly detection, most of the abnormal cases in the proposed dataset can be discriminated. The dataset of this paper can be downloaded from https://rllab-snu.github.io/projects/R3-Driving-Dataset/doc .html.
# TAE: A Semi-Supervised Controllable Behavior-Aware Trajectory Generator and Predictor
## Keywords:
- AI-Based Methods
- Intelligent Transportation Systems
- Autonomous Agents
## Abstract:
Trajectory generation and prediction are two interwoven tasks that play important roles in planner evaluation and decision-making for intelligent vehicles. Most existing methods focus on one of the two and are optimized to directly output the final generated/predicted trajectories, which only contain limited information for critical scenario augmentation and safe planning. In this work, we propose a novel behavior-aware Trajectory Autoencoder (TAE) that explicitly models drivers' behavior such as aggressiveness and intention in the latent space, using semi-supervised adversarial autoencoder and domain knowledge in transportation. Our model addresses trajectory generation and prediction in a unified architecture and benefits both tasks: the model can generate diverse, controllable, and realistic trajectories to enhance planner optimization in safety-critical and long-tailed scenarios, and it can provide predictions of critical behavior in addition to the final trajectories for decision-making. Experimental results demonstrate that our method achieves promising performance on both trajectory generation and prediction.
# Visual-Tactile Sensing for Real-Time Liquid Volume Estimation in Grasping
## Keywords:
- AI-Enabled Robotics
- Deep Learning in Grasping and Manipulation
- Sensor Fusion
## Abstract:
We propose a deep visuo-tactile model for real-time estimation of the liquid inside a deformable container in a proprioceptive way. We fuse two sensory modalities, i.e., the raw visual inputs from the RGB camera and the tactile cues from our specific tactile sensor without any extra sensor calibrations. The robotic system is well controlled and adjusted based on the estimation model in real time. The main contributions and novelties of our work are listed as follows: 1) Explore a proprioceptive way for liquid volume estimation by developing an end-to-end predictive model with multi-modal convolutional networks, which achieve a high precision with an error of around 2 ml in the experimental validation. 2) Propose a multi-task learning architecture which comprehensively considers the losses from both classification and regression tasks, and comparatively evaluate the performance of each variant on the collected data and actual robotic platform. 3) Utilize the proprioceptive robotic system to accurately serve and control the requested volume of liquid, which is continuously flowing into a deformable container in real time. 4) Adaptively adjust the grasping plan to achieve more stable grasping and manipulation according to the real-time liquid volume prediction.
# Comparing Reconstruction and Contrastive-Based Models for Visual Task Planning
## Keywords:
- AI-Enabled Robotics
- Visual Learning
- Task Planning
## Abstract:
Learning state representations enables robotic planning directly from raw observations such as images. Several methods learn state representations by utilizing losses based on the reconstruction of the raw observations from a lower-dimensional latent space. The similarity between observations in the space of images is often assumed and used as a proxy for estimating similarity between the underlying states of the system. However, observations commonly contain task-irrelevant factors of variation which are nonetheless important for reconstruction, such as varying lighting and different camera viewpoints. In this work, we define relevant evaluation metrics and perform a thorough study of different loss functions for state representation learning. We show that models exploiting task priors, such as Siamese networks with a simple contrastive loss, outperform reconstruction-based representations in visual task planning in case of task-irrelevant factors of variations.
# Learning Object-Based State Estimators for Household Robots
## Keywords:
- AI-Enabled Robotics
## Abstract:
A robot operating in a household makes observations of multiple objects as it moves around over the course of days or weeks. The objects may be moved by inhabitants, but not completely at random. The robot may be called upon later to retrieve objects and will need a long-term object-based memory in order to know how to find them. Existing work in semantic SLAM does not attempt to capture the dynamics of object movement. In this paper, we combine some aspects of classic techniques for data-association filtering with modern attention-based neural networks to construct object-based memory systems that operate on high-dimensional observations and hypotheses. We perform end-to-end learning on labeled observation trajectories to learn both the transition and observation models. We demonstrate the system's effectiveness in maintaining memory of dynamically changing objects in both simulated environment and real images, and demonstrate improvements over classical structured approaches as well as unstructured neural approaches. Additional information available at project website: https://yilundu.github.io/obm/.
# Deep Residual Reinforcement Learning Based Autonomous Blimp Control
## Keywords:
- AI-Enabled Robotics
- Aerial Systems: Mechanics and Control
- Reinforcement Learning
## Abstract:
Blimps are well suited to perform long-duration aerial tasks as they are energy efficient, relatively silent and safe. To address the blimp navigation and control task, in previous work we developed a hardware and software-in-the-loop framework and a PID-based controller for large blimps in the presence of wind disturbance. However, blimps have a deformable structure and their dynamics are inherently non-linear and time-delayed, making PID controllers difficult to tune. Thus, often resulting in large tracking errors. Moreover, the buoyancy of a blimp is constantly changing due to variations in ambient temperature and pressure. To address these issues, in this paper we present a learning-based framework based on deep residual reinforcement learning (DRRL), for the blimp control task. Within this framework, we first employ a PID controller to provide baseline performance. Subsequently, the DRRL agent learns to modify the PID decisions by interaction with the environment. We demonstrate in simulation that DRRL agent consistently improves the PID performance. Through rigorous simulation experiments, we show that the agent is robust to changes in wind speed and buoyancy. In real-world experiments, we demonstrate that the agent, trained only in simulation, is sufficiently robust to control an actual blimp in windy conditions. We openly provide the source code of our approach at https://github.com/robot-perception-group/AutonomousBlimpDRL . Video demonstration is provided at https://youtu.be/EMC4KnlH0yI .
# Semantic Grasping Via a Knowledge Graph of Robotic Manipulation: A Graph Representation Learning Approach
## Keywords:
- AI-Enabled Robotics
- Representation Learning
- Grasping
## Abstract:
Semantic grasping aims to make stable robotic grasps suitable for specific object manipulation tasks. While existing semantic grasping models focus only on the grasping regions of objects based on their affordances, reasoning about which gripper to use for grasping, e.g., a rigid parallel-jaw gripper or a soft gripper, and how strongly to grasp the target object allows more sophisticated robotic manipulation. In this paper, we create a knowledge graph of robotic manipulation named roboKG to represent information about objects (e.g., the material and the components of an object), tasks, and appropriate robotic manipulation such as which component of an object to grasp, which gripper to use, and how strongly to grasp. Using knowledge graph embedding, we generate semantic representations of the entities and relations in roboKG, enabling us to make predictions on robotic manipulation. Based on the predicted gripper type, grasping component, and grasping force, a real robot performs seven different real-world tasks on 42 household objects, achieving an accuracy of 95.21%.
# 3D Part Assembly Generation with Instance Encoded Transformer
## Keywords:
- Deep Learning for Visual Perception
- AI-Enabled Robotics
- Object Detection, Segmentation and Categorization
## Abstract:
It is desirable to enable robots capable of automatic assembly. Structural understanding of object parts plays a crucial role in this task yet remains relatively unexplored. In this paper, we focus on the setting of furniture assembly from a complete set of part geometries, which is essentially a 6-DoF part pose estimation problem. We propose a multi-layer transformer-based framework that involves geometric and relational reasoning between parts to update the part poses iteratively. We carefully design a unique instance encoding to solve the ambiguity between geometrically-similar parts so that all parts can be distinguished. In addition to assembling from scratch, we extend our framework to a new task called in-process part assembly. Analogous to furniture maintenance, it requires robots to continue with unfinished products and assemble the remaining parts into appropriate positions. Our method achieves far more than 10% improvements over the current state-of-the-art in multiple metrics on the public PartNet dataset. Extensive experiments and quantitative comparisons demonstrate the effectiveness of the proposed framework.
# Soft Robot Modeling and Control 3
# Continuum-Body-Pose Estimation from Partial Sensor Information Using Recurrent Neural Networks
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- AI-Based Methods
## Abstract:
Soft continuum arms have significant potential for use in various applications due to their extremely high degrees of freedom. For example, these soft arms can be used for grasping and manipulating fragile materials in the deep sea or carrying a human to rescue in unstructured environments. However, in these situations, the environment is often dark and visual cues are not always usable. Therefore, these arms must estimate their pose from proprioceptive sensors to control their behavior and execute their tasks in dark places. Estimating the pose in a dynamic situation is still challenging because of the arms' high dimensionality and the complex structural changes in the body shape. Therefore, this study demonstrates a novel method for estimating the pose of proprioceptive bending sensors using recurrent neural networks (RNNs). In particular, an RNN framework known as deep reservoir computing was used for this purpose. Results from experiments using an octopus-inspired soft robotic arm clearly indicate that the proposed method significantly outperforms existing methods using long short-term memory models or linear models. We expect that our proposed method will enable behavioral control of these arms in dark places such as the deep sea, space, and inside the human body in future applications.
# Sim2Real for Soft Robotic Fish Via Differentiable Simulation
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Bioinspired Robot Learning
- Soft Robot Materials and Design
## Abstract:
Accurate simulation of soft mechanisms under dynamic actuation is critical for the design of soft robots. We address this gap with our differentiable simulation tool by learning the material parameters of our soft robotic fish. On the example of a soft robotic fish, we demonstrate an experimentally-verified, fast optimization pipeline for learning the material parameters from quasi-static data via differentiable simulation and apply it to the prediction of dynamic performance. Our method identifies physically plausible Young’s moduli for various soft silicone elastomers and stiff acetal copolymers used in creation of our three different robotic fish tail designs. We show that our method is compatible with varying internal geometry of the actuators, such as the number of hollow cavities. Our framework allows high fidelity prediction of dynamic behavior for composite bi-morph bending structures in real hardware to millimeter-accuracy and within 3% error normalized to actuator length. We provide a differentiable and robust estimate of the thrust force using a neural network thrust predictor; this estimate allows for accurate modeling of our experimental setup measuring bollard pull. This work presents a prototypical hardware and simulation problem solved using our differentiable framework; the framework can be applied to higher dimensional parameter inference, learning control policies, and computational design due to its differentiable character.
# An Experimental Validation of the Polynomial Curvature Model: Identification and Optimal Control of a Soft Underwater Tentacle
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Flexible Robotics
- Marine Robotics
## Abstract:
The control possibilities for soft robots have long been hindered by the lack of accurate yet computationally treatable dynamic models of soft structures. Polynomial curvature models propose a solution to this
quest for trunk-like structures. Nevertheless, the results produced with this class of models have been so far essentially theoretical. With the present work, we aim to provide a much-needed experimental validation to these recent theories. To this end, we focus on soft tentacles immersed in water. First, we propose an extension of the affine curvature model to underwater structures, considering the drag forces arising from the fluid-solid interaction. Then, we extensively test the model's capability to describe the system behavior across several shapes and working conditions. Finally, we validate model-based
control policies, proposing and solving an optimal control problem for directional underwater swimming. Using the model we show an average increase of more than 3.5 times the swimming speed of a sinusoidal baseline controller, with some tentacles showing an improvement in excess of 5.5 times the baseline.
# Collision-Aware Fast Simulation for Soft Robots by Optimization-Based Geometric Computing
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Simulation and Animation
- Soft Robot Applications
## Abstract:
Soft robots are able to safely interact with environments because of their mechanical compliance. Self-collision is also employed in the modern design of soft robots to enhance their performance in different tasks. However, developing an efficient and reliable simulator which can handle the collision response well, is still a challenging task in the research of soft robotics. This paper presents a collision-aware simulator based on geometric optimization, in which we develop a highly efficient and realistic collision checking / response model incorporating a hyperelastic material property. Both actuated deformation and collision response for soft robots are formulated as geometry-based objectives. The collision-free body of a soft robot can be obtained by minimizing the geometry-based objective function. Different from the FEA-based physical simulation, the proposed pipeline performs a much lower computational cost. Moreover, adaptive remeshing is applied to achieve the improvement of the convergence when dealing with soft robots having large volume variations. Experimental tests are conducted on different soft robots to verify the performance of our approach.
# Model-Based Design Optimization of Underwater Flagellate Propellers
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Soft Robot Applications
## Abstract:
A new family of soft underwater propellers has been recently presented. Mimicking the swimming strategy of bacterial flagella, these modules passively adapt to the surrounding fluid to provide a propulsive thrust. In the present paper we aim at further investigating the behaviour of this device and we address the optimization of its design towards improved swimming capabilities. This process is allowed by an accurate, yet simple, theoretical model which is able to precisely describe the robot’s behaviour. The optimal prototype is fabricated, employing a composite material that is ad-hoc designed to provide the optimal stiffness. Finally, a simple robotic prototype is built and tested to validate the improved performances.
# Prismatic Soft Actuator Augments the Workspace of Soft Continuum Robots
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Soft Robot Applications
- Soft Sensors and Actuators
## Abstract:
Soft robots are promising for manipulation tasks thanks to their compliance, safety, and high degree of freedom. However, the commonly used bidirectional continuum segment design means soft robotic manipulators only function in a limited hemispherical workspace. This work increases a soft robotic arm's workspace by designing, fabricating, and controlling an additional soft prismatic actuator at the base of the soft arm. This actuator consists of pneumatic artificial muscles and a piston, making the actuator back-driveable. We increase the task space volume by 116%, and we are now able to perform manipulation tasks that were previously impossible for soft robots, such as picking and placing objects at different positions on a surface and grabbing an object out of a container. By combining a soft robotic arm with a prismatic joint, we greatly increase the usability of soft robots for object manipulation. This work promotes the use of integrated and modular soft robotic systems for practical manipulation applications in human-centered environments.
# Hybrid Eye-In-Hand/Eye-To-Hand Image Based Visual Servoing for Soft Continuum Arms
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Visual Servoing
- Soft Robot Applications
## Abstract:
Soft continuum arms (SCAs) that are controlled by visual servoing (VS) present trade-offs between the camera range and tracking accuracy. Cameras placed at a distance (eye-to-hand) can observe a larger workspace area and the SCA tip, while a camera at the end effector (eye-in-hand) can more accurately survey the target. In this letter, we present a hybrid eye-to-hand and eye-in-hand VS scheme to track a desired object in the SCA's worksapce. When the target is not in the field-of-view of the tip camera, hand-to-eye VS is implemented using a wide field-of-view camera on the soft robot's base, to servo the soft robot's tip to a feasible region where the target is expected to be seen by the tip camera. This region is estimated by solving an optimization problem that finds the best region to place the SCA assuming a constant curvature model for the SCA. When the target is seen by the tip camera, the system switches to a hand-in-eye controller that keeps the target in the desired image position of the tip camera. Experimental results on the popular BR^2 SCA demonstrates the effectiveness of the hybrid VS scheme under practical settings that include external disturbances.
# Using R-Functions to Control the Shape of Soft Robots
## Keywords:
- Modeling, Control, and Learning for Soft Robots
- Multi-Robot Systems
- Swarm Robotics
## Abstract:
In this paper, we introduce a new approach for soft robot shape formation and morphing using approximate distance fields. The method uses concepts from constructive solid geometry, R-functions, to construct an approximate distance function to the boundary of a domain in Re^d. The gradients of the R-functions can then be used to generate control algorithms for shape formation tasks for soft robots. By construction, R-functions are smooth and convex everywhere, possess precise differential properties, and easily extend from Re^2 to Re^3 if needed. Furthermore, R-function theory provides a straightforward method to creating composite distance functions for any desired shape by combining subsets of distance functions. The process is highly efficient since the shape description is an analytical expression, and in this sense, it is better than competing control algorithms such as those based on potential fields. Although the method could also apply to swarm robots, in this paper it is applied to soft robots to demonstrate shape formation and morphing in 2-D (simulation and experimentation) and 3-D (simulation).
# Cellular, Modular and Cooperating Robots
# RePoSt: Distributed Self-Reconfiguration Algorithm for Modular Robots Based on Porous Structure
## Keywords:
- Cellular and Modular Robots
- Distributed Robot Systems
## Abstract:
In this paper, we propose a new self-reconfiguration scheme for modular robots based on a meta-module design that allows to form a 3D porous structure. The porous structure enables a parallel flow of modules inside it without blocking. The meta-module can also be used to fill its internal volume with an additional number of modules allowing the structure to be compressible and expandable. Hence, it is a potential for improving the self-reconfiguration process. We first present the meta-module model and the porous structure built using it. Then, we describe an algorithm to self-reconfigure the structure from an initial shape to a given goal shape. We evaluated the algorithm in simulation on structures composed of up to 2,700 modules. We studied the performance in term of parallelism, showed that the number of communications is proportional to the number of motions and the execution time varies linearly with the diameter of the configuration.
# Selective Self-Assembly Using Re-Programmable Magnetic Pixels
## Keywords:
- Cellular and Modular Robots
## Abstract:
This paper introduces a method to generate highly selective encodings that can be magnetically "programmed" onto physical modules to enable them to self-assemble in chosen configurations. We generate these encodings based on Hadamard matrices, and show how to design the faces of modules to be maximally attractive to their intended mate, while remaining maximally agnostic to other faces. We derive guarantees on these bounds, and verify their attraction and agnosticism experimentally. Using cubic modules whose faces have been covered in soft magnetic material, we show how inexpensive, passive modules with planar faces can be used to selectively self-assemble into target shapes without geometric guides. We show that these modules can be easily re-programmed for new target shapes using a CNC-based magnetic plotter, and demonstrate self-assembly of 8 cubes in a water tank.
# Physical Neural Cellular Automata for 2D Shape Classification
## Keywords:
- Cellular and Modular Robots
- Biologically-Inspired Robots
## Abstract:
Robots with the ability to self-classify their own class of shape and remodel in response to environment and or damage have the potential to advance a wide range of engineering applications and industries. Biological systems possess the ability not only to self-recognise, self-reconfigure but also self-classify themselves to determine a general organ shape and function. The do not require a specific target shape to grown into, which allows for inherent robustness and variance between individuals. Previous work into modular robotics systems have only enabled self-recognition and self-reconfiguration into a specific target shape, they are missing the inherent robustness present in nature to self-classify. In this paper we therefore take advantage of recent advances in deep learning and neural cellular automata, we present a simple modular 2D robotic system that can infer its own class of shape only through the local communication of its components. Furthermore, we show that our system can be successfully transferred to hardware and thus opens many opportunities for future self-classifying robots. All videos associated with this project can be viewed here: https://youtu.be/VpbHqw58vPM . Code and PCB design can be found here: https://github.com/kattwalker/projectcube.git
# Multi-Modal Multi-Agent Optimization for LIMMS, a Modular Robotics Approach to Delivery Automation
## Keywords:
- Cellular and Modular Robots
- Task and Motion Planning
- Optimization and Optimal Control
## Abstract:
In this paper we present a motion planner for LIMMS, a modular multi-agent, multi-modal package delivery platform. A single LIMMS unit is a robot that can operate as an arm or leg depending on how and what it is attached to, e.g., a manipulator when it is anchored to walls within a delivery vehicle or a quadruped robot when 4 are attached to a box. Coordinating amongst multiple LIMMS, when each one can take on vastly different roles, can quickly become complex. For such a planning problem we first compose the necessary logic and constraints. The formulation is then solved for skill exploration and can be implemented on hardware after refinement. To solve this optimization problem we use alternating direction method of multipliers (ADMM). The proposed planner is experimented under various scenarios which shows the capability of LIMMS to enter into different modes or combinations of them to achieve their goal of moving shipping boxes.
# Design, Modeling and Control of a Composable and Extensible Drone with Tilting Rotors
## Keywords:
- Cellular and Modular Robots
- Cooperating Robots
- Distributed Robot Systems
## Abstract:
In this paper, we introduce a composable and extensible drone with tilting rotors (CEDTR). We aimed for a function that could optimally match the load capacity, degree of freedom (DOF), speed and endurance with diverse mission requirements by changing the quantity and form of combinations. First, we propose a decentralized modular controller to allow a team of physically connected modules to fly cooperatively. Second, we divide all the combinations into three categories according to the different control methods. Three generalized control strategies are proposed to control both position and attitude independently by tilting the directions of the propellers. We carried out experiments to demonstrate the feasibility of this mechanical design and control method. The experiment video is available at https://youtu.be/7RvxiV4FPq4.
# Robotic Parasitic Array Control for Increased RSS in Non-Line-Of-Sight
## Keywords:
- Cooperating Robots
- Networked Robots
- Field Robots
## Abstract:
Safety, security, and rescue missions typically occur in environments where unreliable wireless communication impedes cooperative human and robot missions. A low-VHF band antenna array formed through the coordination of ground robots has the potential to transmit and receive signals more reliably at longer ranges in these environments. We advance this idea here by developing methods for controlling a robot forming a low-VHF antenna array to improve or maintain wireless communication with other agents in these complex environments. We propose and test methods for orienting this robotic antenna array to increase received signal strength (RSS) in a complex environment. In these tests, we show that creating and actuating this array improves RSS in line-of-sight and non-line-of-sight conditions.
# Modular Robot Networking: A Novel Schema and Its Performance Assessment
## Keywords:
- Cellular and Modular Robots
- Cooperating Robots
- Networked Robots
## Abstract:
Modular robots (MRs) consist of unique robots which interconnect and work as a collective to perform objectives. Coordinating these robots rely on robust communication, as modules moving independently can lead to damaging behaviour. We present a robust structure for modular robot communication, implemented and tested on a new MR. The structure has different communication protocols depending on the importance and bandwidth of the exchanged information, has fast error responses, and considerations which allow for two modules to actuate the same joint. We evaluate the wireless protocols, novel error response, and coordinated actuation empirically, validating the system on a new modular robot, the Mori3. We find two wireless protocols can be used to balance speed and reliability; transmitting errors through both wireless and serial is more consistent and faster; and sharing motor targets, control variables, and measurements allow for motors to operate a shared joint with equal efforts.
# Coordinated Multi-Agent Exploration, Rendezvous, & Task Allocation in Unknown Environments with Limited Connectivity
## Keywords:
- Cooperating Robots
- Path Planning for Multiple Mobile Robots or Agents
- Task and Motion Planning
## Abstract:
The lack of communication between agents in a multi-robot system is often regarded as a limiting factor that can affect and delay cooperative exploration and exploitation of cluttered and uncertain environments. On the contrary, this paper proposes a complete planning framework to enable cooperative behavior without the need for constant communication between robots, demonstrating drastic improvements in task completion and coverage time as compared to both fully connected robotic networks and widely used frontier-based exploration methods. Specifically, the proposed scheme considers three behaviors: i) exploration, promoting separation and disconnection, ii) rendezvous to reconnect and share information gained during exploration, and iii) task allocation for prioritized objectives. Exploration is achieved via a Sobel edge detection frontier algorithm that enables navigation of unknown complex (both convex and non-convex) environments. Once a task is discovered, a multi-objective weighted sum optimization method is proposed for allocating tasks based on prioritization and expectation estimation. The utility, generality, and scalability of the proposed approach is demonstrated using extensive simulations and experiments with unmanned ground vehicles in various cluttered environments.
# Multi-AGV's Temporal Memory-Based RRT Exploration in Unknown Environment
## Keywords:
- Cooperating Robots
- Multi-Robot Systems
- Search and Rescue Robots
## Abstract:
With the increasing need for multi-robot for exploring the unknown region in a challenging environment, efficient collaborative exploration strategies are needed for achieving such feat. A frontier-based Rapidly-Exploring Random Tree (RRT) exploration can be deployed to explore an unknown environment. However, its' greedy behavior causes multiple robots to explore the region with the highest revenue, which leads to massive overlapping in exploration process. To address this issue, we present a temporal memory-based RRT (TM-RRT) exploration strategy for multi-robot to perform robust exploration in an unknown environment. It computes adaptive duration for each frontier assigned and calculates the frontier's revenue based on the relative position of each robot. In addition, each robot is equipped with a memory consisting of frontier assigned and share among fleets to prevent repeating assignment of same frontier. Through both simulation and actual deployment, we have shown the robustness of TM-RRT exploration strategy by completing the exploration in a 25.0m x 54.0m (1350.0 **m**^2) area, while the conventional RRT exploration strategy falls short.
# Prosthetics and Exoskeletons 2
# A Novel Method for Detecting Misclassifications of the Locomotion Mode in Lower-Limb Exoskeleton Robot Control
## Keywords:
- Wearable Robotics
- Intention Recognition
- Deep Learning Methods
## Abstract:
Lower-limb exoskeleton robots can support hemiplegic patients’ affected limbs and assist in their rehabilitation. In order to set effective control strategies, it is necessary to obtain the user’s motion intention accurately and timeously. These requirements pose many challenges. The surface electromyography (sEMG) signal has long been used for detecting a person’s locomotion mode. However, most traditional myoelectric motion recognition methods need to collect multi-channel sEMG signals (more than eight) and use feature engineering to obtain the desired accuracy. Additionally, traditional methods make decisions when the recognition probability is still uncertain, resulting in misclassification during continuous recognition. In order to overcome these limitations, a dual-purpose autoencoder-guided temporal convolution network (DA-TCN) is proposed, which is used as a motion detection model for a lower-limb exoskeleton robot based on sEMG. In the proposed method, we first obtain four-channel sEMG signals without any feature engineering. Next, the DA-TCN is used to obtain the discriminative deep features of the sEMG signals. Compared with separable features from common TCNs, discriminative features assist in obtaining a more discriminative twins-loss. Finally, the classification result is redetermined by the decoder, based on the reconstruction of deep features, and misclassifications are rejected based on the value of the twins-loss. The performance of the proposed method was evaluated by obtaining data from seven volunteer subjects in seven locomotion modes. The proposed method was able to effectively detect misclassifications and significantly improved the stability of continuous recognition.
# Sample-Efficient Policy Adaptation for Exoskeletons under Variations in the Users and the Environment
## Keywords:
- Prosthetics and Exoskeletons
- Humanoid and Bipedal Locomotion
- Wearable Robotics
## Abstract:
Controlling lower-limb exoskeletons is extremely challenging due to their direct physical interaction with users wearing them which imposes additional safety concerns. Furthermore, the control policy needs to adapt for different users and surfaces the robot is traversing. Hence, it is crucial to design a control framework that can perform robustly in the presence of these variations. In this paper, we propose a sample-efficient method based on Bayesian Optimization (BO) to adapt a model-based walking controller for a lower-limb exoskeleton, XoMotion. In order to avoid safety risks, we use a set of dummy weights with realistic inertial distributions in the experiments with the robot to find optimal policies. An extensive set of experimental result shows that our controller can adapt for different users and on different terrain in less than 30 real-world trials.
# Deep-Learning to Map a Benchmark Dataset of Non-Amputee Ambulation for Controlling an Open Source Bionic Leg
## Keywords:
- Prosthetics and Exoskeletons
- Deep Learning Methods
## Abstract:
Powered lower-limb prosthetic devices may be becoming a promising option for amputation patients. Although various methods have been proposed to produce gait trajectories similar to those of non-disabled individuals, implementing these control methods is still challenging. It remains unclear whether these methods provide appropriate, safe, and intuitive locomotion as intended. This paper proposes the direct mapping of the voluntary movement of a residual limb (i.e., thigh) to the desired impedance parameters for amputated limbs (i.e., knee and ankle). The proposed model was learned from the gait trajectories of intact limb individuals from a publicly available biomechanics dataset, and was applied to control the prosthetic leg without post-tuning the network. Thus, the proposed method does not require training time with individuals with amputation nor configuration time for its use, and it provides a closely resembling gait trajectory of the intact limb. For preliminary testing, three able-bodied subjects participated in bypass tests. The proposed model accomplished intuitive and reliable level-ground walking at three different step lengths: self-selected, long-, and short-step lengths. The results indicate that intact benchmark data with different sensor configurations can be directly used to train the model to control prosthetic legs.
# Continuous Locomotion Mode Recognition and Gait Phase Estimation Based on a Shank-Mounted IMU with Artificial Neural Networks
## Keywords:
- Prosthetics and Exoskeletons
- Machine Learning for Robot Control
- Human and Humanoid Motion Analysis and Synthesis
## Abstract:
To improve the control of wearable robotics for gait assistance, we present an approach for continuous locomotion mode recognition as well as gait phase and stair slope estimation based on artificial neural networks that include time history information. The input features consist exclusively of processed variables that can be measured with a single shank-mounted inertial measurement unit. We introduce a wearable device to acquire real-world environment test data to demonstrate the performance and the robustness of the approach. Mean absolute error (gait phase, stair slope) and accuracy (locomotion mode) were determined for steady level walking and steady stair ambulation. Robustness was assessed using test data from different sensor hardware, sensor fixations, ambulation environments and subjects. The mean absolute error from the steady gait test data for the gait phase was 2.0–3.5 % for gait phase estimation and 3.3–3.8◦ for stair slope estimation. The accuracy of classifying the correct locomotion mode on the test data with the utilization of time history information was in between 98.51 % and 99.67 %. Results show high performance and robustness for continuously predicting gait phase, stair slope and locomotion mode during steady gait. As hypothesized, time history information improves the locomotion mode recognition. However, while the gait phase estimation performed well for untrained transitions between locomotion modes, our qualitative analysis revealed that it may be beneficial to include transition data into the training of the neural network to improve the prediction of the slope and the locomotion mode. Our results suggest that artificial neural networks could be used for high level control of wearable lower limb robotics.
# Biomechanical Design Optimization of Passive Exoskeletons through Surrogate Modeling on Industrial Activity Data
## Keywords:
- Prosthetics and Exoskeletons
- Wearable Robotics
- Design and Human Factors
## Abstract:
Passive exoskeletons are unpowered wearable robotic devices aimed at providing biomechanical assistance. They can be applied in industries such as manufacturing, construction and logistics to reduce repetitive stress injuries among workers. Their design process typically considers a static user, with muscle outputs computed later during dynamic tasks to evaluate performance. Attempting to reduce human muscle effort at this stage requires manual redesign. Instead, we propose a parameter optimization approach that minimizes muscle effort rates during realistic dynamic tasks in the design stage itself. We extract human kinematics in assembly tasks from an industry-oriented motion capture dataset, and compute the induced joint torques. Using a passive exoskeleton for shoulder joint gravity compensation from the literature as a baseline, we optimize its design parameters through a multi-objective Pareto Local Search, minimizing the muscle effort rates during these tasks. As the estimation of muscle outputs through biomechanical simulation techniques is computationally expensive, we train ensemble regression models for each muscle of interest during the task motions. These models serve as surrogates for the objective function in the design optimization procedure, speeding up search in the parameter space. The resulting exoskeleton with optimized design parameters reduces estimated muscle effort rates by an average of 5.73 % and peak of 35.1 % compared to default parameters, and an average of 14.5 % and peak of 32.2 % compared to not wearing an exoskeleton in overhead assembly tasks. A larger peak reduction compared to default parameters may be due to hindrance in motion caused by device. This approach may be adapted to other exoskeletons and applications, improving biomechanical assistance by design.
# Application of Piece-Wise Constant Strain Model to Flexible Deformation Calculation of Sports Prosthesis and Stiffness Estimation
## Keywords:
- Soft Robot Applications
- Prosthetics and Exoskeletons
- Calibration and Identification
## Abstract:
In this study, we present an application of the Piece-wise Constant Strain (PCS) model to a flexible deformation analysis of a sports prosthesis leg. Dynamic motion analysis of an athlete wearing a sports prosthesis is important to clarify a relationship between the prosthesis characteristics and the performance of an athlete, which contributes to training of an athlete or design of the prosthesis. However, there are few studies on modeling of the three-dimensional deformation of the sports prosthesis. In soft robotics, the PCS model was proposed for calculating a flexible deformation of a beam or rod structure with a low computational cost. We employ the PCS model to calculate the flexible deformation of the prosthesis, assuming that its structure can be discretized into a finite number of segments. Moreover, we propose an estimation method of the prosthesis stiffness using optical motion capture data and calculating the semi-definite programming.
# Real-Time Locomotion Recognition Algorithm for an Active Pelvis Orthosis to Assist Lower-Limb Amputees
## Keywords:
- Prosthetics and Exoskeletons
- Machine Learning for Robot Control
## Abstract:
Powered hip exoskeletons, in combination with passive prostheses, have been recently proposed to improve the economy and pattern of walking of lower-limb amputees within clinical scenarios. However, for everyday life support, a real-time control strategy that can accurately recognize different locomotion modes and transitions is required. In this paper, we proposed a novel locomotion recognition algorithm for an Active Pelvis Orthosis designed to assist people with lower-limb amputation, in quasi-static (sit-to-stand/stand-to-sit) and dynamic locomotion modes (walking and stairs negotiation). Two finite-state machines were combined to recognize in real-time the participants’ locomotion, one was a rule-based algorithm and one was based on four linear discriminant analysis classifiers. Four transfemoral amputees took part in the experiments and performed a circuit of tasks in two conditions, namely in transparent mode (the exoskeleton was controlled to provide null output impedance), and in assistive mode (the exoskeleton was controlled to output an assistive torque consistently with the locomotion mode recognized by the algorithm), to test the algorithm in real-time conditions. The median (25th, 75th percentile) between-subjects recognition accuracy was 94.8% (93.4%, 96.5%) with user-dependent models. Offline analysis on user-independent models with leave-one-subject-out validation resulted in between-subjects recognition accuracy equal to 95.9% (94.0%, 97.8%). The results of this study pave the way for future experimentations of the technology in ecological scenarios.
# Predictive Locomotion Mode Recognition and Accurate Gait Phase Estimation for Hip Exoskeleton on Various Terrains
## Keywords:
- Prosthetics and Exoskeletons
- Sensor-based Control
- RGB-D Perception
## Abstract:
In recent years, lower-limb exoskeletons have been applied to assist people with weak mobility in daily life, which requires enhanced adaptability to complex environments. To achieve a smooth transition between different assistive strategies and provide proper assistance at the desired timing during locomotion on various terrains, two significant issues should be addressed: the delay of locomotion mode recognition (LMR) and the accuracy of gait phase estimation (GPE), which are yet critical challenges for exoskeleton controls. To tackle these challenges, a high-level exoskeleton control, including a depth sensor-based LMR method and an adaptive oscillator-based GPE approach, is developed in this study for terrain-adaptive assistive walking. An experimental study was conducted to evaluate the effectiveness and usability of the proposed control in a real-world scenario. Experimental results suggested that the depth sensor-based LMR method can detect the locomotion mode change 0.5 step ahead of the assistive strategy switch of the leading leg, while the average environment classification accuracy across five subjects was higher than 98%. The accuracy is comparable with the state-of-the-art LMR methods, but its predictive capability is beyond existing LMR methods applied in lower-limb exoskeletons. Moreover, the adaptive oscillator-based GPE approach accurately estimated the user's gait phase during locomotion on various terrains, with a root-mean-square (RMS) gait phase reset error of only 4.12±0.27%, outperforming the literature standard.
# Simultaneous Gesture Classification and Speed Control for Myoelectric Prosthetic Hand Using Joint-Loss Neural Network
## Keywords:
- Prosthetics and Exoskeletons
- Rehabilitation Robotics
- Medical Robots and Systems
## Abstract:
Gesture classification and motion speed regression are always two major issues in myoelectrical prosthetic hand research. However, there is little research considering these two issues in conjunction. Some shared EMG feature information in these two processing tasks is promising to improve the performance of prosthetic hand control. In this study, a joint-loss (JL) neural network architecture is proposed to implement gesture classification and motion speed regression problems in parallel by sharing the hidden neural units in the training process and optimizing the joint loss function. We evaluated the proposed control system through motion experiments performed on six participants. The experiment result shows that the classification and regression models can successfully reproduce smooth movement based on EMG measurement with high accuracy. Furthermore, the possibility of clinical application is demonstrated through the online movement of the real prosthetic hand.
# Robust/Adaptive Control
# Unbiased Active Inference for Classical Control
## Keywords:
- Probabilistic Inference
- Robust/Adaptive Control
- Industrial Robots
## Abstract:
Active inference is a mathematical framework which originated in computational neuroscience. Recently, it has been demonstrated as a promising approach for constructing goal-driven behaviour in robotics. Specifically, the active inference controller (AIC) has been successful in many continuous control and state-estimation tasks. Despite its relative success, some established design choices lead to a number of practical limitations for robot control. These include having a biased estimate of the state, and only an implicit model of control actions. In this paper we highlight these limitations, and propose a new active inference scheme: the unbiased active inference controller (u-AIC). The u-AIC maintains all the compelling benefits of the AIC and removes its limitations. Simulation results on a 2-DOF arm and experiments on a real 7-DoF manipulator show the improved performance of the u-AIC with respect to the standard AIC. The code can be found at https://github.com/cpezzato/unbiased_aic.
# Plane-To-Plane Positioning by Proximity-Based Control
## Keywords:
- Sensor-based Control
- Visual Servoing
## Abstract:
In this paper, we consider a multi-sensor arrangement of proximity sensors that forms a proximity array. A general modeling methodology is considered within the framework of Sensor-based Control. It incorporates multiple sensor signals from the proximity array by giving primary emphasis on the interaction screw. To prove its effectiveness, modeling approach is applied to the task of plane-to-plane positioning. We discuss the development of two sensor-based task functions for the specific task considered. The validity of the methodology is provided using relevant experimental results.
# Safe Control Synthesis with Uncertain Dynamics and Constraints
## Keywords:
- Robust/Adaptive Control
- Optimization and Optimal Control
- Sensor-based Control
## Abstract:
This paper considers safe control synthesis for dynamical systems with either probabilistic or worst-case uncertainty in both the dynamics model and the safety constraints. We formulate novel probabilistic and robust (worst-case) control Lyapunov function (CLF) and control barrier function (CBF) constraints that take into account the effect of uncertainty in either case. We show that either the probabilistic or the robust (worst-case) formulation leads to a second-order cone program (SOCP), which enables efficient safe and stable control synthesis. We evaluate our approach in PyBullet simulations of an autonomous robot navigating in unknown environments and compare the performance with a baseline CLF-CBF quadratic programming approach.
# Robust and Decoupled Position and Stiffness Control for Electrically-Driven Articulated Soft Robots
## Keywords:
- Robust/Adaptive Control
- Flexible Robotics
- Compliance and Impedance Control
## Abstract:
The control of articulated soft robots, i.e. robots with flexible joints and rigid links, presents a challenge due to their intrinsic elastic elements and nonlinear force-deflection dependency. This letter first proposes a discrete-time delayed unknown input-state observer based on a nominal robot model that reconstructs the total torque disturbance vector, resulting from the imperfect knowledge of the elastic torque characteristic, external torques, and other model uncertainties. Then, it introduces a robust controller, that actively compensates for the estimated uncertainty and allows asymptotic tracking of independent link position and joint stiffness reference signals. The convergence of the disturbance estimator and the overall system’s stability in closed loop is proven analytically, while the effectiveness of the proposed control design is first evaluated in simulations with respect to large uncertainty conditions, and then demonstrated through experiments on a real multi-degree-of-freedom articulated soft robot.
# Battle the Wind: Improving Flight Stability of a Flapping Wing Micro Air Vehicle under Wind Disturbance with Onboard Thermistor-Based Airflow Sensing
## Keywords:
- Sensor-based Control
- Energy and Environment-Aware Automation
- Biologically-Inspired Robots
## Abstract:
Flyers in nature equip different airflow sensing mechanisms to navigate through wind disturbances with remarkable flight stability. Embracing bio-inspiration, airflow sensing with conventional sensors has long been utilized in flight control for larger micro air vehicles (MAVs). For smaller MAVs with extremely limited power and payload # such as flapping wing MAVs # onboard airflow sensing in free flight has remained a challenge in spite of various attempts at miniaturized airflow sensor designs. This paper characterizes the measurement performance of a lightweight off-the-shelf thermistor-based airflow sensor through comparison with a hot-wire probe. Wind tunnel tethered flight tests on a 31.3-gram flapping wing MAV Delfly Nimble are carried out to examine the onboard sensing performance at low flow speeds (up to 2 m/s), under the influence of flapping motion. This performance characterization further motivates a miniaturized re-design of the airflow sensor with about 50% size reduction and lower power consumption. The redesigned airflow sensor helps to realize the first flapping wing MAV free flight with onboard airspeed measurements, providing remarkable flight stability under wind speeds in the range of approximately 0.5 to 1.2 m/s. This embodied sensor configuration pushes the weight and power limit of miniaturized electronics for flapping wing MAVs, yet providing an easy-to-integrate solution with good performance, paving the way for more complex control of FWMAVs in dynamic conditions.
# Robust Stabilization of Elastic Joint Robots by ESP and PID Control: Theory and Experiments
## Keywords:
- Robust/Adaptive Control
- Compliance and Impedance Control
- Motion Control
## Abstract:
This work addresses the problem of global set-point control of elastic joint robots by combining elastic structure preserving (ESP) control with non-collocated integral action. Despite the popularity and extensive research on PID control for rigid joint robots, such schemes largely evaded adoption to elastic joint robots. This is mainly due to the underactuation inherent to these systems, which impedes the direct implementation of PID schemes with non-collocated (link position) feedback. We remedy this issue by using the recently developed concept of “quasi-full actuation,” to achieve a link-side PID control structure with “delayed” integral action. The design follows the structure preserving design philosophy of ESP control and ensures global asymptotic stability and local passivity of the closed loop. A key feature of the proposed controller is the switching logic for the integral action that enables the combination of excellent positioning accuracy in free motion with compliant manipulation in contact with the environment. Its performance is evaluated on an elastic joint testbed and a compliant robot arm. The results demonstrate that elastic robots may achieve positioning accuracy comparable to rigid joint robots.
# An Adaptive Approach to Whole-Body Balance Control of Wheel-Bipedal Robot Ollie
## Keywords:
- Robust/Adaptive Control
- Body Balancing
- Motion Control
## Abstract:
The wheel-bipedal robot has the advantages of both wheeled robots and legged robots, but as a cost, it is more challenging to perform flexible movements in various surroundings while keeping it balanced. The inaccurate dynamics of the robot makes the balance problem even more intractable. To solve this problem, the robot Ollie is used as a testbed. The whole-body control (WBC) framework is adopted to enhance the dexterity of the robot with multiple degrees of freedom in the task space. Moreover, a learning-based adaptive technique is applied to assist the WBC such that the balance controller can be designed in the absence of the accurate dynamics. Physical experiments demonstrate that the robot can manage various actions, with the help of the combination of the WBC and the learning-based adaptive technique.
# An Optimal Dynamic Control Method for Manipulators with Virtual Links
## Keywords:
- Redundant Robots
- Motion Control
- Industrial Robots
## Abstract:
Virtual links and virtual joints can be appended to the kinematic chain of a robot arm to assist in modelling and control of certain tasks. Activities such as spray painting, sand blasting, or scanning with a laser or camera can be enhanced by modelling the fluid stream, light beam, or field of view using a virtual link. Virtual joints can be used to allow movement in semi-redundant degrees of freedom of the task space. This can can be exploited to optimize the control of the real robot. A prudent choice is to minimize the effort required by the manipulator to execute the task. This often requires the inversion of the inertia matrix. However, virtual links have no inertia so the inverse does not exist. This paper first explores methods of adding virtual mass or modifying the inertia matrix to allow inversion and the consequences. Then an optimal control problem is proposed that minimizes kinetic energy in the real manipulator and maximizes use of the virtual joints. In doing so, we only need the real inertia matrix which is always invertible. The method is validated in a case study for high pressure water blasting. It is shown to reduce the dynamic torque norm compared to a minimum velocity controller.
# Constrained Imitation Learning for a Flapping Wing Unmanned Aerial Vehicle
## Keywords:
- Aerial Systems: Mechanics and Control
- Imitation Learning
- Optimization and Optimal Control
## Abstract:
This paper presents a data-driven optimal control policy for a micro flapping wing unmanned aerial vehicle.First, a set of optimal trajectories are computed off-line based on a geometric formulation of dynamics that captures the nonlinear coupling between the large angle flapping motion and the quasi-steady aerodynamics. Then, it is transformed into a feedback control system according to the framework of imitation learning. In particular, an additional constraint is incorporated through the learning process to enhance the stability properties of the resulting controlled dynamics. Compared with conventional methods, the proposed constrained imitation learning eliminates the need to generate additional optimal trajectories on-line, without sacrificing stability. As such, the computational efficiency is substantially improved. Furthermore, this establishes the first nonlinear control system that stabilizes the coupled longitudinal and lateral dynamics of flapping wing aerial vehicle without relying on averaging or linearization. These are illustrated by numerical examples for a simulated model inspired by Monarch butterflies.
# Calibration and Robot Safety
# CROON: Automatic Multi-LiDAR Calibration and Refinement Method in Road Scene
## Keywords:
- Calibration and Identification
- Sensor Fusion
- Computer Vision for Automation
## Abstract:
Sensor-based environmental perception is a crucial part of the autonomous driving system. In order to get an excellent perception of the surrounding environment, an intelligent system would configure multiple LiDARs (3D Light Detection and Ranging) to cover the distant and near space of the car. The precision of perception relies on the quality of sensor calibration. This research aims at developing an accurate, automatic, and robust calibration strategy for multiple LiDAR
systems in the general road scene. We thus propose CROON: automatic multi-LiDAR Calibration and Refinement MethOd in rOad sceNe, a two-stage method including rough and refinement calibration. The first stage can calibrate the sensor from an arbitrary initial pose, and the second stage is able to precisely calibrate the sensor iteratively. Specifically, CROON utilize the nature characteristics of road scene so
that it is independent and easy to apply in large-scale conditions. Experimental results on real-world and simulated data sets demonstrate the reliability and accuracy of our method. All the related data sets and codes are open-sourced on the Github website https://github.com/OpenCalib/LiDAR2LiDAR.
# Geometric Calibration of Single-Pixel Distance Sensors
## Keywords:
- Calibration and Identification
- Localization
- Range Sensing
## Abstract:
Single-pixel distance sensors are a low-power, low-cost option for distance ranging, and are often attached to robots for collision detection and avoidance. The pose of the sensor, its position and orientation relative to the robot it is attached to, must be known to relate its measurements to 3D scene geometry. However, sensor pose is difficult to measure accurately, which has precluded the use of single-pixel sensors from applications where precise knowledge of the relative sensor pose is required. In this work, we provide a calibration procedure that can accurately determine the pose of a single-pixel distance sensor given only the known motion of the robot and an unknown planar target. We establish a geometric relationship between the relative sensor pose, robot motion, and an arbitrary plane, and show that the plane and sensor parameters can be recovered via nonlinear optimization. The result is a practical procedure for sensor calibration. We assess the procedure in simulation and in real world experiments, and provide an open source implementation. We consider two commonly available sensors (ST VL6180X and ST VL53L3CX) and characterize them to show that while they deviate from the idealized model used in our derivation, their poses can be recovered precisely and used for effective 3D scene reconstruction.
# Data-Driven Kalman Filter with Kernel-Based Koopman Operators for Nonlinear Robot Systems
## Keywords:
- Calibration and Identification
- Formal Methods in Robotics and Automation
- Wheeled Robots
## Abstract:
Designing the Kalman filter for nonlinear robot systems with theoretical guarantees is challenging, especially when the dynamics model is unavailable. This paper proposes a data-driven Kalman filter algorithm using kernel-based Koopman operators for unknown nonlinear robot systems. First, the Koopman operator using sparse kernel-based extended dynamic decomposition(EDMD) is presented to learn the unknown dynamics with input-output datasets. Unlike classic EDMD, which requires manual selection of kernel functions, our approach automatically constructs kernel functions using an approximate linear dependency analysis method. The resulting Koopman model is a linear dynamic evolution in the kernel space, enabling us to address the nonlinear filtering problem using the standard linear Kalman filter design process. Despite this, our approach generates a nonlinear filtering law thanks to the adopted nonlinear kernel functions. Further more, the extension to a fault-tolerant Kalman filter is presented. The theoretical properties of the proposed Kalman filter and its fault-tolerant extension are guaranteed under modeling errors and external disturbances. Finally, the effectiveness of the proposed approach is validated by simulated and experimental results.
# High Precision and Robust Camera Calibration under Learning-Based Distortion Correction and Feature Detection
## Keywords:
- Calibration and Identification
- Deep Learning for Visual Perception
- Visual Learning
## Abstract:
Camera calibration is a crucial technique which significantly influences the performance of many robotic systems. Robustness and high precision have always been the pursuit of diverse calibration methods. State-of-the-art calibration techniques, however, still suffer from inexact corner detection, radial lens distortion and unstable parameter estimation. Therefore, in this paper, we improve the precision and robustness of calibration by widening these bottlenecks. In particular, effective distortion correction is performed by a learning-based method. Then, accurate sub-pixel feature location is achieved by the combination of robust learning detection, exact refinement and complete post-processing. To obtain stable parameter estimation, an image-level RANSAC-based calibration procedure is proposed. Ultimately, we assemble these methods into a novel and practical calibration framework. Compared with state-of-art methods, experiment results on both real and synthetic datasets under noise, bad lighting and distortion manifest the better robustness and higher precision of the proposed framework. The code is publicly available at https://github.com/Easonyesheng/CCS.
# Extrinsic Camera Calibration from a Moving Person
## Keywords:
- Calibration and Identification
## Abstract:
We propose a novel camera calibration method for a room-scale multi-view imaging system. Our key idea is to leverage our articulated body movements as a calibration target. We show that a freely moving person provides trajectories of a set of oriented points (e.g., neck joint with spine direction) from which we can estimate the locations and poses of all cameras observing them. The method only requires the cameras to be synced and that 2D human poses are estimated in each view sequence. By elevating these 2D poses to 3D which directly provides a set of oriented 3D joints, we compute the extrinsic parameters of all cameras with a linear algorithm. We also show that this enables self-supervision of the 3D joint estimator for refinement, and the iteration of the two leads to accurate camera extrinsics and 3D pose estimates. Experimental results on extensive synthetic and real data demonstrate the effectiveness and flexibility of the method which would serve as a useful tool to expand the utility of multi-view vision systems as it eliminates the need for cumbersome on-site calibration procedures.
# A Barrier-Based Scenario Approach to Verifying Safety-Critical Systems
## Keywords:
- Robot Safety
- Performance Evaluation and Benchmarking
- Multi-Robot Systems
## Abstract:
We detail an approach to safety-critical verification using barrier functions. Our method requires limited system data to verify a system's ability to keep positive a candidate barrier function h at discrete-time intervals over its trajectories. Specifically, our method first randomly samples initial conditions and parameters for a controlled, continuous-time system and records the state trajectory at discrete intervals. Then, we evaluate these states under a candidate barrier function h to determine the constraints for a randomized linear program. The solution to this program provides either a probabilistic verification statement in the aforementioned vein or a counterexample # an instance where the system went unsafe. To showcase our results, we verify the robotarium simulator, identify counterexamples for its hardware counterpart, and experimentally verify the safety of a multi-agent quadrupedal system.
# Quantifying Safety of Learning-Based Self-Driving Control Using Almost-Barrier Functions
## Keywords:
- Robot Safety
- Machine Learning for Robot Control
- AI-Based Methods
## Abstract:
Path-tracking control of self-driving vehicles can benefit from deep learning for tackling longstanding challenges such as nonlinearity and uncertainty. However, deep neural controllers lack safety guarantees, restricting their practical use. We propose a new approach of learning almost-barrier functions, which approximately characterizes the forward invariant set for the system under neural controllers, to quantitatively analyze the safety of deep neural controllers for path-tracking. We design sampling-based learning procedures for constructing candidate neural barrier functions, and certification procedures that utilize robustness analysis for neural networks to identify regions where the barrier conditions are fully satisfied. We use an adversarial training loop between learning and certification to optimize the almost-barrier functions. The learned barrier can also be used to construct online safety monitors through reachability analysis. We demonstrate effectiveness of our methods in quantifying safety of neural controllers in various simulation environments, ranging from simple kinematic models to the TORCS simulator with high-fidelity vehicle dynamics simulation.
# A Task-Based Post-Impact Safety Protocol Based on Energy Tanks
## Keywords:
- Robot Safety
## Abstract:
As situations with robots working in human environments are becoming increasingly important, the aspect of safety is crucial. As a consequence, the design of human friendly robots has been intensively researched in the past years, producing both mechanical and control design advancements. In this work, a safety-aware control architecture is proposed in a scenario in which a predefined task has to be executed. At the core of its implementation, a novel dynamic energy injection protocol is introduced for energy tanks. Contrarily to their most common employment in the past, energy tanks are used to provide relevant information on energy flows used by the safety protocol, rather than to guarantee passivity of the controlled robot, which does not imply safety. The algorithm is able to detect collisions and divergence from nominal task execution by identifying unwanted energy flows, encoded in the energy tanks. A reaction strategy based on low impedance control is implemented in case of collision detection. Experiments on a 7-DoF manipulator successfully validate the proposed strategy.
# Scalable Safety-Critical Policy Evaluation with Accelerated Rare Event Sampling
## Keywords:
- Reinforcement Learning
- Robot Safety
## Abstract:
Evaluating rare but high-stakes events is one of the main challenges in obtaining reliable reinforcement learning policies, especially in large or infinite state/action spaces where limited scalability dictates a prohibitively large number of testing iterations. On the other hand, a biased or inaccurate policy evaluation in a safety-critical system could potentially cause unexpected catastrophic failures during deployment. This paper proposes the Accelerated Policy Evaluation (APE) method, which simultaneously uncovers rare events and estimates the rare event probability in Markov decision processes. The APE method treats the environment nature as an adversarial agent and learns towards, through adaptive importance sampling, the zero-variance sampling distribution for the policy evaluation. Moreover, APE is scalable to large discrete or continuous spaces by incorporating function approximators. We investigate the convergence property of APE in the tabular setting. Our empirical studies show that APE can estimate rare event probability with a smaller bias while only using orders of magnitude fewer samples than baselines in multi-agent and single-agent environments.
# Multi-Contact Whole-Body Motion Planning and Control
# Deep Active Visual Attention for Real-Time Robot Motion Generation: Emergence of Tool-Body Assimilation and Adaptive Tool-Use
## Keywords:
- Neurorobotics
- Perception-Action Coupling
- Bioinspired Robot Learning
## Abstract:
Sufficiently perceiving the environment is a critical factor in robot motion generation. Although the introduction of deep visual processing models has contributed to extending this ability, existing methods lack in the ability to actively modify what to perceive; humans perform internally during visual cognitive processes. This paper addresses the issue by proposing a novel robot motion generation model, inspired by a human cognitive structure. The model incorporates a state-driven active top-down visual attention module, which acquires attentions that can actively change targets based on task states. We term such attentions as role-based attentions, since the acquired attention directed to targets that shared a coherent role throughout the motion. The model was trained on a robot tool-use task, in which the role-based attentions perceived the robot grippers and tool as identical end-effectors, during object picking and object dragging motions respectively. This is analogous to a biological phenomenon called tool-body assimilation, in which one regards a handled tool as an extension of one's body. The results suggested an improvement of flexibility in model's visual perception, which sustained stable attention and motion even if it was provided with untrained tools or exposed to experimenter's distractions.
# Automatic Tuning and Selection of Whole-Body Controllers
## Keywords:
- Humanoid Robot Systems
- Whole-Body Motion Planning and Control
- Machine Learning for Robot Control
## Abstract:
Designing controllers for complex robots such as humanoids is not an easy task. Often, researchers hand-tune controllers, but this is a time-consuming approach that yields a single controller which cannot generalize well to varied tasks. This work presents a method which uses the NSGA-II multi-objective optimization algorithm with various training trajectories to output a diverse Pareto set of well-functioning controller weights and gains. The best of these are shown to also work well on the real Talos robot. The learned Pareto front is then used in a Bayesian optimization (BO) algorithm both as a search space and as a source of prior information in the initial mean estimate. This combined learning approach, leveraging the two optimization methods together, finds a suitable parameter set for a new trajectory within 20 trials and outperforms both BO in the continuous parameter search space and random search along the precomputed Pareto front. The few trials required for this formulation of BO suggest that it could feasibly be applied on the physical robot using a Pareto front generated in simulation.
# Learning to Guide Online Multi-Contact Receding Horizon Planning
## Keywords:
- Multi-Contact Whole-Body Motion Planning and Control
- Humanoid and Bipedal Locomotion
- Legged Robots
## Abstract:
In Receding Horizon Planning (RHP), it is critical that the motion being executed facilitates the completion of the task, e.g. building momentum to overcome large obstacles. This requires a value function to inform the desirability of robot states. However, given the complex dynamics, value functions are often approximated by expensive computation of trajectories in an extended planning horizon. In this work, to achieve online multi-contact Receding Horizon Planning (RHP), we propose to learn an oracle that can predict local objectives (intermediate goals) for a given task based on the current robot state and the environment. Then, we use these local objectives to construct local value functions to guide a short-horizon RHP. To obtain the oracle, we take a supervised learning approach, and we present an incremental training scheme that can improve the prediction accuracy by adding demonstrations on how to recover from failures. We compare our approach against the baseline (long-horizon RHP) for planning centroidal trajectories of humanoid walking on moderate slopes as well as large slopes where static stability cannot be achieved. We validate these trajectories by tracking them via a whole-body inverse dynamics controller in simulation. We show that our approach can achieve online RHP for 95%-98.6% cycles, outperforming the baseline (8%-51.2%).
# Real-Time Footstep Planning and Control of the Solo Quadruped Robot in 3D Environments
## Keywords:
- Multi-Contact Whole-Body Motion Planning and Control
- Legged Robots
## Abstract:
Quadruped robots have proved their robustness to cross complex terrain despite little environment knowledge. Yet advanced locomotion controllers are expected to take advantage of exteroceptive information. This paper presents a complete method to plan and control the locomotion of quadruped robots when 3D information about the surrounding obstacles is available, based on several stages of decision. We first propose a contact planner formulated as a mixed-integer program, optimized on-line at each new robot step. It selects a surface from a set of convex surfaces describing the environment for the next footsteps while ensuring kinematic constraints. We then propose to optimize the exact contact location and the feet trajectories at control frequency to avoid obstacles, thanks to an efficient formulation of quadratic programs optimizing Bezier curves. By relying on the locomotion controller of our quadruped robot Solo, we finally implement the complete method, provided as an open-source package. Its efficiency is asserted by statistical evaluation of the importance of each component in simulation. We have a 100% success rate for our framework, and we show that the deactivation of the contact planning, footstep adaptation and collision avoidance, respectively induced a drop to 70%, 62% and 83% success rate in the worst case, justifying the complete architecture.
# Modeling, Analysis and Activation of Planar Viscoelastically-Combined Rimless Wheels
## Keywords:
- Passive Walking
- Legged Robots
- Mechanism Design
## Abstract:
This paper proposes novel passive-dynamic walkers formed by two cross-shaped frames and eight viscoelastic elements. Since it is a combination of two four-legged rimless wheels via viscoelastic elements, we call it viscoelastically-combined rimless wheel (VCRW). Two types of VCRWs consisting of different cross-shaped frames are introduced; one is formed by combining two Greek-cross-shaped frames (VCRW1), and the other is formed by combining two-link cross-shaped frames that can rotate freely around the central axis (VCRW2). First, we describe the model assumptions and equations of motion and collision. Second, we numerically analyze the basic gait properties of passive dynamic walking. Furthermore, we consider an activation of VCRW2 for generating a stable level gait, and discuss the significance of the study as a novel walking support device.
# Minor Change, Major Gains II: Are Maximal Coordinates the Fastest Choice for Trajectory Optimization?
## Keywords:
- Multi-Contact Whole-Body Motion Planning and Control
- Optimization and Optimal Control
- Legged Robots
## Abstract:
It has been shown that changing the coordinates describing a multi-body system to use absolute rather than relative angles produces a significant improvement in the tractability of trajectory optimization problems. This simplifies the equations of motion when modelling long kinematic chains. In this paper, we extend this idea by investigating whether a maximal coordinate system, which also describes the translational position of bodies using absolute coordinates, might lead to further performance improvements. We compare it to the relative translation, absolute orientation (RTAO) coordinate scheme using a batch of trajectory optimization trials selected with contact-implicit legged locomotion applications in mind. We find that maximal coordinates tend to shorten solving times for spatial problems, while the RTAO formulation still performs best in the case of planar motion.
# Centroidal Trajectory Generation and Stabilization Based on Preview Control for Humanoid Multi-Contact Motion
## Keywords:
- Multi-Contact Whole-Body Motion Planning and Control
- Humanoid and Bipedal Locomotion
- Whole-Body Motion Planning and Control
## Abstract:
Multi-contact motion is important for humanoid robots to work in various environments. We propose a centroidal online trajectory generation and stabilization control for humanoid dynamic multi-contact motion. The proposed method features the drastic reduction of the computational cost by using preview control instead of the conventional model predictive control that considers the constraints of all sample times. By combining preview control with centroidal state feedback for robustness to disturbances and wrench distribution for satisfying contact constraints, we show that the robot can stably perform a variety of multi-contact motions through simulation experiments.
# Integration of Variable-Height and Hopping Strategies for Humanoid Push Recovery
## Keywords:
- Humanoid and Bipedal Locomotion
- Body Balancing
- Motion Control
## Abstract:
In this study, we present a framework to ensure seamless transition in humanoid push recovery involving hopping strategy. We propose a method to adaptively change the time constant that integrated the ankle strategy and variable height strategy. This framework excites a hopping motion against a large disturbance, which provides a seamless transition from the variable height to the hopping strategies. We analyze the applicable region of each strategy based on the simplified model. Moreover, we show that the hopping strategy prevents falling through whole-body dynamic simulations.
# Learning Agile Hybrid Whole-Body Motor Skills for Thruster-Aided Humanoid Robots
## Keywords:
- Humanoid and Bipedal Locomotion
- Machine Learning for Robot Control
- Aerial Systems: Applications
## Abstract:
Humanoid robots are versatile platforms with the potential for multiple locomotion skills. However, this contact-switched system with only two contact feet is fragile to keep balance in many scenarios. Inspired by birds combining legs and wings, we propose the novel hybrid locomotion behavior for the humanoid robots with the aid of a thruster suit. To fully leverage their agility while guaranteeing efficient computation, we develop the neural controller based on reinforcement learning (RL) to handle the complexity of the highly non-linear system. Our learning framework is demonstrated on several thruster-aided humanoid platforms with hybrid walking and even dynamic locomotion skills. To our best knowledge, it is the first work that, 1. demonstrates agile hybrid whole-body locomotion skills on the thruster-aided humanoid robot; 2. achieves hybrid locomotion under the reinforcement learning settings.
# Intelligent Transportation Systems 2
# Active Mapping Via Gradient Ascent Optimization of Shannon Mutual Information Over Continuous SE(3) Trajectories
## Keywords:
- View Planning for SLAM
- Reactive and Sensor-Based Planning
- Perception-Action Coupling
## Abstract:
The problem of active mapping aims to plan an informative sequence of sensing views given a limited budget such as distance traveled. This paper considers active occupancy grid mapping using a range sensor, such as LiDAR or depth camera. State-of-the-art methods optimize information-theoretic measures relating the occupancy grid probabilities with the range sensor measurements. The non-smooth nature of ray-tracing within a grid representation makes the objective function non-differentiable, forcing existing methods to search over a discrete space of candidate trajectories. This work proposes a differentiable approximation of the Shannon mutual information between a grid map and ray-based observations that enables gradient ascent optimization in the continuous space of textit{SE(3)} sensor poses. Our gradient-based formulation leads to more informative sensing trajectories, while avoiding occlusions and collisions. The proposed method is demonstrated in simulated and real-world experiments in 2-D and 3-D environments.
# A Framework for Optimized Topology Design and Leader Selection in Affine Formation Control
## Keywords:
- Networked Robots
- Distributed Robot Systems
- Multi-Robot Systems
## Abstract:
This paper studies the problem of topology design and leader selection to activate affine formation control schemes. The affine formation control enjoys a distinguishing feature from other control methods in that the whole formation can be dynamically maneuvered by controlling a small number of agents called leaders. This relies on the stress matrix which defines the inter-agent communication/sensing topology determining the dynamic performance for an autonomous system. In the first step, a topology design algorithm based on mixed integer semi-definite programming (MISDP) is proposed to obtain the stress matrix with low communication cost, fast convergence speed and high tolerance of time-delay. Secondly, the proposed leader selection algorithm focuses on two objectives of practical significance: convergence speed and control energy, which are tailored to two optimization problems based on MISDP. At last, the collective agents are driven to the target formation via their local interactions and leaders’ external control inputs. The effectiveness of the overall framework is validated by both simulations and physical experiments.
# Contextual Driving Scene Perception from Anonymous Vehicle Bus Data for Automotive Applications
## Keywords:
- Intelligent Transportation Systems
- AI-Based Methods
- Deep Learning Methods
## Abstract:
In recent years, driving context perception has emerged as one of the key aspects to design driving assistance algorithms and user interfaces that are effective in adapting to different traffic situations or environments. To this aim, we introduce the Anonymous Driving Scene Perception (ADSP) Model, a novel deep neural network designed to classify anonymous Controller Area Network (CAN)-bus data into multiple driving context domains. ADSP extends the idea of driving scene classification to time series signals, as previous works relied heavily on visual features. Our model achieved a multi-domain classification accuracy of 84.9% on our custom-built naturalistic data set, as a combination of 92.7% on road type classification and 90.1% on binary traffic detection, performing 2.0% and 1.6% better than the state-of-the-art model for multivariate time series classification. Our work demonstrates the feasibility of driving scene classification from anonymous CAN-bus data, without collecting sensitive data, such as images or GPS.
# Efficient Game-Theoretic Planning with Prediction Heuristic for Socially-Compliant Autonomous Driving
## Keywords:
- Intelligent Transportation Systems
- Agent-Based Systems
- Autonomous Agents
## Abstract:
Planning under social interactions with other agents is an essential problem for autonomous driving. As the actions of the autonomous vehicle in the interactions affect and are also affected by other agents, autonomous vehicles need to efficiently infer the reaction of the other agents. Most existing approaches formulate the problem as a generalized Nash equilibrium problem solved by optimization-based methods. However, they demand too much computational resource and easily fall into the local minimum due to the non-convexity. Monte Carlo Tree Search (MCTS) successfully tackles such issues in game-theoretic problems. However, as the interaction game tree grows exponentially, the general MCTS still requires a huge amount of iterations to reach the optima. In this paper, we introduce an efficient game-theoretic trajectory planning algorithm based on general MCTS by incorporating a prediction algorithm as a heuristic. On top of it, a social-compliant reward and a Bayesian inference algorithm are designed to generate diverse driving behaviors and identify the other driver’s driving preference. Results demonstrate the effectiveness of the proposed framework with datasets containing naturalistic driving behavior in highly interactive scenarios.
# Self-Supervised Scene Flow Estimation with 4-D Automotive Radar
## Keywords:
- Intelligent Transportation Systems
- Computer Vision for Transportation
## Abstract:
Scene flow allows autonomous vehicles to reason about the arbitrary motion of multiple independent objects which is the key to long-term mobile autonomy. While estimating the scene flow from LiDAR has progressed recently, it remains largely unknown how to estimate the scene flow from a 4-D radar # an increasingly popular automotive sensor for its robustness against adverse weather and lighting conditions. Compared with the LiDAR point clouds, radar data are drastically sparser, noisier and in much lower resolution. Annotated datasets for radar scene flow are also in absence and costly to acquire in the real world. These factors jointly pose the radar scene flow estimation as a challenging problem. This work aims to address the above challenges and estimate scene flow from 4-D radar point clouds by leveraging self-supervised learning. A robust scene flow estimation architecture and three novel losses are bespoken designed to cope with intractable radar data. Real-world experimental results validate that our method is able to robustly estimate the radar scene flow in the wild and effectively supports the downstream task of motion segmentation.
# Domain Knowledge Driven Pseudo Labels for Interpretable Goal-Conditioned Interactive Trajectory Prediction
## Keywords:
- Intelligent Transportation Systems
- Deep Learning Methods
- Representation Learning
## Abstract:
Motion forecasting in highly interactive scenarios is a challenging problem in autonomous driving. In such scenarios, we need to accurately predict the joint behavior of interacting agents to ensure the safe and efficient navigation of autonomous vehicles. Recently, goal-conditioned methods have gained increasing attention due to their advantage in performance and their ability to capture the multimodality in trajectory distribution. In this work, we study the joint trajectory prediction problem with the goal-conditioned framework. In particular, we introduce a conditional-variational-autoencoder-based (CVAE) model to explicitly encode different interaction modes into the latent space. However, we discover that the vanilla model suffers from posterior collapse and cannot induce an informative latent space as desired. To address these issues, we propose a novel approach to avoid KL vanishing and induce an interpretable interactive latent space with pseudo labels. The proposed pseudo labels allow us to incorporate domain knowledge on interaction in a flexible manner. We motivate the proposed method using an illustrative toy example. In addition, we validate our framework on the Waymo Open Motion Dataset with both quantitative and qualitative evaluations.
# ACHORD: Communication-Aware Multi-Robot Coordination with Intermittent Connectivity
## Keywords:
- Networked Robots
- Multi-Robot Systems
- Field Robots
## Abstract:
Communication is an important capability for multi-robot exploration because (1) inter-robot communication (comms) improves coverage efficiency and (2) robot-to-base comms improves situational awareness. Exploring comms-restricted (e.g., subterranean) environments requires a multi-robot system to tolerate and anticipate intermittent connectivity, and to carefully consider comms requirements, otherwise mission-critical data may be lost. In this paper, we describe and analyze ACHORD (Autonomous & Collaborative High-Bandwidth Operations with Radio Droppables), a multi-layer networking solution which tightly co-designs the network architecture and high-level decision-making for improved comms. ACHORD provides bandwidth prioritization and timely and reliable data transfer despite intermittent connectivity. Furthermore, it exposes low-layer networking metrics to the application layer to enable robots to autonomously monitor, map, and extend the network via droppable radios, as well as restore connectivity to improve collaborative exploration. We evaluate our solution with respect to the comms performance in several challenging underground environments including the DARPA SubT Finals competition environment. Our findings support the use of robotic message ferrying to complement static relay nodes, data stratification, and flow control to improve bandwidth-usage.
# Detecting Adversarial Perturbations in Multi-Task Perception
## Keywords:
- Intelligent Transportation Systems
- Computer Vision for Transportation
- Deep Learning for Visual Perception
## Abstract:
While deep neural networks (DNNs) achieve impressive performance on environment perception tasks, their sensitivity to adversarial perturbations limits their use in practical applications. In this paper, we (i) propose a novel adversarial perturbation detection scheme based on multi-task perception of complex vision tasks (i.e., depth estimation and semantic segmentation). Specifically, adversarial perturbations are detected by inconsistencies between extracted edges of the input image, the depth output, and the segmentation output. To further improve this technique, we (ii) develop a novel edge consistency loss between all three modalities, thereby improving their initial consistency which in turn supports our detection scheme. We verify our detection scheme's effectiveness by employing various known attacks and image noises. In addition, we (iii) develop a multi-task adversarial attack, aiming at fooling both tasks as well as our detection scheme. Experimental evaluation on the Cityscapes and KITTI datasets shows that under an assumption of a 5% false positive rate up to 100% of images are correctly detected as adversarially perturbed, depending on the strength of the perturbation. Code is available at https://github.com/ifnspaml/AdvAttackDet. A short video at https://youtu.be/KKa6gOyWmH4 provides qualitative results.
# Recognition Beyond Perception: Environmental Model Completion by Reasoning for Occluded Vehicles
## Keywords:
- Intelligent Transportation Systems
- Computer Vision for Transportation
- Deep Learning Methods
## Abstract:
It is widely assumed that considering vehicle interactions for trajectory prediction can significantly improve accuracy. All environmental sensors of an automated vehicle (AV) suffer from occlusion. Therefore, relevant vehicles can be occluded by others, especially in dense traffic situations, and remain invisible to the AV. Unobserved vehicles could lead to a drop in trajectory prediction accuracy and even to poor driving behavior. We propose an environmental model completion module that reconstructs unobserved vehicles in occluded areas only using trajectory information of interacting observed vehicles. We demonstrate the functionality of our approach in principle on a toy example and verify the benefit for an AV by improving trajectory prediction results in highly interactive scenes using the proposed module. To the best of our knowledge, we are the first to investigate such a problem on highway data. Reasoning for occluded vehicles is considered more challenging on the highway than in urban scenes since vehicle interactions and cooperation between vehicles are more subtle and nuanced.
# Data Sets for Robotic Vision
# ProgressLabeller: Visual Data Stream Annotation for Training Object-Centric 3D Perception
## Keywords:
- Data Sets for Robotic Vision
- Deep Learning in Grasping and Manipulation
- Perception for Grasping and Manipulation
## Abstract:
Visual perception tasks often require vast amounts of labelled data, including 3D poses and image space segmentation masks. The process of creating such training data sets can prove difficult or time-intensive to scale up to efficacy for general use. Consider the task of pose estimation for rigid objects. Deep neural network based approaches have shown good performance when trained on large, public datasets. However, adapting these networks for other novel objects, or fine-tuning existing models for different environments, requires significant time investment to generate newly labelled instances. Towards this end, we propose ProgressLabeller as a method for more efficiently generating large amounts of 6D pose training data from color images sequences for custom scenes in a scalable manner. ProgressLabeller is intended to also support transparent or translucent objects, for which the previous methods based on depth dense reconstruction will fail. We demonstrate the effectiveness of ProgressLabeller by rapidly create a dataset of over 1M samples with which we fine-tune a state-of-the-art pose estimation network in order to markedly improve the downstream robotic grasp success rates. Progresslabeller is open-source at https://github.com/huijieZH/ProgressLabeller.
# EVOPS Benchmark: Evaluation of Plane Segmentation from RGBD and LiDAR Data
## Keywords:
- Data Sets for Robotic Vision
- Data Sets for SLAM
- RGB-D Perception
## Abstract:
This paper provides the EVOPS dataset for plane segmentation from 3D data, both from RGBD images and LiDAR point clouds. We have designed two annotation methodologies (RGBD and LiDAR) running on well-known and widely-used datasets for SLAM evaluation and we have provided a complete set of benchmarking tools including point, planes and segmentation metrics. The data includes a total number of 10k RGBD and 7K LiDAR frames over different selected scenes which consist of high quality segmented planes. The experiments report quality of SOTA methods for RGBD plane segmentation on our annotated data. We also have provided learnable baseline for plane segmentation in LiDAR point clouds. All labeled data and benchmark tools used have been made publicly available at https://evops.netlify.app/.
# 6-DoF Pose Estimation of Household Objects for Robotic Manipulation: An Accessible Dataset and Benchmark
## Keywords:
- Data Sets for Robotic Vision
- Visual Learning
- Object Detection, Segmentation and Categorization
## Abstract:
We present a new dataset for 6-DoF pose estimation of known objects, with a focus on robotic manipulation research. We propose a set of toy grocery objects, whose physical instantiations are readily available for purchase and are appropriately sized for robotic grasping and manipulation. We provide 3D scanned textured models of these objects, suitable for generating synthetic training data, as well as RGBD images of the objects in challenging, cluttered scenes exhibiting partial occlusion, extreme lighting variations, multiple instances per image, and a large variety of poses. Using semi-automated RGBD-to-model texture correspondences, the images are annotated with ground truth poses accurate within a few millimeters. We also propose a new pose evaluation metric called {ADD-H} based on the Hungarian assignment algorithm that is robust to symmetries in object geometry without requiring their explicit enumeration. We share pre-trained pose estimators for all the toy grocery objects, along with their baseline performance on both validation and test sets. We offer this dataset to the community to help connect the efforts of computer vision researchers with the needs of roboticists.
# Realism Assessment for Synthetic Images in Robot Vision through Performance Characterization
## Keywords:
- Data Sets for Robotic Vision
- Simulation and Animation
- Data Sets for Robot Learning
## Abstract:
Synthetic image generation plays a crucial role in the development of robot vision algorithms, circumventing manual data collection. However, the realism of synthetic images could affect the performance of the algorithms when applied in real-world settings. In this study, we propose a framework to quantitatively assess the realism of synthetic images using a set of realism metrics as a means of performance characterization. We use a commercial rendering engine as a test-bed for generating synthetic images and ascertain that a set of rendering parameters affect specific realism metrics through statistical hypothesis testing. We demonstrate that this framework can be used to optimize rendering parameter values and generate synthetic datasets with improved performance on downstream robot vision tasks such as instance segmentation.
# Danish Airs and Grounds: A Dataset for Aerial-To-Street-Level Place Recognition and Localization
## Keywords:
- Data Sets for Robotic Vision
- Localization
- Deep Learning for Visual Perception
## Abstract:
Place recognition and visual localization are particularly challenging in wide baseline configurations. In this paper, we contribute with the Danish Airs and Grounds (DAG) dataset, a large collection of street-level and aerial images targeting such cases. Its main challenge lies in the extreme viewing-angle difference between query and reference images with consequent changes in illumination and perspective. The dataset is larger and more diverse than current publicly available data, including more than 50 km of roads in urban, suburban and rural areas. All images are associated with accurate 6-DoF metadata that allows the benchmarking of visual localization methods. Additionally, we validate our data by presenting the results of a simple map-to-image re-localization baseline that first estimates a dense 3D reconstruction from the aerial images and then matches query street-level images to street-level renderings of the 3D model. The dataset can be downloaded at: https://frederikwarburg.github.io/DAG/.
# Object Pose Estimation Using Mid-Level Visual Representations
## Keywords:
- Deep Learning for Visual Perception
- Data Sets for Robotic Vision
- Transfer Learning
## Abstract:
This work proposes a novel pose estimation model for object categories that can be effectively transferred to previously unseen environments. The deep convolutional network models (CNN) for pose estimation are typically trained and evaluated on datasets specifically curated for object detection, pose estimation, or 3D reconstruction, which requires large amounts of training data. In this work, we propose a model for pose estimation that can be trained with small amount of data and is built on the top of generic mid-level representations~cite{taskonomy2018} (e.g. surface normal estimation and re-shading). These representations are trained on a large dataset without requiring pose and object annotations. Later on, the predictions are refined with a small CNN neural network that exploits object masks and silhouette retrieval. The presented approach achieves superior performance on the Pix3D dataset~cite{pix3d} and shows nearly 35% improvement over the existing models when only 25% of the training data is available. We show that the approach is favorable when it comes to generalization and transfer to novel environments. Towards this end, we introduce a new pose estimation benchmark for commonly encountered furniture categories on challenging Active Vision Dataset~cite{Ammirato2017ADF} and evaluated the models trained on the Pix3D dataset.
# Grasp Pre-Shape Selection by Synthetic Training: Eye-In-Hand Shared Control on the Hannes Prosthesis
## Keywords:
- Deep Learning for Visual Perception
- Data Sets for Robotic Vision
- Prosthetics and Exoskeletons
## Abstract:
We consider the task of object grasping with a prosthetic hand capable of multiple grasp types. In this setting, communicating the intended grasp type often requires a high user cognitive load which can be reduced adopting shared autonomy frameworks. Among these, so-called eye-inhand systems automatically control the hand pre-shaping before the grasp, based on visual input coming from a camera on the wrist. In this paper, we present an eye-in-hand learningbased approach for hand pre-shape classification from RGB sequences. Differently from previous work, we design the system to support the possibility to grasp each considered object part with a different grasp type. In order to overcome the lack of data of this kind and reduce the need for tedious data collection sessions for training the system, we devise a pipeline for rendering synthetic visual sequences of hand trajectories. We develop a sensorized setup to acquire real human grasping sequences for benchmarking and show that, compared on practical use cases, models trained with our synthetic dataset achieve better generalization performance than models trained on real data. We finally integrate our model on the Hannes prosthetic hand and show its practical effectiveness. We make publicly available the code and dataset to reproduce the presented results.
# Sequential Thermal Image-Based Adult and Baby Detection Robust to Thermal Residual Heat Marks
## Keywords:
- Human Detection and Tracking
- Data Sets for Robotic Vision
- Surveillance Robotic Systems
## Abstract:
The awareness for preserving privacy in in-home monitoring robots is increasing. Although several studies have proposed privacy-preserved in-home monitoring robot systems for adults, only a limited amount of attention has been paid attention to research on privacy-preserved in-home monitoring of babies. Like previous studies, thermal infrared image-based methods could ensure a privacy-preserved monitoring of babies, yet when existing detection methods were applied to thermal images to detect babies and adults, we discovered a frequent occurrence of misdetection due to the presence of thermal residual heat marks. In this research, we propose a sequential thermal image-based detection that conjugated the characteristics of thermal residual heat marks. The proposed detection reduced misdetection caused by thermal residual heat marks by 98.7% when compared to RetinaNet. In addition, we open-source our collected thermal image-based baby and adult dataset via: https://github.com/donkeymouse/ThermalAdultandBaby
# IndoLayout: Leveraging Attention for Extended Indoor Layout Estimation from an RGB Image
## Keywords:
- Vision-Based Navigation
- Deep Learning for Visual Perception
- Data Sets for Robotic Vision
## Abstract:
In this work, we propose IndoLayout, a novel real-time approach for generating high-quality occupancy maps from an RGB image for indoor scenes. Such occupancy maps are often crucial for path-planning and mapping in indoor environments but are often built using only information contained in the ego view. In contrast, our approach also predicts occupancy values beyond immediately visible regions from just a monocular image, leveraging learnt priors from indoor scenes. Hence, our proposed network can produce a hallucinated, amodal scene layout that includes areas occluded in the RGB image, such as a navigable floor behind a desk. Specifically, we propose a novel architecture that uses self-attention and adversarial learning to vastly improve the quality of the predicted layout. We evaluate our model on several photorealistic indoor datasets and outperform previous relevant work on all metrics that measure layout quality, including newly adopted ones. Finally, we demonstrate the effectiveness of our method by showing significant improvements on the PointNav task over similar approaches using IndoLayout. For more details, please refer to the project page: https://indolayout.github.io/
# Autonomous Agents
# A Biologically-Inspired Simultaneous Localization and Mapping System Based on LiDAR Sensor
## Keywords:
- Biologically-Inspired Robots
- Neurorobotics
- Bioinspired Robot Learning
## Abstract:
Simultaneous localization and mapping (SLAM) is one of the essential techniques and functionalities used by robots to perform autonomous navigation tasks. Inspired by the rodent hippocampus, this paper presents a biologically inspired SLAM system based on a LiDAR sensor using a hippocampal model to build a cognitive map and estimate the robot pose in indoor environments. Based on the biologically inspired models mimicking boundary cells, place cells, and head direction cells, the SLAM system using LiDAR point cloud data is capable of leveraging the self-motion cues from the LiDAR odometry and the boundary cues from the LiDAR boundary cells to build a cognitive map and estimate the robot pose. Experiment results show that with the LiDAR boundary cells the proposed SLAM system greatly outperforms the camera-based brain-inspired method in both simulation and indoor environments, and is competitive with the conventional LiDAR-based SLAM methods.
# Cola-HRL: Continuous-Lattice Hierarchical Reinforcement Learning for Autonomous Driving
## Keywords:
- Autonomous Agents
- Reinforcement Learning
- AI-Based Methods
## Abstract:
Reinforcement learning (RL) has shown promising performance in autonomous driving applications in recent years. The early end-to-end RL method is usually unexplainable and fails to generate stable actions, while the hierarchical RL (HRL) method can tackle the above issues by dividing complex problems into multiple sub-tasks. Prior HRL works either select discrete driving behaviors with continuous control commands, or generate expected goals for the low-level controller. However, they typically have strong scenario dependence or fail to generate goals with good quality. To address the above challenges, we propose a Continuous-Lattice Hierarchical RL (Cola-HRL) method for autonomous driving tasks to make high-quality decisions in various scenarios. We utilize the continuous-lattice module to generate reasonable goals, ensuring temporal and spatial reachability. Then, we train and evaluate our method under different traffic scenarios based on real-world High Definition maps. Experimental results show our method can handle multiple scenarios. In addition, our method also demonstrates better performance and driving behaviors compared to existing RL methods.
# Visibility-Inspired Models of Touch Sensors for Navigation
## Keywords:
- Biologically-Inspired Robots
- Computational Geometry
- Sensor-based Control
## Abstract:
This paper introduces mathematical models of touch sensors for mobile robots based on visibility. Serving a purpose similar to the pinhole camera model for computer vision, the introduced models are expected to provide a useful, idealized characterization of task-relevant information that can be inferred from their outputs or observations. Possible tasks include navigation, localization and mapping when a mobile robot is deployed in an unknown environment. These models allow direct comparisons to be made between traditional depth sensors, highlighting cases in which touch sensing may be interchangeable with time of flight or vision sensors, and characterizing unique advantages provided by touch sensing. The models include contact detection, compression, load bearing, and deflection. The results could serve as a basic building block for innovative touch sensor designs for mobile robot sensor fusion systems.
# Factorization of Dynamic Games Over Spatio-Temporal Resources
## Keywords:
- Autonomous Agents
- Optimization and Optimal Control
- Motion and Path Planning
## Abstract:
Dynamic games feature a state-space complexity that scales superlinearly with the number of players. This makes this class of games often intractable even for a handful of players. We introduce the factorization process of dynamic games as a transformation leveraging the independence of players at equilibrium to build a leaner game graph. When applicable, it yields fewer nodes, fewer players per game node, hence much faster solutions. While for the general case checking for independence of players requires to solve the game itself, we observe that for dynamic games in the robotic domain there exist exact heuristics based on the spatio-temporal occupancy of the individual players. We validate our findings in realistic autonomous driving scenarios showing that already for a 4-players intersection we have a reduction of game nodes and solving time close to 99%.
# Handling Non-Convex Constraints in MPC-Based Humanoid Gait Generation
## Keywords:
- Humanoid and Bipedal Locomotion
- Humanoid Robot Systems
- Legged Robots
## Abstract:
In most MPC-based schemes used for humanoid gait generation, simple Quadratic Programming (QP) problems are considered for real-time implementation. Since these only allow for convex constraints, the generated gait may be conservative. In this paper we focus on the non-convex reachable region of the swinging foot, also known as Kinematic Admissible Region (KAR), and the corresponding constraint. We represent an approximation of such non-convex region as the union of multiple non-overlapping convex sub-regions. By leveraging the concept of feasibility region, i.e., the subset of the state space for which a QP problem is feasible, and introducing a proper selection criterion, we are able to maintain linearity of the constraints and thus use our Intrinsically Stable Model Predictive Control (IS-MPC) scheme with a negligible additional computational load. This approach allows for a wider range of possible generated motions and is very effective when reacting to a push or avoiding an obstacle, as illustrated in dynamically simulated scenarios.
# Low-Drift LiDAR-Only Odometry and Mapping for UGVs in Environments with Non-Level Roads
## Keywords:
- Autonomous Agents
- Mapping
- SLAM
## Abstract:
This study focuses on localization and mapping for UGVs when they are deployed in environments with non-level roads. In these scenarios, the vehicles need to travel through flat but not necessarily level grounds, i.e., ascent or descent, which may cause drifts of the robot pose and distortion of the map. We develop a low-drift LiDAR odometry and mapping approach for the UGV with LiDAR as the only exteroceptive sensor. A factor-graph based pose optimization method is developed with a specifically designed factor named slope factor. This factor includes the slope information that is estimated from a real-time LiDAR data stream. The slope information is also used to enhance the loop-closure detection procedure. Moreover, an incremental pitch estimation mechanism is designed to achieve further pose estimation refinement. We demonstrate the effectiveness of the developed framework in real-world environments. The odometry drift is lower and the map is more precise than experiments with the state-of-the-arts. Notably, on the Kitti dataset, our method also exhibits convincing performance, demonstrating its strength in more general application scenarios.
# Stochastic Games with Stopping States and Their Application to Adversarial Motion Planning Problems
## Keywords:
- Autonomous Agents
- Motion and Path Planning
- Multi-Robot Systems
## Abstract:
We model a finite horizon decision making process between an ego and a non-ego vehicle, where the non-ego vehicle has a certain probability of moving adversarially over each planning stage. The adversarial intent of the non-ego vehicle is inferred only when a particular set of actions are performed by both vehicles, thereby creating a **stopping state**. We term such a decision-making process as a multi-stage stochastic zero-sum game (SSG) with stopping states, i.e., once adversarial intent is ascertained, the non-ego vehicle continues to choose its actions adversarially for the remaining stages of the interaction. We analytically characterize the Nash equilibria of this game for the case of two actions per player. We then demonstrate this approach via two autonomous motion planning applications. The first involves maintaining a safe distance from a non-ego vehicle ahead, modeled using fixed stage costs. The second involves safe lane-changing with costs that are stage dependent. In both scenarios, we provide a comparison between the analytic/simulated and experimental results using ground robots.
# BOBCAT: Behaviors, Objectives and Binary States for Coordinated Autonomous Tasks
## Keywords:
- Autonomous Agents
- Behavior-Based Systems
- Cooperating Robots
## Abstract:
We present our framework Behaviors, Objectives and Binary states for Coordinated Autonomous Tasks (BOBCAT), a multi-agent decision making and task management system for autonomous robots. BOBCAT builds on behavior-based systems and the Belief-Desire-Intention model for decision-making, by using mission objectives as the basis for selecting tasks, or behaviors. We describe how BOBCAT is formulated and present the results of a real-world implementation in the context of exploring austere underground environments in the DARPA Subterranean Challenge.
# ATF-3D: Semi-Supervised 3D Object Detection withAdaptive Thresholds Filtering Based on Confidenceand Distance
## Keywords:
- Autonomous Agents
- Deep Learning Methods
- Object Detection, Segmentation and Categorization
## Abstract:
Performance of current point cloud-based outdoor3D object detection relies heavily on large-scale high-quality 3Dannotations. However, such annotations are usually expensive tocollect and outdoor scenes easily accumulate massive unlabeleddata containing rich scenes. Semi-supervised learning is a effectivealternative to utilize both labeled and unlabeled data,but remains unexplored in outdoor 3D object detection. Inspiredby indoor semi-supervised 3D detection methods, SESS and3DIoUMatch, we propose ATF-3D, a semi-supervised 3D objectdetection framework for outdoor scenes. Specifically, we design asimple yet effective adaptive thresholds search method based ondistances and categories for obtaining high-quality pseudo labels.Concurrently, we propose an iterative training mechanism withpseudo-label training and self-ensembling learning to combinethe advantages of both schemes. Furthermore, we adopt pointcloud data augmentations in the self-ensembling learning stage tofurther improve the performance. Our ATF-3D ranks first amongall single-model methods in the ONCE benchmark. Resultson both ONCE and Waymo datasets demonstrate substatialimprovements over the supervised baseline.
# Actuation and Joint Mechanisms
# Adaptative Friction Shock Absorbers and Reverse Thrust for Fast Multirotor Landing on Inclined Surfaces
## Keywords:
- Actuation and Joint Mechanisms
- Aerial Systems: Mechanics and Control
- Dynamics
## Abstract:
Small multirotors are not capable of landing in complex situations, such as on inclined surfaces, in wind gusts or at high impact velocities. This paper explores the use of lightweight friction shock absorbers, combined with rapid thrust reversal, to increase the landing envelope of a quadrotor. The friction shock absorbers serve to dissipate the drone's kinetic energy and the reverse thrust increases the maximum slope inclination at which it can land. A landing gear prototype was designed and implemented on a DJI F450, and a model was created to generate landing maps to evaluate its benefits. Finally, the technology was tested in real outdoor conditions. The overall system enables drones to safely land on surfaces of up to 60° and at vertical speeds of up to 2.75 m/s, thus increasing the landing envelope by a factor of 8, compared to traditional multirotors
# DeltaZ: An Accessible Compliant Delta Robot Manipulator for Research and Education
## Keywords:
- Compliant Joints and Mechanisms
- Education Robotics
- Additive Manufacturing
## Abstract:
This paper presents the DeltaZ robot, a centimeter-scale, low-cost, delta-style robot that allows for a broad range of capabilities and robust functionalities. The DeltaZ robot is 3D-printed from soft and rigid materials with a design that is easy to assemble and maintain, and lowers the barriers to utilize. Functionality of the robot stems from its three translational degrees of freedom and a closed form kinematic solution which makes manipulation problems more intuitive compared to many other manipulators. Moreover, the low cost of the robot presents an opportunity to democratize manipulators for research and education settings. We describe how the robot can be used as a reinforcement learning benchmark. Open-source 3D-printable designs and code for building and using the robot are available to the public.
# Jumping on Air: Design and Modeling of Latch-Mediated, Spring-Actuated Air-Jumpers
## Keywords:
- Compliant Joints and Mechanisms
- Mechanism Design
- Aerial Systems: Mechanics and Control
## Abstract:
Latch-mediated spring-actuation (LaMSA) is utilized in a majority of jumping robots for its ability to slowly load and quickly release energy to generate high-power movement.
Such mechanisms are found in robots that jump off of solid surfaces and even off of water. However, no robot currently employs LaMSA to jump on air. This paper presents a prototype and model for a LaMSA jumper capable of jumping midair. Our model informs prototype design and provides insight into the scaling properties of the wing area, wing and fuselage mass, and energy. Beyond exploring a new application of LaMSA previously unstudied, this concept can potentially be used in fixed-wing unmanned aerial vehicle (UAV) flight by enabling instantaneous changes in altitude without the addition of extra on-board motors.
# Anisotropic-Stiffness Belt in Mono Wheeled Flexible Track for Rough Terrain Locomotion
## Keywords:
- Compliant Joints and Mechanisms
- Mechanism Design
- Search and Rescue Robots
## Abstract:
Rescue robots that search around on debris during natural disasters require high mobility to overcome various shaped materials scatters in the environment. Our previous study developed a new tracked mechanism called Mono-wheel Track, an elastic track driven by a single wheel, having a high capability to get over obstacles. In designing the MW-Track, the track stiffness is an essential factor—the flexible track can adapt the geometry of the obstacles, but the flexibility prevents grousers from anchoring to the environment steadily. If the track has different localized stiffnesses, both the adaptability and the stability might be archived. In this study, we developed an “anisotropic-stiffness track,” exhibiting different stiffness depending on the bending side, and investigated its deformation characteristics and the effects on mobility. The deformation characteristics of the track were confirmed by load tests. The effects on mobility were evaluated by step-climbing test, ditch-crossing test, and traction measuring with a mobile robot.
# Wave-Shaped Notched Compliant Joint with High Rigidity
## Keywords:
- Compliant Joints and Mechanisms
- Mechanism Design
- Medical Robots and Systems
## Abstract:
In general notched compliant joints (NCJs), the height of the notch is the trade-off to the thickness of the spacer neighboring the notch. Therefore, it is difficult to maximize the rigidity of NCJs while maintaining a large curvature. Here, we propose an NCJ with a novel shape of the notch. The thickness of the spacer can be increased without changing the height of the notch. Furthermore, we determined the best design parameters for achieving the maximum rigidity for a given driving force. The higher rigidity of the proposed NCJ compared with that of general NCJs is shown through a simulation and experiments. Under an applied force, the displacement of the proposed NCJ was smaller than that of general NCJs by 43%. In a cutting test, while keeping the curvature, the proposed NCJ increased the cutting amount by 135% compared with general NCJs. We verified that the proposed NCJ can achieve both high rigidity and large curvature. The main feature of this study is the development of an NCJ in which both the thickness of the spacer and the height of the notch can be independently changed without affecting each other. The proposed NCJ is the first NCJ in which the rigidity can be improved without any loss of curvature.
# A Methodology for Designing a Lightweight and Energy-Efficient Kinematically Redundant Actuator
## Keywords:
- Actuation and Joint Mechanisms
- Redundant Robots
- Product Design, Development and Prototyping
## Abstract:
Redundant actuators enable to distribute power among two motors, which can be selected optimally in terms of efficiency. We propose a methodology that finds effective combinations of motors and gearboxes for a dynamic load, taking into account the constraints, inertia, and efficiency of each component. Focusing on battery-operated robots as an application, it also considers battery pack mass in relation to the energy required by the actuator for multiple hours of operation. Based on this methodology, a prototype of a kinematically redundant actuator for the distal joint of a robot was built. Simulations and experiments are presented to prove the validity of the proposed approach.
# An In-Pipe Crawling Robot Based on Tensegrity Structures
## Keywords:
- Compliant Joints and Mechanisms
- Soft Robot Applications
- Search and Rescue Robots
## Abstract:
This paper presents a novel concept to develop robots capable of crawling in tubular environments, inspired by the movement of earthworms and the biological musculoskeletal systems in nature. A tensegrity structures-based robotic module with shape changeability actuated by only one linear actuator is proposed. The mechanical structure of the robotic module is determined on the basis of force density method. By serially cascading three uniform modules, the in-pipe crawling robot is designed and manufactured. The robot has the abilities to crawl in both horizontal and vertical pipes with different inner diameters, and to pass through elbow pipes adaptively under the control of a simple actuation sequence. The effectiveness of the robot is demonstrated by experimental results on the prototype. Compared with existing robots, this proposed approach enables compact yet robust structures, along with enhanced compliance, mobility, and adaptability.
# Vertical Bend and T-Branch Travels of an Articulated Wheeled In-Pipe Inspection Robot by Combining Its Joint Angle and Torque Controls
## Keywords:
- Actuation and Joint Mechanisms
- Mechanism Design
- Field Robots
## Abstract:
The paper reports the performance verification of vertical bend and T-branch travels of an articulated wheeled in-pipe inspection robot. The robot is composed of only a single active compliant middle joint, two passive compliant joints, three drive wheels, and two roll wheels. The passage of the bend pipe is achieved only by the joint torque control, while the T-branch travel is achieved by controlling both joint angle and torque. Instead of using a torque sensor, a polyurethane-based series elastic actuator (SEA) is installed in the middle joint. In this paper, the travel performances of our developed in-pipe robot were tested on bend pipes and 10 types of T-branch with different gravity directions. From the experiments, in all cases, the effectiveness of the bend and T-branch travels performance was confirmed.
# Sensor Systems
# Learned Depth Estimation of 3D Imaging Radar for Indoor Mapping
## Keywords:
- Range Sensing
- Visual Learning
- Mapping
## Abstract:
3D imaging radar offers robust perception capability through visually demanding environments due to the unique penetrative and reflective properties of millimeter waves (mmWave). Current approaches for 3D perception with imaging radar require knowledge of environment geometry, accumulation of data from multiple frames for perception, or access to between-frame motion. Imaging radar presents an additional difficulty due to the complexity of its data representation. To address these issues, and make imaging radar easier to use for downstream robotics tasks, we propose a learning-based method that regresses radar measurements into cylindrical depth maps using LiDAR supervision. Due to the limitation of the regression formulation, directions where the radar beam could not reach will still generate a valid depth. To address this issue, our method additionally learns a 3D filter to remove those pixels. Experiments show that our system generates visually accurate depth estimation. Furthermore, we confirm the overall ability to generalize in the indoor scene using the estimated depth for probabilistic occupancy mapping with ground truth trajectory. The code and model will be released.
# Mind the Gap: Norm-Aware Adaptive Robust Loss for Multivariate Least-Squares Problems
## Keywords:
- Probability and Statistical Methods
- SLAM
## Abstract:
Measurement outliers are unavoidable when solving real-world robot state estimation problems. A large family of robust loss functions (RLFs) exist to mitigate the effects of outliers, including newly developed adaptive methods that do not require parameter tuning. All of these methods assume the residuals follows a Gaussian-like distribution. However, in multivariate problems the residual is often defined as a norm, and norms follow a Chi-like distribution with a non-zero mode value. This produces a ``mode gap'' that impacts the convergence rate and accuracy of existing RLFs. The proposed approach, ``Adaptive MB,'' accounts for this gap by first estimating the mode of the residuals using an adaptive Chi-like distribution. Applying an existing adaptive weighting scheme only to residuals greater than the mode leads to more robust performance and faster convergence times on two fundamental state estimation problems, point cloud alignment and pose averaging.
# Patchwork++: Fast and Robust Ground Segmentation Solving Partial Under-Segmentation Using 3D Point Cloud
## Keywords:
- Range Sensing
- Mapping
- Object Detection, Segmentation and Categorization
## Abstract:
In the field of 3D perception using 3D LiDAR sensors, ground segmentation is an essential task for various purposes, such as traversable area detection and object recognition. Under these circumstances, several ground segmentation methods have been proposed. However, some limitations are still encountered. First, some ground segmentation methods require fine-tuning of parameters depending on the surroundings, which is excessively laborious and time-consuming. Moreover, even if the parameters are well adjusted, a partial under-segmentation problem can still emerge, which implies ground segmentation failures in some regions. Finally, ground segmentation methods typically fail to estimate an appropriate ground plane when the ground is above another structure, such as a retaining wall. To address these problems, we propose a robust ground segmentation method called Patchwork++, an extension of Patchwork. Patchwork++ exploits adaptive ground likelihood estimation~(A-GLE) to calculate appropriate parameters adaptively based on the previous ground segmentation results. Moreover, temporal ground revert~(TGR) alleviates a partial under-segmentation problem by using the temporary ground property. Also, region-wise vertical plane fitting~(R-VPF) is introduced to segment the ground plane properly even if the ground is elevated with different layers. Finally, we present reflected noise removal~(RNR) to eliminate virtual noise points efficiently based on the 3D LiDAR reflection model. We demonstrate the qualitative and quantitative evaluations using a SemanticKITTI dataset. Our code is available at https://github.com/url-kaist/patchwork-plusplus
# Linewise Non-Rigid Point Cloud Registration
## Keywords:
- Range Sensing
- Mapping
- Autonomous Vehicle Navigation
## Abstract:
Robots are usually equipped with 3D range sensors such as laser line scanners (LLSs) or lidars. These sensors acquire a full 3D scan in a line by line manner while the robot is in motion. All the lines can be referred to a common coordinate frame using data from inertial sensors. However, errors from noisy inertial measurements and inaccuracies in the extrinsic parameters between the scanner and the robot frame are also projected onto the shared frame. This causes a deformation in the final scan containing all the lines, which is known as motion distortion. Rigid point cloud registration with methods like ICP is therefore not well suited for such distorted scans. In this paper we present a non-rigid registration method that finds the optimal rigid transformation to be applied to each line in the scan in order to match an existing model. We fully leverage the continuous and relatively smooth robot motion with respect to the scanning time to formulate our method reducing the computational complexity while improving accuracy. We use synthetic and real data to benchmark our method against a state-of-the-art non-rigid registration method. Finally, the source code for the algorithm is made publicly available.
# A LiDAR-Inertial Odometry with Principled Uncertainty Modeling
## Keywords:
- Range Sensing
- Localization
- SLAM
## Abstract:
This paper proposes a LiDAR-inertial odometry that properly solves the uncertainty estimation problem, guided by the rules of designing a consistent estimator. Our system is built upon an iterated extended Kalman filter, with multiple states in an optimization window. To survive environments without distinctive geometric structures, we do not track features over time. We only extract planar primitives from the local map and use a direct point-to-plane distance metric as the measurement model. The realistic noise parameters are estimated online by modeling point distributions. We use nullspace projection to remove dependency on the feature planes, which is equivalent to transforming the pose-map measurement into relative pose constraints. To avoid reintegrating all the laser points in the local window after every state correction, we use the Schmidt Kalman update to consider the probabilistic effects of past poses while their values are left unaltered. A collection of octrees with an adaptive resolution is designed to manage measurement points and the map efficiently. The consistency and robustness of our system are verified in both simulation and real-world experiments.
# DeepCIR: Insights into CIR-Based Data-Driven UWB Error Mitigation
## Keywords:
- Range Sensing
- Localization
- Deep Learning Methods
## Abstract:
Ultra-Wide-Band (UWB) ranging sensors have been widely adopted for robotic navigation thanks to their extremely high bandwidth and hence high resolution. However, off-the-shelf devices may output ranges with significant errors in cluttered, severe non-line-of-sight (NLOS) environments. Recently, neural networks have been actively studied to improve the ranging accuracy of UWB sensors using the channel-impulse-response (CIR) as input. However, previous works have not systematically evaluated the efficacy of various packet types and their possible combinations in a two-way-ranging transaction, including poll, response and final packets. In this paper, we firstly investigate the utility of different packet types and their combinations when used as input for a neural network. Secondly, we propose two novel data-driven approaches, namely FMCIR and WMCIR, that leverage two-sided CIRs for efficient UWB error mitigation. Our approaches outperform state-of-the-art by a significant margin, further reducing range errors up to 45%. Finally, we create and release a dataset of transaction-level synchronized CIRs (each sample consists of the CIR of the poll, response and final packets), which will enable further studies in this area.
# From Timing Variations to Performance Degradation: Understanding and Mitigating the Impact of Software Execution Timing in SLAM
## Keywords:
- Embedded Systems for Robotic and Automation
- Visual-Inertial SLAM
- Engineering for Robotic Systems
## Abstract:
Timing is an important property for robotic systems that continuously interact with our physical world. Variation in program execution time caused by limited computational resources or system resource contention can lead to significant impact on algorithmic result accuracy. Even though recent work has found Simultaneous Localization And Mapping (SLAM) to be timing-sensitive, little exists in understanding the interactions between the timing variations in SLAM systems and the corresponding degradation. In this paper we conduct a systematic analysis of nine state-of-the-art SLAM systems and dissect the root causes of their degradation. We discovered that timing-induced errors are generated either from delayed execution in certain critical tasks, or from desynchronization in sensor fusion. Based on the insights from our analysis, we propose a solution that combines selective fusion on data in the front end and temporal budget optimization on bundle adjustment in the backend to mitigate the impacts of unexpected timing variation adaptively. Experimental results show that our proposed method makes it possible to migrate expensive algorithms to low-cost platforms without laborious tuning, while making the SLAM system robust against the effects of abnormal timing.
# Combined Dual-Prediction Based Data Fusion and Enhanced Leak Detection and Isolation Method for WSN Pipeline Monitoring System (I)
## Keywords:
- Sensor Networks
- Sensor Fusion
- Failure Detection and Recovery
## Abstract:
In a Wireless Sensor Networks (WSN) based fluid pipeline leak monitoring system, numerous sensors are deployed along the pipeline networks. A great number of measurements are continuously transmitted from the sensor nodes to their corresponding sink nodes. The energy consumed on data transmission dominates the power depletion of a WSN system. To reduce the amount of data transmission and prolong the lifetime of WSN, in this paper, a Combined Dual-Prediction based Data Fusion (CDPDF) method is proposed. Transmissions are only triggered if the measurement is substantially different from the predicted value. Furthermore, unlike existing methods which establish the predictor by merely considering the measurements from a single sensor, the proposed CDPDF learns and updates the predictor by integrating measurements from multiple neighboring sensors, hence the spatial cross-correlation is taken into account and the prediction accuracy is significantly improved. In this paper, an Enhanced Leak Detection and Isolation (EnLDI) method is also proposed in which several important parameters, such as the friction factor and the pressure wave propagation speed, can be online updated, resulting in improvement of the leak localization accuracy. Experimental case studies are conducted. By employing the proposed CDPDF and EnLDI methods in pipeline network monitoring, the accuracy of leak isolation is significantly increased with reduced data transmission demands.
# Upper Limb Movement Estimation and Function Evaluation of the Shoulder Girdle by Multi-Sensing Flexible Sensor Wear
## Keywords:
- Rehabilitation Robotics
- Sensor Fusion
- Wearable Robotics
## Abstract:
To extend the coverage of people able to receive high-quality rehabilitation, remote rehabilitation is required in addition to traditional face-to-face rehabilitation. Although remote rehabilitation using video conferencing systems has been realized to date, communication through physical sensations such as detailed patient motoring information and manual instructions from the therapist has not yet been realized. Therefore, the ultimate goal of this study was to develop multimodal wearable sensor system to support remote rehabilitation with a somatosensory system. To this end, we conducted a basic study of sensing technology in multimodal wear. Multiple strain sensors were attached to the shoulder to digitize the detailed behavior of the shoulder girdle. It was confirmed that the movement of the scapula can be acquired by this strain sensor. Furthermore, it was confirmed that the combination of strain sensors and an inertia measurement unit can be applied for the motion estimation of the entire upper limb.
# Optimization and Optimal Control 2
# A Legendre-Gauss Pseudospectral Collocation Method for Trajectory Optimization in Second Order Systems
## Keywords:
- Optimization and Optimal Control
- Dynamics
## Abstract:
Pseudospectral collocation methods have proven to be powerful tools to solve numerical optimal control problems in many domains. While these methods typically assume the system dynamics is given in the first order form dx/dt = f(x, u, t), where x is the state and u is the control, robotic systems are typically governed by second order ODEs of the form dx^2/dt^2 = g(q, dq/dt, u, t), where q is the system configuration. To convert the second order ODE into a first order one, the usual approach is to introduce a velocity variable v and impose its coincidence with the time derivative of q. Lobatto methods grant this constraint by construction, as their polynomials describing the trajectory for v are the time derivatives of those for q, but the same cannot be said for the Gauss and Radau methods. This is problematic for such methods, as then they cannot guarantee that dx^2/dt^2 = g(q, dq/dt, u, t) at the collocation points. On their negative side, Lobatto methods cannot be used to solve initial value problems, as given the values of u at the collocation points they generate an overconstrained system of equations for the states. In this paper, we propose a Legendre-Gauss collocation method that retains the advantages of the usual Lobatto, Gauss, and Radau methods, while avoiding their shortcomings. The collocation scheme we propose is applicable to solve initial value problems, preserves the consistency between the polynomials for v and q, and ensures that dx^2/dt^2 = g(q, dq/dt, u, t) at the collocation points.
# An Equivalent Time-Optimal Problem to Find Energy-Optimal Paths for Skid-Steer Rovers
## Keywords:
- Optimization and Optimal Control
- Motion and Path Planning
- Space Robotics and Automation
## Abstract:
A skid-steer rover’s power consumption is highly dependent on the turning radius of its path. For example, a point turn consumes a lot of power compared to a straight-line motion. Thus, in path planning for this kind of rover, turning radius is a factor that should be considered explicitly. There is a lack of any analytical approach in literature for finding energy optimal paths for skid-steer rovers. The key contribution of this work is an energy-time equivalency theorem, for skid-steer rovers on obstacle-free hard ground. The theorem converts the energy optimal problem into an equivalent time-optimal problem. This non-intuitive result stems from the fact that with this model of the system the total energy is fully parameterized by the geometry of the path alone. Hence, instead of directly solving the energy optimal path planning problem, which is highly nonlinear, the equivalent time-optimal problem can be solved. Furthermore, experimental results are provided to experimentally prove the equivalency theorem while using the Husky UGV skid-steer rover.
# Visibility-Aware Navigation with Batch Projection Augmented Cross-Entropy Method Over a Learned Occlusion Cost
## Keywords:
- Optimization and Optimal Control
- Motion and Path Planning
- Aerial Systems: Applications
## Abstract:
Gradient-free optimizers like Cross-Entropy Method (CEM) have achieved state-of-the-art results in model-based control. However, their computational efficiency depends on how fast we can query the cost function. Moreover, incorporating hard constraints within CEM remains a challenging problem. This paper solves fundamental bottlenecks of CEM for the specific application of visibility-aware navigation. 
We present two trajectory optimizers based on CEM that differ in handling inequality constraints stemming from bounds on motion derivatives, collision avoidance, tracking error, etc. Our first optimizer augments the inequalities into the cost function, while the second relies on a novel GPU accelerated batch projection algorithm. We adopt a learning-based approach to ensure fast query of occlusion cost arising from the environment. Specifically, we train a neural network to compute occlusion directly from the point obstacles generated from the LIDAR or RGB-D sensor. Our learned occlusion model can be queried up to 3x faster than the approach based on distance computation from occupancy or voxel maps. We improve the state-of-the-art in the following aspects. First, our optimizers do not require any explicit map building and can thus adapt on the fly to the changes in the environment. Second, we compare it against the existing state-of-the-art target-tracking applications and show substantial improvement in maintaining target visibility while being competitive in acceleration effort and computation time.
# Refining Control Barrier Functions through Hamilton-Jacobi Reachability
## Keywords:
- Optimization and Optimal Control
- Robot Safety
## Abstract:
Safety filters based on Control Barrier Functions (CBFs) have emerged as a practical tool for the safety-critical control of autonomous systems. These approaches encode safety through a value function and enforce safety by imposing a constraint on the time derivative of this value function. However, synthesizing a valid CBF that is not overly conservative in the presence of input constraints is a notorious challenge. In this work, we propose refining a candidate CBF using formal verification methods to obtain a valid CBF. In particular, we update an expert-synthesized or backup CBF using dynamic programming (DP) based reachability analysis. Our framework, refineCBF, guarantees that with every DP iteration the obtained CBF is provably at least as safe as the prior iteration and converges to a valid CBF. Therefore, refineCBF can be used in-the-loop for robotic systems. We demonstrate the practicality of our method to enhance safety and/or reduce conservativeness on a range of nonlinear control-affine systems using various CBF synthesis techniques in simulation.
# Newton-PnP: Real-Time Visual Navigation for Autonomous Toy-Drones
## Keywords:
- Optimization and Optimal Control
- Vision-Based Navigation
- Localization
## Abstract:
The Perspective-n-Point problem aims to estimate the relative pose between a calibrated monocular camera and a known 3D model, by aligning pairs of 2D captured image points to their corresponding 3D points in the model. We suggest an algorithm that runs on weak IoT devices in real-time but still provides provable theoretical guarantees for both running time and correctness. Existing solvers provide only one of these requirements. Our main motivation was to turn the popular DJI's Tello Drone (<90gr, <100) into an autonomous drone that navigates in an indoor environment with no external human/laptop/sensor, by simply attaching a Raspberry PI Zero (<9gr, <25) to it. This tiny micro-processor takes as input a real-time video from a tiny RGB camera, and runs our PnP solver on-board. Extensive experimental results, open source code, and a demonstration video are included.
# Constrained Differential Dynamic Programming: A Primal-Dual Augmented Lagrangian Approach
## Keywords:
- Optimization and Optimal Control
- Whole-Body Motion Planning and Control
## Abstract:
Trajectory optimization is an efficient approach for solving optimal control problems for complex robotic systems. It relies on two key components: first the transcription into a sparse nonlinear program, and second the corresponding solver to iteratively compute its solution. On one hand, differential dynamic programming (DDP) provides an efficient approach to transcribe the optimal control problem into a finite-dimensional problem while optimally exploiting the sparsity induced by time. On the other hand, augmented Lagrangian methods make it possible to formulate efficient algorithms with advanced constraint-satisfaction strategies. In this paper, we propose to combine these two approaches into an efficient optimal control algorithm accepting both equality and inequality constraints. Based on the augmented Lagrangian literature, we first derive a generic primal-dual augmented Lagrangian strategy for nonlinear problems with equality and inequality constraints. We then apply it to the dynamic programming principle to solve the value-greedy optimization problems inherent to the backward pass of DDP, which we combine with a dedicated globalization strategy, resulting in a Newton-like algorithm for solving constrained trajectory optimization problems. Contrary to previous attempts of formulating an augmented Lagrangian version of DDP, our approach exhibits adequate convergence properties without any switch in strategies. We empirically demonstrate its interest with several case-studies from the robotics literature.
# Introducing Force Feedback in Model Predictive Control
## Keywords:
- Optimization and Optimal Control
- Force Control
- Humanoid Robot Systems
## Abstract:
In the literature about model predictive control (MPC), contact forces are planned rather than controlled. In this paper, we propose a novel paradigm to incorporate effort measurements into a predictive controller, hence allowing to control them by direct measurement feedback. We first demonstrate why the classical optimal control formulation, based on position and velocity state feedback, cannot handle direct feedback on force information. Following previous approaches in force control, we then propose to augment the classical formulations with a model of the robot actuation, which naturally allows to generate online trajectories that adapt to sensed position, velocity and torques. We propose a complete implementation of this idea on the upper part of a real humanoid robot, and show through hardware experiments that this new formulation incorporating effort feedback outperforms classical MPC in challenging tasks where physical interaction with the environment is crucial.
# Toward Global Sensing Quality Maximization: A Configuration Optimization Scheme for Camera Networks
## Keywords:
- Sensor Networks
- Optimization and Optimal Control
- Sensor Fusion
## Abstract:
The performance of a camera network monitoring a set of targets depends crucially on the configuration of the cameras. In this paper, we investigate the reconfiguration strategy for the parameterized camera network model, with which the sensing qualities of the multiple targets can be optimized globally and simultaneously. To this end, we first propose to use the number of pixels occupied by a unit-length object in image as a metric of the sensing quality of the object, which is determined by the parameters of the camera, such as intrinsic, extrinsic, and distortional coefficients. Then, we form a single quantity that measures the sensing quality of the targets by the camera network. This quantity further serves as the objective function of our optimization problem to obtain the optimal camera configuration. We verify the effectiveness of our approach through extensive simulation and experiments, and the results reveal its improved performance on the AprilTag detection tasks. Codes and related utilities for this work are open-sourced and available at https://github.com/sszxc/MultiCam-Simulation.
# Embedding Koopman Optimal Control in Robot Policy Learning
## Keywords:
- Machine Learning for Robot Control
- Optimization and Optimal Control
- Reinforcement Learning
## Abstract:
Embedding an optimization process has been explored for imposing efficient and flexible policy structures. Existing work often build upon nonlinear optimization with explicitly iteration steps, making policy inference prohibitively expensive for online learning and real-time control. Our approach embeds a linear-quadratic-regulator (LQR) formulation with a Koopman representation, thus exhibiting the tractability from a closed-form solution and richness from a non-convex neural network. We use a few auxiliary objectives and reparameterization to enforce optimality conditions of the policy that can be easily integrated to standard gradient-based learning. Our approach is shown to be effective for learning policies rendering an optimality structure and efficient reinforcement learning, including simulated pendulum control, 2D and 3D walking, and manipulation for both rigid and deformable objects. We also demonstrate real world application in a robot pivoting task.
# Behavior-Based Systems
# HGCN-GJS: Hierarchical Graph Convolutional Network with Groupwise Joint Sampling for Trajectory Prediction
## Keywords:
- Behavior-Based Systems
- Semantic Scene Understanding
- AI-Enabled Robotics
## Abstract:
Pedestrian trajectory prediction is of great importance for downstream tasks, such as autonomous driving and mobile robot navigation. Realistic models of the social interactions within the crowd is crucial for accurate pedestrian trajectory prediction. However, most existing methods do not capture group level interactions well, focusing only on pairwise interactions and neglecting group-wise interactions. In this work, we propose a hierarchical graph convolutional network, HGCN-GJS, for trajectory prediction which well leverages group level interactions within the crowd. Furthermore, we introduce a joint sampling scheme that captures co-dependencies between pedestrian trajectories during trajectory generation. Based on group information, this scheme ensures that generated trajectories within each group are consistent with each other, but enables different groups to act more independently. We demonstrate that our proposed network achieves state of the art performance on all datasets we have considered.
# Teaching Robots to Span the Space of Functional Expressive Motion
## Keywords:
- Emotional Robotics
- Representation Learning
- Humanoid and Bipedal Locomotion
## Abstract:
Our goal is to enable robots to perform functional tasks in emotive ways, be it in response to their users' emotional states, or expressive of their confidence levels. Prior work has proposed learning independent cost functions from user feedback for each target emotion, so that the robot may optimize it alongside task and environment specific objectives for any situation it encounters. However, this approach is inefficient when modeling multiple emotions and unable to generalize to new ones. In this work, we leverage the fact that emotions are not independent of each other: they are related through a latent space of Valence-Arousal-Dominance (VAD). Our key idea is to learn a model for how trajectories map onto VAD with user labels. Considering the distance between a trajectory's mapping and a target VAD allows this single model to represent cost functions for all emotions. As a result 1) all user feedback can contribute to learning about every emotion; 2) the robot can generate trajectories for any emotion in the space instead of only a few predefined ones; and 3) the robot can respond emotively to user-generated natural language by mapping it to a target VAD. We introduce a method that interactively learns to map trajectories to this latent space and test it in simulation and in a user study. In experiments, we use a simple vacuum robot as well as the Cassie biped.
# Manual Maneuverability: Metrics for Analysing and Benchmarking Kinesthetic Robot Guidance
## Keywords:
- Performance Evaluation and Benchmarking
- Physical Human-Robot Interaction
- Human-Centered Robotics
## Abstract:
Kinesthetic teaching of collaborative robots is applied for intuitive and flexible robot programming by demonstration. This enables non-experts to program such robots on the task-level. Multiple strategies exist to teach velocity# or torque-controlled robots and, thus, the maneuverability among commercial robots differs significantly. However, currently there exists no metric that quantifies how ``well'' the robot can be guided, e.g., how much effort is required to initiate a motion. In this paper, we propose standardized procedures to quantitatively assess robot manual maneuverability. First, we identify different motion phases during kinesthetic teaching. For each phase, we then propose metrics and experimental setups to evaluate them. The experimental protocols are applied to the proprietary teaching schemes of five commercial robots, namely the KUKA LWR iiwa 14, Yuanda Yu+, Franka Emika robot, and Universal Robot's UR5e and UR10e. The experimental comparison highlights distinct differences between the robots and shows that the proposed methods are a meaningful contribution to the performance and ergonomics assessment of collaborative robots.
# Learning Bidirectional Translation between Descriptions and Actions with Small Paired Data
## Keywords:
- Embodied Cognitive Science
- Learning from Experience
- Representation Learning
## Abstract:
This study achieved bidirectional translation between descriptions and actions using small paired data from different modalities. The ability to mutually generate descriptions and actions is essential for robots to collaborate with humans in their daily lives, which generally requires a large dataset that maintains comprehensive pairs of both modality data. However, a paired dataset is expensive to construct and difficult to collect. To address this issue, this study proposes a two-stage training method for bidirectional translation. In the proposed method, we train recurrent autoencoders (RAEs) for descriptions and actions with a large amount of non-paired data. Then, we fine-tune the entire model to bind their intermediate representations using small paired data. Because the data used for pre-training do not require pairing, behavior-only data or a large language corpus can be used. We experimentally evaluated our method using a paired dataset consisting of motion-captured actions and descriptions. The results showed that our method performed well, even when the amount of paired data to train was small. The visualization of the intermediate representations of each RAE showed that similar actions were encoded in a clustered position and the corresponding feature vectors were well aligned.
# Generalizability Analysis of Graph-Based Trajectory Predictor with Vectorized Representation
## Keywords:
- Behavior-Based Systems
- Intelligent Transportation Systems
## Abstract:
Trajectory prediction is one of the essential tasks for autonomous vehicles. Recent progress in machine learning gave birth to a series of advanced trajectory prediction algorithms. Lately, the effectiveness of using graph neural networks (GNNs) with vectorized representations for trajectory prediction has been demonstrated by many researchers. Nonetheless, these algorithms either pay little attention to models' generalizability across various scenarios or simply assume training and test data follow similar statistics. In fact, when test scenarios are unseen or Out-of-Distribution (OOD), the resulting train-test domain shift usually leads to significant degradation in prediction performance, which will impact downstream modules and eventually lead to severe accidents. Therefore, it is of great importance to thoroughly investigate the prediction models in terms of their generalizability, which can help identify their weaknesses and provide insights on how to improve these models. This paper proposes a generalizability analysis framework using feature attribution methods to help interpret black-box models. For the case study, we provide an in-depth generalizability analysis of one of the state-of-the-art graph-based trajectory predictors that utilize vectorized representation. Results show significant performance degradation due to domain shift, and feature attribution provides insights to identify potential causes of these problems. Finally, we conclude the common prediction challenges and how weighting biases induced by the training process can deteriorate the accuracy.
# CreativeBot: A Creative Storyteller Agent Developed by Leveraging Pre-Trained Language Models
## Keywords:
- Behavior-Based Systems
- Education Robotics
- Autonomous Agents
## Abstract:
In an attempt to nurture children's creativity, we developed a creative conversational agent to be used in a collaborative storytelling context with a child. We presented a novel approach to develop creative Artificial Intelligence (AI). Our approach uses the four creativity measures: fluency, flexibility, elaboration and originality in order to generate creative behavior. We analyzed and annotated our previously collected storytelling data sets -collected with children# according to our four creativity measures. We then used the extracted and annotated data (636 statements) in order to fine-tune two pre-trained language models (Open AI GPT-3). The two models were aimed at generating creative versus non-creative behavior in a collaborative storytelling scenario. We developed the two models to be able to assess the results and compare them together. We conducted an evaluation to assess stories generated collaboratively between a human and both agents separately (n = 26). Adult Users rated the creativity of the agent according to the stories generated. Results showed that the creative agent was perceived as significantly more creative than the non-creative agent. With the experiment results confirming the validity of our system, we may therefore proceed with testing the effects of the creative behavior of the agent on children's creativity skills.
# Adaptive Sequential Composition for Robot Behaviours
## Keywords:
- Control Architectures and Programming
- Behavior-Based Systems
## Abstract:
Autonomous robots are prone to fail in real world environments, where unknown factors can cause their world model to be inaccurate or incomplete. This causes robots to become stuck or repeatedly perform unsuccessful actions believing it is the best option. Static switching frameworks such as sequential composition guarantee stability of the overall system if its constituents are also stable. However, due to unknown factors, robot actions may fail when the robot senses the environment inaccurately. We propose Adaptive Sequential Composition, a novel framework that dynamically selects robot behaviours based on their utility to achieving success. We show the usefulness of the framework in a simulated second order system task as well as its application in navigating a robot through narrow gaps, where the clearance with the gap is smaller than position accuracy. Simulated results show adaptive sequential composition outperforms sequential composition by up to 30% when presented with unknown factors leading to behaviour failure. For navigating through a narrow gap, adaptive sequential composition improved success by 65%.
# Collective Conditioned Reflex: A Bio-Inspired Fast Emergency Reaction Mechanism for Designing Safe Multi-Robot Systems
## Keywords:
- Behavior-Based Systems
- AI-Based Methods
- Autonomous Agents
## Abstract:
A multi-robot system (MRS) is a group of coordinated robots designed to cooperate with each other and accomplish given tasks. Due to the uncertainties in operating environments, the system may encounter emergencies, such as unobserved obstacles, moving vehicles, and extreme weather. Animal groups such as bee colonies initiate collective emergency reaction behaviors such as bypassing obstacles and avoiding predators, similar to muscle-conditioned reflex which organizes local muscles to avoid hazards in the first response without delaying passage through the brain. Inspired by this, we develop a similar collective conditioned reflex mechanism for multi-robot systems to respond to emergencies. In this study, Collective Conditioned Reflex (CCR), a bio-inspired emergency reaction mechanism, is developed based on animal collective behavior analysis and multi-agent reinforcement learning (MARL). The algorithm uses a physical model to determine if the robots are experiencing an emergency; then, rewards for robots involved in the emergency are augmented with corresponding heuristic rewards, which evaluate emergency magnitudes and consequences and decide local robots' participation. CCR is validated on three typical emergency scenarios: textit{turbulence, strong wind, and hidden obstacle}. Simulation results demonstrate that CCR improves robot teams' emergency reaction capability with faster reaction speed and safer trajectory adjustment compared with baseline methods.
# Use of Action Label in Deep Predictive Learning for Robot Manipulation
## Keywords:
- Embodied Cognitive Science
- Learning from Experience
- Learning from Demonstration
## Abstract:
Various forms of human knowledge can be explicitly used to enhance deep robot learning from demonstrations. Annotation of subtasks from task segmentation is one type of human symbolism and knowledge. Annotated subtasks can be referred to as action labels, which are more primitive symbols that can be building blocks for more complex human reasoning, like language instructions. However, action labels are not widely used to boost learning processes because of problems that include (1) real-time annotation for online manipulation, (2) temporal inconsistency by annotators, (3) difference in data characteristics of motor commands and action labels, and (4) annotation cost. To address these problems, we propose the Gated Action Motor Predictive Learning (GAMPL) framework to leverage action labels for improved performance. GAMPL has two modules to obtain soft action labels compatible with motor commands and to generate motion. In this study, GAMPL is evaluated for towel-folding manipulation tasks in a real environment with a six degrees-of-freedom (6 DoF) robot and shows improved generalizability with action labels.
# Motion and Path Planning 9
# Safe Active Dynamics Learning and Control: A Sequential Exploration-Exploitation Framework (I)
## Keywords:
- Machine Learning for Robot Control
- Optimization and Optimal Control
- Model Learning for Control
## Abstract:
Safe deployment of autonomous robots in diverse scenarios requires agents that are capable of efficiently adapting to new environments while satisfying constraints. In this article, we propose a practical and theoretically justified approach to maintain safety in the presence of dynamics uncertainty. Our approach leverages Bayesian meta-learning with last-layer adaptation. The expressiveness of neural-network features trained offline, paired with efficient last-layer online adaptation, enables the derivation of tight confidence sets, which contract around the true dynamics as the model adapts online. We exploit these confidence sets to plan trajectories that guarantee the safety of the system. Our approach handles problems with high dynamics uncertainty, where reaching the goal safely is potentially initially infeasible, by first exploring to gather data and reduce uncertainty, before autonomously exploiting the acquired information to safely perform the task. Under reasonable assumptions, we prove that our framework guarantees the high-probability satisfaction of all constraints at all times jointly, i.e., over the total task duration. This theoretical analysis also motivates two regularizers of last-layer meta-learning models that improve online adaptation capabilities as well as performance by reducing the size of the confidence sets. We extensively demonstrate our approach in simulation and on hardware.
# Fast Cost-Aware Lazy-Theta* Over Euclidean Distance Functions for 3D Planning of Aerial Robots in Building-Like Environments
## Keywords:
- Motion and Path Planning
## Abstract:
This paper presents a fast cost-aware any-angle path planning algorithm for aerial robots in 3D building-like environments. The approach integrates Euclidean Distance Fields (EDF) and Lazy Theta* algorithm to compute safe and smooth paths. We show how to consider the analytical properties of EDFs for polygonal obstacles to get an approximation of the cost along the line of sight segments of the planner, reducing the computational requirements. Numerous tests in a realistic building-like environment are performed to evaluate the proposed algorithm with respect to other heuristic search algorithms considering the distance cost by using an EDF. The results show that the proposed algorithm considerably reduces the computation time in indoor and outdoor environments enabling fast, safe and smooth paths.
# Conflict-Based Search for Multi-Robot Motion Planning with Kinodynamic Constraints
## Keywords:
- Motion and Path Planning
- Multi-Robot Systems
## Abstract:
Multi-robot motion planning (MRMP) is the fundamental problem of finding non-colliding trajectories for multiple robots acting in an environment, under kinodynamic constraints. Due to its complexity, existing algorithms are either incomplete, or utilize simplifying assumptions. This work introduces Kinodynamic Conflict-Based Search (K-CBS), a decentralized MRMP algorithm that is general, scalable, and probabilistically complete. The algorithm takes inspiration from successful solutions to the discrete analogue of MRMP over finite graphs, known as Multi-Agent Path Finding (MAPF). Specifically, we adapt ideas from Conflict-Based Search (CBS)–a popular decentralized MAPF algorithm–to the MRMP setting. The novelty of our approach is that we work directly in the continuous domain, without discretization. In particular, the kinodynamic constraints are treated natively. K-CBS plans for each robot individually using a low-level planner and grows a conflict tree to resolve collisions between robots by defining constraints. The low-level planner can be any sampling-based, tree-search algorithm for kinodynamic robots, thus lifting existing planners for single robots to the multi-robot setting. We show that K-CBS inherits the (probabilistic) completeness of the low-level planner. We illustrate the generality and performance of K-CBS in several case studies and benchmarks.
# Motion Planning by Search in Derivative Space and Convex Optimization with Enlarged Solution Space
## Keywords:
- Motion and Path Planning
- Motion Control
## Abstract:
To efficiently generate safe trajectories for an autonomous vehicle in dynamic environments, a layered motion planning method with decoupled path and speed planning is widely used. This paper studies speed planning, which mainly deals with dynamic obstacle avoidance given a planned path. The main challenges lie in the optimization in a non-convex space and the trade-off between safety, comfort, and efficiency. First, this work proposes to conduct a search in second-order derivative space for generating a comfort-optimal reference trajectory. Second, by combining abstraction and refinement, an algorithm is proposed to construct a convex feasible space for optimization. Finally, a piecewise Bezier polynomial optimization approach with trapezoidal corridors is presented, which theoretically guarantees safety and significantly enlarges the solution space compared with the existing rectangular corridors based approach. We validate the efficiency and effectiveness of the proposed approach in simulations.
# From Low to High Order Motion Planners: Safe Robot Navigation Using Motion Prediction and Reference Governor
## Keywords:
- Motion and Path Planning
- Integrated Planning and Control
- Collision Avoidance
## Abstract:
Safe navigation around obstacles is a fundamental challenge for highly dynamic robots. The state-of-the-art approach for adapting simple reference path planners to complex robot dynamics using trajectory optimization and tracking control is brittle and requires significant replanning cycles. In this letter, we introduce a novel feedback motion planning framework that extends the applicability of low-order	(e.g. position-/velocity-controlled) reference motion planners to high-order (e.g., acceleration-/jerk-controlled) robot models using motion prediction and reference governors. We use predicted robot motion range for safety assessment and establish a bidirectional interface between high-level planning and low-level control via a reference governor. We describe the generic fundamental building blocks of our feedback motion planning framework and give specific example constructions for motion control, prediction, and reference planning. We prove the correctness of our planning framework and demonstrate its performance in numerical simulations. We conclude that accurate motion prediction is crucial for closing the gap between high-level planning and low-level control.
# Hierarchical Planning through Goal-Conditioned Offline Reinforcement Learning
## Keywords:
- Integrated Planning and Learning
- Reinforcement Learning
- Autonomous Agents
## Abstract:
Offline Reinforcement learning (RL) has shown potent in many safe-critical tasks in robotics where exploration is risky and expensive. However, it still struggles to acquire skills in temporally extended tasks. A promising solution to long-horizon tasks is to leverage a hierarchical framework, consisting of a low-level policy to solve short-horizon tasks with supervision from a high-level planner reasoning about long-term strategy. In this paper, we propose such a hierarchical planning framework through goal-conditioned offline reinforcement learning. The low-level policy is trained by offline RL in a goal-conditioned setting. We improve the offline training to deal with OOD goals by a perturbed goal sampling process. The high-level planner selects intermediate sub-goals by taking advantage of model-based planning methods. It plans over future sub-goal sequences based on the learned value function of the low-level policy. We adopt a conditional variational autoencoder (CVAE) to sample meaningful high-dimensional sub-goal candidates and to solve the high-level long-term strategy optimization problem. We evaluate our proposed method in long-horizon and safe-critical driving scenarios. Experiments show that our method outperforms other regular planners without hierarchy in complex driving tasks.
# Learning Minimum Time Flight in Cluttered Environments
## Keywords:
- Integrated Planning and Learning
- Motion and Path Planning
- Reinforcement Learning
## Abstract:
We tackle the problem of minimum-time flight for a quadrotor through a sequence of waypoints in the presence of obstacles while exploiting the full quadrotor dynamics. Early works relied on simplified dynamics or polynomial trajectory representations that did not exploit the full actuator potential of the quadrotor, and, thus, resulted in suboptimal solutions. Recent works can plan minimum-time trajectories; yet, the trajectories are executed with control methods that do not account for obstacles. Thus, a successful execution of such trajectories is prone to errors due to model mismatch and in-flight disturbances. To this end, we leverage deep reinforcement learning and classical topological path planning to train robust neural-network controllers for minimum-time quadrotor flight in cluttered environments. The resulting neural network controller demonstrates substantially better performance of up to 19% over state-of-the-art methods. More importantly, the learned policy solves the planning and control problem simultaneously online to account for disturbances, thus achieving much higher robustness. As such, the presented method achieves 100% success rate of flying minimum-time policies without collision, while traditional planning and control approaches achieve only 40%. The proposed method is validated in both simulation and the real world, with quadrotor speeds of up to 42km/h and accelerations of 3.6g.
# NFOMP: Neural Field for Optimal Motion Planner of Differential Drive Robots with Nonholonomic Constraints
## Keywords:
- Motion and Path Planning
- Nonholonomic Motion Planning
- Wheeled Robots
## Abstract:
Optimal motion planning is one of the most critical problems in mobile robotics. On the one hand, classical sampling-based methods propose asymptotically optimal solutions to this problem. However, these planners cannot achieve smooth and short trajectories in reasonable calculation time. On the other hand, optimization-based methods are able to generate smooth and plain trajectories in a variety of scenarios, including a dense human crowd. However, modern optimization-based methods use the precomputed signed distance function for collision loss estimation, and it limits the application of these methods for general configuration spaces, including a differential drive non-circular robot with non-holonomic constraints. Moreover, optimization-based methods lack the ability to handle U-shaped or thin obstacles accurately. We propose to improve the optimization methods in two aspects. Firstly, we developed an obstacle neural field model to estimate collision loss; training this model together with trajectory optimization allows improving collision loss continuously, while achieving more feasible and smoother trajectories. Secondly, we forced the trajectory to consider non-holonomic constraints by adding Lagrange multipliers to the trajectory loss function. We applied our method for solving the optimal motion planning problem for differential drive robots with non-holonomic constraints, benchmarked our solution, and proved that the novel planner generates smooth, short, and plain trajectories perfectly suitable for a robot to follow, and outperforms the state-of-the-art approaches by 25% on normalized curvature and by 75% on the number of cusps in the MovingAI environment.
# Db-A*: Discontinuity-Bounded Search for Kinodynamic Mobile Robot Motion Planning
## Keywords:
- Motion and Path Planning
- Nonholonomic Motion Planning
- Optimization and Optimal Control
## Abstract:
We consider time-optimal motion planning for dynamical systems that are translation-invariant, a property that holds for many mobile robots, such as differential-drives, cars, airplanes, and multirotors. Our key insight is that we can extend graph-search algorithms to the continuous case when used symbiotically with optimization. For the graph search, we introduce discontinuity-bounded A* (db-A*), a generalization of the A* algorithm that uses concepts and data structures from sampling-based planners. Db-A* reuses short trajectories, so-called motion primitives, as edges and allows a maximum user-specified discontinuity at the vertices. These trajectories are locally repaired with trajectory optimization, which also provides new improved motion primitives. Our novel kinodynamic motion planner, kMP-db-A*, has almost surely asymptotic optimal behavior and computes near-optimal solutions quickly. For our empirical validation, we provide the first benchmark that compares search-, sampling-, and optimization-based time-optimal motion planning on multiple dynamical systems in different settings. Compared to the baselines, kMP-db-A* consistently solves more problem instances, finds lower-cost initial solutions, and converges more quickly.
# Legged Robots 3
# Auto-Tuning of Controller and Online Trajectory Planner for Legged Robots
## Keywords:
- Legged Robots
- Calibration and Identification
- Integrated Planning and Learning
## Abstract:
This letter presents an approach for auto-tuning feedback controllers and online trajectory planners to achieve robust locomotion of a legged robot. The auto-tuning approach uses an Unscented Kalman Filter (UKF) formulation, which adapts/calibrates control parameters online using a recursive implementation. In particular, this letter shows how to use the auto-tuning approach to calibrate cost function weights of a Model Predictive Control (MPC) stance controller and feedback gains of a swing controller for a quadruped robot. Furthermore, this letter extends the auto-tuning approach to calibrating parameters of an online trajectory planner, where the height of a swing leg and the robot’s walking speed are optimized, while minimizing its energy consumption and foot slippage. This allows us to generate stable reference trajectories online and in real time. Results using a high-fidelity Unitree A1 robot simulator in Gazebo provided by the robot manufacturer show the advantages of using auto-tuning for calibrating feedback controllers and for computing reference trajectories online for reduced development time and improved tracking performance.
# An Online Interactive Approach for Crowd Navigation of Quadrupedal Robots
## Keywords:
- Legged Robots
- Motion and Path Planning
- Automation Technologies for Smart Cities
## Abstract:
Robot navigation in human crowds remains the challenge of understanding human behaviors in different scenarios. We present an approach for interactive and human-friendly crowd navigation in complex static environments. The planner models the online interactions among the robot, humans, and the static environment based on game theory. It recurrently expands and optimizes the estimated trajectories for the robot and neighboring agents and provides human-friendly navigation commands. We use various indicators to evaluate the social awareness of the planners and show that our method outperforms existing approaches in success rate to reach the goals and compatibility with humans while maintaining low navigation times. The planner is successfully deployed on a real-world quadrupedal robot, demonstrating safe and interactive crowd navigation with real-time performance.
# Simultaneous Contact-Rich Grasping and Locomotion Via Distributed Optimization Enabling Free-Climbing for Multi-Limbed Robots
## Keywords:
- Legged Robots
- Optimization and Optimal Control
- Grasping
## Abstract:
While motion planning of locomotion for legged robots has shown great success, motion planning for legged robots with dexterous multi-finger grasping is not mature yet. We present an efficient motion planning framework for simultaneously solving locomotion (e.g., centroidal dynamics), grasping (e.g., patch contact), and contact (e.g., gait) problems. To accelerate the planning process, we propose distributed optimization frameworks based on Alternating Direction Methods of Multipliers (ADMM) to solve the original large-scale Mixed-Integer NonLinear Programming (MINLP). The resulting frameworks use Mixed-Integer Quadratic Programming (MIQP) to solve contact and NonLinear Programming (NLP) to solve nonlinear dynamics, which are more computationally tractable and less sensitive to parameters. Also, we explicitly enforce patch contact constraints from limit surfaces with micro-spine grippers. We demonstrate our proposed framework in the hardware experiments, showing that the multi-limbed robot is able to realize various motions including free-climbing at a slope angle 45° with a much shorter planning time.
# Vision-Assisted Localization and Terrain Reconstruction with Quadruped Robots
## Keywords:
- Legged Robots
- Localization
- Mapping
## Abstract:
Legged robots, specifically quadruped robots, have good locomotion performance in complex and rugged terrain and are becoming widely used in field exploration and rescue missions. To achieve full autonomy in such scenarios, robots need not only accurate localization but also an accurate understanding of the surrounding terrain, which will be used for robots path planning and foothold planning. However, due to the kinetic characteristic and limitation of size, quadruped robots have the disadvantages of high-frequency jitter and limited field of sensors, which lead to some challenges in environmental perception. In this paper, we propose a vision-assisted rugged terrain environment reconstruction and localization method for quadruped robots. We use a depth camera to assist in the generation of high-precision localization and terrain reconstruction results, which can help achieve the autonomous mobility of quadruped robots in this environment. We test our method on a quadruped robot platform. Our experimental results show less error and lower drift in different stairs terrain types than the commonly used lidar-based localization method.
# Improved Task Space Locomotion Controller for a Quadruped Robot with Parallel Mechanisms
## Keywords:
- Legged Robots
- Whole-Body Motion Planning and Control
- Parallel Robots
## Abstract:
In this work, an advanced quadruped robot with abundant kinematic loops and passive joints is introduced. Due to the existence of many closed chains, the robot dynamic model is quite complex, and is derived using the Gauss's principle of least constraint. To explicitly consider the loop-closure constraints, we propose a task-space inverse dynamics based approach to obtain the robot locomotion controller. Besides, to meet the demand of high frequency (> 500Hz) in controller, an alternative method is provided. It uses the projected dynamics to find an analytical mapping from the desired contact force to the desired torque of actuators under full consideration of passive joints and loop-closure constraints. The effectiveness and efficiency of the proposed algorithms in this paper have been validated by simulation with a reliable physical engine MuJoCo.
# Feasible Wrench Set Computation for Legged Robots
## Keywords:
- Legged Robots
- Multi-Contact Whole-Body Motion Planning and Control
- Methods and Tools for Robot System Design
## Abstract:
During locomotion, legged robots interact with the ground by sequentially establishing and breaking contact. The interaction wrenches that arise from contact are used to steer the robot’s Center of Mass (CoM) and reject perturbations that make the system deviate from the desired trajectory and often make them fall. The feasibility of a given control target (desired CoM wrench or acceleration) is conditioned by the contact point distribution, ground friction, and actuation limits. In this work, we develop a method to compute the set of feasible wrenches that a legged robot can exert on its CoM through contact. The presented method can be used with any amount of nonco# planar contacts and takes into account actuation limits and limitations based on an inelastic contact model with Coulomb friction. This is exemplified with a planar biped model standing with the feet at different heights. Exploiting assumptions from the contact model, we explain how to compute the set of wrenches that are feasible on the CoM when the contacts remain in position as well as the ones that are feasible when some of the contacts are broken. Therefore, this method can be used to assess whether a switch in contact configuration is feasible while achieving a given control task. Furthermore, the method can be used to identify the directions in which the system is not actuated (i.e. a wrench cannot be exerted in those directions). We show how having a joint be actuated or passive can change the non-actuated wrench directions of a robot at a given pose using a spatial model of a lower-extremity exoskeleton. Therefore, this method is also a useful tool for the design phase of the system. This work presents a useful tool for the control and design of legged systems that extends on the current state of the art.
# Online Kinematic Calibration for Legged Robots
## Keywords:
- Legged Robots
- Calibration and Identification
- Probability and Statistical Methods
## Abstract:
This paper describes an online method to calibrate certain kinematic parameters of legged robots, including leg lengths, that can be difficult to measure offline due to dynamic deformation effects and rolling contacts. A kinematic model of the robot’s legs that depends on these parameters is used, along with measurements from joint encoders, foot contact sensors, and an inertial measurement unit (IMU) to predict the robot’s body velocity. This predicted velocity is then compared to another velocity measurement from, for example, a camera or motion capture system, and the difference between them is used to compute an update on the kinematic parameters. The method can be incorporated into both Kalman filter or sliding-window optimization-based state estimator. We provide a theoretical observability analysis of our method, as well as validation both in simulation and on hardware. Hardware experiments demonstrate that online kinematic calibration can significantly reduce position drift when relying on odometry.
# Collision Detection and Identification for a Legged Manipulator
## Keywords:
- Legged Robots
- Robot Safety
- Physical Human-Robot Interaction
## Abstract:
To safely deploy legged robots in the real world it is necessary to provide them with the ability to reliably detect unexpected contacts and accurately estimate the corresponding contact force. In this paper, we propose a collision detection and identification pipeline for a quadrupedal manipulator. We first introduce an approach to estimate the collision time span based on band-pass filtering and show that this information is key for obtaining accurate collision force estimates. We then improve the accuracy of the identified force magnitude by compensating for model inaccuracies, unmodeled loads, and any other potential source of quasi-static disturbances acting on the robot. We validate our framework with extensive hardware experiments in various scenarios, including trotting and additional unmodeled load on the robot.
# Bio-Inspired Rhythmic Locomotion for Quadruped Robots
## Keywords:
- Legged Robots
- Reinforcement Learning
## Abstract:
The mechanisms of locomotion in mammals have been extensively studied and inspire the related researches on designing the control architectures for the legged robots. Reinforcement learning (RL) is a promising approach allowing robots to automatically learn locomotion policies. However, careful reward-function adjustments are often required via trial-and-error until achieving a desired behavior, as RL policy behaviors are sensitive to the rewards. In this paper, we draw inspiration from the rhythmic locomotion behaviors of animals and propose a new control architecture by incorporating a rhythm generator to naturally stimulate periodic motor patterns, which actively participates in the timing of phase transitions in the robot step cycle. To speed up training, we use the joint position increments rather than the conventional joint positions as the outputs of the RL policy. During deployment, the rhythm generator can be reused for the state estimation of quadruped robots. We validate our method by realizing the full spectrum of quadruped locomotion in both simulated and real-world scenarios.
# Constrained Motion Planning
# Predictive Angular Potential Field-Based Obstacle Avoidance for Dynamic UAV Flights
## Keywords:
- Collision Avoidance
- Aerial Systems: Perception and Autonomy
- Reactive and Sensor-Based Planning
## Abstract:
In recent years, unmanned aerial vehicles (UAVs) are used for numerous inspection and video capture tasks. Manually controlling UAVs in the vicinity of obstacles is challenging, however, and poses a high risk of collisions. Even for autonomous flight, global navigation planning might be too slow to react to newly perceived obstacles. Disturbances such as wind might lead to deviations from the planned trajectories.
In this work, we present a fast predictive obstacle avoidance method that does not depend on higher-level localization or mapping and maintains the dynamic flight capabilities of UAVs. It directly operates on LiDAR range images in real time and adjusts the current flight direction by computing angular potential fields within the range image. The velocity magnitude is subsequently determined based on a trajectory prediction and time-to-contact estimation.
Our method is evaluated using Hardware-in-the-Loop simulations. It keeps the UAV at a safe distance to obstacles, while allowing higher flight velocities than previous reactive obstacle avoidance methods that directly operate on sensor data.
# Avoiding Dynamic Obstacles with Real-Time Motion Planning Using Quadratic Programming for Varied Locomotion Modes
## Keywords:
- Collision Avoidance
- Aerial Systems: Mechanics and Control
- Humanoid and Bipedal Locomotion
## Abstract:
We present a real-time motion planner that avoids multiple moving obstacles without knowing their dynamics or intentions. This method uses convex optimization to generate trajectories for a linear plant model over a planning horizon (i.e. model-predictive control). While convex optimizations allow for fast planning, obstacle avoidance can be challenging to incorporate because Euclidean distance calculations tend to break convexity. By using a half-space convex relaxation, our planner reasons about an approximated distance-to-obstacle measure that is linear in its decision variables and preserves convexity. Further, by iteratively updating the relaxation over the planning horizon, the half-space approximation is improved, enabling nimble avoidance maneuvers. We further augment avoidance performance with a soft penalty slack-variable formulation that introduces a piecewise quadratic cost. As a proof of concept, we demonstrate the planner on double-integrator models in both single-agent and multi-agent tasks # avoiding multiple obstacles and other agents in 2D and 3D environments. We show extensions to legged locomotion by bipedally walking around obstacles using the Linear Inverted Pendulum Model (LIPM). We then present two sets of experiments showing real-time obstacle avoidance with quadrotor drones: (1) avoiding a swinging pendulum and (2) dodging a chasing drone.
# CoMBiNED: Multi-Constrained Model Based Planning for Navigation in Dynamic Environments
## Keywords:
- Human-Aware Motion Planning
## Abstract:
Recent deep reinforcement learning (DRL) approaches have achieved high success rate in map-less dynamic obstacle avoidance tasks. However, navigation in unseen dynamic scenarios without a pre-built map in the presence of dynamic obstacles still remains an open challenge. Since, learning accurate models for complex robotic scenarios such as navigation directly from high dimensional sensory measurements requires a large amount of data and training. Furthermore, even a small change on robot configuration such as kino-dynamics or sensor in the inference time requires re-training of the policy. In this paper, we address these issues in a principled fashion through a multi-constraint model based online planning (CoMBiNED) framework that does not require any retraining or modifications on the existing policy. We disentangle the given task into sub-tasks and learn dynamical models for them. Treating these dynamical models as soft-constraints, we employ stochastic optimisation to jointly optimize these sub-tasks on-the-fly at the inference time. We consider navigation as central application in this work and evaluate our approach on publicly available benchmark with complex dynamic scenarios and achieved significant improvement over recent approaches both in the cases of with-and-without given map of the environment.
# A Saturation-Aware Trajectory-Based Explicit Reference Governor for a Robotic Arm
## Keywords:
- Constrained Motion Planning
- Industrial Robots
- Motion Control
## Abstract:
As with all actuated mechanical systems, the development of a control scheme for robotic systems must take actuator saturation into account. However, in order to properly control a robotic arm, other types of mechanical limitations must also be considered (e.g. limited operating range of the joint, speed limitations). In this paper, we propose a saturation-aware trajectory-based Explicit Reference Governor, a lightweight constrained control scheme with no on-line optimization. Furthermore, we tested the efficiency of the proposed control architecture with an experimental study, in which we implemented our control strategy on a KUKA IIWA14 R820, an industrial robotic arm. Lastly, both the performance and the computational time of our proposed solution were tested against other constrained control solutions available in the literature.
# Time-Optimal Online Replanning for Agile Quadrotor Flight
## Keywords:
- Integrated Planning and Control
- Motion and Path Planning
- Optimization and Optimal Control
## Abstract:
In this paper, we tackle the problem of flying a quadrotor using time-optimal control policies that can be replanned online when the environment changes or when encountering unknown disturbances. This problem is challenging as the time-optimal trajectories that consider the full quadrotor dynamics are computationally expensive to generate (order of minutes or even hours). We introduce a sampling-based method for efficient generation of time-optimal paths of a point-mass model. These paths are then tracked using a Model Predictive Contouring Control approach that considers the full quadrotor dynamics and the single rotor thrust limits. Our combined approach is able to run in real-time, being the first time-optimal method that is able to adapt to changes on-the-fly. We showcase our approach's adaption capabilities by flying a quadrotor at more than 60 km/h in a racing track where gates are moving. Additionally, we show that our online replanning approach can cope with strong disturbances caused by winds of up to 68 km/h.
# Collision Detection for Unions of Convex Bodies with Smooth Boundaries Using Closed-Form Contact Space Parameterization
## Keywords:
- Computational Geometry
- Collision Avoidance
- Motion and Path Planning
## Abstract:
This paper studies the narrow phase collision detection problem for two general unions of convex bodies encapsulated by smooth surfaces. The approach, namely CFC (Closed-Form Contact space), is based on parameterizing their contact space in closed-form. The first body is dilated to form the contact space while the second is shrunk to a point. Then, the collision detection is formulated as finding the closest point on the parametric contact space with the center of the second body. Numerical solutions are proposed based on the point-to-surface distance as well as the common-normal concept. Furthermore, when the two bodies are moving or under linear deformations, their first time of contact is solved continuously along the time-parameterized trajectories. Benchmark studies are conducted for the proposed algorithms in terms of solution stability and computational cost. Applications of the sampling-based motion planning for robot manipulators are demonstrated.
# Trajectory Planning for UAVs Based on Interfered Fluid Dynamical System and Bézier Curves
## Keywords:
- Constrained Motion Planning
- Aerial Systems: Mechanics and Control
- Collision Avoidance
## Abstract:
In this paper, a 3D trajectory planner for Unmanned Aerial Vehicles (UAVs) based on Interfered Fluid Dynamical System (IFDS) and Bézier curves is introduced. The proposed strategy joints the potentialities of IFDS with the use of Bézier curves to obtain optimized trajectories with continuous curvature. While IFDS computes an initial trajectory to safely avoid fixed and dynamic obstacles, Bézier curve optimization generates a trajectory satisfying kinematic constraints. This combination is computationally efficient for online applications with limited hardware and a smoothed path is obtained, for safe and flyable trajectories. Simulations are performed for a fixed-wing UAV in a complex and dynamic environment.
# Time-Optimal Trajectory Planning with Interaction with the Environment
## Keywords:
- Constrained Motion Planning
- Optimization and Optimal Control
- Compliance and Impedance Control
## Abstract:
Optimal motion planning along prescribed paths can be solved with several techniques, but most of them do not take into account the wrenches exerted by the end-effector when in contact with the environment. When a dynamic model of the environment is not available, no consolidated methodology exists to consider the effect of the interaction. Regardless of the specific performance index to optimize, this article proposes a strategy to include external wrenches in the optimal planning algorithm, considering the task specifications. This procedure is instantiated for minimum-time trajectories and validated on a real robot performing an interaction task under admittance control. The results prove that the inclusion of end-effector wrenches affect the planned trajectory, in fact modifying the manipulator's dynamic capability.
# Obstacle Aware Sampling for Path Planning
## Keywords:
- Computational Geometry
- Motion and Path Planning
## Abstract:
Many path planning algorithms are based on sampling the state space. While this approach is very simple, it can become costly when the obstacles are unknown, since samples hitting these obstacles are wasted. The goal of this paper is to efficiently identify obstacles in a map and remove them from the sampling space. To this end, we propose a pre-processing algorithm for space exploration that enables more efficient sampling. We show that it can boost the performance of other space sampling methods and path planners. 
Our approach is based on the fact that a convex obstacle can be approximated provably well by its minimum volume enclosing ellipsoid (MVEE), and a non-convex obstacle may be partitioned into convex shapes. Our main contribution is an algorithm that strategically finds a small sample, called the emph{active-coreset}, that adaptively samples the space via membership-oracle such that the MVEE of the coreset approximates the MVEE of the obstacle.	 Experimental results confirm the effectiveness of our approach across multiple planners based on Rapidly-exploring random trees, showing significant improvement in terms of time and path length.
# Multi-Robot Systems 3
# Distributed Ranging SLAM for Multiple Robots with Ultra-WideBand and Odometry Measurements
## Keywords:
- Multi-Robot Systems
- Range Sensing
- Multi-Robot SLAM
## Abstract:
To accomplish task efficiently in a multiple robots system, a problem that has to be addressed is Simultaneous Localization and Mapping (SLAM). LiDAR (Light Detection and Ranging) has been used for many SLAM solutions due to its superb accuracy, but its performance degrades in featureless environments, like tunnels or long corridors. Centralized SLAM solves the problem with a cloud server, which requires a huge amount of computational resources and lacks robustness against central node failure. To address these issues, we present a distributed SLAM solution to estimate the trajectory of a group of robots using Ultra-WideBand (UWB) ranging and odometry measurements. The proposed approach distributes the processing among the robot team and significantly mitigates the computation concern emerged from the centralized SLAM. Our solution determines the relative pose (also known as loop closure) between two robots by minimizing the UWB ranging measurements taken at different positions when the robots are in close proximity. UWB provides a good distance measure in line-of-sight conditions, but retrieving a precise pose estimation remains a challenge, due to ranging noise and unpredictable path traveled by the robot. To deal with the suspicious loop closures, we use Pairwise Consistency Maximization (PCM) to examine the quality of loop closures and perform outlier rejections. The filtered loop closures are then fused with odometry in a distributed pose graph optimization (DPGO) module to recover the full trajectory of the robot team. Extensive experiments are conducted to validate the effectiveness of the proposed approach.
# MT*: Multi-Robot Path Planning with Temporal Logic Specification
## Keywords:
- Multi-Robot Systems
- Formal Methods in Robotics and Automation
- Motion and Path Planning
## Abstract:
We address the path planning problem for a team of robots satisfying a complex high-level mission specification given in the form of a Linear Temporal Logic (LTL) formula. The state-of-the-art approach to this problem employs the automata-theoretic model checking technique to solve this problem. This approach involves computation of a product graph of the Buchi automaton generated from the LTL specification and a joint transition system that captures the collective motion of the robots and then computation of the shortest path using Dijkstra's shortest path algorithm. We propose MT*, an algorithm that reduces the computation burden for generating such plans for multi-robot systems significantly. Our approach generates a reduced version of the product graph without computing the complete joint transition system, which is computationally expensive. It then divides the complete mission specification among the participating robots and generates the trajectories for the individual robots independently. Our approach demonstrates substantial speedup in terms of computation time over the state-of-the-art approach and scales well with both the number of robots and the size of the workspace.
# Meeting-Merging-Mission: A Multi-Robot Coordinate Framework for Large-Scale Communication-Limited Exploration
## Keywords:
- Multi-Robot Systems
- Path Planning for Multiple Mobile Robots or Agents
- Swarm Robotics
## Abstract:
This letter presents a complete framework Meeting-Merging-Mission for multi-robot exploration under communication restriction. Considering communication is limited in both bandwidth and range in the real world, we propose a lightweight environment presentation method and an efficient cooperative exploration strategy. For lower bandwidth, each robot uses specific polytopes to maintain free space and to generate Super Frontier Information (SFI), which serves as the source for exploration decision-making. To reduce repeated exploration, we develop a mission-based protocol that drives robots to share collected information in stable rendezvous. We also design a complete path planning scheme for both centralized and decentralized cases. To validate that our framework is practical and generic, we present an extensive benchmark and deploy our system into multi-UGV and multi-UAV platforms.
# Communication-Preserving Bids in Market-Based Task Allocation
## Keywords:
- Multi-Robot Systems
- Distributed Robot Systems
## Abstract:
In this paper, we study the effects of impaired communications on the performances of auction-based task allocation in a dynamic surveillance scenario. We propose a novel connectivity term to include in the bid valuation formula, that aims at improving communications in the multi-robot team. We evaluate our method as well as another state-of-the-art method using robot inter-distance to maintain communication, on randomly generated scenarios and on a real-world scenario. We demonstrate that including our connectivity term in the bid valuation formula improves the performances of the auction scheme.
# Toolbox Release: A WiFi-Based Relative Bearing Framework for Robotics
## Keywords:
- Multi-Robot Systems
- Software Tools for Benchmarking and Reproducibility
- Hardware-Software Integration in Robotics
## Abstract:
This paper presents the WiFi-Sensor-for-Robotics (WSR) open-source toolbox. It enables robots in a team to obtain relative bearing to each other, even in non-line-of-sight (NLOS) settings which is a very challenging problem in robotics. It does so by analyzing the phase of their communicated WiFi signals as the robots traverse the environment. This capability, based on the theory developed in our prior works, is made available for the first time as an open-source toolbox. It is motivated by the lack of easily deployable solutions that use robots' local resources (e.g WiFi) for sensing in NLOS. This has implications for multi-robot mapping and rendezvous, ad-hoc robot networks, and security in multi-robot teams, amongst other applications. The toolbox is designed for distributed and online deployment on robot platforms using commodity hardware and on-board sensors. We also release datasets demonstrating its performance in NLOS and line-of-sight (LOS) settings and for a multi-robot localization use case. Empirical results for hardware experiments show that the bearing estimation from our toolbox achieves accuracy with mean and standard deviation of 1.13 degrees, 11.07 degrees in LOS and 6.04 degrees, 26.4 degrees for NLOS, respectively, in an indoor office environment.
# Multi-Robot Dynamic Swarm Disablement
## Keywords:
- Multi-Robot Systems
- Swarm Robotics
- Optimization and Optimal Control
## Abstract:
Motivated by the use of robots for pest control in agriculture, this work introduces the Multi-Robot Dynamic Swarm Disablement problem, in which a team of robots is required to disable a swarm of agents (for example, locust agents) passing through an area, while minimizing the swarm members' accumulated time (equivalent to the accumulated damage they cause) in the area. Showing that the problem is hard even in naive settings, we turn to examine algorithms seeking to optimize the robots' performance against the swarm by exploiting the known movement pattern of the swarm agents. Motivated by the poor performance when a weak group of robots attempts to catch a large swarm of agents, whether it is a significant numerical minority or poor speed gaps, we suggest the use of blocking lines: the robots form lines that block the agents along their movement in the environment. We show by both theoretical analysis and rigorous empirical evaluation in different settings that these algorithms outperform common task-assignment-based algorithms, especially for limited robots versus a large swarm.
# Attention-Based Population-Invariant Deep Reinforcement Learning for Collision-Free Flocking with a Scalable Fixed-Wing UAV Swarm
## Keywords:
- Multi-Robot Systems
- Collision Avoidance
- Reinforcement Learning
## Abstract:
A swarm of fixed-wing unmanned aerial vehicles (UAVs) is expected to efficiently accomplish various tasks in complex scenarios. This paper proposes an attention-based population-invariant multi-agent deep reinforcement learning (MADRL) approach to solve the decentralized collision-free flocking control problem for a scalable fixed-wing UAV swarm. First, this problem is formulated as a decentralized partially observable Markov decision process from the perspective of each follower. Then, an improved multi-agent deep deterministic policy gradient (MADDPG) algorithm is presented to efficiently learn the population-invariant flocking policy. In this algorithm, the parameter sharing with ego-centric representation mechanism is incorporated to improve learning efficiency. Besides, the attention-based population-invariant network structure (APINet) is designed by leveraging the self-attention mechanism. With this structure, the learned flocking policy is invariant to the population of the swarm. Finally, both numerical and hardware-in-the-loop simulation results verify the efficiency and scalability of the proposed approach.
# Multi-UAV Cooperative Short-Range Combat Via Attention-Based Reinforcement Learning Using Individual Reward Shaping
## Keywords:
- Multi-Robot Systems
- Reinforcement Learning
- Distributed Robot Systems
## Abstract:
In this paper, we propose a novel distributed method based on attention-based deep reinforcement learning using individual reward shaping, for multiple unmanned aerial vehicles (UAVs) cooperative short-range combat mission. Specifically, a two-level attention distributed policy, composed of observation-level and communication-level attention networks, is designed to enable each UAV to selectively focus on important environmental features and messages, for enhancing the effectiveness of the cooperative policy. Moreover, due to the high complexity and stochasticity of the UAV combat mission, the learning of UAVs is tricky and low efficient. To embed knowledge to accelerate the policy learning, a potential-based individual reward function is constructed by implicitly translating the individual reward into the specific form of dynamic action potentials. In addition, an actor-critic training algorithm based on the centralized training and decentralized execution framework is adopted to train the policy network of UAV maneuver decision. We build a three-dimensional UAV simulation and training platform based on Unity for multi-UAV short-range combat missions. Simulation results demonstrate the effectiveness of the proposed method and the superiority of the attention policy and individual reward shaping.
# Vision-Based Distributed Multi-UAV Collision Avoidance Via Deep Reinforcement Learning for Navigation
## Keywords:
- Multi-Robot Systems
- Vision-Based Navigation
- Path Planning for Multiple Mobile Robots or Agents
## Abstract:
Online path planning for multiple unmanned aerial vehicle (multi-UAV) systems is considered a challenging task. It needs to ensure collision-free path planning in real-time, especially when the multi-UAV systems can become very crowded on certain occasions. In this paper, we presented a vision-based decentralized collision-avoidance policy learning method for multi-UAV systems. The policy takes depth images and inertial measurements as sensory inputs and outputs UAV's steering commands, and it is trained together with the latent representation of depth images using a policy gradient-based reinforcement learning algorithm and autoencoder in the multi-UAV three-dimensional workspaces. Each UAV follows the same trained policy and acts independently to reach the goal without colliding or communicating with other UAVs. We validate our method in various simulated scenarios. The experimental results show that our learned policy can guarantee fully autonomous collision-free navigation for multi-UAV in three-dimensional workspaces, and its navigation performance will not be greatly affected by the increase in the number of UAVs.
# Path Planning for Multiple Mobile Robots and Agents 3
# Sequence-Of-Constraints MPC: Reactive Timing-Optimal Control of Sequential Manipulation
## Keywords:
- Task and Motion Planning
- Reactive and Sensor-Based Planning
## Abstract:
Task and Motion Planning has made great progress in solving hard sequential manipulation problems. However, a gap between such planning formulations and control methods for reactive execution remains. In this paper we propose a model predictive control approach dedicated to robustly execute a single sequence of constraints, which corresponds to a discrete decision sequence of a TAMP plan. We decompose the overall control problem into three sub-problems (solving for sequential waypoints, their timing, and a short receding horizon path) that each is a non-linear program solved online in each MPC cycle. The resulting control strategy can account for long-term interdependencies of constraints and reactively plan for a timing-optimal transition through all constraints. We additionally propose phase backtracking when running constraints of the current phase cannot be fulfilled, leading to a fluent re-initiation behavior that is robust to perturbations and interferences by an experimenter.
# RHH-LGP: Receding Horizon and Heuristics-Based Logic-Geometric Programming for Task and Motion Planning
## Keywords:
- Task and Motion Planning
- Manipulation Planning
## Abstract:
Sequential decision-making and motion planning for robotic manipulation induce combinatorial complexity. For long-horizon tasks, especially when the environment comprises many objects that can be interacted with, planning efficiency becomes even more important. To plan such long-horizon tasks, we present the RHH-LGP algorithm for combined task and motion planning (TAMP). First, we propose a TAMP approach (based on Logic-Geometric Programming) that effectively uses geometry-based heuristics for solving long-horizon manipulation tasks. The efficiency of this planner is then further improved by a receding horizon formulation, resulting in RHH-LGP. We demonstrate the robustness and effectiveness of our approach on a diverse range of long-horizon tasks that require reasoning about interactions with a large number of objects. Using our framework, we can solve tasks that require multiple robots, including a mobile robot and snake-like walking robots, to form novel heterogeneous kinematic structures autonomously. By combining geometry-based heuristics with iterative planning, our approach brings an order-of-magnitude reduction of planning time in all investigated problems.
# FC3: Feasibility-Based Control Chain Coordination
## Keywords:
- Task and Motion Planning
- Behavior-Based Systems
- AI-Enabled Robotics
## Abstract:
Hierarchical coordination of controllers often uses symbolic state representations that fully abstract their underlying low-level controllers, treating them as "black boxes" to the symbolic action abstraction. This paper proposes a framework to realize robust behavior, which we call Feasibility-based Control Chain Coordination (FC3). Our controllers expose the geometric features and constraints they operate on. Based on this FC3, can reason over the controllers' feasibility and their sequence feasibility. For a given task, FC3 first automatically constructs a library of potential controller chains using a symbolic action tree, which is then used to coordinate controllers in a chain, evaluate task feasibility, as well as switching between controller chains if necessary. In several real-world experiments we demonstrate FC3's robustness and awareness of the task's feasibility through its own actions and gradual responses to different interferences.
# Inspection of Ship Hulls with Multiple UAVs: Exploiting Prior Information for Online Path Planning
## Keywords:
- Path Planning for Multiple Mobile Robots or Agents
- Multi-Robot Systems
## Abstract:
This paper addresses a path planning problem for a fleet of Unmanned Aerial Vehicles (UAVs) that uses both prior information and online gathered data to efficiently inspect large surfaces such as ship hulls and water tanks. UAVs can detect corrosion patches and other defects on the surface from low-resolution images. If defects are detected, they get closer to the surface for a high-resolution inspection. The prior information provides expected defects locations and is affected by both false positives and false negatives. The mission objective is to prioritize the close-up inspection of defected areas while keeping a reasonable time for the coverage of the entire surface. We propose two solutions to this problem: a coverage algorithm that divides the problem into a set of Traveling Salesman Problems (Part-TSP) and a cooperative frontier approach that introduces frontier utilities to incorporate the prior information (Coop-Frontier). We finally provide extensive simulation results to analyze the performance of these approaches and compare them with alternative solutions. These results suggest that both Part-TSP and Coop-Frontier perform better than the baseline solution. Part-TSP has the best performance in most cases. However, coop-Frontier is preferable in extreme cases because more robust to inhomogeneous corrosion distribution and imperfect information.
# Collision-Free Minimum-Time Trajectory Planning for Multiple Vehicles Based on ADMM
## Keywords:
- Path Planning for Multiple Mobile Robots or Agents
- Collision Avoidance
- Optimization and Optimal Control
## Abstract:
The paper presents a practical approach for planning trajectories for multiple vehicles where both collision avoidance and minimum travelling time are simultaneously considered. It is first proposed to exploit the mixed-integer programming (MIP) approach to formulate the collision avoidance paradigm, where the linear dynamic models are utilized to derive the linear constraints. Moreover, travelling time of each vehicle is compromised among them and set to be minimized so that all the vehicles can practically reach the expected destinations at the shortest time. Unfortunately, the formulated optimization problem is NP-hard. In order to effectively address it, we propose to employ the alternating direction method of multipliers (ADMM), which can share the computational burdens to distributive optimization solvers. Thus, the proposed method can enable each vehicle to obtain an expected trajectory in a practical time. Convergence of the proposed algorithm is also discussed. To verify effectiveness of our approach, we implemented it in a numerical example, where the obtained results are highly promising.
# Collaborative Navigation and Manipulation of a Cable-Towed Load by Multiple Quadrupedal Robots
## Keywords:
- Path Planning for Multiple Mobile Robots or Agents
- Multi-Robot Systems
- Legged Robots
## Abstract:
This paper tackles the problem of robots collaboratively towing a load with cables to a specified goal location while avoiding collisions in real time. The introduction of cables (as opposed to rigid links) enables the robotic team to travel through narrow spaces by changing its intrinsic dimensions through slack/taut switches of the cable. However, this is a challenging problem because of the hybrid mode switches and the dynamical coupling among multiple robots and the load. Previous attempts at addressing such a problem were performed offline and do not consider avoiding obstacles online. In this paper, we introduce a cascaded planning schematic with a parallelized centralized trajectory optimization that deals with hybrid mode switches along with a set of decentralized planners, enabling solving the problem online. We develop and demonstrate one of the first collaborative autonomy framework for multiple quadrupedal robots that is able to move a cable-towed load through narrow spaces through real-time feedback and reactive planning in experiments.
# AB-Mapper: Attention and BicNet Based Multi-Agent Path Planning for Dynamic Environment
## Keywords:
- Path Planning for Multiple Mobile Robots or Agents
- Reinforcement Learning
- Networked Robots
## Abstract:
Multi-agent path finding in dynamic environments is of great academic and practical value for multi-robot systems in the real world. To improve the effectiveness and efficiency of the learning process during path planning in dynamic environments, we introduce an algorithm called Attention and BicNet based Multi-agent path planning with effective reinforcement(AB-Mapper) under the actor-critic reinforcement learning framework. In this framework, on one hand, we design an actor-network that can utilize the BicNet with communication function to achieve the intra-team coordination. On the other hand, we propose a critic network that can selectively allocate attention weights to surrounding agents. This attention mechanism allows an individual agent to automatically learn a better evaluation of actions by considering the behaviours of its surrounding agents. Compared with the SOTA method Mapper in crowded environments with dynamic obstacles, our AB-Mapper is more effective (90.27±0.06% vs. 61.65±13.90% in terms of mean success rate) in solving the general multi-agent path finding problem.
# Graph Embedding for Multi-Robot Path Planning in Complex Environments
## Keywords:
- Path Planning for Multiple Mobile Robots or Agents
- Computational Geometry
## Abstract:
We propose a graph-embedding approach to approximate continuous multi-agent path planning (MPP) problems as discrete ones, allowing known discrete planning techniques be exploited in realistic, complex continuous environments. We first design a special pebble graph with a set of conditions, under which MPP problems have the feasibility guarantee. We then develop a mesh optimization algorithm to embed our pebble graph into arbitrarily complex environments. We show that our feasibility conditions	can be converted into differentiable geometric constraints, such that our mesh optimizer can find feasible solutions via constrained numerical optimization. Two algorithms can be used to solve MPP problems on our pebble graphs. Conflict-Based Searches (CBS) are preferred for finding (near) optimal solutions. We further introduce a space-time parallel scheduling approach to find sub-optimal solutions for large swarms of congested robots. We have evaluated the effectiveness of our approach on a set of environments with complex geometries, where our method achieves an average of 99.0% free-space coverage and 30.3% robot density, ensuring a large solution space of discrete MPP algorithms executed on the graphs.
# Artificial Learning for Part Identification in Robotic Disassembly through Automatic Rule Generation in an Ontology (I)
## Keywords:
- Disassembly
- Sustainable Production and Service Automation
- Robotics in Hazardous Fields
## Abstract:
With the increasing concern for sustainable treatment of waste electrical and electronic equipment (WEEE), methods of robotic disassembly of WEEE to address various challenges of handling end-of-life products has been a trend in research. The main challenge for robotic disassembly is the uncertainties of product structures, models, and conditions. The ability of a robotic disassembly system to learn new product structures and reason about existing knowledge of product structure is vital to addressing this challenge. This paper presents an effective learning framework and demonstrates the system’s ability to learn relevant information for the disassembly of LCD monitors. The learning algorithm uses a database of previous disassembly experience of the product family and analyses it to create rules and relations between the components and disassembly concepts before expanding the generic ontology for future disassembly runs. The results show a significant increase from 11% to 87% in successful part identification of LCD monitors after being trained on past disassembly experience. The proposed method can greatly aid robotic disassembly of any product family.
